    1  make -j32
    2   cd ~/pwd/saliency_on_videoset/_Train/
    3  git clone https://github.com/ndrplz/dilation-tensorflow.git
    4  cd dilation-tensorflow/
    5  python main_tf.py 
    6  python
    7  pytho
    8  python
    9  vim ~/.bashrc
   10  source ~/.bashrc
   11  python
   12  pwd
   13  cd /home/sunnycia/pwd/saliency_on_videoset/_Train/Deep-Feature-Flow-master
   14  ls model/
   15  python ./rfcn/demo.py
   16  pip install easydict
   17  python ./rfcn/demo.py
   18  pip install mxnet
   19  ls
   20  python
   21  cd /home/sunnycia/pwd/saliency_on_videoset/_Train/dilation-tensorflow
   22  python
   23  python main_tf.py 
   24  vim ~/.bashrc
   25  source ~/.bashrc
   26  python
   27  pwd
   28  top
   29  cd 
   30  cd pwd/saliency_on_videoset/_Train/dilation-tensorflow/
   31  python
   32  python main_tf.py 
   33  exit()
   34  pip uninstall tensorflow
   35  pip uninstall tensorflow-gpu
   36  cd ~
   37  git clone https://github.com/tensorflow/tensorflow 
   38  unzip tensorflow-master.zip 
   39  cd tensorflow-master/
   40  git checkout
   41  python
   42  cd ~
   43  python
   44  pip install tensorflow
   45  cd pwd/saliency_on_videoset/_Train/dilation-tensorflow/
   46  python main_tf.py 
   47  python
   48  pip install opencv-python
   49  python main_tf.py 
   50  pip uninstall tensorflow
   51  git clone https://github.com/bazelbuild/bazel.git
   52  cd ~
   53  git clone https://github.com/bazelbuild/bazel.git
   54  python
   55  pip install --ignore-installed --upgrade https://storage.googleapis.com/tensorflow/linux/gpu/tensorflow_gpu-1.3.0-cp34-cp34m-linux_x86_64.whl
   56  pip install --ignore-installed https://storage.googleapis.com/tensorflow/linux/gpu/tensorflow_gpu-1.3.0-cp36-cp36m-linux_x86_64.whl
   57  python
   58  locate libcudnn*
   59  ls /usr/local
   60  cd cuda
   61  cd /usr/local/cuda
   62  ls
   63  cd lib
   64  cd lib64/
   65  ls
   66  ls lib cudnn*
   67  ls libcudnn*
   68  ls -l libcudnn*
   69  nvidia-smi
   70  top
   71  cd pwd/saliency_on_videoset/_Train/
   72  ls
   73  git clone https://github.com/sampepose/flownet2-tf.git
   74  ls
   75  ls flow*
   76  unzip flownet2-tf.zip 
   77  cd flownet2-tf/
   78  pip install enum
   79  python
   80  cd checkpoints/
   81  bash download.sh 
   82  vim download.sh 
   83  bash download.sh 
   84  ls
   85  tar -xzvf weights.tar.gz 
   86  cd ..
   87  ls src
   88  python -m src.flownet2.test --input_a data/samples/0img0.ppm --input_b data/samples/0img1.ppm --out ./
   89  python
   90  vim ~/.bahsrc
   91  vim ~/.bashrc
   92  source ~/.bashrc
   93  python -m src.flownet2.test --input_a data/samples/0img0.ppm --input_b data/samples/0img1.ppm --out ./
   94  cd pwd/saliency_on_videoset/_Train/
   95  cd flownet2-tf/
   96  python -m src.flownet2.test --input_a data/samples/0img0.ppm --input_b data/samples/0img1.ppm --out ./
   97  python
   98  vim ~/.bahsrc
   99  vim ~/.bashrc
  100  source ~/.bashrc
  101  python
  102  cd pwd/saliency_on_videoset/_Train/flownet2-tf/
  103  python -m src.flownet2.test --input_a data/samples/0img0.ppm --input_b data/samples/0img1.ppm --out ./
  104  pip install image
  105  python -m src.flownet2.test --input_a data/samples/0img0.ppm --input_b data/samples/0img1.ppm --out ./
  106  make all
  107  nvcc
  108  ls /usr/lib/nvi*
  109  ls /usr/lib
  110  ls nvidia-current
  111  nvcc
  112  vim ~/.bash_profile 
  113  vim ~/.bashrc
  114  source ~/.bashrc
  115  nvcc
  116  cd pwd/saliency_on_videoset/_Train/flownet2-tf/
  117  python -m src.flownet2.test --input_a data/samples/0img0.ppm --input_b data/samples/0img1.ppm --out ./
  118  make clean
  119  make all
  120  make clean
  121  make -j16 all
  122  python -m src.flownet2.test --input_a data/samples/0img0.ppm --input_b data/samples/0img1.ppm --out ./
  123  python -m src.flownet2.test --input_a data/samples/frame88.bmp --input_b data/samples/frame90.bmp --out ./
  124  python -m src.flownet2.test --input_a data/samples/0img0.ppm --input_b data/samples/0img1.ppm --out ./
  125  export CUDA_VISIBLE_DEVICES=6
  126  python -m src.flownet2.test --input_a data/samples/0img0.ppm --input_b data/samples/0img1.ppm --out ./
  127  python -m src.flownet2.test --input_a data/samples/frame88.bmp --input_b data/samples/frame90.bmp --out ./
  128  cd ..
  129  git clone https://github.com/shekkizh/FCN.tensorflow.git
  130  unzip FCN.tensorflow.zip 
  131  cd FCN.tensorflow/
  132  ls
  133  python FCN.py 
  134  cd Data_zoo/MIT_SceneParsing/
  135  unzip ADEChallengeData2016.zip 
  136  cd ../..
  137  python FCN.py 
  138  df -h
  139  cd /
  140  cd /data/
  141  ls
  142  cd sunnycia/
  143  ls
  144  cd YouTube8m/
  145  ls
  146  cd ..
  147  rm -rf YouTube8m/
  148  df -h
  149  pwd
  150  cd ~/pwd/
  151  du -h --max-depth=1 ./
  152  mv saliency_on_videoset/ /data/sunnycia/
  153  df -h
  154  ln -s /data/sunnycia/saliency_on_videoset/ saliency_on_videoset
  155  cd saliency_on_videoset/
  156  pwd
  157  cd pwd/saliency_on_videoset/
  158  ls
  159  cd _Train/
  160  cd FCN.tensorflow/
  161  python FCN.py 
  162  df -h
  163  ls /data
  164  ls /data/zhangpp/
  165  python FCN.py 
  166  cd pwd/saliency_on_videoset/
  167  pwd
  168  cd _Train/FCN.tensorflow/
  169  python FCN.py 
  170  top
  171  nvidia-smi 
  172  export CUDA_VISIBLE_DEVICES=6
  173  python FCN.py 
  174  cd pwd/saliency_on_videoset/_Train/
  175  cd FCN.tensorflow/
  176  python FCN --mode=test
  177  python FCN.py --mode=test
  178  bash ~/setup.sh 
  179  vim ~/setup.sh 
  180  bash ~/setup.sh 
  181  nvidia-smi
  182  top
  183  python FCN.py --mode=test
  184  python FCN.py --mode=visualize
  185  python FCN_inference.py 
  186  export CUDA_VISIBLE_DEVICES=6
  187  nvidia-smi
  188  python FCN_inference.py 
  189  xtermxtermxterm
  190  python FCN_inference.py 
  191  top
  192  nvidia-smi
  193  top
  194  free -h
  195  nvidia-smi
  196  ls
  197  cd pwd/
  198  ln -s /data/sunnycia/pwd/Industry/ Industry
  199  cd Industry/
  200  unzip A61.zip 
  201  cd ~/pwd/saliency_on_videoset/_Train/
  202  ls
  203  cd YT8M/
  204  ls
  205  cd yt8m-feature-extractor/
  206  ls
  207  pwd
  208  th
  209  luarock
  210  cd pwd/saliency_on_videoset/_Train/YT8M/
  211  l
  212  ls
  213  cd yt8m-feature-extractor/
  214  pwd
  215  cd /data/sunnycia/pwd/Industry/A61深度学习/黄保胶
  216  python parse_model.py 
  217  PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION=python
  218  python parse_model.py 
  219  unzip tensorflow-vgg-master.zip 
  220  cd tensorflow-vgg-master/
  221  ls
  222  cd ..
  223  ls
  224  cd data/
  225  ls
  226  python gen_list.py 
  227  python gen_dat.py 
  228  cd training/OK/
  229  ls 
  230  python
  231  cd ..
  232  python gen_dat.py 
  233  python
  234  python gen_dat.py 
  235  python gen_lbl.py 
  236  ls
  237  cd ..
  238  python calc_mean.py 
  239  cd data/
  240  cd _scripts/
  241  python gen_dat.py 
  242  python gen_dat.py training
  243  python gen_dat.py train_imgs.pkl train_lbls.pkl test_imgs.pkl test_lbls.pkl
  244  cd ..
  245  python train_vgg19.py 
  246  cd data/_scripts/
  247  python gen_dat.py 
  248  history
  249  python gen_dat.py train_imgs.pkl train_lbls.pkl test_imgs.pkl test_lbls.pkl
  250  cd ../..
  251  python train_vgg19.py 
  252  python gen_dat.py train_imgs.pkl train_lbls.pkl test_imgs.pkl test_lbls.pkl
  253  cd data/_scripts/
  254  python gen_dat.py train_imgs.pkl train_lbls.pkl test_imgs.pkl test_lbls.pkl
  255  cd pwd/Industry/
  256  ls
  257  cd A61/
  258  l
  259  ls
  260  cd data/
  261  python gen_dat.py 
  262  top
  263  nvidia-smi
  264  free -h
  265  top
  266  nvidi-smi
  267  nviid-amsi
  268  nvidia-smi
  269  top
  270  free -h
  271  top
  272  free -h
  273  cd pwd/Industry/A61/data/_scripts/
  274  python gen_dat.py 
  275  history
  276  python gen_dat.py train_imgs.pkl train_lbls.pkl test_imgs.pkl test_lbls.pkl
  277  cd ../..
  278  python train_vgg19.py 
  279  cd pwd/Industry/A61/
  280  python train_vgg19.py 
  281  nvidia-smi
  282  export CUDA_VISIBLE_DEVICES=7
  283  python train_vgg19.py 
  284  cd data/_scripts/
  285  python gen_dat.py train_imgs.pkl train_lbls.pkl test_imgs.pkl test_lbls.pkl
  286  top
  287  nvidia-smi
  288  free -h
  289  cd pwd/Industry/A61/
  290  cd data/_scripts/
  291  python gen_dat.py train_imgs.pkl train_lbls.pkl test_imgs.pkl test_lbls.pkl
  292  python gen_dat.py 
  293  python gen_dat.py train_imgs.pkl train_lbls.pkl test_imgs.pkl test_lbls.pkl
  294  cd ../..
  295  python train_vgg19.py 
  296  nvidia-smi
  297  python train_vgg19.py 
  298  export CUDA_VISIBLE_DEVICES=7
  299  python train_vgg19.py 
  300  python
  301  python train_vgg19.py 
  302  cd data/_scripts/
  303  python gen_dat.py 
  304  python gen_dat.py train_imgs.pkl train_lbls.pkl test_imgs.pkl test_lbls.pkl
  305  cd ../..
  306  python train_vgg19.py 
  307  cd data/_scripts/
  308  python gen_dat.py 
  309  python gen_dat.py train_imgs.pkl train_lbls.pkl test_imgs.pkl test_lbls.pkl
  310  cd ../..
  311  python train_vgg19.py 
  312  cd data/_scripts/
  313  python gen_dat.py train_imgs.pkl train_lbls.pkl test_imgs.pkl test_lbls.pkl
  314  cd ../..
  315  python train_vgg19.py 
  316  nvidia-smi
  317  python train_vgg19.py 
  318  nvidia-smi
  319  export CUDA_VISIBLE_DEVICES=1
  320  cd pwd/Industry/A61/
  321  python train_vgg19.py 
  322  nvidia-smi
  323  history
  324  export CUDA_VISIBLE_DEVICES=0
  325  cd pwd/Industry/A61/
  326  python train_vgg19.py 
  327  top
  328  nvidia-smi
  329  otp
  330  top
  331  export CUDA_VISIBLE_DEVICES=7
  332  python train_vgg19.py 
  333  cd pwd/Industry/A61/patch_based/
  334  export CUDA_VISIBLE_DEVICES=6
  335  python train_vgg19.py 
  336  cd pwd/Industry/A61/patch_based/
  337  python train_vgg19.py 
  338  nvidia-smi
  339  export CUDA_VISIBLE_DEVICES=7
  340  python train_vgg19.py 
  341  cd /data/sunnycia/pwd/Industry/A61/data/_scripts
  342  python gen_list.py 
  343  python gen_dat.py 
  344  python gen_dat.py training_imgs.pkl training_lbls.pkl _ _
  345  python gen_dat.py 
  346  python gen_dat.py training_imgs.pkl training_lbls.pkl
  347  python gen_dat.py training_imgs.pkl training_lbls.pkl _ _
  348  nvidia-smi
  349  cd pwd/Industry/A61/patch_based/
  350  ls
  351  export CUDA_VISIBLE_DEVICES=6
  352  ls
  353  python 4_convolutional_network.py 
  354  python
  355  python 4_convolutional_network.py 
  356  export CUDA_VISIBLE_DEVICES=7
  357  cd pwd/Industry/A61/patch_based/
  358  python 4_convolutional_network.py 
  359  nvidia-smi
  360  top
  361  nvidia-smi
  362  cd pwd/Industry/A61/data/
  363  cd _scripts/
  364  python gen_dat.py 
  365  python gen_dat.py training_imgs.pkl training_lbls.pkl _ _
  366  export CUDA_VISIBLE_DEVICES=7
  367  python 
  368  cp -R /usr/local/caffe-master/examples/ ~/pwd/
  369  cd pdw
  370  cd ~/pwd/
  371  ls
  372  mv -R caffe_examples/ /data/sunnycia/pwd/
  373  mv caffe_examples/ /data/sunnycia/pwd/
  374  ln -s /data/sunnycia/pwd/caffe_examples/ caffe_examples
  375  df -h
  376  cd caffe_examples/
  377  ls
  378  cd mnist/
  379  caffe
  380  vim ~/.bashrc
  381  source ~/.bashrc
  382  top
  383  nvidia-smi
  384  caffe
  385  locate VGG_ILSVRC_16_layers.caffemodel
  386  rsync -avz 172.31.234.250:/home/qiudan/caffe/models/bvlc_vgg/VGG_ILSVRC_16_layers.caffemodel /home/sunnycia/pwd/Industry/A61
  387  caffe
  388  cd /data/sunnycia/pwd/Industry/A61/caffe/finetune_VGG16
  389  cp VGG_ILSVRC_16_layers_deploy.prototxt deploy.prototxt
  390  cd ..
  391  vim spot.py
  392  python spot.py 
  393  python
  394  vim ~/.bashrc
  395  source ~/.bashrc
  396  top
  397  nvidia-smi
  398  export CUDA_VISIBLE_DEVICES=6
  399  cd pwd/Industry/A61/
  400  cd patch_based/
  401  python 4_convolutional_network.py 
  402  top
  403  nvidia-smi
  404  python spot.py 
  405  vim ~/.bashrc
  406  vim spot.py
  407  python spot.py
  408  nvidia-smi
  409  top
  410  cd /data/root/
  411  ls
  412  cd MATLAB_2017a/
  413  ls
  414  ./install
  415  cd ..
  416  top
  417  nvidia-smi
  418  ls
  419  cd ~/pwd/mat
  420  cd /data/sunnycia/pwd/matconvnet_examples/
  421  ls
  422  matlab -nodesktop
  423  export CUDA_VISIBLE_DEVICES=6
  424  matlab -nodesktop
  425  pwd
  426  cd ..
  427  ls
  428  cd matconvnet-master/
  429  ls
  430  matlab -nodeskto
  431  matlab -nodesktop
  432  top
  433  nvidia-smi
  434  top
  435  ls
  436  matlab -nodesktop
  437  cd pwd/Industry/A61/
  438  mkdir matlab
  439  cd matlab
  440  ls
  441  git clone https://github.com/vlfeat/matconvnet.git
  442  cd matconvnet/
  443  matlab -nodesktop
  444  clear
  445  cd /data/sunnycia/saliency_on_videoset/_Train/Deep-Feature-Flow-master
  446  cd ~
  447  l
  448  ls
  449  cd mxnet/
  450  make -j8
  451  locate cblas_*
  452  make clean
  453  make -j8
  454  make clean
  455  make -j16
  456  ls /root
  457  yum install atlas
  458  cd mxnet/
  459  make -j4
  460  make clean
  461  make -j32
  462  make clean
  463  make -j32
  464  -lcblas
  465  cd mxnet/
  466  make clean
  467  make -j32
  468  cd ~/pwd/saliency_on_videoset/_Train/
  469  ls
  470  git clone https://github.com/lmb-freiburg/flownet2.git
  471  cd flownet2
  472  ls
  473  cp Makefile.config.example Makefile.config
  474  python
  475  conda install nomkl numpy scipy scikit-learn numexpr
  476  python
  477  exit()
  478  vim ~/.bashrc
  479  source ~/.bashrc
  480  python
  481  cd pwd/saliency_on_videoset/_Train/flownet2
  482  ls
  483  make -j5 all tools pycaffe
  484  cd models/
  485  tar -xf flownet2-models.tar.gz 
  486  tar -xf flownet2-models-sintel.tar.gz
  487  tar -xf flownet2-models-kitti.tar.gz
  488  vim ~/.bashrc
  489  source ~/.bashrc
  490  cd pwd/saliency_on_videoset/_Train/flownet2
  491  run-flownet.py /path/to/$net/$net_weights.caffemodel[.h5]                  /path/to/$net/$net_deploy.prototxt.template \ 
  492  cd scripts/
  493  ls
  494  run-flownet.py
  495  cd ..
  496  source set-env.sh 
  497  PATH
  498  $PATH
  499  run-flownet.py models/FlowNet2/FlowNet2_weights.caffemodel.h5 models/FlowNet2/FlowNet2_deploy.prototxt.template x.png y.png z.flo
  500  python run-flownet.py models/FlowNet2/FlowNet2_weights.caffemodel.h5 models/FlowNet2/FlowNet2_deploy.prototxt.template x.png y.png z.flo
  501  cd scripts/
  502  python run-flownet.py models/FlowNet2/FlowNet2_weights.caffemodel.h5 models/FlowNet2/FlowNet2_deploy.prototxt.template x.png y.png z.flo
  503  python run-flownet.py ../models/FlowNet2/FlowNet2_weights.caffemodel.h5 ../models/FlowNet2/FlowNet2_deploy.prototxt.template x.png y.png z.flo
  504  python run-flownet.py ../models/FlowNet2/FlowNet2_weights.caffemodel.h5 ../models/FlowNet2/FlowNet2_deploy.prototxt.template frame4.bmp frame6.bmp output.flo
  505  nvidia-smi
  506  export CUDA_VISIBLE_DEVICES=6
  507  python run-flownet.py ../models/FlowNet2/FlowNet2_weights.caffemodel.h5 ../models/FlowNet2/FlowNet2_deploy.prototxt.template frame4.bmp frame6.bmp output.flo
  508  nvidia-smi
  509  export CUDA_VISIBLE_DEVICES=6,7
  510  python run-flownet.py ../models/FlowNet2/FlowNet2_weights.caffemodel.h5 ../models/FlowNet2/FlowNet2_deploy.prototxt.template frame4.bmp frame6.bmp output.flo
  511  cd /data/sunnycia/pwd/Industry/A61/tensorflow/vgg_stuff
  512  nvidia-smi
  513  export CUDA_VISIBLE_DEVICES=6
  514  python train_vgg19.py 
  515  nvidia-smi
  516  export CUDA_VISIBLE_DEVICES=7
  517  cd /data/sunnycia/pwd/Industry/A61/tensorflow/patch_based
  518  python 4_convolutional_network.py 
  519  python train_vgg19.py 
  520  nvidia-smi
  521  cd mxnet/
  522  make -j16
  523  cd ..
  524  mkdir mxtest
  525  cd mxtest/
  526  git clone https://github.com/msracver/Deep-Feature-Flow.git
  527  git clone --recursive https://github.com/dmlc/mxnet.git
  528  unzip mxnet.zip 
  529  cd mxnet/
  530  git checkout 62ecb60
  531  make -j16
  532  cd /data/sunnycia/
  533  ls
  534  mkdir ILSVRC2015
  535  cd ILSVRC2015/
  536  mkdir VID && cd VID
  537  wget http://bvisionweb1.cs.unc.edu/ilsvrc2015/ILSVRC2015_VID.tar.gz
  538  ls
  539  rm ILSVRC2015_VID.tar.gz 
  540  wget http://bvisionweb1.cs.unc.edu/ilsvrc2015/ILSVRC2015_VID.tar.gz
  541  x25% frame6.bmp frame7.bmp
  542  ls
  543  ls -l
  544  python run-flownet.py ../models/FlowNet2/FlowNet2_weights.caffemodel.h5 ../models/FlowNet2/FlowNet2_deploy.prototxt.template frame5.bmp frame7.bmp output.flo
  545  convert -sample 25%x25% frame6.bmp frame7.jpg
  546  convert -sample 25%x25% frame4.bmp frame5.jpg
  547  python run-flownet.py ../models/FlowNet2/FlowNet2_weights.caffemodel.h5 ../models/FlowNet2/FlowNet2_deploy.prototxt.template frame5.jpg frame7.jpg output.flo
  548  python
  549  caffe --version
  550  python
  551  pwd
  552  cd ../../Deep-Feature-Flow-master/
  553  python rfcn/demo.py 
  554  du -h max-depth=3 /data/sunnycia
  555  du -h max-depth=1 /data/sunnycia
  556  du -h max_depth=1 /data/sunnycia
  557  du -h --max-depth=1 /data/sunnycia
  558  du -h --max-depth=1 /data/sunnycia/pwd
  559  du -h --max-depth=1 /data/sunnycia/pwd/saliency_on_videoset/
  560  du -h --max-depth=1 /data/sunnycia/pwd/saliency_on_videoset/_Saliencymap/
  561  du -h --max-depth=1 /data/sunnycia/ImageSet
  562  du -h --max-depth=1 /data
  563  du -h --max-depth=1 /data/zhangpp
  564  cd /data/sunnycia/saliency_on_videoset/_Train/sam-master
  565  python main.py test figs
  566  python
  567  vim ~/.bashrc
  568  source ~/.bashrc
  569  python
  570  pip install keras==1.1.0
  571  python main.py test figs
  572  vim ~/.keras/keras.json 
  573  locate keras.json
  574  vim ~/.keras/keras.json 
  575  python main.py test figs
  576  vim ~/.keras/keras.json 
  577  python main.py test figs
  578  vim ~/.keras/keras.json 
  579  python main.py test figs
  580  cd ..
  581  git clone https://github.com/marcellacornia/sam.git
  582  unzip sam-master
  583  cd sam-master
  584  python main.py test sample_images
  585  top
  586  ssh qiudan@172.31.234.248
  587  cd pwd/saliency_on_videoset/_Train/
  588  ls
  589  cd sam-master/
  590  ls
  591  vim main.py 
  592  python main.py test sample_images/
  593  vim main.py 
  594  pwd
  595  cd /data/sunnycia/SaliencyDataset/Image/SALICON/Tools/salicon-api/PythonAPI
  596  python saliconDemo.py 
  597  conda install nomkl numpy scipy scikit-learn numexpr
  598  vim ~/.bashrc
  599  source ~/.bashrc
  600  python
  601  cd /data/sunnycia/
  602  ls
  603  cd ImageSet
  604  ls
  605  pwd
  606  cd ..
  607  ls
  608  clean
  609  cd ILSVRC2015/
  610  ls
  611  cd VID/
  612  ls
  613  cd ..
  614  wget --help
  615  wget -c 
  616  cd VID/
  617  ls
  618  tail -f wget-log
  619  wget -c http://bvisionweb1.cs.unc.edu/ilsvrc2015/ILSVRC2015_VID.tar.gz
  620  top
  621  nvidia-smi
  622  top
  623  tar -tf ILSVRC2015_VID.tar.gz 
  624  vim ILSVRC2015_VID.tar.gz 
  625  tar -vf ILSVRC2015_VID.tar.gz 
  626  tar -xf ILSVRC2015_VID.tar.gz 
  627  cd pwd/saliency_on_videoset/_Train/
  628  ls
  629  cd sam-master/
  630  ls
  631  cd /data/sunnycia/SaliencyDataset/Image/SALICON/Tools/salicon-api/PythonAPI
  632  python
  633  python saliconDemo.py 
  634  cd /data/sunnycia/SaliencyDataset/Image/SALICON/Images
  635  unzip image.zip 
  636  cd ..
  637  ls
  638  cd salicon-api/
  639  ls
  640  cd PythonAPI/
  641  python saliconDemo.py
  642  cd PythonAPI/
  643  python saliconDemo.py
  644  python gen_saliconset.py 
  645  python
  646  whereis python
  647  ls -l /usr/bin/python*
  648  ls
  649  python saliconDemo.
  650  python saliconDemo.py
  651  python gen_saliconset.py 
  652  python saliconDemo.
  653  python saliconDemo.py
  654  python gen_saliconset.py 
  655  ls
  656  cd ..
  657  ls
  658  cd ..
  659  ls
  660  cd ..
  661  cd DATA/
  662  ls
  663  df -h
  664  python assign_images.py 
  665  rsync -avz 172.31.234.248:/home/qiudan/sunnycia/sam-master-from-dd ./
  666  cd sam-master-from-dd/
  667  python main.py test sample_images/
  668  vim ~/.bashrc
  669  vim ~/.keras/keras.json 
  670  python main.py test sample_images/
  671  cd ..
  672  rm -rf sam-master-from-dd/
  673  cd pwd/saliency_on_videoset/_Train/
  674  ls
  675  cd Deep-Feature-Flow-master/
  676  ls
  677  cd experiments/
  678  ls
  679  cd rfcn/
  680  ls
  681  cd /data/sunnycia/saliency_on_videoset/_Train/Deep-Feature-Flow-master/model/fortrain
  682  unzip pretrained_model.zip 
  683  clear
  684  cd pwd/saliency_on_videoset/_Train/Deep-Feature-Flow-master/
  685  ls
  686  nvidia-smi
  687  python experiments/dff_rfcn/dff_rfcn_end2end_train_test.py --cfg experiments/dff_rfcn/cfgs/resnet_v1_101_flownet_imagenet_vid_rfcn_end2end_ohem.yaml
  688  export CUDA_VISIBLE_DEVICES=6,7
  689  nvidia-smi
  690  clear
  691  python experiments/dff_rfcn/dff_rfcn_end2end_train_test.py --cfg experiments/dff_rfcn/cfgs/resnet_v1_101_flownet_imagenet_vid_rfcn_end2end_ohem.yaml
  692  cd /data/sunnycia/saliency_on_videoset/_Train/Deep-Feature-Flow-master
  693  export CUDA_VISIBLE_DEVICES=4,5,6,7
  694  python experiments/dff_rfcn/dff_rfcn_end2end_train_test.py --cfg experiments/dff_rfcn/cfgs/resnet_v1_101_flownet_imagenet_vid_rfcn_end2end_ohem.yaml
  695  cd pwd/saliency_on_videoset/Train/
  696  cd gen_dataset/
  697  python gen_dataset.py 
  698  top
  699  free -h
  700  python
  701  top
  702  free -h
  703  history
  704  clear
  705  ls /data/sunnycia/
  706  ls /data/sunnycia/ImageSet
  707  ls /data/sunnycia/ImageSet/frame/
  708  cd /data/sunnycia/ImageSet/frame/
  709  cd videoSRC001
  710  ls
  711  cd ..
  712  pwd
  713  cd ~/pwd/saliency_on_videoset/Train/
  714  ls
  715  cd gen_dataset/
  716  python gen_dataset.py 
  717  top
  718  nvidia-smi
  719  python gen_dataset.py 
  720  cd ..
  721  ls
  722  python training.py 
  723  nvidia-smi
  724  export CUDA_VISIBLE_DEVICES=6
  725  python training.py 
  726  python
  727  cd /data/sunnycia/ILSVRC2015/ImageSets
  728  clear
  729  cd DET/
  730  rename
  731  for f in *;do mv "$f" "DET_$f";done
  732  cd ../VID/
  733  ls
  734  for f in *;do mv "$f" "VID_$f";done
  735  pwd
  736  cd ..
  737  pwd
  738  ls
  739  nvidia-smi
  740  top
  741  nvidia-smi
  742  top
  743  nvidia-smi
  744  top
  745  nvidia-smi
  746  top
  747  nvidia-smi
  748  nvidi-amsi
  749  nvidia-smi
  750  top
  751  nvidia-smi
  752  top
  753  nvidia-smi
  754  top
  755  pwd
  756  cd ~/caffe-master/
  757  ls
  758  make matcaffe
  759  make -j16 matcaffe
  760  vim Makefile.config
  761  top
  762  vim Makefile.config
  763  cd /usr/local/MATLAB/
  764  ls
  765  nvidia-smi
  766  top
  767  nvidia-smi
  768  vim ~/.bashrc
  769  df -h
  770  top
  771  free -h
  772  cd /data/sunnycia/saliency_on_videoset/Train
  773  python training.py 
  774    name: "bn4f_branch2c"
  775  CFLAGS="-O0" pip install greenlet==0.4.0
  776  python training.py 
  777  cd pwd/saliency_on_videoset/_Train/
  778  ls
  779  cd Deep-Feature-Flow-master/
  780  ls
  781  python experiments/dff_rfcn/dff_rfcn_end2end_train_test.py --cfg experiments/dff_rfcn/cfgs/resnet_v1_101_flownet_imagenet_vid_rfcn_end2end_ohem.yaml
  782  cd /data/sunnycia/saliency_on_videoset/Train
  783  python training.py 
  784  nvidia-smi
  785  python training.py 
  786  nvidia-smi
  787  en_dataset.py 
  788  free -h
  789  python gen_dataset.py 
  790  cd /data/sunnycia/saliency_on_videoset/Train/dataset
  791  python
  792  cd ..
  793  python training.py
  794  ls
  795  top
  796  nviida-smi
  797  nvidia-smi
  798  pwd
  799  nvidia-smi
  800  cp *.p* training_script
  801  cd training_script/
  802  cd ..
  803  cd script/
  804  ls
  805  git init
  806  git add --all
  807  git commit -m 'Init. Commit first convergence network. all scripts should be placed under this folder.'
  808  git config --global user.email sunzhenhao@sina.com
  809  git config --global user.name sunnycia
  810  git commit -m 'Init. Commit first convergence network. all scripts should be placed under this folder.'
  811  git log
  812  git stage
  813  git add .
  814  git stage
  815  vim solver_new.prototxt 
  816  git status
  817  git add .
  818  git status
  819  git commit 'a dummy test for version unroll'
  820  git add --all
  821  git commit 'a dummy test for version unroll'
  822  git log
  823  git commit 'a dummy test for version unroll'
  824  vim solver_new.prototxt 
  825  git commit 'a dummy test for version unroll'
  826  git fetch
  827  git checkout
  828  git remote add origin https://github.com/sunnycia/scripts.git
  829  git push -u origin master
  830  git status
  831  git add --all
  832  git status
  833  git commit 'a dummy test'
  834  git clone https://github.com/sunnycia/scripts.git
  835  cd scripts/
  836  ls
  837  vim solver_new.prototxt 
  838  git status
  839  git add -a
  840  git add --all
  841  git commit 'a dummy test'
  842  git commit "a dummy test"
  843  git commit "adummytest"
  844  git commit -m "a dummy test"
  845  git push -u origin master
  846  cd ..
  847  rm -rf scripts/
  848  git status
  849  git reset HEAD solver_new.prototxt
  850  git status
  851  git checkout -- solver_new.prototxt
  852  git status
  853  git fetch
  854  git status
  855  git pull
  856  vim ~/.bashrc
  857  source ~/.bashrc
  858  cd /data/sunnycia/saliency_on_videoset/Train
  859  export CUDA_VISIBLE_DEVICES=6
  860  python training.py 
  861  cd scripts/
  862  python test.py 
  863  nvidia-smi
  864  python 
  865  cd /data/sunnycia/saliency_on_videoset/Train/scripts
  866  export CUDA_VISIBLE_DEVICES=6
  867  python test.py 
  868  cd ~/pwd/saliency_on_videoset/
  869  ls
  870  cd _Train/Deep-Feature-Flow-master/
  871  ls
  872  export CUDA_VISIBLE_DEVICES=6,7
  873  cd experiments/
  874  ls
  875  cd dff_rfcn/
  876  ls
  877  cd cfgs/
  878  ls
  879  vim resnet_v1_101_flownet_imagenet_vid_rfcn_end2end_ohem.yaml 
  880  cd ../../..
  881  python experiments/dff_rfcn/dff_rfcn_end2end_train_test.py --cfg experiments/dff_rfcn/cfgs/resnet_v1_101_flownet_imagenet_vid_rfcn_end2end_ohem.yaml
  882  history
  883  git log
  884  git reset --hard 0a667d660f7e906c1c632d481ecbf90bacee9b60
  885  vim solver_new.prototxt 
  886  top
  887  nvidia-smi
  888  cd ..
  889  rm -rf script/
  890  git clone https://github.com/sunnycia/scripts.git
  891  cd scripts/
  892  ls
  893  git log
  894  vim solver_new.prototxt 
  895  git reset --hard 0a667d660f7e906c1c632d481ecbf90bacee9b60
  896  vim solver_new.prototxt 
  897  export CUDA_VISIBLE_DEVICES=7
  898  python training.py
  899  python training.py 
  900  top
  901  nvidia-smi
  902  pwd
  903  top
  904  nvidia-smi
  905  top
  906  history
  907  cd /data/sunnycia/saliency_on_videoset/Train
  908  convert_imageset -encoded -shuffle -encode_type jpg / imagedata_mini.txt dataset/mini_lmdb
  909  export locate convert_imageset
  910  locate convert_imageset
  911  export PATH=$PATH:/usr/local/caffe-master/tools/
  912  convert_imageset -encoded -shuffle -encode_type jpg / imagedata_mini.txt dataset/mini_lmdb
  913  export PATH=$PATH:/usr/local/caffe-master/.build_release/tools/
  914  convert_imageset -encoded -shuffle -encode_type jpg / imagedata_mini.txt dataset/mini_lmdb
  915  python 
  916  free -h
  917  python
  918  cd nvidia-smi
  919  nvidia-smi
  920  free -h
  921  export CUDA_VISIBLE_DEVICES=6
  922  free -h
  923  top
  924  nvidia-smi
  925  free -h
  926  cd ../_Train/
  927  ls
  928  cd Deep-Feature-Flow-master/
  929  ls
  930  cd experiments/dff_rfcn/cfgs/
  931  vim resnet_v1_101_flownet_imagenet_vid_rfcn_end2end_ohem.yaml 
  932  cd ../../
  933  cd ..
  934  python experiments/dff_rfcn/dff_rfcn_end2end_train_test.py --cfg experiments/dff_rfcn/cfgs/resnet_v1_101_flownet_imagenet_vid_rfcn_end2end_ohem.yaml
  935  export CUDA_VISIBLE_DEVICES=4,5,6,7
  936  python experiments/dff_rfcn/dff_rfcn_end2end_train_test.py --cfg experiments/dff_rfcn/cfgs/resnet_v1_101_flownet_imagenet_vid_rfcn_end2end_ohem.yaml
  937  cd /data/sunnycia/saliency_on_videoset/Train/scripts
  938  export CUDA_VISIBLE_DEVICES=6
  939  python training.py
  940  cd pwd/saliency_on_videoset/Train
  941  cd dataset/
  942  ls
  943  top
  944  python gen_dataset.py 
  945  top
  946  nvidia-smi
  947  df -h
  948  pwd
  949  cd ..
  950  python gen_lmdb.py 
  951  ls 
  952  convert_imageset
  953  vim ~/.bahser
  954  vim ~/.bahsr
  955  vim ~/.bashrc
  956  clear
  957  locate convert_imageset.bin
  958  cp /usr/local/caffe-master/.build_release/tools/convert_imageset.bin ./
  959  ls
  960  convert_imageset
  961  ./convert_imageset
  962  ./bin
  963  ./convert_imageset.bin
  964  ls /usr/local/caffe-master/.build_release/tools/
  965  export PATH=$PATH:/usr/local/caffe-master/.build_release/tools/
  966  clear
  967  convert_imagenet
  968  ./convert_imagenet
  969  convert_imageset
  970  convert_imageset -encoded -shuffle -encode_type jpg / imagedata.txt dataset/lmdb
  971  python gen_lmdb.py 
  972  convert_imageset -encoded -shuffle -encode_type jpg / framedata.txt dataset/lmdb
  973  cxx
  974  CXX
  975  convert_imageset -encoded -shuffle -encode_type jpg / framedata.txt dataset/lmdb
  976  cd /data/sunnycia/SaliencyDataset/Image/CAT2000
  977  unzip trainSet.zip 
  978  cd ~/pwd/saliency_on_videoset/Train/
  979  cd scripts/
  980  python gen_salicon_dataset.py 
  981  export CUDA_VISIBLE_DEVICES=6
  982  python training.
  983  python training.py 
  984  git status
  985  git add --all
  986  git commit -m "add test module, revise on salicon dataset. Salicon-Ver-1.'
  987  git commit -m "add test module, revise on salicon dataset. Salicon-Ver1'
  988  git commit -m "add test module, revise on salicon dataset. Salicon-Ver1"
  989  git push -u origin master
  990  git pull
  991  git status
  992  git log
  993  git reset --hard 4e7cda7fa4cebd123a7c81912d2a2db3cc8c756b
  994  git status
  995  git push -u origin master
  996  git pull
  997  git push -u origin master
  998  top
  999  nvidia-smi
 1000  df -h
 1001  clear
 1002  top
 1003  cd pwd/saliency_on_videoset/clearn
 1004  clear
 1005  cd /data/sunnycia/saliency_on_videoset/Train/scripts
 1006  git fetch
 1007  git status
 1008  git add --all
 1009  git commit -m "Version3, combination of euc loss and kld/nss loss."
 1010  git push -u origin master
 1011  clear
 1012  python metric.py 
 1013  python
 1014  python metric.py 
 1015  python
 1016  python -h
 1017  python -m 'import matlab.engine'
 1018  nvidia-smi
 1019  python -m 'import matlab.engine'
 1020  python -m 'import matlab'
 1021  python metric.py 
 1022  top
 1023  export CUDA_VISIBLE_DEVICES=6 && cd /data/sunnycia/saliency_on_videoset/Train/scripts && export PYTHONPATH=../caffe-master/python:$PYTHONPATH
 1024  python metric.py 
 1025  python
 1026  python metric.py 
 1027  cd /usr/lib/python2.7/site-packages/
 1028  ls
 1029  python metric.py 
 1030  cd -
 1031  python metric.py 
 1032  python
 1033  python metric.py 
 1034  cd /data/sunnycia/saliency_on_videoset/Train/scripts
 1035  python gen_salicon_dataset.py 
 1036  nvidia-smi
 1037  top
 1038  nvidia-smi
 1039  top
 1040  nvidia-smi
 1041  top
 1042  python
 1043  top
 1044  nvidia-smi
 1045  cd ../caffe-saliency/
 1046  ls
 1047  make clean
 1048  cd ..
 1049  ls
 1050  cd caffe-saliency/
 1051  make clean
 1052  ls
 1053  vim Makefile.config
 1054  make -j8 all
 1055  make -j4 all
 1056  make clean
 1057  make -j8 all
 1058  make clean
 1059  vim Makefile.config
 1060  make -j8 all
 1061  vim Makefile.config
 1062  cp ~/caffe-master/ ../
 1063  cp -R ~/caffe-master/ ../
 1064  cd ../caffe-master/
 1065  ls
 1066  make clean
 1067  make -j8 all
 1068  make -j4 pycaffe
 1069  cd ..
 1070  cd scripts/
 1071  top
 1072  nvidia-smi
 1073  cd /data/sunnycia/saliency_on_videoset/Train/scripts
 1074  export CUDA_VISIBLE_DEVICES=6
 1075  python training.py 
 1076  python test.py 
 1077  python
 1078  ls /usr/local/MATLAB/
 1079  ls
 1080  python training.py 
 1081  vim bashrc
 1082  vim ~/.bashrc
 1083  export PYTHONPATH=../caffe-master/python:$PYTHONPATH
 1084  python
 1085  top
 1086  nvidia-smi
 1087  top
 1088  nvidia-smi
 1089  top
 1090  nvidia-smi
 1091  top
 1092  python avg_metric.py 
 1093  cd /data/sunnycia/saliency_on_videoset/Train/scripts
 1094  python training.py 
 1095  export CUDA_VISIBLE_DEVICES=7
 1096  python training.py --debug=True
 1097  python training.py -debug=True
 1098  python training.py --debug=True
 1099  python training.py 
 1100  python training.py -h
 1101  python training.py --debug True
 1102  git add --all
 1103  git commit -m "Last version for loss=95820 on salicon dataset.Consider it may due to bad performance of sigmoid layer, loss layer will be changed in next version."
 1104  git push -u origin master
 1105  git fetch
 1106  git status
 1107  git push
 1108  python training.py
 1109  python training.py --debug True
 1110  python training.py --debug False
 1111  nvidia-smi
 1112  top
 1113  nvidia-smi
 1114  cd /data/sunnycia/saliency_on_videoset/Train/scripts
 1115  export PYTHONPATH=../caffe-master/python:$PYTHONPATH
 1116  python training.py --debug=True --prototxt='train_nssloss.prototxt'
 1117  python training.py --debug=True --train_prototxt='train_nssloss.prototxt'
 1118  python training.py --debug=False --train_prototxt='train_nssloss.prototxt'
 1119  python training.py --debug=False --train_prototxt='train_kldloss_withouteuc.prototxt'
 1120  python training.py --debug=False --use_snapshot=True --train_prototxt='train_kldloss_withouteuc.prototxt'
 1121  python training.py --debug=False --use_snapshot=True --train_prototxt='../train_prototxt/train_kldloss_withouteuc.prototxt'
 1122  python training.py --debug=False --use_snapshot=True --train_prototxt='train_prototxt/train_kldloss_withouteuc.prototxt'
 1123  python training.py --debug=False --use_snapshot=True --train_prototxt='training_protocol/train_kldloss_withouteuc.prototxt'
 1124  cd /data/sunnycia/saliency_on_videoset/Train/scripts
 1125  export CUDA_VISIBLE_DEVICES=4
 1126  export PYTHONPATH=../caffe-master/python:$PYTHONPATH
 1127  python training.py --debug=True --train_prototxt='train_igloss.prototxt'
 1128  python training.py --debug=True --train_prototxt='train_kldloss.prototxt'
 1129  python training.py --debug=False --train_prototxt='train_kldloss.prototxt'
 1130  cd /data/sunnycia/saliency_on_videoset/Train/scripts
 1131  export CUDA_VISIBLE_DEVICES=5
 1132  export PYTHONPATH=../caffe-master/python:$PYTHONPATH
 1133  python training.py --debug=True --train_prototxt='train_nss-kldloss.prototxt'
 1134  python training.py --debug=False --train_prototxt='train_nss-kldloss.prototxt'
 1135  python training.py --debug=False --train_prototxt='train_nssloss_withouteuc.prototxt'
 1136  cd pwd/saliency_on_videoset/Train/scripts/
 1137  python test.py 
 1138  python test.py
 1139  top
 1140  nvidia-smi
 1141  export CUDA_VISIBLE_DEVICES=6
 1142  python test.py 
 1143  df -h
 1144  cd /data/sunnycia/SaliencyDataset/Image/NUS
 1145  python change_name.py 
 1146  cd -
 1147  python test.py
 1148  cd /data/sunnycia/SaliencyDataset/Image/MIT1003
 1149  python change_name.py 
 1150  cd ALLFIXATIONMAPS/
 1151  rm -f *_fixPts.jpg
 1152  cd -
 1153  cd --
 1154  cd pwd/saliency_on_videoset/Train/scripts/
 1155  python avg_metric.py 
 1156  top
 1157  nvidia-smi
 1158  ./plot_training_log.py.example
 1159  cd caffe_plot/
 1160  chmod u+x *
 1161  ./parse_log.sh ../../log/train_kldloss_withouteuc 
 1162  ./plot_training_log.py.example 0 save.png ../../log/train_kldloss
 1163  ./plot_training_log.py.example 0 save.png ../../log/train_nss_kldloss_goodweight
 1164  ./plot_training_log.py.example 0 save.png caffe.localhost.localdomain.sunnycia.log.INFO.20171012-085342.16593 
 1165  ./plot_training_log.py.example 0 save.png ../../log/train_nss_kldloss_goodweight
 1166  ./plot_training_log.py.example 0 save.png ../../log/caffe.localhost.localdomain.sunnycia.log.INFO.20171012-085342.16592
 1167  df -h
 1168  cd /data/sunnycia/SaliencyDataset/Image/CAT2000
 1169  unzip testSet.zip 
 1170  cd trainSet/
 1171  python combine.py 
 1172  cd  
 1173  cd /data/sunnycia/saliency_on_videoset/Train/scripts
 1174  python test.py 
 1175  nvidia-smi
 1176  export CUDA_VISIBLE_DEVICES=6
 1177  python test.py 
 1178  top
 1179  nvidia-smi
 1180  top
 1181  matlab -nodesktop
 1182  cd /data/sunnycia/saliency_on_videoset/Train/scripts
 1183  matlab -nodesktop
 1184  export CUDA_VISIBLE_DEVICES=5 && cd /data/sunnycia/saliency_on_videoset/Train/scripts && export PYTHONPATH=../caffe-master/python:$PYTHONPATH
 1185  python training.py --debug=False --train_prototxt='./training_protocol/train_nss_kldloss_goodweight.prototxt 2>&1 | tee ../log/train_nss_kldloss_goodweight_SGDSOLVER
 1186  python training.py --debug=False --train_prototxt='./training_protocol/train_nss_kldloss_goodweight.prototxt' 2>&1 | tee ../log/train_nss_kldloss_goodweight_SGDSOLVER
 1187  cd /data/sunnycia/saliency_on_videoset/Train/scripts
 1188  nvidia-smi
 1189  export CUDA_VISIBLE_DEVICES=6
 1190  export PYTHONPATH=../caffe-master/python:$PYTHONPATH
 1191  python training.py --debug=True --train_prototxt='train_nss-kldloss_withouteuc.prototxt'
 1192  top
 1193  nvidia-smi
 1194  git fetch
 1195  git add --all
 1196  git status
 1197  git commit -m "Add different loss function training prototxt. Add metric code."
 1198  git push -u origin master
 1199  ./train.sh
 1200  chmod u+x train.sh
 1201  ./train.sh
 1202  vim train.sh 
 1203  ./train.sh
 1204  ./train.sh ../training_protocol/train_nss_kldloss_withouteuc.prototxt
 1205  ./train.sh training_protocol/train_nss_kldloss_withouteuc.prototxt
 1206  ./train.sh training_protocol/train_nss_kldloss_withouteuc.prototxt False
 1207  df -h
 1208  clear
 1209  cd pwd/saliency_on_videoset/Train/scripts/
 1210  ./train.sh ./training_protocol/train_nss_kldloss_goodweight.prototxt False
 1211  nvidia-smi
 1212  export CUDA_VISIBLE_DEVICES=7
 1213  ./train.sh ./training_protocol/train_nss_kldloss_goodweight.prototxt False
 1214  export CUDA_VISIBLE_DEVICES=7 && cd /data/sunnycia/saliency_on_videoset/Train/scripts && export PYTHONPATH=../caffe-master/python:$PYTHONPATH
 1215  ./train.sh ./training_protocol/train_nss_kldloss_goodweight.prototxt False
 1216  cd /data/sunnycia/saliency_on_videoset/Train/scripts
 1217  matlab -nodesktop
 1218  cd /data/sunnycia/saliency_on_videoset/Train/scripts
 1219  ls /home
 1220  top
 1221  nvidia-smi
 1222  matlab -nodesktop
 1223  cd pwd/saliency_on_videoset/Train/scripts/
 1224  vim ~/.bashrc
 1225  cd /data/sunnycia/saliency_on_videoset/_Train/DSCLRCN/caffe-master
 1226  make -j8 all
 1227  vim Makefile.config
 1228  make clean
 1229  make -j8 all
 1230  vim Makefile.config
 1231  make clean
 1232  make -j8 all
 1233  vim Makefile.config
 1234  cd ..
 1235  cd caffe-master/
 1236  ls
 1237  vim Makefile.config
 1238  make -j8 all
 1239  make clean
 1240  make -j8 all
 1241  vim Makefile.config
 1242  make clean
 1243  make -j16 all
 1244  cd /home/sunnycia/pwd/saliency_on_videoset/Train/scripts
 1245  python metric.py
 1246  cd /home/sunnycia/pwd/saliency_on_videoset/Train/scripts
 1247  python metric.py
 1248  cd pwd/saliency_on_videoset/Train/scripts/
 1249  python avg_metric.py 
 1250  top
 1251  nvidia-smi
 1252  python avg_metric.py 
 1253  vim /etc/profile
 1254  git clone https://github.com/herrlich10/saliency.git
 1255  mv saliency/ pymetric
 1256  python metric.py
 1257  clear
 1258  python metric.py
 1259  clear
 1260  python metric.py
 1261  clear
 1262  python metric.py
 1263  clear
 1264  python metric.py
 1265  clear
 1266  python metric.py
 1267  pwd
 1268  top
 1269  nvidia-smi
 1270  cd pwd/saliency_on_videoset/Train/scripts/
 1271  matlab -nodesktop
 1272  clear
 1273  cd /data/sunnycia/saliency_on_videoset/Train/scripts
 1274  python avg_metric.py 
 1275  nvidia-smi
 1276  export CUDA_VISIBLE_DEVICES=6 && cd /data/sunnycia/saliency_on_videoset/Train/scripts && export PYTHONPATH=../caffe-master/python:$PYTHONPATH
 1277  python test.py 
 1278  python admin.py 
 1279  vim ~/.bashrc
 1280  python admin.py 
 1281  python test.py 
 1282  python admin.py 
 1283  top
 1284  nvdia-smi
 1285  nvidia-smi
 1286  clear
 1287  rsync -avz 172.31.234.248:/home/data/qiudan/DATASET/SALICON/val2014/saliency/* /data/sunnycia/SaliencyDataset/Image/SALICON/DATA/train_val/val2014/saliency/sam
 1288  rsync -avz 172.31.234.248:/home/data/qiudan/DATASET/MIT1003/saliency/* /data/sunnycia/SaliencyDataset/Image/MIT1003/saliency/sam
 1289  matlab -nodesktop
 1290  python metric.py
 1291  clear
 1292  python metric.py
 1293  cd /data/sunnycia/saliency_on_videoset/_Train/flownet2-tf
 1294  python
 1295  cd /data/sunnycia/saliency_on_videoset/_Train/flownet2
 1296  python
 1297  clear
 1298  cd /data/sunnycia/SaliencyDataset/Video/XU
 1299  python
 1300  clear
 1301  python gen_fixation_map.py 
 1302  cd ..
 1303  cd DIEM/
 1304  python gen_fixation.py 
 1305  clear
 1306  python gen_fixation.py 
 1307  clear
 1308  python gen_fixation.py 
 1309  clear
 1310  python gen_fixation.py 
 1311  clear
 1312  cd ..
 1313  cd MSU/
 1314   python gen_fixation.py 
 1315  clear
 1316   python gen_fixation.py 
 1317  ls
 1318  python playground.py 
 1319  python add_frame_index.py 
 1320  clear
 1321  python add_frame_index.py 
 1322  vim ~/.bashrc
 1323  cd /data/sunnycia/saliency_on_videoset/_Train/flownet2
 1324  source set-env.sh 
 1325  vim ~/.bashrc
 1326  PATH
 1327  $PATH
 1328  python run-flownet.py
 1329  ls ~/.*
 1330  vim ~/.bash_history 
 1331  cd scripts/
 1332  ls -h
 1333  ls /home
 1334  cd ~/pwd/saliency_on_videoset/_Train/Deep-Feature-Flow-master/
 1335  history>history.txt
 1336  export CUDA_VISIBLE_DEVICES=4,5,6,7
 1337  python experiments/dff_rfcn/dff_rfcn_end2end_train_test.py --cfg experiments/dff_rfcn/cfgs/resnet_v1_101_flownet_imagenet_vid_rfcn_end2end_ohem.yaml
 1338  export CUDA_VISIBLE_DEVICES=6,7
 1339  python experiments/dff_rfcn/dff_rfcn_end2end_train_test.py --cfg experiments/dff_rfcn/cfgs/resnet_v1_101_flownet_imagenet_vid_rfcn_end2end_ohem.yaml
 1340  cd /data/sunnycia/SaliencyDataset/Video/MSU
 1341  python add_frame_index_hist.py 
 1342  cd /data/sunnycia/saliency_on_videoset/Train/scripts
 1343  export CUDA_VISIBLE_DEVICES=7
 1344  python training.py --debug=True --train_prototxt='train_nss-kldloss_withouteuc.prototxt'
 1345  export CUDA_VISIBLE_DEVICES=7
 1346  python training.py --debug=True --train_prototxt='../training_protocol/train_nss-kldloss_withouteuc.prototxt'
 1347  python training.py --debug=True --train_prototxt='training_protocol/train_nss-kldloss_withouteuc.prototxt'
 1348  python training.py --debug=True --train_prototxt='training_protocol/train_kldloss_withouteuc.prototxt'
 1349  export PYTHONPATH=../caffe-master/python:$PYTHONPATH
 1350  python training.py --debug=True --train_prototxt='training_protocol/train_kldloss_withouteuc.prototxt'
 1351  clear
 1352  cd pwd/saliency_on_videoset/Train/scripts/
 1353  python training.py --train_prototxt='prototxt/train_kldloss_withouteuc_5layer_deconv.prototxt' --batch=8
 1354  export CUDA_VISIBLE_DEVICES=5
 1355  python training.py --train_prototxt='prototxt/train_kldloss_withouteuc_5layer_deconv.prototxt' --batch=8
 1356  clear
 1357  python training.py --train_prototxt='prototxt/train_kldloss_withouteuc_5layer_deconv.prototxt' --batch=8
 1358  bash set_env.sh 
 1359  python training.py --train_prototxt='prototxt/train_kldloss_withouteuc_5layer_deconv.prototxt' --batch=8 --debug=1
 1360  source set_env.sh 
 1361  python training.py --train_prototxt='prototxt/train_kldloss_withouteuc_5layer_deconv.prototxt' --batch=8 --debug=1
 1362  cd pwd/saliency_on_videoset/Train/scripts/
 1363  python scavenger.py 
 1364  git status
 1365  git add --all
 1366  git commit -m "add dilated convolution network prototxt"
 1367  git push -u origin master
 1368  clear
 1369  cd pwd/saliency_on_videoset/Train/scripts/
 1370  source set_env.sh 
 1371  history
 1372  clear
 1373  python training.py --train_prototxt='prototxt/train_kldloss_withouteuc_5layer_deconv.prototxt' --batch=8 --debug=1
 1374  python training.py --train_prototxt='prototxt/train_kldloss_withouteuc_5layer_deconv.prototxt' --batch=8
 1375  clear
 1376  python training.py --train_prototxt='prototxt/train_kldloss_withouteuc_5layer_deconv.prototxt' --batch=8
 1377  export CUDA_VISIBLE_DEVICES=6
 1378  python training.py --train_prototxt='prototxt/debug_add_lr_train_kldloss_withouteuc.prototxt' --batch=8
 1379  python training.py --train_prototxt='prototxt/debug_add_lr_train_kldloss_withouteuc.prototxt' --batch=8 --debug=1
 1380  python training.py --train_prototxt='prototxt/debug_add_lr_train_kldloss_withouteuc.prototxt' --batch=8
 1381  export CUDA_VISIBLE_DEVICES=6 && cd /data/sunnycia/saliency_on_videoset/Train/scripts && export PYTHONPATH=../caffe-master/python:$PYTHONPATH
 1382  history
 1383  python training.py --debug=True --train_prototxt='training_protocol/train_kldloss_withouteuc.prototxt'
 1384  python
 1385  python training.py --debug=True --train_prototxt='training_protocol/train_kldloss_withouteuc.prototxt'
 1386  ls
 1387  git status
 1388  git add --all
 1389  git commit -m "Add loss plot module in training.py"
 1390  git push -u origin master
 1391  git status
 1392  cd /data/sunnycia/fang
 1393  python pictureshow.py 
 1394  cd 
 1395  cd /data/sunnycia/saliency_on_videoset/Train/scripts
 1396  python change_net_test.py 
 1397  python training.py 
 1398  python training.py --debug=False
 1399  python training.py --debug=False --train_prototxt='net/train.prototxt'
 1400  python training.py --debug=False
 1401  python training.py --debug=False --train_prototxt='net/train.prototxt'
 1402  python training.py --debug=False --train_prototxt='net/train.prototxt' --batch=512
 1403  python training.py --debug=False --train_prototxt='net/train.prototxt' --batch=32
 1404  python training.py --debug=False --train_prototxt='net/train.prototxt' --batch=512
 1405  python training.py --debug False --train_prototxt='net/train.prototxt' --batch=512
 1406  python training.py --debug=False --train_prototxt='net/train.prototxt' --batch=512
 1407  export CUDA_VISIBLE_DEVICES=7
 1408  python training.py --debug=False --train_prototxt='net/train.prototxt' --batch=512
 1409  python training.py --debug=False --train_prototxt='net/train.prototxt' --batch=64
 1410  python training.py --debug=False --train_prototxt='net/train.prototxt' --batch=16
 1411  export CUDA_VISIBLE_DEVICES=6,7
 1412  python training.py --debug=False --train_prototxt='net/train.prototxt' --batch=8
 1413  python training.py --debug=False --train_prototxt='net/train.prototxt' --batch=16
 1414  python training.py --debug='False' --train_prototxt='net/train.prototxt' --batch=16
 1415  python scavenger.py 
 1416  python training.py --debug='False' --train_prototxt='net/train.prototxt' --batch=16
 1417  python training.py --debug='False' --train_prototxt='net/train.prototxt' --batch=8
 1418  python training.py --debug='False' --train_prototxt='net/train_kldloss_withouteuc.prototxt' --batch=8
 1419  clear
 1420  python training.py --train_prototxt='net/train_kldloss_withouteuc.prototxt' --batch=8 --use_snapshot='../training_output/salicon/train_kldloss_withouteuc-batch-8_1509584263/snapshot-_iter_100000.solverstate'
 1421  python training.py --train_prototxt='prototxt/train_kldloss_withouteuc.prototxt' --batch=8 --use_snapshot='../training_output/salicon/train_kldloss_withouteuc-batch-8_1509584263/snapshot-_iter_100000.solverstate'
 1422  df -h
 1423  python utils/scavenger.py 
 1424  python utils/scavenger.py --snapshot=1
 1425  git status
 1426  git add --all
 1427  git commit -m "add generate density map script. Clean training script, add vo-training script(not done yet)"
 1428  git push -u origin master
 1429  cd /data/sunnycia/SaliencyDataset/Video/XU
 1430  clear
 1431  python extract_fixation.py 
 1432  matlab
 1433  top
 1434  nvidia-smi
 1435  clear
 1436  df -h
 1437  cd ..
 1438  cd DIEM/
 1439  python gen_fixation.py 
 1440  clear
 1441  python gen_fixation.py 
 1442  clear
 1443  python gen_fixation.py 
 1444  ffmpeg
 1445  cd ../MSU/
 1446  ffmpeg -r 25 -f image2 -s 1920x1080 -i _temp/frame_%d.jpg -vcodec libx264 -crf 25 -pix_fmt yuv420p test.mp4
 1447  python
 1448  nvidia-smi
 1449  top
 1450  nvidia-smi
 1451  top
 1452  nvidia-smi
 1453  python add_frame_index_hist.py 
 1454  cd /data/sunnycia/saliency_on_videoset/Train/scripts
 1455  git status
 1456  git add --all
 1457  git commit -m "update, forget what i've done.."
 1458  git push -u origin master
 1459  python avg_metric.py 
 1460  cd /data/sunnycia/saliency_on_videoset/Train/scripts
 1461  history > history.txt
 1462  python training.py
 1463  python training.py --debug=True
 1464  python training.py --debug=True --train_prototxt='training_protocol/train_kldloss_withouteuc.prototxt'
 1465  export PYTHONPATH=../caffe-master/python:$PYTHONPATH
 1466  python training.py --debug=True --train_prototxt='training_protocol/train_kldloss_withouteuc.prototxt'
 1467  export CUDA_VISIBLE_DEVICES=6
 1468  python training.py --debug=True --train_prototxt='training_protocol/train_kldloss_withouteuc.prototxt'
 1469  python scavenger.py 
 1470  git add --all
 1471  git commit -m "add batch training function.Programatically change net prototxt"
 1472  git push -u origin master
 1473  python scavenger.py 
 1474  git status
 1475  git add --all
 1476  git commit -m "fixed some bug"
 1477  git push -u origin master
 1478  python scavenger.py 
 1479  python training.py --debug --train_prototxt='net/train_kldloss_withouteuc_dilated4_conv.prototxt'
 1480  python training.py --debug=1 --train_prototxt='net/train_kldloss_withouteuc_dilated4_conv.prototxt'
 1481  python training.py --debug=1 --train_prototxt='net/train_kldloss_withouteuc_dilated4_conv.prototxt' batch=8
 1482  export CUDA_VISIBLE_DEVICES=3
 1483  python training.py --debug=1 --train_prototxt='net/train_kldloss_withouteuc_dilated4_conv.prototxt' batch=8
 1484  python training.py --debug=1 --train_prototxt='net/train_kldloss_withouteuc_dilated4_conv.prototxt' --batch=8
 1485  python training.py --train_prototxt='net/train_kldloss_withouteuc_dilated4_conv.prototxt' --batch=8
 1486  cd ../../_Train/
 1487  git clone https://github.com/remega/OMCNN_2CLSTM.git
 1488  clear
 1489  python training.py --train_prototxt='prototxt/train_kldloss_withouteuc_dilated4_conv.prototxt' --batch=8 --use_snapshot='../training_output/salicon/train_kldloss_withouteuc_dilated4_conv-batch-8_1509601246/snapshot-_iter_100000.solverstate'
 1490  cd ../Train/scripts/
 1491  python training.py --train_prototxt='prototxt/train_kldloss_withouteuc_dilated4_conv.prototxt' --batch=8 --use_snapshot='../training_output/salicon/train_kldloss_withouteuc_dilated4_conv-batch-8_1509601246/snapshot-_iter_100000.solverstate'
 1492  python utils/scavenger.py 
 1493  python test.py 
 1494  nvidia-smi
 1495  export CUDA_VISIBLE_DEVICES=5
 1496  python test.py 
 1497  cd /data/sunnycia/SaliencyDataset/Video/MSU
 1498  python gen_density.py 
 1499  git clone https://github.com/clibs/lmdb.git
 1500  ls
 1501  pip install lmdb
 1502  cd /data/sunnycia/saliency_on_videoset/_Train/flownet2
 1503  cd python/
 1504  python
 1505  cd ..
 1506  cd ~
 1507  clear
 1508  wget https://s3.amazonaws.com/videomattingstor/savam/sources.zip
 1509  ls
 1510  ls sources.zip 
 1511  ls -l sources.zip 
 1512  rm sources.zip 
 1513  clear
 1514  cd /data/sunnycia/SaliencyDataset/Video/XU
 1515  python gen_fixation_map.py 
 1516  vim ~/.bashrc
 1517  cd ..
 1518  ls
 1519  cd MSU/
 1520  ls
 1521  unzip sources.zip 
 1522  nvidia-smi
 1523  free -h
 1524  top
 1525  df ph
 1526  df -h
 1527  ls
 1528  mv COPYRIGHTED_sources/*.avi videos/
 1529  mv VQEG_sources/*.avi videos/
 1530  top
 1531  nvidia-smi
 1532  top
 1533  cd ~/pwd/saliency_on_videoset/_Train/Deep-Feature-Flow-master/
 1534  export CUDA_VISIBLE_DEVICES=6,7
 1535  python experiments/dff_rfcn/dff_rfcn_end2end_train_test.py --cfg experiments/dff_rfcn/cfgs/
 1536  python experiments/dff_rfcn/dff_rfcn_end2end_train_test.py --cfg experiments/dff_rfcn/cfgs/resnet_v1_101_flownet_imagenet_vid_rfcn_end2end_ohem.yaml
 1537  python experiments/dff_rfcn/dff_rfcn_end2end_train_test.py --cfg experiments/dff_rfcn/cfgs/
 1538  python experiments/dff_rfcn/dff_rfcn_end2end_train_test.py --cfg experiments/dff_rfcn/cfgs/resnet_v1_101_flownet_imagenet_vid_rfcn_end2end_ohem.yaml
 1539  cd /data/sunnycia/SaliencyDataset/Video/MSU
 1540  python add_frame_index.py 
 1541  cd /data/sunnycia/saliency_on_videoset/_Train/Deep-Feature-Flow-master
 1542  python experiments/dff_rfcn/dff_rfcn_end2end_train_test.py --cfg experiments/dff_rfcn/cfgs/resnet_v1_101_flownet_imagenet_vid_rfcn_end2end_ohem.yaml
 1543  export CUDA_VISIBLE_DEVICES=6,7
 1544  python experiments/dff_rfcn/dff_rfcn_end2end_train_test.py --cfg experiments/dff_rfcn/cfgs/resnet_v1_101_flownet_imagenet_vid_rfcn_end2end_ohem.yaml
 1545  free -h
 1546  cd /data/sunnycia/saliency_on_videoset/Train/scripts
 1547  python training.py
 1548  python training.py --debug=True
 1549  python training.py --debug=True --train_prototxt='net/train_kldloss_withouteuc_dilated_conv.prototxt' --batch=8
 1550  export PYTHONPATH=../caffe-master/python:$PYTHONPATH
 1551  python training.py --debug=True --train_prototxt='net/train_kldloss_withouteuc_dilated_conv.prototxt' --batch=8
 1552  export CUDA_VISIBLE_DEVICES=7
 1553  python training.py --debug=True --train_prototxt='net/train_kldloss_withouteuc_dilated_conv.prototxt' --batch=8
 1554  python training.py --debug=False --train_prototxt='net/train_kldloss_withouteuc_dilated_conv.prototxt' --batch=8
 1555  python training.py --train_prototxt='net/train_kldloss_withouteuc_dilated_conv.prototxt' --batch=8
 1556  clera
 1557  clear
 1558  python training.py --train_prototxt='prototxt/train_kldloss_withouteuc_dilated_conv.prototxt' --batch=8 --use_snapshot='../training_output/salicon/train_kldloss_withouteuc_dilated_conv-batch-8_1509595085/snapshot-_iter_100000.solverstate'
 1559  nvidia-smi
 1560  top
 1561  nvidia-smi
 1562  heaven
 1563  nvidia-smi
 1564  python
 1565  top
 1566  clear
 1567  free -h
 1568  nvidia-smi
 1569  python utils/slice_frames.py 
 1570  python utils/slice_frames.py --videobase='/data/sunnycia/SaliencyDataset/Video/MSU/videos' --outputbase='/data/sunnycia/SaliencyDataset/Video/MSU/frames' --wildcard='*left.*' --debug=1
 1571  python utils/slice_frames.py --videobase='/data/sunnycia/SaliencyDataset/Video/MSU/videos' --outputbase='/data/sunnycia/SaliencyDataset/Video/MSU/frames' --wildcard="*left.*" --debug=1
 1572  python utils/slice_frames.py --videobase='/data/sunnycia/SaliencyDataset/Video/MSU/videos' --outputbase='/data/sunnycia/SaliencyDataset/Video/MSU/frames' --vowildcard="*left.*" --debug=1
 1573  python utils/slice_frames.py --videobase='/data/sunnycia/SaliencyDataset/Video/MSU/videos' --outputbase='/data/sunnycia/SaliencyDataset/Video/MSU/frames' --vowildcard="*left.*"
 1574  unrar
 1575  cd ..
 1576  cd -
 1577  cd /data/sunnycia/SaliencyDataset/Video/LEDOV
 1578  unrar LEDOV.part1.rar 
 1579  unrar e LEDOV.part1.rar 
 1580  unrar x LEDOV.part1.rar 
 1581  cd -
 1582  clear
 1583  cd /data/sunnycia/SaliencyDataset/Video/MSU
 1584  python gen_fixation.py 
 1585  vim gen_fixation.py 
 1586  clear
 1587  python gen_fixation.py 
 1588  python gen_density.py --sigma=32
 1589  clear
 1590  cd pwd/saliency_on_videoset/Train/scripts/
 1591  source set_env.sh 
 1592  nvidia-smi
 1593  source set_env.sh 
 1594  python test.py
 1595  clear
 1596  python test.py
 1597  cd /data/sunnycia/SaliencyDataset/Image/NCTU
 1598  unzip NCTU-3DFixation.zip 
 1599  unzip -q NCTU-3DFixation.zip 
 1600  cd -
 1601  clear
 1602  source set_env.sh 
 1603  export CUDA_VISIBLE_DEVICES=7
 1604  python test.py 
 1605  python 
 1606  clear
 1607  python
 1608  clear
 1609  python test.py
 1610  python metric/metric.py 
 1611  clear
 1612  python metric/metric.py 
 1613  clear
 1614  python metric/metric.py --debug --ds_name='mit1003'
 1615  python metric/metric.py --debug=1 --ds_name=mit1003
 1616  clear
 1617  python metric/metric.py --debug=1 --ds_name=mit1003
 1618  clear
 1619  python metric/metric.py --debug=1 --ds_name=mit1003
 1620  clear
 1621  python metric/metric.py --ds_name=mit1003
 1622  nvidia-smi
 1623  top
 1624  nvidia-smi
 1625  top
 1626  nvidia-smi
 1627  df -h
 1628  top
 1629  nvida-smi
 1630  nvidia-smi
 1631  clear
 1632  nvidia-smi
 1633  top
 1634  nvidia-smi
 1635  top
 1636  python metric/metric_video.py 
 1637  python metric/metric_video.py -dsname='videoset'
 1638  python metric/metric_video.py --dsname='videoset'
 1639  python metric/avg_metric.py 
 1640  cd pwd/saliency_on_videoset/Train/scripts/
 1641  source set_env.sh 
 1642  export CUDA_VISIBLE_DEVICES=0
 1643  clear
 1644  python test.py 
 1645  top
 1646  nvidia-smi
 1647  top
 1648  nvidia-smi
 1649  clear
 1650  cd  /data/sunnycia/saliency_on_videoset/_Train
 1651  git clone https://github.com/liruoteng/FlowNet.git
 1652  top
 1653  nvidia-smi
 1654  top
 1655  free -h
 1656  python
 1657  cd ../Train/
 1658  cd scripts/
 1659  cd /data/sunnycia/SaliencyDataset/Video/MSU
 1660  python all_in_one.py 
 1661  top
 1662  nvidia-smi
 1663  clear
 1664  top
 1665  nvidia-smi
 1666  top
 1667  clear
 1668  cd /data/sunnycia/saliency_on_videoset/Train/scripts
 1669  python training_image.py --train_prototxt='prototxt/train_kldloss_withouteuc_msra.prototxt' --batch=8
 1670  export CUDA_VISIBLE_DEVICES=4
 1671  python training_image.py --train_prototxt='prototxt/train_kldloss_withouteuc_msra.prototxt' --batch=8
 1672  python training_image.py --train_prototxt='prototxt/train_kldloss_withouteuc_msra.prototxt' --batch=8 --debug=1
 1673  python training_image.py --train_prototxt='prototxt/train_kldloss_withouteuc_uniform.prototxt' --batch=8
 1674  free
 1675  free -h
 1676  vim ~/.bashrc
 1677  top
 1678  nvidia-smi
 1679  top
 1680  clear
 1681  cd pwd/saliency_on_videoset/Train/scripts/
 1682  source set_env.sh 
 1683  nvidia-smi
 1684  export CUDA_VISIBLE_DEVICES=7
 1685  python test.py 
 1686  clear
 1687  python test.py
 1688  clear
 1689  python metric/metric.py --dsname='salicon'
 1690  python training_video.py 
 1691  cler
 1692  clear
 1693  python training_video.py 
 1694  matlab
 1695  python training_video.py 
 1696  python training_video.py --train_prototxt='prototxt/vo_train_kldloss_withouteuc.prototxt' 
 1697  clear
 1698  python training_video.py --train_prototxt='prototxt/vo-v1_train_kldloss_withouteuc.prototxt' 
 1699  export CUDA_VISIBLE_DEVICES=6
 1700  python training_video.py --train_prototxt='prototxt/vo-v1_train_kldloss_withouteuc.prototxt' 
 1701  export CUDA_VISIBLE_DEVICES=6,7
 1702  python training_video.py --train_prototxt='prototxt/vo-v1_train_kldloss_withouteuc.prototxt' 
 1703  clear
 1704  python training_video.py --train_prototxt='prototxt/vo-v1_train_kldloss_withouteuc.prototxt' 
 1705  clear
 1706  python test.py 
 1707  python metric/metric.py 
 1708  python metric/metric.py --dsname='mit1003'
 1709  python metric/avg_metric.py 
 1710  export CUDA_VISIBLE_DEVICES=5
 1711  python training_video_framestack_based.py --train_prototxt='prototxt/vo-v3_train_kldloss_withouteuc.prototxt' --use_model='../training_output/salicon/train_kldloss_withouteuc-batch-8_1509584263/snapshot-_iter_100000.caffemodel' 
 1712  clear
 1713  python training_video_framestack_based.py --train_prototxt='prototxt/vo-v3_train_kldloss_withouteuc.prototxt' --use_model='../training_output/salicon/train_kldloss_withouteuc-batch-8_1509584263/snapshot-_iter_100000.caffemodel' 
 1714  clear
 1715  python training_video_framestack_based.py --train_prototxt='prototxt/vo-v3_train_kldloss_withouteuc.prototxt' --use_model='../training_output/salicon/train_kldloss_withouteuc-batch-8_1509584263/snapshot-_iter_100000.caffemodel' 
 1716  python training_video_framestack_based.py --train_prototxt='prototxt/vo-v3_train_kldloss_withouteuc.prototxt' --use_model='../training_output/salicon/train_kldloss_withouteuc-batch-8_1509584263/snapshot-_iter_100000.caffemodel' --visualization=1
 1717  clear
 1718  python training_video_framestack_based.py --train_prototxt='prototxt/vo-v3_train_kldloss_withouteuc.prototxt' --use_model='../training_output/salicon/train_kldloss_withouteuc-batch-8_1509584263/snapshot-_iter_100000.caffemodel'
 1719  top
 1720  nvidia-smi
 1721  top
 1722  nvidia-smi
 1723  export CUDA_VISIBLE_DEVICES=0
 1724  cd pwd/saliency_on_videoset/Train/scripts/
 1725  source set_env.sh 
 1726  export CUDA_VISIBLE_DEVICES=0
 1727  clear
 1728  python test.py 
 1729  clear
 1730  git status
 1731  git add --all 
 1732  git commit -m "regular update. 5 layer deconvolution."
 1733  git push -u origin master
 1734  python metric/avg_metric.py 
 1735  python utils/scavenger.py 
 1736  cd /data/sunnycia/SaliencyDataset/Video/MSU/density/sigma32
 1737  rename 's/(.*)/$1_left/' *
 1738  rename 's/(*)/$1_left/' *
 1739  rename 's/^/_left/' *
 1740  for f in *; do mv "$f" "$f_left"; done
 1741  rename 's/^//_left' *
 1742  rename 's/^/_left' *
 1743  rename 's/^/^_left' *
 1744  rename 's/^/^_left/' *
 1745  rename 's/*/*_left/' *
 1746  rename 's/(*)/$1_left/' *
 1747  rename 's/(.*)$/$1_left/' *
 1748  rename 's/(.*)$/.$1_left/' *
 1749  python
 1750  cd -
 1751  git status
 1752  git add --all
 1753  git commit -m "VideoDataset complete, training video script complete.Network version-1, concate RGB and flow vector after datalayer"
 1754  git push -u origin master
 1755  cd /data/sunnycia/SaliencyDataset/Video/MSU
 1756  python all_in_one.py 
 1757  cd -
 1758  clear
 1759  nvidia-smi
 1760  top
 1761  nvidia-smi
 1762  export CUDA_VISIBLE_DEVICES=6
 1763  python test.py 
 1764  cd -
 1765  ls
 1766  cd -
 1767  python utils/slice_frames.py --videobase='/data/sunnycia/SaliencyDataset/Video/MSU/videos' --outputbase='/data/sunnycia/SaliencyDataset/Video/MSU/frames' --vowildcard='*_left.*'
 1768  cd -
 1769  python all_in_one.py 
 1770  cd -
 1771  python test.py 
 1772  git status
 1773  git add --all
 1774  git commit -m "Done for video network version-3"
 1775  git push -u origin master
 1776  clear
 1777  python visualize_weight.py 
 1778  python visualize_weight.py --deploy='prototxt/deploy_3layer_deconv.prototxt' --model='../training_output/salicon/train_kldloss_withouteuc-batch-8_1509584263/snapshot-_iter_100000.caffemodel' --output='conv1.jpg' 
 1779  python visualize_weight.py --deploy='prototxt/deploy_3layer_deconv.prototxt' --model='../training_output/salicon/train_kldloss_withouteuc-batch-8_1509584263/snapshot-_iter_100000.caffemodel' --output='conv2.jpg' --layer='conv2'
 1780  python visualize_weight.py --deploy='prototxt/deploy_3layer_deconv.prototxt' --model='../training_output/salicon/train_kldloss_withouteuc-batch-8_1509584263/snapshot-_iter_100000.caffemodel' --output='upsample1.jpg' --layer='upsample_1'
 1781  python visualize_weight.py --deploy='prototxt/deploy_3layer_deconv.prototxt' --model='../training_output/salicon/train_kldloss_withouteuc-batch-8_1509584263/snapshot-_iter_100000.caffemodel' --output='upsample2.jpg' --layer='upsample_2'
 1782  python visualize_weight.py --deploy='prototxt/deploy_3layer_deconv.prototxt' --model='../training_output/salicon/train_kldloss_withouteuc-batch-8_1509584263/snapshot-_iter_100000.caffemodel' --output='scale5c_branch2c.jpg' --layer='scale5c_branch2c'
 1783  python visualize_weight.py --deploy='prototxt/deploy_3layer_deconv.prototxt' --model='../training_output/salicon/train_kldloss_withouteuc-batch-8_1509584263/snapshot-_iter_100000.caffemodel' --output='saliency_map.jpg' --layer='saliency_map'
 1784  python visualize_weight.py --deploy='prototxt/deploy_3layer_deconv.prototxt' --model='../training_output/salicon/train_kldloss_withouteuc-batch-8_1509584263/snapshot-_iter_100000.caffemodel' --output='res3c_branch2c.jpg' --layer='res3c_branch2c'
 1785  python visualize_weight.py --deploy='prototxt/deploy_3layer_deconv.prototxt' --model='../training_output/salicon/train_kldloss_withouteuc-batch-8_1509584263/snapshot-_iter_100000.caffemodel' --output='res2a_branch2a.jpg' --layer='res2a_branch2a'
 1786  python visualize_weight.py --deploy='prototxt/deploy_3layer_deconv.prototxt' --model='../training_output/salicon/train_kldloss_withouteuc-batch-8_1509584263/snapshot-_iter_100000.caffemodel' --output='scale_conv1.jpg' --layer='scale_conv1'
 1787  python visualize_weight.py --deploy='prototxt/deploy_3layer_deconv.prototxt' --model='../training_output/salicon/train_kldloss_withouteuc-batch-8_1509584263/snapshot-_iter_100000.caffemodel' --output='res2a_branch1.jpg' --layer='res2a_branch1'
 1788  nvidia-smi
 1789  vim ~/.bashrc
 1790  clear
 1791  nvidia-smi
 1792  df -h
 1793  nvidia-smi
 1794  clear
 1795  cd /data/sunnycia/saliency_on_videoset
 1796  python main.py 
 1797  cd Fruit-Ninja-Final-Project/
 1798  python main.py 
 1799  clear
 1800  history
 1801  nvidia-smi
 1802  cd ../../
 1803  cd pwd/saliency_on_videoset/
 1804  ls
 1805  cd ~/pwd/saliency_on_videoset/Train/scripts/
 1806  python utils/scavenger.py 
 1807  top
 1808  nvidia-smi
 1809  free -h
 1810  clear
 1811  clc
 1812  cd ../../_Train/Deep-Feature-Flow-master/
 1813  ls
 1814  pwd
 1815  export CUDA_VISIBLE_DEVICES=4,5,6,7
 1816  python experiments/dff_rfcn/dff_rfcn_end2end_train_test.py --cfg experiments/dff_rfcn/cfgs/resnet_v1_101_flownet_imagenet_vid_rfcn_end2end_ohem.yaml
 1817  clear
 1818  python experiments/dff_rfcn/dff_rfcn_end2end_train_test.py --cfg experiments/dff_rfcn/cfgs/resnet_v1_101_flownet_imagenet_vid_rfcn_end2end_ohem.yaml
 1819  nvidia-smi
 1820  export CUDA_VISIBLE_DEVICES=4,7
 1821  python experiments/dff_rfcn/dff_rfcn_end2end_train_test.py --cfg experiments/dff_rfcn/cfgs/resnet_v1_101_flownet_imagenet_vid_rfcn_end2end_ohem.yaml
 1822  nvidia-smi
 1823  top
 1824  nvidia-smi
 1825  cd /data/sunnycia/saliency_on_videoset/Train/scripts
 1826  nvidia-smi
 1827  export CUDA_VISIBLE_DEVICES=5,6
 1828  clear
 1829  python training_video.py --train_prototxt='prototxt/vo-v2_train_kldloss_withouteuc.prototxt' --use_model='../training_output/salicon/train_kldloss_withouteuc-batch-8_1509584263/snapshot-_iter_100000.caffemodel'
 1830  source set_env.sh 
 1831  export CUDA_VISIBLE_DEVICES=5,6
 1832  python training_video.py --train_prototxt='prototxt/vo-v2_train_kldloss_withouteuc.prototxt' --use_model='../training_output/salicon/train_kldloss_withouteuc-batch-8_1509584263/snapshot-_iter_100000.caffemodel'
 1833  clear
 1834  cd pwd/saliency_on_videoset/_Train/Deep-Feature-Flow-master/
 1835  ls
 1836  nvidia-smi
 1837  export CUDA_VISIBLE_DEVICES=4,5
 1838  history > histroy.txt
 1839  python experiments/dff_rfcn/dff_rfcn_end2end_train_test.py --cfg experiments/dff_rfcn/cfgs/resnet_v1_101_flownet_imagenet_vid_rfcn_end2end_ohem.yaml
 1840  clear
 1841  cd ../../Train/
 1842  cd scripts/
 1843  export PYTHONPATH=../caffe-flownet/python:$PYTHONPATH
 1844  python training.py --train_prototxt='prototxt/train_kldloss.prototxt' --use_snapshot='../training_output/salicon/train_kldloss_withouteuc-batch-8_1509584263/snapshot-_iter_100000.solverstate' --batch=1
 1845  export CUDA_VISIBLE_DEVICES=3
 1846  python training.py --train_prototxt='prototxt/train_kldloss.prototxt' --use_snapshot='../training_output/salicon/train_kldloss_withouteuc-batch-8_1509584263/snapshot-_iter_100000.solverstate' --batch=1
 1847  clear
 1848  python training_video.py --train_prototxt='prototxt/vo-v1_train_kldloss_withouteuc.prototxt' --use_model='../training_output/salicon/train_kldloss_withouteuc-batch-8_1509584263/snapshot-_iter_100000.caffemodel'
 1849  export CUDA_VISIBLE_DEVICES=6
 1850  python training_video.py --train_prototxt='prototxt/vo-v1_train_kldloss_withouteuc.prototxt' --use_model='../training_output/salicon/train_kldloss_withouteuc-batch-8_1509584263/snapshot-_iter_100000.caffemodel'
 1851  export CUDA_VISIBLE_DEVICES=6,7
 1852  python training_video.py --train_prototxt='prototxt/vo-v1_train_kldloss_withouteuc.prototxt' --use_model='../training_output/salicon/train_kldloss_withouteuc-batch-8_1509584263/snapshot-_iter_100000.caffemodel'
 1853  clear
 1854  python training_video.py --train_prototxt='prototxt/vo-v1_train_kldloss_withouteuc.prototxt' --use_model='../training_output/salicon/train_kldloss_withouteuc-batch-8_1509584263/snapshot-_iter_100000.caffemodel'
 1855  clear
 1856  cd 
 1857  cd /home/sunnycia/pwd/saliency_on_videoset/Train/caffe-flownet
 1858  make -j16 all
 1859  make -j8 pycaffe
 1860  make clean
 1861  make -j16 all && make -j4 pycaffe
 1862  make clean
 1863  make -j16 all && make -j4 pycaffe
 1864  make clean
 1865  make -j16 all && make -j4 pycaffe
 1866  make clean
 1867  make -j16 all && make -j4 pycaffe
 1868  make clean
 1869  make -j16 all && make -j4 pycaffe
 1870  make clean
 1871  make -j16 all && make -j4 pycaffe
 1872  make clean
 1873  make -j16 all && make -j4 pycaffe
 1874  make clean
 1875  make -j16 all && make -j4 pycaffe
 1876  make clean
 1877  make -j16 all && make -j4 pycaffe
 1878  cd ../scripts/
 1879  ls
 1880  pwd
 1881  source set_env.sh 
 1882  vim set_env.sh 
 1883  source set_env.sh 
 1884  python training.py --debug 
 1885  python training.py --debug =1
 1886  python training.py --debug =1 --solver_prototxt='net/train.prototxt'
 1887  python training.py --debug =1 --train_prototxt='net/train.prototxt'
 1888  python training.py --debug =1 --train_prototxt='net/train_kldloss_withouteuc.prototxt'
 1889  cd ..
 1890  cd Train/caffe-flownet/
 1891  make -j8 pycaffe
 1892  cd ..
 1893  cd scripts/
 1894  python training.py --debug =1 --train_prototxt='net/train_kldloss_withouteuc.prototxt'
 1895  cd ../caffe-flownet/
 1896  make clean
 1897  vim Makefile.config
 1898  make clean
 1899  make -j16 all && make pycaffe
 1900  cd ..
 1901  cd scripts/
 1902  python training.py --debug =1 --train_prototxt='net/train_kldloss_withouteuc.prototxt'
 1903  clear
 1904  export PYTHONPATH=../caffe-flownet/python:$PYTHONPATH
 1905  python training.py --train_prototxt='prototxt/train_kldloss.prototxt' --use_snapshot='../training_output/salicon/train_kldloss_withouteuc-batch-8_1509584263/snapshot-_iter_100000.solverstate' --batch=1
 1906  export CUDA_VISIBLE_DEVICES=6
 1907  python training.py --train_prototxt='prototxt/train_kldloss.prototxt' --use_snapshot='../training_output/salicon/train_kldloss_withouteuc-batch-8_1509584263/snapshot-_iter_100000.solverstate' --batch=1
 1908  nvidia-smi
 1909  export CUDA_VISIBLE_DEVICES=7
 1910  python training.py --train_prototxt='prototxt/train_kldloss.prototxt' --use_snapshot='../training_output/salicon/train_kldloss_withouteuc-batch-8_1509584263/snapshot-_iter_100000.solverstate' --batch=1
 1911  top
 1912  nvidia-smi
 1913  top
 1914  nvidia-smi
 1915  top
 1916  clear
 1917  top
 1918  nvidia-smi
 1919  free -h
 1920  top
 1921  nvidia-smi
 1922  cd pwd/saliency_on_videoset/Train/scripts/
 1923  source set_env.sh 
 1924  nvidia-smi
 1925  export CUDA_VISIBLE_DEVICES=7
 1926  python test_video.py --output_type='image' --model_code='v3' --video_base="/data/sunnycia/SaliencyDataset/Video/VideoSet"
 1927  top
 1928  clear
 1929  top
 1930  clear
 1931  ssh qiudan@172.31.234.248
 1932  source set_env.sh 
 1933  nvidia-smi
 1934  export CUDA_VISIBLE_DEVICES=5,6
 1935  python test_image.py 
 1936  python utils/video_image_type_converter.py --type='tomany' --basedir='/data/sunnycia/SaliencyDataset/Video/VideoSet/All_in_one/frame'
 1937  python utils/video_image_type_converter.py --type='toone' --basedir='/data/sunnycia/SaliencyDataset/Video/VideoSet/All_in_one/frame'
 1938  python utils/video_image_type_converter.py --type='tomany' --basedir='/data/sunnycia/SaliencyDataset/Video/VideoSet/All_in_one/frame'
 1939  python utils/video_image_type_converter.py --type='toone' --basedir='/data/sunnycia/SaliencyDataset/Video/VideoSet/All_in_one/frame'
 1940  python utils/video_image_type_converter.py --type='tomany' --basedir='/data/sunnycia/SaliencyDataset/Video/VideoSet/All_in_one/frame'
 1941  python utils/video_image_type_converter.py --basedir='/data/sunnycia/SaliencyDataset/Video/VideoSet/All_in_one/saliency' --type='tomany' --group=1
 1942  top
 1943  nvidia-smi
 1944  cd pwd/saliency_on_videoset/Train/scripts/
 1945  ls
 1946  python utils/visualization.py 
 1947  clear
 1948  python utils/visualization.py 
 1949  git status
 1950  git add --all
 1951  git commit -m "Video inference module"
 1952  git push -u origin master
 1953  python utils/visualization.py 
 1954  python metric/avg_metric.py 
 1955  python utils/visualization.py 
 1956  git status
 1957  git add --all
 1958  git commit -m "Done for v1 model inference and metric "
 1959  clear
 1960  python test_video.py 
 1961  python test_video.py --output_type='video' --model_code='v3'
 1962  python test_video.py --output_type='video' --model_code='v3' --video_base="/data/sunnycia/SaliencyDataset/Video/VideoSet"
 1963  export CUDA_VISIBLE_DEVICES=7
 1964  python test_video.py --output_type='video' --model_code='v3' --video_base="/data/sunnycia/SaliencyDataset/Video/VideoSet"
 1965  python utils/convert_2_all_in_one.py --basedir="/data/sunnycia/SaliencyDataset/Video/VideoSet/saliency_map/v3"
 1966  cler
 1967  clear
 1968  python metric/metric.py --dsname='videoset'
 1969  python metric/avg_metric.py 
 1970  nvidia-smi
 1971  python utils/scavenger.py 
 1972  ls -a utils
 1973  mv .py video_image_type_converter.py
 1974  cd utils && mv .py video_image_type_converter.py
 1975  cd ..
 1976  python utils/video_image_type_converter.py --basedir='/data/sunnycia/SaliencyDataset/Video/VideoSet/saliency_map/v3' --type='tomany'
 1977  python utils/video_image_type_converter.py --basedir='/data/sunnycia/SaliencyDataset/Video/VideoSet/saliency_map/v1' --type='tomany'
 1978  top
 1979  clear
 1980  python
 1981  cd /data/sunnycia/saliency_on_videoset/_Train/OMCNN_2CLSTM
 1982  python TestDemo.py 
 1983  top
 1984  nvidia-smi
 1985  python TestDemo.py 
 1986  pwd
 1987  python TestDemo.py 
 1988  top
 1989  nvidia-smi
 1990  top
 1991  free -h
 1992  clear
 1993  cd pwd/saliency_on_videoset/Train/
 1994  cd scripts/
 1995  python test_video.py 
 1996  nvidia-smi
 1997  export CUDA_VISIBLE_DEVICES=4
 1998  python test_video.py 
 1999  nvidia-smi
 2000  export CUDA_VISIBLE_DEVICES=4,5
 2001  python test_video.py 
 2002  source set_env.sh 
 2003  export CUDA_VISIBLE_DEVICES=4,5
 2004  python test_video.py 
 2005  clear
 2006  python test_video.py 
 2007  clear
 2008  python test_video.py 
 2009  clear
 2010  python test_video.py 
 2011  sudo apt-get purge nvidia* 
 2012  python test_video.py 
 2013  cd /data/sunnycia/SaliencyDataset/Video/VideoSet/ImageSet/frame
 2014  ffmpeg
 2015  ffmpeg -f image2 -i videoSRC001/frame%d.bmp -vcodec libx264 -r 100 -b 200k test.mp4
 2016  ffmpeg -f image2 -i videoSRC001/frame%d.bmp -vcodec libx264 -r 100 test.mp4
 2017  ffmpeg -f image2 -i videoSRC001/frame%d.bmp -vcodec libx264 -r 50 test.mp4
 2018  ffmpeg -f image2 -i videoSRC001/frame%d.bmp -vcodec libx264 -r 10 test.mp4
 2019  ffmpeg -f image2 -i videoSRC001/frame%d.bmp -vcodec libx264 -r 5 test.mp4
 2020  top
 2021  nvidia-smi
 2022  pwd
 2023  cd /data/sunnycia/saliency_on_videoset/_Train/OMCNN_2CLSTM
 2024  python TestDemo.py 
 2025  python
 2026  cd ~/pwd/saliency_on_videoset/
 2027  ls
 2028  cd _Utils/
 2029  ls
 2030  clear
 2031  cd metric_code/
 2032  ls
 2033  matlab -nodesktop
 2034  clear
 2035  cd pwd/saliency_on_videoset/Train/
 2036  ls
 2037  cd scripts/
 2038  ls
 2039  source set_env.sh 
 2040  nvidia-smi
 2041  export CUDA_VISIBLE_DEVICES=5,6
 2042  python test_video.py 
 2043  python test_video.py --output_type=image
 2044  python test_video.py --output_type="image"
 2045  python test_video.py --output_type="image" allinone=1
 2046  python test_video.py --output_type="image" --allinone=1
 2047  python test_video.py --output_type="image" --allinone=1 --video_base="/data/sunnycia/SaliencyDataset/Video/VideoSet"
 2048  cd /data/sunnycia/SaliencyDataset/Video/VideoSet/All_in_one
 2049  python
 2050  python change_name.py 
 2051  cd -
 2052  python metric/metric.py --ds_name='videoset' --debug=1
 2053  python metric/metric.py --dsname='videoset' --debug=1
 2054  cd -
 2055  python change_name.py 
 2056  cd -
 2057  python metric/metric.py --dsname='videoset' --debug=1
 2058  python metric/metric.py --dsname='videoset'
 2059  cler
 2060  clear
 2061  python metric/metric.py --dsname='videoset' --debug=1
 2062  python metric/metric.py --dsname='videoset'
 2063  clear
 2064  python metric/metric.py --dsname='videoset'
 2065  git status
 2066  git add --all
 2067  git commit -m "v3 model inference"
 2068  git push -u origin master
 2069  top
 2070  nvidia-smi
 2071  cd pwd/saliency_on_videoset/Train/scripts/
 2072  ls
 2073  python utils/copy_last_frame.py --videodir="/data/sunnycia/SaliencyDataset/Video/VideoSet/videos" --exttype="duplicate" --extlength=30 --outputdir="/data/sunnycia/SaliencyDataset/Video/VideoSet/ext_videos"
 2074  top
 2075  nvidia-smi
 2076  git status
 2077  git add --all
 2078  git commit -m "Copy last frame for video"
 2079  git push -u origin master
 2080  clear
 2081  python metric/avg_metric.py 
 2082  matlab
 2083  top
 2084  nvidia-smi
 2085  top
 2086  clear
 2087  clc
 2088  clear
 2089  python utils/analyse_vomodel_metric.py --metricdir="/data/sunnycia/saliency_on_videoset/novt_result/final/_Result_1_fc_6/train_kldloss-kld_weight-100-batch-1_1510102029_usesnapshot_1509584263_snapshot-_iter_100000" --plotdir="../analyse_vomodel"
 2090  python utils/analyse_vomodel_metric.py --metricdir="/data/sunnycia/saliency_on_videoset/novt_result/final/_Result_1_fc_6/v3" --plotdir="../analyse_vomodel"
 2091  python utils/analyse_vomodel_metric.py --metricdir="/data/sunnycia/saliency_on_videoset/novt_result/final/_Result_1_fc_6/SAM" --plotdir="../analyse_vomodel"
 2092  python utils/analyse_vomodel_metric.py --metricdir="/data/sunnycia/saliency_on_videoset/novt_result/final/_Result_1_fc_6/v3" --plotdir="../analyse_vomodel"
 2093  clear
 2094  python utils/analyse_vomodel_metric.py --metricdir="/data/sunnycia/saliency_on_videoset/novt_result/final/_Result_1_fc_6/v3" --plotdir="../analyse_vomodel"
 2095  clear
 2096  python utils/analyse_vomodel_metric.py --metricdir="/data/sunnycia/saliency_on_videoset/novt_result/final/_Result_1_fc_6/v3" --plotdir="../analyse_vomodel"
 2097  clear
 2098  python utils/analyse_vomodel_metric.py --metricdir="/data/sunnycia/saliency_on_videoset/novt_result/final/_Result_1_fc_6/v3" --plotdir="../analyse_vomodel"
 2099  python utils/analyse_vomodel_metric.py --metricdir="/data/sunnycia/saliency_on_videoset/novt_result/final/_Result_1_fc_6/sam" --plotdir="../analyse_vomodel"
 2100  python utils/analyse_vomodel_metric.py --metricdir="/data/sunnycia/saliency_on_videoset/novt_result/final/_Result_1_fc_6/SAM" --plotdir="../analyse_vomodel"
 2101  clear
 2102  python utils/analyse_vomodel_metric.py --metricdir="/data/sunnycia/saliency_on_videoset/novt_result/final/_Result_1_fc_6/SAM" --plotdir="../analyse_vomodel"
 2103  git status
 2104  python utils/VorI/combine_frames.py --framedir="/data/sunnycia/SaliencyDataset/Video/VideoSet/Results/saliency_map/image_model_result/train_kldloss-kld_weight-100-batch-1_1510102029_usesnapshot_1509584263_snapshot-_iter_100000" --outputdir='/data/sunnycia/SaliencyDataset/Video/VideoSet/Results/saliency_video/image_model_result/train_kldloss-kld_weight-100-batch-1_1510102029_usesnapshot_1509584263_snapshot-_iter_100000' --videolength=5 --resolution=(1920,1080)
 2105  python utils/VorI/combine_frames.py --framedir="/data/sunnycia/SaliencyDataset/Video/VideoSet/Results/saliency_map/image_model_result/train_kldloss-kld_weight-100-batch-1_1510102029_usesnapshot_1509584263_snapshot-_iter_100000" --outputdir='/data/sunnycia/SaliencyDataset/Video/VideoSet/Results/saliency_video/image_model_result/train_kldloss-kld_weight-100-batch-1_1510102029_usesnapshot_1509584263_snapshot-_iter_100000' --videolength=5 
 2106  python utils/blend_video.py --orivideodir='/data/sunnycia/SaliencyDataset/Video/VideoSet/Videos/videos_origin' --salvideodir='/data/sunnycia/SaliencyDataset/Video/VideoSet/Results/saliency_video/image_model_result/train_kldloss-kld_weight-100-batch-1_1510102029_usesnapshot_1509584263_snapshot-_iter_100000' --outputdir='/data/sunnycia/SaliencyDataset/Video/VideoSet/Videos/videos_blend_baseline' --weight=0.3
 2107  python utils/blend_video.py --orivideodir='/data/sunnycia/SaliencyDataset/Video/VideoSet/Videos/videos_origin' --salvideodir='/data/sunnycia/SaliencyDataset/Video/VideoSet/Results/saliency_video/image_model_result/train_kldloss-kld_weight-100-batch-1_1510102029_usesnapshot_1509584263_snapshot-_iter_100000' --outputdir='/data/sunnycia/SaliencyDataset/Video/VideoSet/Videos/videos_blend_baseline' --weight=0.3  clear
 2108  ccccccccccccccccc
 2109  clear
 2110  python utils/analyse_vomodel_metric.py --metricdir="/data/sunnycia/saliency_on_videoset/novt_result/final/_Result_1_fc_6/SAM" --outputbase="../analyse_vomodel"
 2111  git status
 2112  git add --all
 2113  python utils/analyse_vomodel_metric.py 
 2114  python utils/analyse_vomodel_metric.py --metricdir="/data/sunnycia/saliency_on_videoset/novt_result/final/_Result_1_fc_6/SAM" --outputbase="../analyse_vomodel"
 2115  clear
 2116  python utils/analyse_vomodel_metric.py --metricdir="/data/sunnycia/saliency_on_videoset/novt_result/final/_Result_1_fc_6/SAM" --outputbase="../analyse_vomodel"
 2117  python utils/metric_plot_video.py --metricdir='/data/sunnycia/saliency_on_videoset/novt_result/final/_Result_1_fc_6/train_kldloss-kld_weight-100-batch-1_1510102029_usesnapshot_1509584263_snapshot-_iter_100000' --outputdir='/data/sunnycia/saliency_on_videoset/Train/analyse_vomodel'
 2118  python utils/metric_plot_video.py --metricdir='/data/sunnycia/saliency_on_videoset/novt_result/final/_Result_1_fc_6/train_kldloss-kld_weight-100-batch-1_1510102029_usesnapshot_1509584263_snapshot-_iter_100000' --outputbase='/data/sunnycia/saliency_on_videoset/Train/analyse_vomodel'
 2119  python utils/analyse_vomodel_metric.py --metricdir="/data/sunnycia/saliency_on_videoset/novt_result/final/_Result_1_fc_6/SAM" --outputbase="../analyse_vomodel"
 2120  python utils/metric_plot_video.py --metricdir='/data/sunnycia/saliency_on_videoset/novt_result/final/_Result_1_fc_6/train_kldloss-kld_weight-100-batch-1_1510102029_usesnapshot_1509584263_snapshot-_iter_100000' --outputbase='/data/sunnycia/saliency_on_videoset/Train/analyse_vomodel'
 2121  claer
 2122  clear
 2123  python utils/metric_plot_video.py --metricdir='/data/sunnycia/saliency_on_videoset/novt_result/final/_Result_1_fc_6/train_kldloss-kld_weight-100-batch-1_1510102029_usesnapshot_1509584263_snapshot-_iter_100000' --outputbase='/data/sunnycia/saliency_on_videoset/Train/analyse_vomodel'
 2124  python utils/analyse_vomodel_metric.py --metricdir="/data/sunnycia/saliency_on_videoset/novt_result/final/_Result_1_fc_6/train_kldloss-kld_weight-100-batch-1_1510102029_usesnapshot_1509584263_snapshot-_iter_100000" --outputbase="../analyse_vomodel"
 2125  clear
 2126  python utils/analyse_vomodel_metric.py --metricdir="/data/sunnycia/saliency_on_videoset/novt_result/final/_Result_1_fc_6/train_kldloss-kld_weight-100-batch-1_1510102029_usesnapshot_1509584263_snapshot-_iter_100000" --outputbase="../analyse_vomodel"
 2127  clear
 2128  python utils/analyse_vomodel_metric.py --metricdir="/data/sunnycia/saliency_on_videoset/novt_result/final/_Result_1_fc_6/train_kldloss-kld_weight-100-batch-1_1510102029_usesnapshot_1509584263_snapshot-_iter_100000" --outputbase="../analyse_vomodel"
 2129  clear
 2130  python utils/analyse_vomodel_metric.py --metricdir="/data/sunnycia/saliency_on_videoset/novt_result/final/_Result_1_fc_6/train_kldloss-kld_weight-100-batch-1_1510102029_usesnapshot_1509584263_snapshot-_iter_100000" --outputbase="../analyse_vomodel"
 2131  git status 
 2132  git add --all
 2133  git commit -m "Done for jigsaw video visualization"
 2134  git push -u origin master
 2135  python
 2136  clear
 2137  top
 2138  nvidia-smi
 2139  top
 2140  python utils/metric_plot_video.py --metricdir='/data/sunnycia/saliency_on_videoset/_Metric_results/nopar/final/_Result_1_fc_6/train_kldloss-kld_weight-100-batch-1_1510102029_usesnapshot_1509584263_snapshot-_iter_100000' --outputbase='/data/sunnycia/saliency_on_videoset/Train/analyse_vomodel'
 2141  python utils/analyse_vomodel_metric.py --metricdir='/data/sunnycia/saliency_on_videoset/_Metric_results/nopar/final/_Result_1_fc_6/xu_dupext40' --outputbase='../analyse_vomodel'
 2142  python utils/metric_plot_video.py 
 2143  python utils/metric_plot_video.py --metricdir
 2144  python utils/metric_plot_video.py --metricdir='/data/sunnycia/saliency_on_videoset/_Metric_results/nopar/final/_Result_1_fc_6/xu_dupext40'
 2145  python utils/metric_plot_video.py --metricdir='/data/sunnycia/saliency_on_videoset/_Metric_results/nopar/final/_Result_1_fc_6/xu_dupext40' --outputbase='../analyse_vomodel'
 2146  python utils/VorI/combine_frames.py --framedir='/data/sunnycia/SaliencyDataset/Video/VideoSet/Results/saliency_map/video_model_result/xu_dupext40' --outputdir='/data/sunnycia/SaliencyDataset/Video/VideoSet/Results/saliency_video/video_model_result/xu_dupext40' --videolength=5 
 2147  cd /data/sunnycia/SaliencyDataset/Video/VideoSet/Results/saliency_map/image_model_result/SAM
 2148  python
 2149  python utils/analyse_vomodel_metric.py --metricdir='/data/sunnycia/saliency_on_videoset/_Metric_results/nopar/final/_Result_1_fc_6/SAM' --salvodir='/data/sunnycia/SaliencyDataset/Video/VideoSet/Results/saliency_video/image_model_result/SAM' --metvobase='/data/sunnycia/saliency_on_videoset/Train/analyse_vomodel/SAM' --outputbase='../all_visualization
 2150  '
 2151  python utils/analyse_vomodel_metric.py --metricdir='/data/sunnycia/saliency_on_videoset/_Metric_results/nopar/final/_Result_1_fc_6/SAM' --salvodir='/data/sunnycia/SaliencyDataset/Video/VideoSet/Results/saliency_video/image_model_result/SAM' --metvobase='/data/sunnycia/saliency_on_videoset/Train/analyse_vomodel/SAM' --outputbase='../all_visualization'
 2152  cd /data/sunnycia/saliency_on_videoset/Train/scripts
 2153  python utils/analyse_vomodel_metric.py --metricdir='/data/sunnycia/saliency_on_videoset/_Metric_results/nopar/final/_Result_1_fc_6/SAM' --salvodir='/data/sunnycia/SaliencyDataset/Video/VideoSet/Results/saliency_video/image_model_result/SAM' --metvobase='/data/sunnycia/saliency_on_videoset/Train/analyse_vomodel/SAM' --outputbase='../all_visualization'
 2154  cd utils/
 2155  ls
 2156  touch concat_videos.py
 2157  cd ..
 2158  python utils/concat_videos.py --videodir='/data/sunnycia/saliency_on_videoset/Train/analyse_vomodel/xu_dupext40/jud' --outputpath='../output.avi'
 2159  git status
 2160  git add --all
 2161  git commit -m "Add concat video function"
 2162  git push -m origin master
 2163  git push -u origin master
 2164  python utils/concat_videos.py --videodir='/data/sunnycia/saliency_on_videoset/Train/analyse_vomodel/xu_dupext40/jud' --outputpath='../output.avi' --randomorder=1
 2165  python utils/concat_videos.py --videodir='/data/sunnycia/saliency_on_videoset/Train/all_visualization/xu_dupext40/visualization/jud' --outputpath='../xulstm_jud.avi' --randomorder=1
 2166  python utils/concat_videos.py --videodir='/data/sunnycia/saliency_on_videoset/Train/all_visualization/xu_dupext40/visualization/sauc' --outputpath='../xulstm_sauc.avi' --randomorder=1
 2167  python utils/concat_videos.py --videodir='/data/sunnycia/saliency_on_videoset/Train/all_visualization/xu_dupext40/visualization/kld' --outputpath='../xulstm_kld.avi' --randomorder=1
 2168  python utils/concat_videos.py --videodir='/data/sunnycia/saliency_on_videoset/Train/all_visualization/xu_dupext40/visualization/nss' --outputpath='../xulstm_nss.avi' --randomorder=1
 2169  python utils/concat_videos.py --videodir='/data/sunnycia/saliency_on_videoset/Train/all_visualization/train_kldloss-kld_weight-100-batch-1_1510102029_usesnapshot_1509584263_snapshot-_iter_100000/visualization/nss' --outputpath='../propose_nss.avi' --randomorder=1
 2170  python utils/concat_videos.py --videodir='/data/sunnycia/saliency_on_videoset/Train/all_visualization/sam/visualization/nss' --outputpath='../sam_nss.avi' --randomorder=1
 2171  python utils/concat_videos.py --videodir='/data/sunnycia/saliency_on_videoset/Train/all_visualization/SAM/visualization/nss' --outputpath='../sam_nss.avi' --randomorder=1
 2172  python utils/concat_videos.py --videodir='/data/sunnycia/saliency_on_videoset/Train/all_visualization/SAM/visualization/kld' --outputpath='../sam_kld.avi' --randomorder=1
 2173  python utils/concat_videos.py --videodir='/data/sunnycia/saliency_on_videoset/Train/all_visualization/SAM/visualization/sauc' --outputpath='../sam_sauc.avi' --randomorder=1
 2174  python utils/concat_videos.py --videodir='/data/sunnycia/saliency_on_videoset/Train/all_visualization/SAM/visualization/jud' --outputpath='../sam_jud.avi' --randomorder=1
 2175  ls
 2176  vim ~/.bashrc
 2177  top
 2178  etop
 2179  top
 2180  clear
 2181  python
 2182  cd pwd/saliency_on_videoset/
 2183  cd _Train/OMCNN_2CLSTM/
 2184  ls
 2185  nvidia-smi
 2186  export CUDA_VISIBLE_DEVICES=6
 2187  python TestDemo.py 
 2188  python test.py --videodir='/data/sunnycia/SaliencyDataset/Video/VideoSet/videos' --ouptutdir='/data/sunnycia/SaliencyDataset/Video/VideoSet/saliency_video/xu' --outputtype='video'
 2189  python test.py --videodir='/data/sunnycia/SaliencyDataset/Video/VideoSet/videos' --outputdir='/data/sunnycia/SaliencyDataset/Video/VideoSet/saliency_video/xu' --outputtype='video'
 2190  top
 2191  nvidia-smi
 2192  top
 2193  pwd
 2194  python test.py --videodir='/data/sunnycia/SaliencyDataset/Video/VideoSet/ext_videos_cv2' --outputdir='/data/sunnycia/SaliencyDataset/Video/VideoSet/saliency_video/xu_dupext30" --outputtype="video"
 2195  python test.py --videodir='/data/sunnycia/SaliencyDataset/Video/VideoSet/ext_videos_cv2' --outputdir='/data/sunnycia/SaliencyDataset/Video/VideoSet/saliency_video/xu_dupext30' --outputtype="video"
 2196  nvidia-smi
 2197  export CUDA_VISIBLE_DEVICES=6
 2198  python test.py --videodir='/data/sunnycia/SaliencyDataset/Video/VideoSet/ext_videos_cv2' --outputdir='/data/sunnycia/SaliencyDataset/Video/VideoSet/saliency_video/xu_dupext30' --outputtype="video"
 2199  python test.py --videodir='/data/sunnycia/SaliencyDataset/Video/VideoSet/ext_videos_cv2' --outputdir='/data/sunnycia/SaliencyDataset/Video/VideoSet/saliency_map/xu_dupext30' --outputtype="image"
 2200  python test.py --videodir='/data/sunnycia/SaliencyDataset/Video/VideoSet/ext_videos_cv2' --outputdir='/data/sunnycia/SaliencyDataset/Video/VideoSet/saliency_map/xu_dupext40' --outputtype="image"
 2201  top
 2202  cd -
 2203  cd ~/pwd/saliency_on_videoset/Train/scripts/
 2204  ls
 2205  clear
 2206  cd 
 2207  cd /data/sunnycia/SaliencyDataset/Video/VideoSet/Videos
 2208  python rename.py 
 2209  top
 2210  nvidia-smi
 2211  cd /data/sunnycia/saliency_on_videoset/Train/scripts
 2212  git status
 2213  git add --all
 2214  git commit -m "add common util. add videl/frame level analysis module"
 2215  git push -u origin master
 2216  nvidia-smi
 2217  top
 2218  python utils/analyse_vomodel_metric.py --metricdir='/data/sunnycia/saliency_on_videoset/novt_result/final/_Result_1_fc_6/train_kldloss-kld_weight-100-batch-1_1510102029_usesnapshot_1509584263_snapshot-_iter_100000' --outputbase='../analyse_vomodel'
 2219  top
 2220  python utils/analyse_vomodel_metric.py --metricdir='/data/sunnycia/saliency_on_videoset/novt_result/final/_Result_1_fc_6/train_kldloss-kld_weight-100-batch-1_1510102029_usesnapshot_1509584263_snapshot-_iter_100000' --outputbase='../analyse_vomodel'
 2221  python utils/metric_plot_video.py --metricdir='/data/sunnycia/saliency_on_videoset/novt_result/final/_Result_1_fc_6/train_kldloss-kld_weight-100-batch-1_1510102029_usesnapshot_1509584263_snapshot-_iter_100000' --outputbase='../analyse_vomodel'
 2222  cd /data/sunnycia/saliency_on_videoset/_Train
 2223  git clone https://github.com/piiswrong/deep3d.git
 2224  df -h
 2225  top
 2226  cd /data/sunnycia/saliency_on_videoset/_Utils/metric_code
 2227  matlab -nodesktop
 2228  cd /data/sunnycia/saliency_on_videoset/Train/scripts
 2229  ls
 2230  python utils/metric_plot_video.py --metricdir='/data/sunnycia/saliency_on_videoset/_Metric_results/nopar/final/_Result_1_fc_6/xu_dupext40' --outputbase='../analyse_vomodel'
 2231  python utils/analyse_vomodel_metric.py --metricdir='/data/sunnycia/saliency_on_videoset/_Metric_results/nopar/final/_Result_1_fc_6/train_kldloss-kld_weight-100-batch-1_1510102029_usesnapshot_1509584263_snapshot-_iter_100000' --outputbase='../analyse_vomodel'
 2232  ls
 2233  python utils/VorI/combine_frames.py --framedir='/data/sunnycia/SaliencyDataset/Video/VideoSet/Results/saliency_map/image_model_result/SAM' --outputdir='/data/sunnycia/SaliencyDataset/Video/VideoSet/Results/saliency_video/image_model_result/SAM' --videolength=5
 2234   python utils/analyse_vomodel_metric.py --metricdir='/data/sunnycia/saliency_on_videoset/_Metric_results/nopar/final/_Result_1_fc_6/xu_dupext40' --salvodir='/data/sunnycia/SaliencyDataset/Video/VideoSet/Results/saliency_video/video_model_result/xu_dupext40' --metvobase='/data/sunnycia/saliency_on_videoset/Train/analyse_vomodel/xu_dupext40' --outputbase='../all_visualization' 
 2235   python utils/analyse_vomodel_metric.py --metricdir='/data/sunnycia/saliency_on_videoset/_Metric_results/nopar/final/_Result_1_fc_6/train_kldloss-kld_weight-100-batch-1_1510102029_usesnapshot_1509584263_snapshot-_iter_100000' --salvodir='/data/sunnycia/SaliencyDataset/Video/VideoSet/Results/saliency_video/image_model_result/train_kldloss-kld_weight-100-batch-1_1510102029_usesnapshot_1509584263_snapshot-_iter_100000' --metvobase='/data/sunnycia/saliency_on_videoset/Train/analyse_vomodel/train_kldloss-kld_weight-100-batch-1_1510102029_usesnapshot_1509584263_snapshot-_iter_100000' --outputbase='../all_visualization' 
 2236  clear
 2237  cd pwd/saliency_on_videoset/_Train/OMCNN_2CLSTM/
 2238  python test.py 
 2239  python test.py --videodir='/data/sunnycia/SaliencyDataset/Video/VideoSet/videos' --outputdir='/data/sunnycia/SaliencyDataset/Video/VideoSet/saliency_map/xu' --outputtype='image'
 2240  nvidia-smi
 2241  clear
 2242  export CUDA_VISIBLE_DEVICES=7
 2243  clear
 2244  python test.py --videodir='/data/sunnycia/SaliencyDataset/Video/VideoSet/videos' --outputdir='/data/sunnycia/SaliencyDataset/Video/VideoSet/saliency_map/xu' --outputtype='image'
 2245  clear
 2246  python test.py --videodir='/data/sunnycia/SaliencyDataset/Video/VideoSet/videos' --outputdir='/data/sunnycia/SaliencyDataset/Video/VideoSet/saliency_map/xu' --outputtype='image'
 2247  clear
 2248  python test.py --videodir='/data/sunnycia/SaliencyDataset/Video/VideoSet/videos' --outputdir='/data/sunnycia/SaliencyDataset/Video/VideoSet/saliency_map/xu' --outputtype='image'
 2249  python TestDemo.py 
 2250  cd ~/pwd/saliency_on_videoset/Train/
 2251  ls
 2252  cd scripts/
 2253  ls
 2254  git status
 2255  git add --all
 2256  git commit -m "routine submit"
 2257  git push -u origin master
 2258  python utils/copy_last_frame.py --videodir="/data/sunnycia/SaliencyDataset/Video/VideoSet/videos" --exttype="duplicate" --extlength=30 --outputdir"/data/sunnycia/SaliencyDataset/Video/VideoSet/ext_videos_cv2"
 2259  python utils/copy_last_frame.py --videodir="/data/sunnycia/SaliencyDataset/Video/VideoSet/videos" --exttype="duplicate" --extlength=30 --outputdir="/data/sunnycia/SaliencyDataset/Video/VideoSet/ext_videos_cv2"
 2260  python utils/copy_last_frame.py --videodir="/data/sunnycia/SaliencyDataset/Video/VideoSet/videos" --exttype="duplicate" --extlength=30 --outputdir"/data/sunnycia/SaliencyDataset/Video/VideoSet/ext_videos_cv2"
 2261  python utils/copy_last_frame.py --videodir="/data/sunnycia/SaliencyDataset/Video/VideoSet/videos" --exttype="duplicate" --extlength=30 --outputdir="/data/sunnycia/SaliencyDataset/Video/VideoSet/ext_videos_cv2"
 2262  python utils/copy_last_frame.py --videodir="/data/sunnycia/SaliencyDataset/Video/VideoSet/videos" --exttype="duplicate" --extlength=40 --outputdir="/data/sunnycia/SaliencyDataset/Video/VideoSet/ext_videos_cv2"
 2263  cd /data/sunnycia/saliency_on_videoset/_Utils
 2264  cd -
 2265  matlab -nodesktop
 2266  top
 2267  cd /data/sunnycia/SaliencyDataset/Image/MIT300
 2268  ls
 2269  unzip BenchmarkIMAGES.zip 
 2270  ls
 2271  cd BenchmarkIMAGES/
 2272  ls
 2273  cd pwd/saliency_on_videoset/Train/scripts/
 2274  git clone https://github.com/lmb-freiburg/flownet2.git
 2275  cp -R /data/sunnycia/saliency_on_videoset/_Train/flownet2 ./
 2276  cd flownet2/
 2277  git status
 2278  cd ../pymetric/
 2279  ls -a
 2280  cd ..
 2281  cd flownet2/
 2282  ls
 2283  history > history
 2284  python run-flownet.py ../models/FlowNet2/FlowNet2_weights.caffemodel.h5 ../models/FlowNet2/FlowNet2_deploy.prototxt.template frame5.jpg frame7.jpg output.flo
 2285  cd scripts/
 2286  python run-flownet.py ../models/FlowNet2/FlowNet2_weights.caffemodel.h5 ../models/FlowNet2/FlowNet2_deploy.prototxt.template frame5.jpg frame7.jpg output.flo
 2287  cd ..
 2288  ./set-env.sh 
 2289  cd scripts/
 2290  python run-flownet.py ../models/FlowNet2/FlowNet2_weights.caffemodel.h5 ../models/FlowNet2/FlowNet2_deploy.prototxt.template frame5.jpg frame7.jpg output.flo
 2291  python
 2292  cd ..
 2293  ./set-env.sh 
 2294  export PYTHONPATH="$CAFFE_PATH/python:$PYTHONPATH"
 2295  export PYTHONPATH="./python:$PYTHONPATH"
 2296  python
 2297  python run-flownet.py ../models/FlowNet2/FlowNet2_weights.caffemodel.h5 ../models/FlowNet2/FlowNet2_deploy.prototxt.template frame5.jpg frame7.jpg output.flo
 2298  cd scripts/
 2299  python run-flownet.py ../models/FlowNet2/FlowNet2_weights.caffemodel.h5 ../models/FlowNet2/FlowNet2_deploy.prototxt.template frame5.jpg frame7.jpg output.flo
 2300  cd ..
 2301  source set-env.sh 
 2302  cd scripts/
 2303  python run-flownet.py ../models/FlowNet2/FlowNet2_weights.caffemodel.h5 ../models/FlowNet2/FlowNet2_deploy.prototxt.template frame5.jpg frame7.jpg output.flo
 2304  python run-flownet.py ../models/FlowNet2/FlowNet2_weights.caffemodel.h5 ../models/FlowNet2/FlowNet2_deploy.prototxt.template frame4.bmp frame6.bmp output.flo
 2305  cd ..
 2306  cp -R flownet2/ ../
 2307  cd ..
 2308  cd caffe-flownet/
 2309  make clean
 2310  pwd
 2311  cd ../scripts/
 2312  python scavenger.py 
 2313  cd flownet2/
 2314  source set-env.sh 
 2315  cd scripts/
 2316  python run-flownet.py ../models/FlowNet2/FlowNet2_weights.caffemodel.h5 ../models/FlowNet2/FlowNet2_deploy.prototxt.template frame5.jpg frame7.jpg output.flo
 2317  cd /data/sunnycia/saliency_on_videoset/Train/scripts
 2318  python call_flownet.py 
 2319  cd flownet2/
 2320  source set-env.sh 
 2321  cd ..
 2322  python call_flownet.py 
 2323  source set_env.sh 
 2324  python call_flownet.py 
 2325  export CUDA_VISIBLE_DEVICES=0
 2326  python call_flownet.py 
 2327  git status
 2328  git add --all
 2329  git commit -m "Add flownet module, set environment variable"
 2330  git push -u origin master
 2331  git clone https://github.com/liruoteng/OpticalFlowToolkit.git
 2332  git status
 2333  git add --all 
 2334  git commit -m "clean my table. Something need to be modify later"
 2335  git push -u origin master
 2336  python call_flownet.py 
 2337  $PATH
 2338  python call_flownet.py 
 2339  git status
 2340  git add --all
 2341  git commit -m "Extract Saliencynet from test module, not check yet"
 2342  clear
 2343  export CUDA_VISIBLE_DEVICES=7
 2344  python training.py --train_prototxt='prototxt/train_kldloss.prototxt' --use_snapshot='../training_output/salicon/train_kldloss_withouteuc-batch-8_1509584263/snapshot-_iter_100000.solverstate' --batch=1
 2345  pwd
 2346  git status
 2347  git add --all
 2348  git commit -m "Video network version-2 on going"
 2349  git push -u origin master
 2350  clear
 2351  nvidia-smi
 2352  python utils/scavenger.py 
 2353  clear
 2354  python metric/metric.py --dsname='msu'
 2355  cd /data/sunnycia/SaliencyDataset/Video/VideoSet/All_in_one/saliency
 2356  ls
 2357  cd -
 2358  cd /data/sunnycia/saliency_on_videoset/_Utils/metric_code
 2359  matlab -nodesktop
 2360  matlab
 2361  matlab -nodesktop
 2362  cd /data/sunnycia/saliency_on_videoset/Train/scripts
 2363  ls
 2364  git status
 2365  python utils/metric_plot_video.py --metricdir='/data/sunnycia/saliency_on_videoset/_Metric_results/nopar/final/_Result_1_fc_6/SAM' --outputbase='/data/sunnycia/saliency_on_videoset/Train/analyse_vomodel'
 2366  python utils/analyse_vomodel_metric.py --metricdir='/data/sunnycia/saliency_on_videoset/_Metric_results/nopar/final/_Result_1_fc_6/SAM' --outputbase='../analyse_vomodel'
 2367  source set_env.sh 
 2368  nvidia-smi
 2369  export CUDA_VISIBLE_DEVICES=6
 2370  python test_image.py 
 2371  python utils/analyse_vomodel_metric.py --metricdir='/data/sunnycia/saliency_on_videoset/_Metric_results/nopar/final/_Result_1_fc_6/SAM' --salvodir='/data/sunnycia/SaliencyDataset/Video/VideoSet/Results/saliency_video/image_model_result/SAM' --metvobase='/data/sunnycia/saliency_on_videoset/Train/analyse_vomodel/SAM' --outputbase='../analyse_vomodel'
 2372  python utils/analyse_vomodel_metric.py --metricdir='/data/sunnycia/saliency_on_videoset/_Metric_results/nopar/final/_Result_1_fc_6/xu_dupext40' --salvodir='/data/sunnycia/SaliencyDataset/Video/VideoSet/Results/saliency_video/video_model_result/xu_dupext40' --metvobase='/data/sunnycia/saliency_on_videoset/Train/analyse_vomodel/xu_dupext40' --outputbase='../analyse_vomodel'
 2373  df -h
 2374  top
 2375  nvidia-smi
 2376  top
 2377  nvidia-smi
 2378  top
 2379  nvidia-smi
 2380  top
 2381  nvidia-smi
 2382  top
 2383  nvidia-smi
 2384  top
 2385  cd pwd/saliency_on_videoset/Train/scripts/
 2386  ls
 2387  git status
 2388  python metric/img2mat.py --help
 2389  python metric/img2mat.py --imgdir='/data/sunnycia/SaliencyDataset/Image/MIT1003/fixPts' --matdir='/data/sunnycia/SaliencyDataset/Image/MIT1003/fixPts-mat'
 2390  git status
 2391  git add --all
 2392  git commit -m "Clean code for metric 1. add function: img2mat"
 2393  git push -u origin master
 2394  git status
 2395  python metric/avg_metric.py --metricdir='../metric-matlab'
 2396  pwd
 2397  top
 2398  nvidia-smi
 2399  cd metric/l
 2400  cd metric/
 2401  ls
 2402  cd saliency/
 2403  ls
 2404  cd code_forOptimization/
 2405  ls
 2406  matlab 
 2407  cd ../..
 2408  cd ..
 2409  git status
 2410  git add --all
 2411  git commit -m "add metric for videoset data base. Special:fadopt frame_cut"
 2412  git push -u origin master
 2413  cd pwd/saliency_on_videoset/Train/scripts/
 2414  ls
 2415  python metric/avg_metric.py --metricdir='../metric-matlab'
 2416  history >history
 2417  clear
 2418  cd pwd/saliency_on_videoset/Train/
 2419  ls
 2420  cd scripts/
 2421  matlab -nodesktop
 2422  top
 2423  df -h
 2424  top
 2425  nvidia-smi
 2426  free -h
 2427  python test_image.py --testset='mit1003' --modelname='train_kldloss-dataset-bigunion-batch-8_1511876736_usesnapshot_1509584263_snapshot-_iter_100000' --iterselection='full'
 2428  export CUDA_VISIBLE_DEVICES=7
 2429  nvidia-smi
 2430  python test_image.py --testset='mit1003' --modelname='train_kldloss-dataset-bigunion-batch-8_1511876736_usesnapshot_1509584263_snapshot-_iter_100000' --iterselection='full'
 2431  clear
 2432  python test_image.py --testset='mit1003' --modelname='train_kldloss-dataset-bigunion-batch-8_1511876736_usesnapshot_1509584263_snapshot-_iter_100000' --iterselection='full'
 2433  matlab -nodesktop
 2434  clear 
 2435  clear
 2436  matlab -nodesktop
 2437  python metric/avg_metric.py 
 2438  python metric/avg_metric.py --metricdir='../metric-matlab'
 2439  python test_image.py --testset='mit1003' --modelname='train_kldloss-kld_weight-100-batch-1_1510102029_usesnapshot_1509584263_snapshot-_iter_100000' --iterselection='full'
 2440  matlab -nodesktop
 2441  top
 2442  nvidia-smi
 2443  top
 2444  free -h
 2445  cd pwd/saliency_on_videoset/
 2446  ls
 2447  cd Train/
 2448  ls
 2449  git clone https://github.com/chuckcho/video-caffe.git
 2450  cd video-caffe/
 2451  ls
 2452  cp Makefile.config.example Makefile.config
 2453  make -j4
 2454  ls /usr/lib/
 2455  make clean
 2456  mkdir build && cd build
 2457  cmake ..
 2458  cd ..
 2459  clear
 2460  make -j4
 2461  cd examples/c3d_ucf101/
 2462  ls
 2463  unrar
 2464  clear
 2465  cd /data/sunnycia/UCF101
 2466  unrar x UCF101.rar 
 2467  cd -
 2468  ls
 2469  clear
 2470  export CUDA_VISIBLE_DEVICES=7
 2471  nvidia-smi
 2472  bash extract_UCF-101_frames.sh 
 2473  cd /data/sunnycia/UCF-101/PlayingFlute/v_PlayingFlute_g18_c03
 2474  ls
 2475  cd -
 2476  cd /data/sunnycia/UCF-101/PlayingFlute/
 2477  ls
 2478  cd ..
 2479  cd -
 2480  rmdir 
 2481  rmdir --help
 2482  rmdir .
 2483  rmdir -p ./
 2484  pwd
 2485  cd /data/sunnycia/saliency_on_videoset/Train/video-caffe/examples/c3d_ucf101
 2486  bash extract_UCF-101_frames.sh 
 2487  top
 2488  nvidia-smi
 2489  top
 2490  topq
 2491  top
 2492  nvidia-smi
 2493  free -h
 2494  clear
 2495  cd pwd/saliency_on_videoset/Train/
 2496  cd scripts/
 2497  matlab -nodesktop
 2498  ls
 2499  python metric/metric.py --dsname='mit1003' --modelname='cb-train_kldloss-kld_weight-100-batch-1_1510102029_usesnapshot_1509584263_snapshot-_iter_100000'
 2500  python metric/avg_metric.py 
 2501  cd ../..
 2502  cd _Utils/metric_code/
 2503  matlab -nodesktop
 2504  pwd
 2505  cd ../..
 2506  cd Train/scripts/
 2507  cd utils/
 2508  ls
 2509  git clone https://github.com/cvzoya/saliency.git
 2510  ls
 2511  cd ..
 2512  ls
 2513  matlab
 2514  matlab -nodesktop
 2515  clear
 2516  matlab -nodekstop
 2517  clear
 2518  matlab -nodesktop
 2519  clear
 2520  matlab -nodesktop
 2521  clear
 2522  matlab -nodesktop
 2523  clear
 2524  matlab -nodesktop
 2525  clear
 2526  matlab -nodesktop
 2527  clear
 2528  matlab -nodesktop
 2529  clear
 2530  matlab -nodesktop
 2531  clear
 2532  python test_image.py --
 2533  nvidia-smi
 2534  export CUDA_VISIBLE_DEVICES=7
 2535  python test_image.py --train_prorotxt='train_kldloss.prototxt' --updatesolverdict={'lr_policy':'"step"','stepsize':'100000','gamma':'0.1'} --extrainfodict={'dataset':'bigunion'} --use_snapshot='../training_output/salicon/train_kldloss_withouteuc-batch-8_1509584263/snapshot-_iter_100000.solverstate' --batch=1 --dsname='bigunion' 
 2536  python test_image.py --train_prorotxt='train_kldloss.prototxt' --updatesolverdict='{'lr_policy':'"step"','stepsize':'100000','gamma':'0.1'}' --extrainfodict='{'dataset':'bigunion'}' --use_snapshot='../training_output/salicon/train_kldloss_withouteuc-batch-8_1509584263/snapshot-_iter_100000.solverstate' --batch=1 --dsname='bigunion' 
 2537  python test_image.py --train_prorotxt='train_kldloss.prototxt' --use_snapshot='../training_output/salicon/train_kldloss_withouteuc-batch-8_1509584263/snapshot-_iter_100000.solverstate' --batch=1 --dsname='bigunion' 
 2538  python test_image.py --train_prototxt='train_kldloss.prototxt' --use_snapshot='../training_output/salicon/train_kldloss_withouteuc-batch-8_1509584263/snapshot-_iter_100000.solverstate' --batch=1 --dsname='bigunion' 
 2539  python training_image.py --train_prototxt='train_kldloss.prototxt' --use_snapshot='../training_output/salicon/train_kldloss_withouteuc-batch-8_1509584263/snapshot-_iter_100000.solverstate' --batch=1 --dsname='bigunion' 
 2540  python training_image.py --train_prototxt='prototxt/train_kldloss.prototxt' --use_snapshot='../training_output/salicon/train_kldloss_withouteuc-batch-8_1509584263/snapshot-_iter_100000.solverstate' --batch=1 --dsname='bigunion' 
 2541  source set_env.sh 
 2542  export CUDA_VISIBLE_DEVICES=7
 2543  clear
 2544  python training_image.py --train_prototxt='prototxt/train_kldloss.prototxt' --use_snapshot='../training_output/salicon/train_kldloss_withouteuc-batch-8_1509584263/snapshot-_iter_100000.solverstate' --batch=1 --dsname='bigunion' 
 2545  python training_image.py --train_prototxt='prototxt/train_kldloss.prototxt' --use_snapshot='../training_output/salicon/train_kldloss_withouteuc-batch-8_1509584263/snapshot-_iter_100000.solverstate' --batch=1 --dsname='bigunion' --debug=1
 2546  clear
 2547  top
 2548  nvidia-smi
 2549  python metric/avg_metric.py 
 2550  python metric/avg_metric.py --metricdir='../metric-matlab'
 2551  df -h
 2552  top
 2553  nvidia-smi
 2554  clear
 2555  cd /data//sunnycia/SaliencyDataset/Video/MSU/
 2556  ls
 2557  cd frames_allinone/
 2558  ls F*
 2559  ls A*
 2560  ls a*
 2561  ls
 2562  clear
 2563  cp * /data/sunnycia/SaliencyDataset/Image/Combine_salicon_msu_nus_cat2000_videoset/Image/
 2564  cd /data/sunnycia/SaliencyDataset/Image/SALICON/DATA
 2565  ls
 2566  cd images
 2567  ls *
 2568  clear
 2569  cp * /data/sunnycia/SaliencyDataset/Image/Combine_salicon_msu_nus_cat2000_videoset/Image
 2570  cd ..
 2571  ls
 2572  cd train_val/
 2573  ls
 2574  cd train2014/
 2575  ls
 2576  pwd
 2577  ls
 2578  cd images/
 2579  cp * /data/sunnycia/SaliencyDataset/Image/Combine_salicon_msu_nus_cat2000_videoset/Image/
 2580  cd ../..
 2581  ls
 2582  cd val2014/
 2583  ls
 2584  cd images/
 2585  cp * /data/sunnycia/SaliencyDataset/Image/Combine_salicon_msu_nus_cat2000_videoset/Image
 2586  cd ..
 2587  ls
 2588  cd density/
 2589  cp * /
 2590  cp * /data/sunnycia/SaliencyDataset/Image/Combine_salicon_msu_nus_cat2000_videoset/Density
 2591  pwd
 2592  cd ../../train2014/density/
 2593  cp * /data/sunnycia/SaliencyDataset/Image/Combine_salicon_msu_nus_cat2000_videoset/Density
 2594  cd ..
 2595  cd /home/sunnycia/pwd/saliency_on_videoset/Train/scripts
 2596  ls
 2597  clear
 2598  claer
 2599  source set_env.sh 
 2600  nvidia-smi
 2601  export CUDA_VISIBLE_DEVICES=6
 2602  history > history.txt 
 2603  python training_image.py --train_prototxt='prototxt/train_kldloss.prototxt' --use_snapshot='../training_output/alicon/train_kldloss_withouteuc-batch-8_1509584263/snapshot-_iter_100000.solverstate' --batch=8 --dsname='bigunion' --debug=True
 2604  python training_image.py --train_prototxt='prototxt/train_kldloss.prototxt' --use_snapshot='../training_output/salicon/train_kldloss_withouteuc-batch-8_1509584263/snapshot-_iter_100000.solverstate' --batch=8 --dsname='bigunion' --debug=True
 2605  python training_image.py --train_prototxt='prototxt/train_kldloss.prototxt' --use_snapshot='../training_output/salicon/train_kldloss_withouteuc-batch-8_1509584263/snapshot-_iter_100000.solverstate' --batch=8 --dsname='bigunion'
 2606  cd pwd/saliency_on_videoset/Train/scripts/
 2607  ls
 2608  history > history
 2609  python test_image.py 
 2610  clear
 2611  top
 2612  python test_image.py --modelname='train_kldloss-dataset-bigunion-batch-8_1511876736_usesnapshot_1509584263_snapshot-_iter_100000' 
 2613  python test_image.py --modelname='train_kldloss-dataset-bigunion-batch-8_1511876736_usesnapshot_1509584263_snapshot-_iter_100000'  --testset='mit1003'
 2614  nvidia-smi
 2615  export CUDA_VISIBLE_DEVICES=7
 2616  python test_image.py --modelname='train_kldloss-dataset-bigunion-batch-8_1511876736_usesnapshot_1509584263_snapshot-_iter_100000'  --testset='mit1003'
 2617  ls
 2618  pwd
 2619  matlab
 2620  matlab -nodesktop
 2621  clear
 2622  ls -l /data/sunnycia/SaliencyDataset/Image/MIT1003/saliency
 2623  cd metric/
 2624  matlab -nodesktop
 2625  clear
 2626  cd pwd/saliency_on_videoset/Train/
 2627  ls
 2628  cd scripts/
 2629  history >history
 2630  cd /data/sunnycia/saliency_on_videoset/Train/scripts/utils/OpticalFlowToolkit/data/example/Middlebury
 2631  matlab
 2632  cd pwd/saliency_on_videoset/Train/scripts/
 2633  source set_env.sh 
 2634  nvidia-smi
 2635  export CUDA_VISIBLE_DEVICES=6
 2636  clear
 2637  python training_video.py --train_prototxt='prototxt/vo-v1_train_kldloss_withouteuc.prototxt' --use_model='../training_output/salicon/train_kldloss_withouteuc-batch-8_1509584263/snapshot-_iter_100000.caffemodel'
 2638  python training_video_c3d_based.py --train_prototxt='prototxt/vo-v1_train_kldloss_withouteuc.prototxt' --use_model='../training_output/salicon/train_kldloss_withouteuc-batch-8_1509584263/snapshot-_iter_100000.caffemodel'
 2639  top
 2640  nvidia-smi
 2641  clear
 2642  pwd
 2643  cd ..
 2644  ls
 2645  git clone https://github.com/facebook/C3D.git
 2646  cd C3D/
 2647  ls
 2648  cd C3D-v1.1/
 2649  ls
 2650  cd examples/
 2651  ls
 2652  cd c3d_ucf101_finetuning/
 2653  ls
 2654  vim finetuning_ucf101.sh 
 2655  pwd
 2656  cd ../..
 2657  ls
 2658  cp Makefile.config.example Makefile.config
 2659  make -j8 all
 2660  make pycaffe
 2661  cd -
 2662  ls
 2663  clear
 2664  ls
 2665  bash finetuning_ucf101.sh 
 2666  clear
 2667  top
 2668  nvidia-smi
 2669  cd pwd/saliency_on_videoset/Train/scripts/
 2670  source set_env.sh 
 2671  export CUDA_VISIBLE_DEVICES=6
 2672  python training_video_framestack_based.py --train_prototxt='prototxt/vo-v3_train_kldloss_withouteuc.prototxt' --use_model='../training_output/salicon/train_kldloss_withouteuc-batch-8_1509584263/snapshot-_iter_100000.caffemodel'
 2673  clear
 2674  top
 2675  nvidia-smi
 2676  cd pwd/saliency_on_videoset/Train/
 2677  cd video-caffe/
 2678  tools/extra/plot_training_loss.sh 
 2679  tools/extra/plot_training_loss.sh examples/c3d_ucf101/c3d_ucf101_train.log 
 2680  top
 2681  nvidia-smi
 2682  cd ..
 2683  cd scripts/
 2684  python training_video_framestack_based.py --train_prototxt='prototxt/vo-v3_train_kldloss_withouteuc.prototxt' --use_model='../training_output/salicon/train_kldloss_withouteuc-batch-8_1509584263/snapshot-_iter_100000.caffemodel' 
 2685  export CUDA_VISIBLE_DEVICES=6
 2686  python training_video_framestack_based.py --train_prototxt='prototxt/vo-v3_train_kldloss_withouteuc.prototxt' --use_model='../training_output/salicon/train_kldloss_withouteuc-batch-8_1509584263/snapshot-_iter_100000.caffemodel' 
 2687  source set_env.sh 
 2688  export CUDA_VISIBLE_DEVICES=6
 2689  python training_video_framestack_based.py --train_prototxt='prototxt/vo-v3_train_kldloss_withouteuc.prototxt' --use_model='../training_output/salicon/train_kldloss_withouteuc-batch-8_1509584263/snapshot-_iter_100000.caffemodel' 
 2690  clear
 2691  clear
 2692  cd pwd/saliency_on_videoset/Train/scripts/
 2693  source set_env.sh 
 2694  nvidia-smi
 2695  top
 2696  export CUDA_VISIBLE_DEVICES=6
 2697  pwd
 2698  python training_video_framestack_based.py --train_prototxt='prototxt/vo-v3_train_kldloss_withouteuc.prototxt' --use_model='../training_output/salicon/train_kldloss_withouteuc-batch-8_1509584263/snapshot-_iter_100000.caffemodel' 
 2699  export CUDA_VISIBLE_DEVICES=6
 2700  clear
 2701  python training_video_framestack_based.py --train_prototxt='prototxt/vo-v3_train_kldloss_withouteuc.prototxt' --use_model='../training_output/salicon/train_kldloss_withouteuc-batch-8_1509584263/snapshot-_iter_100000.caffemodel' 
 2702  top
 2703  nvidia-smi
 2704  top
 2705  nvidia-smi
 2706  top
 2707  clear
 2708  cd /data/sunnycia/SaliencyDataset/Video/LEDOV/LEDOV
 2709  matlab 
 2710  top
 2711  nvidia-smi
 2712  cd pwd/saliency_on_videoset/_Train/
 2713  ls
 2714  cd ../Train/
 2715  ls
 2716  cd video-caffe/
 2717  ls
 2718  make -j4
 2719  make pycaffe
 2720  ls
 2721  cd examples/
 2722  ls
 2723  cd c3d_ucf101/
 2724  ls
 2725  pwd
 2726  export CUDA_VISIBLE_DEVICES=7
 2727  cd ../..
 2728  examples/c3d_ucf101/train_ucf101.sh
 2729  ./build/tools/caffe
 2730  ./build/tools/caffe   train   --solver=examples/c3d_ucf101/c3d_ucf101_solver.prototxt   $@   2>&1 | tee examples/c3d_ucf101/c3d_ucf101_train.log
 2731  make clean
 2732  top
 2733  nvidia-smi
 2734  make -j8 all
 2735  ./build/tools/caffe   train   --solver=examples/c3d_ucf101/c3d_ucf101_solver.prototxt   $@   2>&1 | tee examples/c3d_ucf101/c3d_ucf101_train.log
 2736  cd /data/sunnycia/saliency_on_videoset/Train/scripts/prototxt
 2737  ls
 2738  cd .
 2739  cd ..
 2740  clear
 2741  git status
 2742  git add --all
 2743  git status
 2744  git commit -m "FIX BUG:V3 model bug"
 2745  git push -u origin master
 2746  history > history
 2747  source set_env.sh 
 2748  clear
 2749  nvidia-smi
 2750  export CUDA_VISIBLE_DEVICES=7
 2751  clear
 2752  python training_video_framestack_based.py --train_prototxt='prototxt/vo-v3_kldloss_withouteuc.prototxt' --use_model='../training_output/salicon/train_kldloss_withouteuc-batch-8_1509584263/snapshot-_iter_100000.caffemodel'
 2753  python training_video_framestack_based.py --train_prototxt='prototxt/vo-v3_train_kldloss_withouteuc.prototxt' --use_model='../training_output/salicon/train_kldloss_withouteuc-batch-8_1509584263/snapshot-_iter_100000.caffemodel'
 2754  clear
 2755  python training_video_framestack_based.py --train_prototxt='prototxt/vo-v3_train_kldloss_withouteuc.prototxt' --use_model='../training_output/salicon/train_kldloss_withouteuc-batch-8_1509584263/snapshot-_iter_100000.caffemodel'
 2756  cler
 2757  clear
 2758  python training_video_framestack_based.py --train_prototxt='prototxt/vo-v3_train_kldloss_withouteuc.prototxt' --use_model='../training_output/salicon/train_kldloss_withouteuc-batch-8_1509584263/snapshot-_iter_100000.caffemodel'
 2759  clear
 2760  python training_video_framestack_based.py --train_prototxt='prototxt/vo-v3_train_kldloss_withouteuc.prototxt' --use_model='../training_output/salicon/train_kldloss_withouteuc-batch-8_1509584263/snapshot-_iter_100000.caffemodel'
 2761  to
 2762  top
 2763  nvidia-smi
 2764  clear
 2765  top
 2766  nvidia-smi
 2767  cd pwd/saliency_on_videoset/Train/scripts/
 2768  ls
 2769  git status
 2770  git add --all
 2771  git commit -m "Debug stack based v3 training process. add stack8/16 network prototxt"
 2772  git push -u origin master
 2773  clera
 2774  clear
 2775  top
 2776  nvidia-smi
 2777  top
 2778  python training_video_framestack_based.py --train_prototxt='prototxt/vo-v3_train_kldloss_withouteuc.prototxt' --use_model='../training_output/salicon/train_kldloss_withouteuc-batch-8_1509584263/snapshot-_iter_100000.caffemodel'
 2779  nvidia-smi
 2780  python training_video_framestack_based.py --train_prototxt='prototxt/vo-v3_train_kldloss_withouteuc.prototxt' --use_model='../training_output/salicon/train_kldloss_withouteuc-batch-8_1509584263/snapshot-_iter_100000.caffemodel'
 2781  nvidia-smi
 2782  cd pwd/saliency_on_videoset/Train/scripts/
 2783  ls
 2784  source set_env.sh 
 2785  ls
 2786  export CUDA_VISIBLE_DEVICES=7
 2787  ls
 2788  clear
 2789  python training_video_framestack_based.py --train_prototxt='prototxt/vo-v3_train_kldloss_withouteuc_stack8.prototxt' --use_model='../training_output/salicon/train_kldloss_withouteuc-batch-8_1509584263/snapshot-_iter_100000.caffemodel' --keyframeinterv=8
 2790  top
 2791  nvidia-smi
 2792  top
 2793  nvidia-smi
 2794  export CUDA_VISIBLE_DEVICES=4
 2795  cd pwd/saliency_on_videoset/Train/scripts/
 2796  source set_env.sh 
 2797  export CUDA_VISIBLE_DEVICES=4
 2798  clear
 2799  python python training_video_framestack_based.py --train_prototxt='prototxt/vo-v3_train_kldloss_withouteuc.prototxt' --use_model='../training_output/salicon/train_kldloss_withouteuc-batch-8_1509584263/snapshot-_iter_100000.caffemodel' --imagesize=(480,288) --keyframeinterv=16
 2800  python training_video_framestack_based.py --train_prototxt='prototxt/vo-v3_train_kldloss_withouteuc.prototxt' --use_model='../training_output/salicon/train_kldloss_withouteuc-batch-8_1509584263/snapshot-_iter_100000.caffemodel' --imagesize=(480,288) --keyframeinterv=16
 2801  python training_video_framestack_based.py --train_prototxt='prototxt/vo-v3_train_kldloss_withouteuc.prototxt' --use_model='../training_output/salicon/train_kldloss_withouteuc-batch-8_1509584263/snapshot-_iter_100000.caffemodel' --keyframeinterv=16
 2802  clear
 2803  python training_video_framestack_based.py --train_prototxt='prototxt/vo-v3_train_kldloss_withouteuc_stack16.prototxt' --use_model='../training_output/salicon/train_kldloss_withouteuc-batch-8_1509584263/snapshot-_iter_100000.caffemodel' --keyframeinterv=16
 2804  python training_video_framestack_based.py --train_prototxt='prototxt/vo-v3_train_kldloss_withouteuc_stack16.prototxt' --use_model='../training_output/salicon/train_kldloss_withouteuc-batch-8_1509584263/snapshot-_iter_100000.caffemodel' --keyframeinterv=8
 2805  export CUDA_VISIBLE_DEVICES=7
 2806  python training_video_framestack_based.py --train_prototxt='prototxt/vo-v3_train_kldloss_withouteuc_stack16.prototxt' --use_model='../training_output/salicon/train_kldloss_withouteuc-batch-8_1509584263/snapshot-_iter_100000.caffemodel' --keyframeinterv=8
 2807  python training_video_framestack_based.py --train_prototxt='prototxt/vo-v3_train_kldloss_withouteuc_stack16.prototxt' --use_model='../training_output/salicon/train_kldloss_withouteuc-batch-8_1509584263/snapshot-_iter_100000.caffemodel' --keyframeinterv=16
 2808  git status 
 2809  git add --all 
 2810  git commit -m "Done for v4-1. set_env.sh add argument. Done for C3D training scripts"
 2811  git push -u origin master
 2812  top
 2813  clear
 2814  cd pwd/saliency_on_videoset/Train/scripts/
 2815  source set_env.sh 
 2816  python training_video_framestack_based.py --train_prototxt='prototxt/vo-v3_train_kldloss_withouteuc.prototxt' --use_model='../training_output/salicon/train_kldloss_withouteuc-batch-8_1509584263/snapshot-_iter_100000.caffemodel'
 2817  export CUDA_VISIBLE_DEVICES=6
 2818  nvidia-smi
 2819  export CUDA_VISIBLE_DEVICES=7
 2820  clear
 2821  python training_video_framestack_based.py --train_prototxt='prototxt/vo-v3_train_kldloss_withouteuc.prototxt' --use_model='../training_output/salicon/train_kldloss_withouteuc-batch-8_1509584263/snapshot-_iter_100000.caffemodel'
 2822  clear
 2823  python training_video_framestack_based.py --train_prototxt='prototxt/vo-v3_train_kldloss_withouteuc.prototxt' --use_model='../training_output/salicon/train_kldloss_withouteuc-batch-8_1509584263/snapshot-_iter_100000.caffemodel'
 2824  clear
 2825  python training_video_framestack_based.py --train_prototxt='prototxt/vo-v3_train_kldloss_withouteuc.prototxt' --use_model='../training_output/salicon/train_kldloss_withouteuc-batch-8_1509584263/snapshot-_iter_100000.caffemodel'
 2826  clear
 2827  python training_video_framestack_based.py --train_prototxt='prototxt/vo-v3_train_kldloss_withouteuc.prototxt' --use_model='../training_output/salicon/train_kldloss_withouteuc-batch-8_1509584263/snapshot-_iter_100000.caffemodel'
 2828  clear
 2829  clera
 2830  clear
 2831  python training_video_framestack_based.py --train_prototxt='prototxt/vo-v3_train_kldloss_withouteuc.prototxt' --use_model='../training_output/salicon/train_kldloss_withouteuc-batch-8_1509584263/snapshot-_iter_100000.caffemodel'
 2832  clear
 2833  python training_video_framestack_based.py --train_prototxt='prototxt/vo-v3_train_kldloss_withouteuc.prototxt' --use_model='../training_output/salicon/train_kldloss_withouteuc-batch-8_1509584263/snapshot-_iter_100000.caffemodel'
 2834  ffprobe
 2835  clear
 2836  cd pwd/saliency_on_videoset/Train/scripts/
 2837  ls
 2838  git status
 2839  git add --all
 2840  git commit -m "add c3d dataset interface(not finish yet)"
 2841  git push -u origin master
 2842  clear
 2843  cd ..
 2844  ls
 2845  git clone python
 2846  python
 2847  pip3
 2848  ls /usr/local/bin/
 2849  clear
 2850  pip3
 2851  clear
 2852  pip3 install http://download.pytorch.org/whl/cu80/torch-0.3.0.post4-cp35-cp35m-linux_x86_64.whl 
 2853  git clone https://github.com/kenshohara/video-classification-3d-cnn-pytorch.git
 2854  ls
 2855  ls -l
 2856  pip3 install http://download.pytorch.org/whl/cu80/torch-0.3.0.post4-cp35-cp35m-linux_x86_64.whl 
 2857  pip install --upgrade pip
 2858  pip3 install --upgrade pip3
 2859  pip3 install http://download.pytorch.org/whl/cu80/torch-0.3.0.post4-cp35-cp35m-linux_x86_64.whl 
 2860  pip
 2861  clear
 2862  pip3
 2863  clear
 2864  ls .pip
 2865  ls ~/.pip
 2866  pip
 2867  cd scripts/
 2868  sl
 2869  ls
 2870  cd ../video-caffe/examples/c3d_ucf101/
 2871  ls
 2872  pwd
 2873  ./train_ucf101.sh 
 2874  cd ../..
 2875  ./examples/c3d_ucf101/train_ucf101.sh 
 2876  nvidia-smi
 2877  top
 2878  clear
 2879  export CUDA_VISIBLE_DEVICES=6
 2880  ./examples/c3d_ucf101/train_ucf101.sh 
 2881  cd pwd/saliency_on_videoset/Train/scripts/
 2882  history > history
 2883  nvidia-smi
 2884  cd pwd/saliency_on_videoset/Train/scripts/
 2885  source set_env.sh ../video-caffe/
 2886  export CUDA_VISIBLE_DEVICES=4
 2887  python training_video_c3d_based.py  --train_prototxt='prototxt/vo-v4.prototxt' --batch=25 --solver_prototxt='prototxt/solver-static.prototxt' --staticsolver=1
 2888  python training_video_c3d_based.py  --train_prototxt='prototxt/vo-v4-1.prototxt' --batch=25 --solver_prototxt='prototxt/solver-static.prototxt' --staticsolver=1
 2889  cd pwd/saliency_on_videoset/Train/scripts/
 2890  clear
 2891  source set_env.sh ../video-caffe/
 2892  nvidia-smi
 2893  export CUDA_VISIBLE_DEVICES=4
 2894  export CUDA_VISIBLE_DEVICES=6
 2895  python training_video_c3d_based.py --train_prototxt='prototxt/vo-v4-2.prototxt' --batch=20 --lastlayer='fc9'
 2896  python training_video_c3d_based.py --train_prototxt='prototxt/vo-v4-2.prototxt' --batch=10 --lastlayer='fc9'
 2897  python training_video_c3d_based.py --train_prototxt='prototxt/vo-v4-2.prototxt' --batch=20
 2898  python training_video_c3d_based.py --train_prototxt='prototxt/vo-v4-2.prototxt' --batch=10
 2899  python training_video_c3d_based.py --train_prototxt='prototxt/vo-v4-2.prototxt' --batch=5
 2900  export CUDA_VISIBLE_DEVICES=6
 2901  python training_video_c3d_based.py --train_prototxt='prototxt/vo-v4-2.prototxt' --batch=2 --plot_iter=20
 2902  python training_video_c3d_based.py --train_prototxt='prototxt/vo-v4-2.prototxt' --batch=2 --plotiter=20
 2903  python training_video_c3d_based.py --train_prototxt='prototxt/vo-v4-2.prototxt' --batch=1 --plotiter=40
 2904  source set_env.sh ../caffe-flownet/
 2905  export CUDA_VISIBLE_DEVICES=6
 2906  clear
 2907  python training_video_framestack_based.py --train_prototxt='prototxt/vo-v3_train_kldloss_withouteuc.prototxt' --use_model='../training_output/salicon/train_kldloss_withouteuc-batch-8_1509584263/snapshot-_iter_100000.caffemodel' 
 2908  top
 2909  nvidia-smi
 2910  clear
 2911  cd pwd/saliency_on_videoset/Train/scripts/
 2912  th
 2913  clear
 2914  source set_env.sh 
 2915  python test_video.py --output_type='video' --model_code='v3' --video_base="/data/sunnycia/SaliencyDataset/Video/VideoSet" --video_model_path='/data/sunnycia/saliency_on_videoset/Train/training_output/salicon/vo-v3_train_kldloss_withouteuc-batch-1_1512487825/snapshot-_iter_100000.caffemodel' --framestack=5 
 2916  nvidia-smi
 2917  clear
 2918  export CUDA_VISIBLE_DEVICES=3
 2919  nvidia-smi
 2920  python test_video.py --output_type='video' --model_code='v3' --video_base="/data/sunnycia/SaliencyDataset/Video/VideoSet" --video_model_path='/data/sunnycia/saliency_on_videoset/Train/training_output/salicon/vo-v3_train_kldloss_withouteuc-batch-1_1512487825/snapshot-_iter_100000.caffemodel' --framestack=5 
 2921  clear
 2922  python test_video.py --output_type='video' --model_code='v3' --video_base="/data/sunnycia/SaliencyDataset/Video/VideoSet" --video_model_path='/data/sunnycia/saliency_on_videoset/Train/training_output/salicon/vo-v3_train_kldloss_withouteuc-batch-1_1512487825/snapshot-_iter_100000.caffemodel' --framestack=5 
 2923  python test_video.py --output_type='video' --model_code='v3' --video_base="/data/sunnycia/SaliencyDataset/Video/VideoSet/Videos/videos_origin" --test_base='videoset' --video_model_path='/data/sunnycia/saliency_on_videoset/Train/training_output/salicon/vo-v3_train_kldloss_withouteuc-batch-1_1512487825/snapshot-_iter_100000.caffemodel' --framestack=5 
 2924  clear
 2925  python test_video.py --output_type='video' --model_code='v3' --video_base="/data/sunnycia/SaliencyDataset/Video/VideoSet/Videos/videos_origin" --test_base='videoset' --video_model_path='/data/sunnycia/saliency_on_videoset/Train/training_output/salicon/vo-v3_train_kldloss_withouteuc-batch-1_1512487825/snapshot-_iter_100000.caffemodel' --framestack=5 
 2926  python test_video.py --output_type='video' --model_code='v3' --video_base="/data/sunnycia/SaliencyDataset/Video/VideoSet/Videos/videos_origin" --test_base='videoset' --video_model_path='/data/sunnycia/saliency_on_videoset/Train/training_output/salicon/vo-v3_train_kldloss_withouteuc-batch-1_1512487825/snapshot-_iter_150000.caffemodel' --framestack=5 
 2927  python test_video.py --output_type='video' --model_code='v3' --video_base="/data/sunnycia/SaliencyDataset/Video/VideoSet/Videos/videos_origin" --test_base='videoset' --video_model_path='/data/sunnycia/saliency_on_videoset/Train/training_output/salicon/vo-v3_train_kldloss_withouteuc-batch-1_1512487825/snapshot-_iter_150000.caffemodel' --framestack=5  &
 2928  python test_video.py --output_type='video' --model_code='v3' --video_base="/data/sunnycia/SaliencyDataset/Video/VideoSet/Videos/videos_origin" --test_base='videoset' --video_model_path='/data/sunnycia/saliency_on_videoset/Train/training_output/salicon/vo-v3_train_kldloss_withouteuc-batch-1_1512487825/snapshot-_iter_150000.caffemodel' --framestack=5
 2929  clear
 2930  python utils/weight_visualization.py --model='/data/sunnycia/saliency_on_videoset/Train/training_output/salicon/vo-v3_train_kldloss_withouteuc_stack16-batch-1_1512533810/snapshot-_iter_50000.caffemodel' --deploy='/data/sunnycia/saliency_on_videoset/Train/scripts/prototxt/vo-v3-16_deploy.prototxt
 2931  python utils/weight_visualization.py --model='/data/sunnycia/saliency_on_videoset/Train/training_output/salicon/vo-v3_train_kldloss_withouteuc_stack16-batch-1_1512533810/snapshot-_iter_50000.caffemodel' --deploy='/data/sunnycia/saliency_on_videoset/Train/scripts/prototxt/vo-v3-16_deploy.prototxt' --output='./'
 2932  python utils/weight_visualization.py --model='/data/sunnycia/saliency_on_videoset/Train/training_output/salicon/vo-v3_train_kldloss_withouteuc_stack16-batch-1_1512533810/snapshot-_iter_50000.caffemodel' --deploy='/data/sunnycia/saliency_on_videoset/Train/scripts/prototxt/vo-v3-16_deploy.prototxt' --output='./' --layer='conv1_new'
 2933  python utils/weight_visualization.py --model='/data/sunnycia/saliency_on_videoset/Train/training_output/salicon/vo-v3_train_kldloss_withouteuc_stack16-batch-1_1512533810/snapshot-_iter_50000.caffemodel' --deploy='/data/sunnycia/saliency_on_videoset/Train/scripts/prototxt/vo-v3-16_deploy.prototxt' --output='./output.jpg' --layer='conv1_new'
 2934  python utils/weight_visualization.py --model='/data/sunnycia/saliency_on_videoset/Train/training_output/salicon/vo-v3_train_kldloss_withouteuc-batch-1_1512487825/snapshot-_iter_200000.caffemodel' --deploy='/data/sunnycia/saliency_on_videoset/Train/scripts/prototxt/vo-v3_deploy.prototxt' --output='./output.jpg' --layer='conv1_new'
 2935  python utils/weight_visualization.py --model='/data/sunnycia/saliency_on_videoset/Train/video-caffe/examples/c3d_ucf101/c3d_ucf101_iter_35000.caffemodel' --deploy='/data/sunnycia/saliency_on_videoset/Train/video-caffe/examples/c3d_ucf101/c3d_ucf101_deploy.prototxt' --output='./output.jpg' --layer='conv1a'
 2936  cd /data/sunnycia/saliency_on_videoset/Train/video-caffe/examples/c3d_ucf101
 2937  source set_env.sh 
 2938  cd /data/sunnycia/saliency_on_videoset/Train/video-caffe
 2939  make pycaffe
 2940  cd -
 2941  bash set_env.sh 
 2942  vim set_env.sh 
 2943  bash set_env.sh 
 2944  source set_env.sh 
 2945  pytho viz_weight.py --model='c3d_ucf101_iter_35000.caffemodel' --deploy='c3d_ucf101_deploy.prototxt'
 2946  python viz_weight.py --model='c3d_ucf101_iter_35000.caffemodel' --deploy='c3d_ucf101_deploy.prototxt'
 2947  python viz_weight.py --model='c3d_ucf101_iter_35000.caffemodel' --deploy='c3d_ucf101_deploy.prototxt' --output='./output.jpg'
 2948  python
 2949  source set_env.sh 
 2950  python viz_weight.py --model='c3d_ucf101_iter_35000.caffemodel' --deploy='c3d_ucf101_deploy.prototxt' --output='./output.jpg'
 2951  python viz_weight.py --model='c3d_ucf101_iter_35000.caffemodel' --deploy='c3d_ucf101_deploy.prototxt' --output='./output.jpg' --layer='conv1a'
 2952  top
 2953  nvidia-smi
 2954  cd ..
 2955  cd ~/pwd/saliency_on_videoset/Train/scripts/
 2956  source set_env.sh 
 2957  cd /data/sunnycia/saliency_on_videoset/Train/video-caffe/examples/c3d_ucf101
 2958  cd ../..
 2959  bash ./tools/extra/plot_training_loss.sh 
 2960  bash ./tools/extra/plot_training_loss.sh examples/c3d_ucf101/*.log
 2961  cd /data/sunnycia/saliency_on_videoset/Train/video-caffe/examples/c3d_ucf101
 2962  bash ../../tools/extra/plot_training_loss.sh *.log
 2963  cd /data/sunnycia/saliency_on_videoset/Train/video-caffe/examples/c3d_ucf101
 2964  bash ../../tools/extra/plot_training_loss.sh *.log
 2965  eog
 2966  bash ../../tools/extra/plot_training_loss.sh *.log
 2967  python ../../py_plot_training_loss.py /tmp/iter_loss_RlOJsQ0oCrLlg4WWM4TLfziRrUn8VJ06.txt /tmp/iter_loss_RlOJsQ0oCrLlg4WWM4TLfziRrUn8VJ06.png /tmp/iter_accuracy_RlOJsQ0oCrLlg4WWM4TLfziRrUn8VJ06.txt /tmp/iter_accuracy_top5_RlOJsQ0oCrLlg4WWM4TLfziRrUn8VJ06.txt
 2968  python ../../tools/extra/py_plot_training_loss.py /tmp/iter_loss_RlOJsQ0oCrLlg4WWM4TLfziRrUn8VJ06.txt /tmp/iter_loss_RlOJsQ0oCrLlg4WWM4TLfziRrUn8VJ06.png /tmp/iter_accuracy_RlOJsQ0oCrLlg4WWM4TLfziRrUn8VJ06.txt /tmp/iter_accuracy_top5_RlOJsQ0oCrLlg4WWM4TLfziRrUn8VJ06.txt
 2969  $TMPTIME
 2970  clear
 2971  vim /etc/default/rcS
 2972  vim /etc/default/rc5
 2973  ls /etc/default/
 2974  clear
 2975  ls /etc/cron*
 2976  vim /etc/cron.daily/
 2977  ls /usr/lib/tmpfiles.d/tmp.conf 
 2978  vim /usr/lib/tmpfiles.d/tmp.conf 
 2979  clear
 2980  nvidia-smi
 2981  top
 2982  nvidia-smi
 2983  top
 2984  nvidia-smi
 2985  watch -n 1 nvidia-smi
 2986  watch -n 0.5 nvidia-smi
 2987  top
 2988  nvidia-smi
 2989  cd ~/pwd/saliency_on_videoset/Train/scripts/
 2990  source set_env.sh ../video-caffe/
 2991  export CUDA_VISIBLE_DEVICES=7
 2992  clear
 2993  $
 2994  python training_video_c3d_based.py  --train_prototxt='prototxt/vo-v4.prototxt' --batch=25 --solver_prototxt='prototxt/solver-static.prototxt' --staticsolver=1
 2995  python training_video_c3d_based.py  --train_prototxt='prototxt/vo-v4-1.prototxt' --batch=25 --solver_prototxt='prototxt/solver-static.prototxt' --staticsolver=1
 2996  python
 2997  clear
 2998  python test_video.py --output_type="video" --test_base='videoset'  --model_code='v4' --video_deploy_path='prototxt/vo-v4-1-deploy.prototxt' --video_model_path='../training_output/vo-v4-1-static/snapshot-_iter_1000.caffemodel'
 2999  clear
 3000  python test_video.py --output_type="video" --test_base='videoset'  --model_code='v4' --video_deploy_path='prototxt/vo-v4-1-deploy.prototxt' --video_model_path='../training_output/vo-v4-1-static/snapshot-_iter_1000.caffemodel'
 3001  cd pwd/saliency_on_videoset/Train/scripts/
 3002  source set_env.sh 
 3003  nvidia-smi
 3004  export CUDA_VISIBLE_DEVICES=5
 3005  clear
 3006  python test_video.py --output_type='video' --output_type='video' --video_base='/data/sunnycia/SaliencyDataset/Video/VideoSet/Videos/videos_origin' --test_base='videoset' --video_deploy_path='/data/sunnycia/saliency_on_videoset/Train/scripts/prototxt/vo-v3-8_deploy.prototxt' --video_model_path='/data/sunnycia/saliency_on_videoset/Train/training_output/salicon/vo-v3_train_kldloss_withouteuc_stack8-batch-1_1512533943/snapshot-_iter_100000.caffemodel' --framestack=8
 3007  nvidia-smi
 3008  export CUDA_VISIBLE_DEVICES=4
 3009  python test_video.py --output_type='video' --output_type='video' --video_base='/data/sunnycia/SaliencyDataset/Video/VideoSet/Videos/videos_origin' --test_base='videoset' --video_deploy_path='/data/sunnycia/saliency_on_videoset/Train/scripts/prototxt/vo-v3-8_deploy.prototxt' --video_model_path='/data/sunnycia/saliency_on_videoset/Train/training_output/salicon/vo-v3_train_kldloss_withouteuc_stack8-batch-1_1512533943/snapshot-_iter_100000.caffemodel' --framestack=8
 3010  python test_video.py --output_type='video' --output_type='video' --video_base='/data/sunnycia/SaliencyDataset/Video/VideoSet/Videos/videos_origin' --test_base='videoset' --video_deploy_path='/data/sunnycia/saliency_on_videoset/Train/scripts/prototxt/vo-v3-16_deploy.prototxt' --video_model_path='/data/sunnycia/saliency_on_videoset/Train/training_output/salicon/vo-v3_train_kldloss_withouteuc_stack16-batch-1_1512533810/snapshot-_iter_50000.caffemodel' --framestack=8
 3011  python test_video.py --output_type='video' --output_type='video' --video_base='/data/sunnycia/SaliencyDataset/Video/VideoSet/Videos/videos_origin' --test_base='videoset' --video_deploy_path='/data/sunnycia/saliency_on_videoset/Train/scripts/prototxt/vo-v3-16_deploy.prototxt' --video_model_path='/data/sunnycia/saliency_on_videoset/Train/training_output/salicon/vo-v3_train_kldloss_withouteuc_stack16-batch-1_1512533810/snapshot-_iter_50000.caffemodel' --framestack=16
 3012  git status
 3013  git add --all
 3014  git commit -m "Done for v3 5/8/16 testing code."
 3015  git push -u origin master
 3016  clear
 3017  $1
 3018  $0
 3019  bash set_env.sh ../video-caffe/
 3020  python
 3021  source set_env.sh ../video-caffe/
 3022  python
 3023  clear
 3024  python training_video_c3d_based.py 
 3025  nvidia-smi
 3026  export CUDA_VISIBLE_DEVICES=5
 3027  python training_video_c3d_based.py --train_prototxt='prototxt/vo-v4.prototxt'
 3028  python training_video_c3d_based.py --train_prototxt='prototxt/vo-v4.prototxt' --batch=25
 3029  python training_video_c3d_based.py --train_prototxt='prototxt/vo-v4.prototxt' --batch=16 
 3030  python training_video_c3d_based.py --train_prototxt='prototxt/vo-v4.prototxt' --batch=50
 3031  python utils/scavenger.py 
 3032  clear
 3033  python utils/scavenger.py 
 3034  python training_video_c3d_based.py --train_prototxt='prototxt/vo-v4.prototxt' --batch=50
 3035  python training_video_c3d_based.py --train_prototxt='prototxt/vo-v4.prototxt' --batch=25
 3036  clear
 3037  python training_video_c3d_based.py --train_prototxt='prototxt/vo-v4.prototxt' --batch=25
 3038  clear
 3039  python training_video_c3d_based.py --train_prototxt='prototxt/vo-v4.prototxt' --batch=25
 3040  clear
 3041  python training_video_c3d_based.py --train_prototxt='prototxt/vo-v4.prototxt' --batch=25
 3042  python training_video_c3d_based.py --train_prototxt='prototxt/vo-v4-1.prototxt' --batch=25
 3043  top
 3044  nvidia-smi
 3045  top
 3046  nvidia-smi
 3047  cd pwd/saliency_on_videoset/Train/scripts/
 3048  history > history
 3049  source set_env.sh ../caffe-flownet/
 3050  nvidia-smi
 3051  export CUDA_VISIBLE_DEVICES=6
 3052  python test_video.py --output_type='video' --output_type='video' --video_base='/data/sunnycia/SaliencyDataset/Video/VideoSet/Videos/videos_origin' --test_base='videoset' --video_deploy_path='/data/sunnycia/saliency_on_videoset/Train/scripts/prototxt/vo-v3-16_deploy.prototxt' --video_model_path='/data/sunnycia/saliency_on_videoset/Train/training_output/salicon/vo-v3_train_kldloss_withouteuc_stack16-batch-1_1512533810/snapshot-_iter_50000.caffemodel' --framestack=16
 3053  python test_video.py --output_type='video' --output_type='video' --test_base='videoset' --video_deploy_path='/data/sunnycia/saliency_on_videoset/Train/scripts/prototxt/vo-v3-16_deploy.prototxt' --video_model_path='/data/sunnycia/saliency_on_videoset/Train/training_output/salicon/vo-v3_train_kldloss_withouteuc_stack16-batch-1_1512533810/snapshot-_iter_50000.caffemodel' --framestack=16
 3054  python training_video_c3d_based.py --train_prototxt='prototxt/vo-v4-1.prototxt' --batch=25
 3055  source set_env.sh ../video-caffe/
 3056  python training_video_c3d_based.py --train_prototxt='prototxt/vo-v4-1.prototxt' --batch=25
 3057  python training_video_c3d_based.py --train_prototxt='prototxt/vo-v4-1.prototxt' --batch=20
 3058  python training_video_c3d_based.py  --train_prototxt='prototxt/vo-v4-1.prototxt' --batch=25 --solver_prototxt='prototxt/solver-static.prototxt' --staticsolver=1 
 3059  clear
 3060  python training_video_c3d_based.py  --train_prototxt='prototxt/vo-v4-1.prototxt' --batch=25 --solver_prototxt='prototxt/solver-static.prototxt' --staticsolver=1 
 3061  python training_video_c3d_based.py  --train_prototxt='prototxt/vo-v4-1.prototxt' --batch=25 --solver_prototxt='prototxt/solver-static.prototxt' --staticsolver=1 clear
 3062  clear
 3063  python training_video_c3d_based.py  --train_prototxt='prototxt/vo-v4-1.prototxt' --batch=25 --solver_prototxt='prototxt/solver-static.prototxt' --staticsolver=1 
 3064  top
 3065  watch -n 0.5 nvidia-smi
 3066  top
 3067  free -h
 3068  nvidia-smi
 3069  clear
 3070  cd pwd/saliency_on_videoset/Train/scripts/
 3071  git status
 3072  source set_env.sh ../caffe-flownet/
 3073  export CUDA_VISIBLE_DEVICES=7
 3074  python test_video.py --output_type='video' --output_type='video' --video_base='/data/sunnycia/SaliencyDataset/Video/VideoSet/Videos/videos_origin' --test_base='videoset' --video_deploy_path='/data/sunnycia/saliency_on_videoset/Train/scripts/prototxt/vo-v3-16_deploy.prototxt' --video_model_path='/data/sunnycia/saliency_on_videoset/Train/training_output/salicon/vo-v3_train_kldloss_withouteuc_stack16-batch-1_1512533810/snapshot-_iter_50000.caffemodel' --framestack=8
 3075  python test_video.py --output_type='video' --output_type='video' --test_base='videoset' --video_deploy_path='/data/sunnycia/saliency_on_videoset/Train/scripts/prototxt/vo-v3-16_deploy.prototxt' --video_model_path='/data/sunnycia/saliency_on_videoset/Train/training_output/salicon/vo-v3_train_kldloss_withouteuc_stack16-batch-1_1512533810/snapshot-_iter_50000.caffemodel' --framestack=8
 3076  nvidia-smi
 3077  export CUDA_VISIBLE_DEVICES=6
 3078  python test_video.py --output_type='video' --output_type='video' --test_base='videoset' --video_deploy_path='/data/sunnycia/saliency_on_videoset/Train/scripts/prototxt/vo-v3-16_deploy.prototxt' --video_model_path='/data/sunnycia/saliency_on_videoset/Train/training_output/salicon/vo-v3_train_kldloss_withouteuc_stack16-batch-1_1512533810/snapshot-_iter_50000.caffemodel' --framestack=8
 3079  python test_video.py --output_type='video' --output_type='video' --test_base='videoset' --video_deploy_path='/data/sunnycia/saliency_on_videoset/Train/scripts/prototxt/vo-v3-8_deploy.prototxt' --video_model_path='/data/sunnycia/saliency_on_videoset/Train/training_output/salicon/vo-v3_train_kldloss_withouteuc_stack16-batch-1_1512533810/snapshot-_iter_50000.caffemodel' --framestack=8
 3080  python test_video.py --output_type='video' --output_type='video' --test_base='videoset' --video_deploy_path='/data/sunnycia/saliency_on_videoset/Train/scripts/prototxt/vo-v3-8_deploy.prototxt' --video_model_path='/data/sunnycia/saliency_on_videoset/Train/training_output/salicon//data/sunnycia/saliency_on_videoset/Train/training_output/salicon/vo-v3_train_kldloss_withouteuc_stack8-batch-1_1512533943/snapshot-_iter_350000.caffemodel' --framestack=16
 3081  python test_video.py --output_type='video' --output_type='video' --test_base='videoset' --video_deploy_path='/data/sunnycia/saliency_on_videoset/Train/scripts/prototxt/vo-v3-8_deploy.prototxt' --video_model_path='/data/sunnycia/saliency_on_videoset/Train/training_output/salicon//data/sunnycia/saliency_on_videoset/Train/training_output/salicon/vo-v3_train_kldloss_withouteuc_stack8-batch-1_1512533943/snapshot-_iter_350000.caffemodel' --framestack=8
 3082  python test_video.py --output_type='video' --output_type='video' --test_base='videoset' --video_deploy_path='/data/sunnycia/saliency_on_videoset/Train/scripts/prototxt/vo-v3-8_deploy.prototxt' --video_model_path='/data/sunnycia/saliency_on_videoset/Train/training_output/salicon/vo-v3_train_kldloss_withouteuc_stack8-batch-1_1512533943/snapshot-_iter_350000.caffemodel' --framestack=8
 3083  nvidia-smi
 3084  python test_video.py --output_type='video' --output_type='video' --test_base='videoset' --video_deploy_path='/data/sunnycia/saliency_on_videoset/Train/scripts/prototxt/vo-v3-8_deploy.prototxt' --video_model_path='/data/sunnycia/saliency_on_videoset/Train/training_output/salicon/vo-v3_train_kldloss_withouteuc_stack8-batch-1_1512533943/snapshot-_iter_350000.caffemodel' --framestack=8
 3085  git clone https://github.com/albioTQ/CNN_Visualization.git
 3086  git clone https://github.com/hvy/chainer-visualization.git
 3087  top
 3088  nvidia-smi
 3089  cd ../C3D-v1.0/
 3090  vim Makefile.config
 3091  make clean
 3092  make -j8 all
 3093  cd examples/
 3094  ls
 3095  cd c3d_feature_extraction/
 3096  ls
 3097  chmod u+x c3d_sport1m_feature_extraction_*sh
 3098  ls
 3099  ./c3d_sport1m_feature_extraction_video.sh 
 3100   cd ~/pwd/saliency_on_videoset/Train/scripts/
 3101  source set_env.sh ../C3D-v1.0/
 3102  python
 3103  clea
 3104  clear
 3105  ls
 3106  cd ..
 3107  cd Train/
 3108  cd C3D-v1.1/
 3109  make runtest
 3110  export CUDA_VISIBLE_DEVICES=5
 3111  make runtest
 3112  cd ..
 3113  cd scripts/
 3114  ls
 3115  python training_video_c3d_based.py 
 3116  python training_video_c3d_based.py --train_prototxt='prototxt/vo-v4-2.prototxt' --use_model='../pretrained_model/conv3d_deepnetA_sport1m_iter_1900000' --trainingbase='msu' --videolength=16
 3117  source set_env.sh ../C3D-v1.1/
 3118  nvidia-smi
 3119  export CUDA_VISIBLE_DEVICES=5
 3120  python training_video_c3d_based.py --train_prototxt='prototxt/vo-v4-2.prototxt' --use_model='../pretrained_model/conv3d_deepnetA_sport1m_iter_1900000' --trainingbase='msu' --videolength=16
 3121  python
 3122  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2.prototxt' --use_model='../pretrained_model/conv3d_deepnetA_sport1m_iter_1900000' --trainingbase='msu'
 3123  cd ../../
 3124  cd Train/
 3125  cd C3D-v1.1/
 3126  make clean
 3127  make -j8 all
 3128  make pycaffe
 3129  make clean
 3130  make -j8 all && make -j4 pycaffe
 3131  cd ..
 3132  cd scripts/
 3133  python training_video_c3d_based.py --train_prototxt='prototxt/vo-v4-2.prototxt' --use_model='../pretrained_model/conv3d_deepnetA_sport1m_iter_1900000' --trainingbase='msu' --videolength=16
 3134  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2.prototxt' --use_model='../pretrained_model/conv3d_deepnetA_sport1m_iter_1900000' --trainingbase='msu'
 3135  cd ..
 3136  git clone https://github.com/facebook/C3D.git
 3137  cd C3D/
 3138  cd ../C3D-v1.1/
 3139  ls
 3140  cp Makefile.config.example Makefile.config
 3141  ls
 3142  pwd
 3143  ls
 3144  cd ..
 3145  cd C3D-v1.1/
 3146  ls
 3147  cp Makefile.config.example Makefile.config
 3148  vim Makefile.config
 3149  cd src/
 3150  ls
 3151  cd ..
 3152  make -j8 all && make -j4 pycaffe
 3153  cd ../scripts/
 3154  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2.prototxt' --use_model='../pretrained_model/conv3d_deepnetA_sport1m_iter_1900000' --trainingbase='msu'
 3155  source set_env.sh ../C3D-v1.1/
 3156  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2.prototxt' --use_model='../pretrained_model/conv3d_deepnetA_sport1m_iter_1900000' --trainingbase='msu'
 3157  nvidia-smi
 3158  export CUDA_VISIBLE_DEVICES=6
 3159  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2.prototxt' --use_model='../pretrained_model/conv3d_deepnetA_sport1m_iter_1900000' --trainingbase='msu'
 3160  cd -
 3161  make clean
 3162  make -j8 all && make -j8 pycaffe
 3163  cd -
 3164  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2.prototxt' --use_model='../pretrained_model/conv3d_deepnetA_sport1m_iter_1900000' --trainingbase='msu'
 3165  cd -
 3166  make clean
 3167  make -j8 all && make pycaffe
 3168  make clean
 3169  make -j8 all
 3170  make -j8 pycaffe
 3171  cd -
 3172  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2.prototxt' --use_model='../pretrained_model/conv3d_deepnetA_sport1m_iter_1900000' --trainingbase='msu'
 3173  cd -
 3174  make clean
 3175  make -j16 all -make -j16 pycaffe
 3176  make -j16 all && make -j16 pycaffe
 3177  make clean
 3178  make -j16 all && make -j16 pycaffe
 3179  cd -
 3180  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2.prototxt' --use_model='../pretrained_model/conv3d_deepnetA_sport1m_iter_1900000' --trainingbase='msu'
 3181  cd -
 3182  make clean 
 3183  make -j8 caffe && make -j16 pycaffe
 3184  make -j8 all && make -j16 pycaffe
 3185  cd -
 3186  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2.prototxt' --use_model='../pretrained_model/conv3d_deepnetA_sport1m_iter_1900000' --trainingbase='msu'
 3187  cd -
 3188  make clean 
 3189  make -j8 all && make -j16 pycaffe
 3190  make clean
 3191  make -j8 all && make -j16 pycaffe
 3192  cd ..
 3193  git clone https://github.com/sjtutsb/caffe-3DConv-master.git
 3194  ls -l
 3195  rm -rf caffe-3DConv-master/
 3196  git clone https://github.com/dutran/C3D_dev.git
 3197  cd C3D_dev/
 3198  ls
 3199  cp Makefile.config.example Makefile.config
 3200  vim Makefile.config
 3201  make -j8 all && make pycaffe
 3202  vim Makefile.config
 3203  make -j8 all && make pycaffe
 3204  vim Makefile.config
 3205  make -j8 all && make pycaffe
 3206  make clean
 3207  make -j16 all
 3208  cd ..
 3209  rm -rf C3D_dev/
 3210  ls
 3211  git clone https://github.com/BVLC/caffe.git
 3212  cd caffe
 3213  ls
 3214  cp Makefile.config.example Makefile.config
 3215  vim Makefile.config
 3216  cd src/
 3217  ls
 3218  cd caffe/
 3219  screen -h
 3220  top
 3221  cd pwd/saliency_on_videoset/Train/scripts/
 3222  source set_env.sh ../video-caffe/
 3223  export CUDA_VISIBLE_DEVICES=5
 3224  python test_video.py --output_type="video" --test_base='videoset'  --model_code='v4' --video_deploy_path='prototxt/vo-v4-1-deploy.prototxt' --video_model_path='../training_output/vo-v4-1-static/snapshot-_iter_1000.caffemodel'
 3225  python test_video.py --output_type="video" --test_base='videoset'  --model_code='v4' --video_deploy_path='prototxt/vo-v4-1-deploy.prototxt' --video_model_path='../training_output/vo-v4-1-static-adadelta/snapshot-_iter_1000.caffemodel'
 3226  cd /data/sunnycia/saliency_on_videoset/Train/C3D/C3D-v1.0
 3227  ls
 3228  cp Makefile.config.example Makefile.config
 3229  vim Makefile.config
 3230  make -j8 all
 3231  make clean
 3232  make -j8 all
 3233  make pycaffe
 3234  python
 3235  clear
 3236  cd ../../
 3237  git clone https://github.com/chuckcho/video-caffe.git
 3238  cd video-caffe
 3239  make -j8 all
 3240  cd ..
 3241  cd video-caffe-c3d/
 3242  make -j8 all
 3243  cp Makefile.config.example Makefile.config
 3244  vim Makefile.config
 3245  make -j8 all
 3246  cd ..
 3247  ls
 3248  cd C3D
 3249  cd ..
 3250  cd C3D-v1.0/
 3251  cd /data/sunnycia/saliency_on_videoset/Train/C3D-v1.0/examples/c3d_feature_extraction
 3252  bash c3d_sport1m_feature_extraction_video.sh 
 3253  nvidia-smi
 3254  export CUDA_VISIBLE_DEVICES=5
 3255  bash c3d_sport1m_feature_extraction_video.sh 
 3256  cd ../..
 3257  vim Makefile.config
 3258  make runtest
 3259  make -j8 runtest
 3260  cd /data/sunnycia/saliency_on_videoset/Train/C3D-v1.0
 3261  make clean
 3262  ls
 3263  cm -rf include/
 3264  rm -rf include/
 3265  make -j8 all
 3266  cd ..
 3267  ls
 3268  cd C3D-v1.1/
 3269  make -j8 all
 3270  make clean
 3271  make -j8 all
 3272  ls
 3273  cd ../scripts/
 3274  source set_env.sh ../C3D-v1.1/
 3275  python
 3276  cd -
 3277  vim Makefile
 3278  vim Makefile.config
 3279  ls
 3280  cd python/
 3281  python
 3282  make pycaffe
 3283  cd ..
 3284  make pycaffe
 3285  cd -
 3286  cd ..
 3287  cd ../scripts/
 3288  source set_env.sh ../C3D-v1.1/
 3289  python
 3290  clea
 3291  clear
 3292  python utils/scavenger.py 
 3293  nvidia-smi
 3294  top
 3295  nvidia-smi
 3296  clear
 3297  export CUDA_VISIBLE_DEVICES=5
 3298  export CUDA_VISIBLE_DEVICES=6
 3299  python training_video_framestack_based.py --train_prototxt='prototxt/vo-v3_train_kldloss_withouteuc.prototxt' --use_model='../training_output/salicon/train_kldloss_withouteuc-batch-8_1509584263/snapshot-_iter_100000.caffemodel'
 3300  source set_env.sh ../video-caffe/
 3301  python training_video_framestack_based.py --train_prototxt='prototxt/vo-v3_train_kldloss_withouteuc.prototxt' --use_model='../training_output/salicon/train_kldloss_withouteuc-batch-8_1509584263/snapshot-_iter_100000.caffemodel'
 3302  python training_video_framestack_based.py --train_prototxt='prototxt/vo-v3_train_kldloss_withouteuc.prototxt' --use_model='../training_output/salicon/train_kldloss_withouteuc-batch-8_1509584263/snapshot-_iter_100000.caffemodel' stack=8
 3303  python training_video_framestack_based.py --train_prototxt='prototxt/vo-v3_train_kldloss_withouteuc.prototxt' --use_model='../training_output/salicon/train_kldloss_withouteuc-batch-8_1509584263/snapshot-_iter_100000.caffemodel'
 3304  clear
 3305  top
 3306  nvidia-smi
 3307  cd~
 3308  cd ~
 3309  cd ~/pwd/saliency_on_videoset/Train/
 3310  cd caffe-master/
 3311  ls
 3312  cd src/caffe/layers/
 3313  ls
 3314  pwd
 3315  ls
 3316  top
 3317  cd pwd/saliency_on_videoset/
 3318  ls
 3319  top
 3320  nvidia-smi
 3321  top
 3322  nvidia-smi
 3323  ls
 3324  cd pwd/
 3325  ls
 3326  git clone 
 3327  git clone https://github.com/swook/autocrop.git
 3328  ls
 3329  cd autocrop/
 3330  ls
 3331  make
 3332  mkdir build
 3333  cd build/
 3334  cmake ..
 3335  cd ..
 3336  l
 3337  ls
 3338  make clean
 3339  cd ~/pwd/saliency_on_videoset/
 3340  ls
 3341  cd Train/
 3342  ls
 3343  clear
 3344  ls
 3345  cd scripts/
 3346  source set_env.sh ../caffe-flownet 4
 3347  nvidia-smi
 3348  source set_env.sh ../caffe-flownet 4
 3349  clear
 3350  python test_video.py --output_type="video" --test_base='videoset' --model_code='v3' --infertype='slide' --video_deploy_path='prototxt/vo-v3-2_deploy.prototxt' --video_model_path='../training_output/salicon/vo-v3-2_train_kldloss_withouteuc-batch-1_1513084718/snapshot-_iter_50000.caffemodel'
 3351  python test_video.py --output_type="video" --test_base='videoset' --model_code='v3' --infertype='slide' --video_deploy_path='prototxt/vo-v3-2_deploy.prototxt' --video_model_path='../training_output/salicon/vo-v3-2_train_kldloss_withouteuc-batch-1_1513084718/snapshot-_iter_50000.caffemodel' --videolength=16
 3352  nvidia-smi
 3353  clear
 3354  cd ..
 3355  ls
 3356  cd C3D/
 3357  ls
 3358  cd C3D-v1.0/
 3359  ls
 3360  cp Makefile.config.example Makefile.config
 3361  vim Makefile.config
 3362  make -j8 all
 3363  make pycaffe
 3364  ls
 3365  cd python/
 3366  ls
 3367  python
 3368  cd ..
 3369  make pycaffe
 3370  export CPLUS_INCLUDE_PATH=/usr/include/python2.7
 3371  make pycaffe
 3372  python
 3373  cd python/
 3374  import caffe
 3375  python
 3376  cd ..
 3377  cd..
 3378  cd ..
 3379  cp C3D-v1.0/ ../
 3380  cp -R C3D-v1.0/ ../
 3381  cd ..
 3382  ls -l
 3383  ls -ls
 3384  cd scripts/
 3385  source set_env.sh ../C3D-v1.0/
 3386  nvidia-smi
 3387  source set_env.sh ../C3D-v1.0/ 4
 3388  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2.prototxt' --use_model='../pretrained_model/conv3d_deepnetA_sport1m_iter_1900000' --trainingbase='msu'
 3389  python
 3390  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2.prototxt' --use_model='../pretrained_model/conv3d_deepnetA_sport1m_iter_1900000' --trainingbase='msu' --solver_prototxt='prototxt/solver-static.prototxt' --staticsolver=1 
 3391  cd ..
 3392  git clone https://github.com/AustinVan/IC.git
 3393  cd IC/
 3394  la
 3395  python
 3396  cd python/
 3397  python
 3398  cd ..
 3399  vim Makefile.config
 3400  make clean
 3401  make -j8 all
 3402  cd ..
 3403   rm -rf IC/ 
 3404  clear
 3405  ls
 3406  cd C3D-v1.1/
 3407  ls
 3408  cd python/
 3409  python
 3410  cd ..
 3411  make pycaffe
 3412  make clean
 3413  make -j16 all && make -j8 pycaffe
 3414  cd ..
 3415  rm -rf C3D-v1.0/ C3D-v1.1/
 3416  ls
 3417  cp C3D/C3D-v1.1/ ./
 3418  cp -R C3D/C3D-v1.1/ ./
 3419  cd C3D-v1.1/
 3420  ls
 3421  cd python/
 3422  python
 3423  cd ..
 3424  make clean
 3425  cp Makefile.config.example Makefile.config
 3426  vim Makefile.config
 3427  make -j8 all && make pycaffe
 3428  cd python/
 3429  python
 3430  clear
 3431  cd ..
 3432  cd scripts/
 3433  source set_env.sh ../C3D-v1.1/
 3434  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2.prototxt' --use_model='../pretrained_model/conv3d_deepnetA_sport1m_iter_1900000' --trainingbase='msu'
 3435  source set_env.sh ../C3D-v1.1/ 4
 3436  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2.prototxt' --use_model='../pretrained_model/conv3d_deepnetA_sport1m_iter_1900000' --trainingbase='msu'
 3437  cd ..
 3438  cd C3D-v1.1/
 3439  ls
 3440  make clean
 3441  make all && make pycaffe
 3442  make clean
 3443  make all && make pycaffe
 3444  cd -
 3445  cd scripts/
 3446  ls
 3447  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2.prototxt' --use_model='../pretrained_model/conv3d_deepnetA_sport1m_iter_1900000' --trainingbase='msu'
 3448  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2.prototxt' --trainingbase='msu'
 3449  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2.prototxt' --use_model='../pretrained_model/conv3d_deepnetA_sport1m_iter_1900000' --trainingbase='msu'
 3450  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2.prototxt' --use_model='../pretrained_model/conv3d_deepnetA_sport1m_iter_1900000_v1.1.caffemodel' --trainingbase='msu'
 3451  cd pwd/saliency_on_videoset/
 3452  ls
 3453  cd Train/scripts/
 3454  history > history
 3455  source set_env.sh ../caffe-flownet/
 3456  pwd
 3457  python training_image.py --train_prototxt='prototxt/train_kldloss.prototxt' --use_snapshot='../training_output/salicon/
 3458  export CUDA_VISIBLE_DEVICES=6
 3459  python training_image.py --train_prototxt='prototxt/train_kldloss.prototxt' --use_snapshot='../training_output/salicon/
 3460  python training_image.py --train_prototxt='prototxt/train_kldloss.prototxt' --use_snapshot='../training_output/salicon/'
 3461  python training_image.py --train_prototxt='prototxt/train_kldloss.prototxt' --use_snapshot='../training_output/salicon/train_kldloss_withouteuc-batch-8_1509584263/snapshot-_iter_100000.solverstate' --batch=8 --dsname='bigunion'
 3462  cd pwd/autocrop/
 3463  cd src/
 3464  mkdir build
 3465  cd build/
 3466  cmake ..
 3467  ls
 3468  cd ..
 3469  cd build/
 3470  ls
 3471  make install
 3472  make
 3473  make clean
 3474  cd ..
 3475  ls
 3476  rm -rf build/
 3477  cd ..
 3478  ls
 3479  rm -rf build/
 3480  cd ..
 3481  tar -czf autocrop/ autocrop.tar.gz
 3482  tar -czf autocrop.tar.gz autocrop/
 3483  top
 3484  nvidia-smi
 3485  clear
 3486  nvidia-smi
 3487  watch -n 2 nvidia-smi
 3488  top
 3489  nvidia-smi
 3490  cd saliency_on_videoset/Train/scripts/
 3491  source set_env.sh ../C3D-v1.1/ 4
 3492  nvidia-smi
 3493  source set_env.sh ../C3D-v1.1/ 6
 3494  clear
 3495  history > history 
 3496  cd /data/sunnycia/saliency_on_videoset/Train/C3D-v1.1/examples/c3d_ucf101_finetuning
 3497  bash testing_ucf101.sh 
 3498  clear
 3499  cd -
 3500  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-resnet.prototxt' --use_model='../pretrained_model/c3d_resnet18_sports1m_r2_iter_2800000.caffemodel' --trainingbase='msu'
 3501  nvidi-asmi
 3502  nvidia-smi
 3503  top
 3504  cd pwd/saliency_on_videoset/Train/scripts/
 3505  ls
 3506  source set_env.sh ../C3D-v1.1/ 6
 3507  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-resnet.prototxt' --use_model='../pretrained_model/c3d_resnet18_sports1m_r2_iter_2800000.caffemodel' --trainingbase='msu'
 3508  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-resnet.prototxt' --use_model='../pretrained_model/c3d_resnet18_sports1m_r2_iter_2800000.caffemodel' --trainingbase='msu' --batch=16
 3509  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-resnet.prototxt' --use_model='../pretrained_model/c3d_resnet18_sports1m_r2_iter_2800000.caffemodel' --trainingbase='msu' --batch=2
 3510  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-resnet.prototxt' --use_model='../pretrained_model/c3d_resnet18_sports1m_r2_iter_2800000.caffemodel' --trainingbase='msu' --batch=16
 3511  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-resnet.prototxt' --use_model='../pretrained_model/c3d_resnet18_sports1m_r2_iter_2800000.caffemodel' --trainingbase='msu' --batch=2
 3512  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-resnet-noscale.prototxt' --use_model='../pretrained_model/c3d_resnet18_sports1m_r2_iter_2800000.caffemodel' --trainingbase='msu' --batch=2
 3513  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-resnet.prototxt' --use_model='../pretrained_model/c3d_resnet18_sports1m_r2_iter_2800000.caffemodel' --trainingbase='msu' --batch=2
 3514  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2.prototxt' --use_model='../pretrained_model/c3d_resnet18_sports1m_r2_iter_2800000.caffemodel' --trainingbase='msu' --batch=2
 3515  python utils/scavenger.py 
 3516  clear
 3517  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2.prototxt' --use_model='../pretrained_model/c3d_resnet18_sports1m_r2_iter_2800000.caffemodel' --trainingbase='msu' --batch=2
 3518  clear
 3519  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2.prototxt' --use_model='../pretrained_model/conv3d_deepnetA_sport1m_iter_1900000_v1.1.caffemodel' --trainingbase='msu' --batch=2
 3520  clear
 3521  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2.prototxt' --use_model='../pretrained_model/conv3d_deepnetA_sport1m_iter_1900000_v1.1.caffemodel' --trainingbase='msu' --batch=2
 3522  clear
 3523  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2.prototxt' --use_model='../pretrained_model/conv3d_deepnetA_sport1m_iter_1900000_v1.1.caffemodel' --trainingbase='msu' --batch=2
 3524  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2.prototxt' --use_model='../pretrained_model/conv3d_deepnetA_sport1m_iter_1900000_v1.1.caffemodel' --trainingbase='msu' --batch=8
 3525  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2.prototxt' --use_model='../pretrained_model/conv3d_deepnetA_sport1m_iter_1900000_v1.1.caffemodel' --trainingbase='msu' --batch=2
 3526  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2.prototxt' --use_model='../pretrained_model/conv3d_deepnetA_sport1m_iter_1900000_v1.1.caffemodel' --trainingbase='msu' --batch=8
 3527  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2.prototxt' --use_model='../pretrained_model/conv3d_deepnetA_sport1m_iter_1900000_v1.1.caffemodel' --trainingbase='msu' --batch=8 --overlap=15 --trainingexampleprops=0.8 --validiter=1800 --savemodeliter=1800
 3528  nvidia-smi
 3529  nvidia-smi
 3530  clear
 3531  top
 3532  nvidia-smi
 3533  clear
 3534  cd pwd/saliency_on_videoset/Train/scripts/
 3535  source set_env.sh ../C3D-v1.1-kldloss/ 7
 3536   python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2.prototxt' --use_model='../pretrained_model/conv3d_deepnetA_sport1m_iter_1900000_v1.1.caffemodel' --trainingbase='msu' --batch=8 --trainingexampleprops=0.8 --overlap=15
 3537   python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-3-1.prototxt' --use_model='../pretrained_model/conv3d_deepnetA_sport1m_iter_1900000_v1.1.caffemodel' --trainingbase='msu' --batch=8 --trainingexampleprops=0.8 --overlap=15
 3538   python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-3-1.prototxt' --use_model='../pretrained_model/conv3d_deepnetA_sport1m_iter_1900000_v1.1.caffemodel' --trainingbase='msu' --batch=8 --trainingexampleprops=0.8 --overlap=0
 3539   python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-3-1.prototxt' --use_model='../pretrained_model/conv3d_deepnetA_sport1m_iter_1900000_v1.1.caffemodel' --trainingbase='msu' --batch=8 --trainingexampleprops=0.8 --overlap=15
 3540   python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-3-1.prototxt' --use_model='../pretrained_model/conv3d_deepnetA_sport1m_iter_1900000_v1.1.caffemodel' --trainingbase='msu' --batch=8 --trainingexampleprops=0.8 --overlap=0
 3541   python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-3-1.prototxt' --use_model='../pretrained_model/conv3d_deepnetA_sport1m_iter_1900000_v1.1.caffemodel' --trainingbase='msu' --batch=8 --trainingexampleprops=0.995 --overlap=0
 3542   python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-3-1.prototxt' --use_model='../pretrained_model/conv3d_deepnetA_sport1m_iter_1900000_v1.1.caffemodel' --trainingbase='msu' --batch=8 --trainingexampleprops=0.99 --overlap=0
 3543  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-3-1.prototxt' --use_model='../pretrained_model/conv3d_deepnetA_sport1m_iter_1900000_v1.1.caffemodel' --trainingbase='msu' --batch=8 --trainingexampleprops=0.99 --overlap=0 --debug=1
 3544  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-3-1.prototxt' --use_model='../pretrained_model/conv3d_deepnetA_sport1m_iter_1900000_v1.1.caffemodel' --trainingbase='msu' --batch=8 --trainingexampleprops=0.8 --overlap=15
 3545  clear
 3546  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-3-1.prototxt' --use_model='../pretrained_model/conv3d_deepnetA_sport1m_iter_1900000_v1.1.caffemodel' --trainingbase='msu' --batch=8 --trainingexampleprops=0.8 --overlap=15 --validiter=1800 --savemodeliter=1800 
 3547  clear
 3548  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-3-1.prototxt' --use_model='../pretrained_model/conv3d_deepnetA_sport1m_iter_1900000_v1.1.caffemodel' --trainingbase='msu' --batch=8 --trainingexampleprops=0.8 --overlap=15 --validiter=1800 --savemodeliter=1800 
 3549  clear
 3550  clera
 3551  clear
 3552  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-3-1.prototxt' --use_model='../pretrained_model/conv3d_deepnetA_sport1m_iter_1900000_v1.1.caffemodel' --trainingbase='msu' --batch=8 --trainingexampleprops=0.99 --overlap=0 --debug=1
 3553  clear
 3554  clera
 3555  clear
 3556  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-3-1.prototxt' --use_model='../pretrained_model/conv3d_deepnetA_sport1m_iter_1900000_v1.1.caffemodel' --trainingbase='msu' --batch=8 --trainingexampleprops=0.8 --overlap=15 --validiter=1800 --savemodeliter=1800 --extramodinfo='abs'
 3557  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2.prototxt' --use_model='../pretrained_model/conv3d_deepnetA_sport1m_iter_1900000_v1.1.caffemodel' --trainingbase='msu' --batch=8 --overlap=15 --trainingexampleprops=0.8 --validiter=1800
 3558  nvidia-smi
 3559  cd pwd/saliency_on_videoset/Train/scripts/
 3560  source set_env.sh ../C3D-v1.1-kldloss/ 5
 3561  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-3-1.prototxt' --use_model='../pretrained_model/conv3d_deepnetA_sport1m_iter_1900000_v1.1.caffemodel' --trainingbase='msu' --batch=8 --trainingexampleprops=0.8 --overlap=15 --validiter=1800 --savemodeliter=1800 --extramodinfo='relu'
 3562  clear
 3563  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-3-1.prototxt' --use_model='../pretrained_model/conv3d_deepnetA_sport1m_iter_1900000_v1.1.caffemodel' --trainingbase='msu' --batch=8 --trainingexampleprops=0.8 --overlap=15 --validiter=1800 --savemodeliter=1800 --extramodinfo='relu'
 3564  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2.prototxt' --use_model='../pretrained_model/conv3d_deepnetA_sport1m_iter_1900000_v1.1.caffemodel' --trainingbase='msu' --batch=8 --overlap=15 --trainingexampleprops=0.8 --validiter=1800
 3565  clear
 3566  cd pwd/saliency_on_videoset/Train/scripts/
 3567  git status
 3568  git add --all
 3569  git commit -m "add v3-2 model(multiple input, one output), add v4-2 model(not finished for the caffe problem)
 3570  "
 3571  git push -u origin master
 3572  nvidia-smi
 3573  python training_video_framestack_based.py --train_prototxtrototxt' --use_model='../training_output/salicon/train_kldloss_withouteuc-batch-8_150958ion=2 --keyframeinterv=9
 3574  source set_env.sh ../caffe-flownet/
 3575  vim set_env.sh 
 3576  source set_env.sh ../caffe-flownet/ 7
 3577  source set_env.sh ../caffe-flownet/ 5
 3578  python training_video_framestack_based.py --train_prototxtrototxt' --use_model='../training_output/salicon/train_kldloss_withouteuc-batch-8_150958ion=2 --keyframeinterv=16 -overlap=15
 3579  python training_video_framestack_based.py --train_prototxtrototxt' --use_model='../training_output/salicon/train_kldloss_withouteuc-batch-8_150958ion=2 --keyframeinterv=16 --overlap=15
 3580  python training_video_framestack_based.py --train_prototxt='prototxt/vo-v3-2_train_kldloss_withouteuc.prototxt' --use_model='../training_output/salicon/train_kldloss_withouteuc-batch-8_150958ion=2 --keyframeinterv=16 --overlap=15
 3581  clear
 3582   python training_video_framestack_based.py --train_prototxt='prototxt/vo-v3-2_train_kldloss_withouteuc.prototxt' --version=2 --keyframeinterv=16 --overlap=15
 3583  nvidia-smi
 3584  git status
 3585  git add --all
 3586  git commit -m "Modify v4-2 to v4-2-fixweight+dropout, fix the weight of feature extractor, add dropout layer"
 3587  git push -u origin master
 3588  top
 3589  nvidia-smi
 3590  source set_env.sh ../C3D-v1.1 2
 3591  nvdia-smi
 3592  nvidia-smi
 3593  top
 3594  nvidia-smi
 3595  python test_video.py --video_deploy_path='prototxt/vo-v4-2-deploy.prototxt' --video_model_path='../training_output/salicon/vo-v4-2-weight_decay-0.000005-base_lr-0.0001-snapshot-999999-display-1-momentum-0.95--batch-8_1513596875/snapshot-21600.caffemodel' --infertype='slice' --output_type='image' --test_base='videoset' --model_code='v4-2' --videolength=16
 3596  nvidia-smi
 3597  export CUDA_VISIBLE_DEVICES=1
 3598  python test_video.py --video_deploy_path='prototxt/vo-v4-2-deploy.prototxt' --video_model_path='../training_output/salicon/vo-v4-2-weight_decay-0.000005-base_lr-0.0001-snapshot-999999-display-1-momentum-0.95--batch-8_1513596875/snapshot-21600.caffemodel' --infertype='slice' --output_type='image' --test_base='videoset' --model_code='v4-2' --videolength=16
 3599  python test_video.py --video_deploy_path='prototxt/vo-v4-2-deploy.prototxt' --video_model_path='../training_output/salicon/vo-v4-2-weight_decay-0.000005-base_lr-0.0001-snapshot-999999-display-1-momentum-0.95--batch-8_1513596875/snapshot-21600.caffemodel' --infertype='slice' --output_type='video' --test_base='videoset' --model_code='v4-2' --videolength=16
 3600  python test_video.py --video_deploy_path='prototxt/vo-v4-2-deploy.prototxt' --video_model_path='../training_output/salicon/vo-v4-2-weight_decay-0.000005-base_lr-0.001-snapshot-999999-display-1-momentum-0.95--batch-8_1513597332/snapshot-21000.caffemodel' --infertype='slice' --output_type='video' --test_base='videoset' --model_code='v4-2' --videolength=16
 3601  python test_video.py --video_deploy_path='prototxt/vo-v4-2-deploy.prototxt' --video_model_path='../training_output/salicon/vo-v4-2-weight_decay-0.000005-base_lr-0.00001-snapshot-999999-display-1-momentum-0.95--batch-8_1513597365/snapshot-21000.caffemodel' --infertype='slice' --output_type='video' --test_base='videoset' --model_code='v4-2' --videolength=16
 3602  clear
 3603  matlab -nodesktop
 3604  clear
 3605  cd pwd/saliency_on_videoset/Train/scripts/
 3606  python utils/gen_density.py --sigma=32 --fixation_base='/data/sunnycia/SaliencyDataset/Video/LEDOV/fixation' --density_base='/data/sunnycia/SaliencyDataset/Video/LEDOV/density-cv2'
 3607  python utils/gen_density.py --sigma=32 --fixation_base='/data/sunnycia/SaliencyDataset/Video/LEDOV/fixation' --density_base='/data/sunnycia/SaliencyDataset/Video/LEDOV/density-cv2' --fixationtype='image'
 3608  top
 3609  nvidia-smi
 3610  top
 3611  nvidia-smi
 3612  python test_video.py --video_deploy_path='prototxt/vo-v4-2-deploy.prototxt' --video_model_path='../training_output/salicon/vo-v4-2-resnet-snapshot-999999-display-1--batch-2_1513775008/snapshot-12000.caffemodel' --infertype='slice' --output_type='image' --test_base='videoset' --model_code='v4-2' --videolength=16
 3613  source set_env.sh ../C3D-v1.1 0
 3614  python test_video.py --video_deploy_path='prototxt/vo-v4-2-deploy.prototxt' --video_model_path='../training_output/salicon/vo-v4-2-resnet-snapshot-999999-display-1--batch-2_1513775008/snapshot-12000.caffemodel' --infertype='slice' --output_type='image' --test_base='videoset' --model_code='v4-2' --videolength=16
 3615  python test_video.py --video_deploy_path='prototxt/vo-v4-2-deploy.prototxt' --video_model_path='../training_output/salicon/vo-v4-2-resnet-snapshot-999999-display-1--batch-2_1513775008/snapshot-12000.caffemodel' --infertype='slice' --output_type='video' --test_base='videoset' --model_code='v4-2' --videolength=16
 3616  python test_video.py --video_deploy_path='prototxt/vo-v4-2-deploy.prototxt' --video_model_path='../training_output/salicon/train_kldloss-leaky-batch-8_1513739634_usesnapshot_1509584263_snapshot-_iter_100000/snapshot-_iter_150000.caffemodel' --infertype='slice' --output_type='video' --test_base='videoset' --model_code='v4-2' --videolength=16
 3617  python test_video.py --video_deploy_path='prototxt/vo-v4-2-resnet-deploy.prototxt' --video_model_path='../training_output/salicon/vo-v4-2-resnet-snapshot-999999-display-1--batch-2_1513775008/snapshot-12000.caffemodel' --infertype='slice' --output_type='video' --test_base='videoset' --model_code='v4-2' --videolength=16
 3618  clear
 3619  python test_video.py --video_deploy_path='prototxt/vo-v4-2-resnet-deploy.prototxt' --video_model_path='../training_output/salicon/vo-v4-2-resnet-snapshot-999999-display-1--batch-2_1513775008/snapshot-12000.caffemodel' --infertype='slice' --output_type='video' --test_base='videoset' --model_code='v4-2' --videolength=16
 3620  python test_video.py --video_deploy_path='prototxt/vo-v4-2-resnet-deploy.prototxt' --video_model_path='../training_output/salicon/vo-v4-2-resnet-snapshot-999999-display-1--batch-2_1513775008/snapshot-39000.caffemodel' --infertype='slice' --output_type='video' --test_base='videoset' --model_code='v4-2' --videolength=16
 3621  python test_video.py --video_deploy_path='prototxt/vo-v4-2-resnet.prototxt' --video_model_path='../training_output/salicon/vo-v4-2-resnet-snapshot-999999-display-1--batch-2_1513775008/snapshot-39000.caffemodel' --infertype='slice' --output_type='video' --test_base='videoset' --model_code='v4-2' --videolength=16
 3622  clear &&clear
 3623  python test_video.py --video_deploy_path='prototxt/vo-v4-2.prototxt' --video_model_path='../training_output/salicon/train_kldloss-leaky-batch-8_1513739634_usesnapshot_1509584263_snapshot-_iter_100000/snapshot-_iter_150000.caffemodel' --infertype='slice' --output_type='video' --test_base='videoset' --model_code='v4-2' --videolength=16
 3624  python test_video.py --video_deploy_path='prototxt/vo-v4-2.prototxt' --video_model_path='../training_output/salicon/vo-v4-2-snapshot-999999-display-1-ledovSet-batch-8_1513764025/snapshot-11250.caffemodel' --infertype='slice' --output_type='video' --test_base='videoset' --model_code='v4-2' --videolength=16
 3625  python test_video.py --video_deploy_path='prototxt/vo-v4-2.prototxt' --video_model_path='../training_output/salicon/vo-v4-2-snapshot-999999-display-1-ledovSet-batch-8_1513764025/snapshot-11250.caffemodel' --infertype='slice' --output_type='image' --test_base='videoset' --model_code='v4-2' --videolength=16
 3626  nvidia-smi
 3627  matlab -nodesktop
 3628  clear
 3629  python test_video.py --video_deploy_path='prototxt/vo-v4-2.prototxt' --video_model_path='../training_output/salicon/vo-v4-2-resnet-catfeat-snapshot-2500-display-1--batch-2_1513846105/snapshot-_iter_7500.caffemodel' --infertype='slice' --output_type='video' --test_base='videoset' --model_code='v4-2' --videolength=16
 3630  python test_video.py --video_deploy_path='prototxt/vo-v4-2.prototxt' --video_model_path='../training_output/salicon/vo-v4-2-resnet-catfeat-snapshot-2500-display-1--batch-2_1513846105/snapshot-_iter_7500.caffemodel' --infertype='slide' --output_type='video' --test_base='videoset' --model_code='v4-2' --videolength=16
 3631  python test_video.py --video_deploy_path='prototxt/vo-v4-2.prototxt' --video_model_path='../training_output/salicon/vo-v4-2-snapshot-999999-display-1-ledovSet-batch-8_1513764025/snapshot-22500.caffemodel' --infertype='slide' --output_type='video' --test_base='videoset' --model_code='v4-2' --videolength=16
 3632  python test_video.py --video_deploy_path='prototxt/vo-v4-2.prototxt' --video_model_path='../training_output/salicon/vo-v4-2-resnet-catfeat-snapshot-2500-display-1--batch-2_1513846105/snapshot-_iter_67500.caffemodel' --infertype='slide' --output_type='video' --test_base='videoset' --model_code='v4-2' --videolength=16
 3633  top
 3634  nvidia-smi
 3635  clear
 3636  top
 3637  nvidia-smi
 3638  top
 3639  nvidia-smi
 3640  top
 3641  nvidia-smi
 3642  source set_env.sh ../C3D-v1.1 0
 3643  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-resnet.prototxt' --use_model='../pretrained_model/c3d_resnet18_sports1m_r2_iter_2800000.caffemodel' --trainingbase='msu'
 3644  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-resnet.prototxt' --use_model='../pretrained_model/c3d_resnet18_sports1m_r2_iter_2800000.caffemodel' --trainingbase='msu' --batch=1
 3645  source set_env.sh ../C3D-v1.1 5
 3646  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-resnet.prototxt' --use_model='../pretrained_model/c3d_resnet18_sports1m_r2_iter_2800000.caffemodel' --trainingbase='msu' --batch=8
 3647  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-resnet.prototxt' --use_model='../pretrained_model/c3d_resnet18_sports1m_r2_iter_2800000.caffemodel' --trainingbase='msu' --batch=2
 3648  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2.prototxt' --use_model='../pretrained_model/conv3d_deepnetA_sport1m_iter_1900000_v1.1.caffemodel' --trainingbase='msu' --batch=2
 3649  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2.prototxt' --use_model='../pretrained_model/conv3d_deepnetA_sport1m_iter_1900000_v1.1.caffemodel' --trainingbase='msu' --batch=8
 3650  clear
 3651  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2.prototxt' --use_model='../pretrained_model/conv3d_deepnetA_sport1m_iter_1900000_v1.1.caffemodel' --trainingbase='msu' --batch=8
 3652  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2.prototxt' --use_model='../pretrained_model/conv3d_deepnetA_sport1m_iter_1900000_v1.1.caffemodel' --trainingbase='msu' --batch=8 --trainingexampleprops=0.9995
 3653  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2.prototxt' --use_model='../pretrained_model/conv3d_deepnetA_sport1m_iter_1900000_v1.1.caffemodel' --trainingbase='msu' --batch=8 --trainingexampleprops=0.9995 --plot_iter=5 --validiter=5
 3654  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2.prototxt' --use_model='../pretrained_model/conv3d_deepnetA_sport1m_iter_1900000_v1.1.caffemodel' --trainingbase='msu' --batch=8 --trainingexampleprops=0.9995 --plotiter=5 --validiter=5
 3655  df -h
 3656  nvidia-smi
 3657  cd pwd/saliency_on_videoset/
 3658  cd Train/metric
 3659  matlab -nodesktop
 3660  cd /data/sunnycia/SaliencyDataset/Video/LEDOV/mats
 3661  matlab
 3662  matlab -nodesktop
 3663  nvidia-smi
 3664  cd pwd/saliency_on_videoset/Train/scripts/
 3665  pwd
 3666  clear
 3667  source set_env.sh ../caffe-flownet/ 3
 3668  python test_video.py --output_type='image' --test_base='videoset' --model_code='v3' video_deploy_path='prototxt/vo-v3-2_deploy.prototxt' --video_model_path='../training_output/salicon/vo-v3-2_train_kldloss_withouteuc-batch-1_1513084718/snapshot-_iter_150000.caffemodel' --infertype='slide' --output_type='image'
 3669  python test_video.py --output_type='image' --test_base='videoset' --model_code='v3' --video_deploy_path='prototxt/vo-v3-2_deploy.prototxt' --video_model_path='../training_output/salicon/vo-v3-2_train_kldloss_withouteuc-batch-1_1513084718/snapshot-_iter_150000.caffemodel' --infertype='slide' --output_type='image'
 3670  python test_video.py --output_type='image' --test_base='videoset' --model_code='v3' --video_deploy_path='prototxt/vo-v3-2_deploy.prototxt' --video_model_path='../training_output/salicon/vo-v3-2_train_kldloss_withouteuc-batch-1_1513084718/snapshot-_iter_150000.caffemodel' --infertype='slide' --output_type='image' --videolength=16
 3671  top
 3672  nvidia-smi
 3673  git status
 3674  git add -all
 3675  git add --all
 3676  git commit -m "Modify Saliencynet.py, abstract class VideoSaliencyNet'
 3677  '
 3678  git commit -m "Modify Saliencynet.py, abstract class VideoSaliencyNet"
 3679  git push -u origin master
 3680  source set_env.sh ../C3D-v1.1/ 3
 3681  nvidia-smi
 3682  clear
 3683  python test_video.py --video_deploy_path='prototxt/vo-v4-2-deploy.prototxt' --video_model_path='../training_output/salicon/vo-v4-2-base_lr-0.01-snapshot-20000-display-1-batch-8_1513218849/snapshot-13500.caffemodel' --infertype='slice' --output_type='image' --test_base='videoset' --model_code='v4-2' --videolength=16
 3684  python test_video.py --video_deploy_path='prototxt/vo-v4-2-deploy.prototxt' --video_model_path='../training_output/salicon/vo-v4-2-base_lr-0.01-snapshot-20000-display-1-batch-8_1513218849/snapshot-6000.caffemodel' --infertype='slice' --output_type='image' --test_base='videoset' --model_code='v4-2' --videolength=16
 3685  python test_video.py --video_deploy_path='prototxt/vo-v4-2-deploy.prototxt' --video_model_path='../training_output/salicon/vo-v4-2-base_lr-0.01-snapshot-20000-display-1-batch-8_1513218849/snapshot-6000.caffemodel' --infertype='slice' --output_type='video' --test_base='videoset' --model_code='v4-2' --videolength=16
 3686  python test_video.py --video_deploy_path='prototxt/vo-v4-2-deploy.prototxt' --video_model_path='../training_output/salicon/vo-v4-2-base_lr-0.01-snapshot-20000-display-1-batch-8_1513218849/snapshot-2000.caffemodel' --infertype='slice' --output_type='video' --test_base='videoset' --model_code='v4-2' --videolength=16
 3687  python test_video.py --video_deploy_path='prototxt/vo-v4-2-deploy.prototxt' --video_model_path='../training_output/salicon/vo-v4-2-base_lr-0.01-snapshot-20000-display-1-batch-8_1513218849/snapshot-3000.caffemodel' --infertype='slice' --output_type='video' --test_base='videoset' --model_code='v4-2' --videolength=16
 3688  python test_video.py --video_deploy_path='prototxt/vo-v4-2-deploy.prototxt' --video_model_path='../training_output/salicon/vo-v4-2-base_lr-0.01-snapshot-20000-display-1-batch-8_1513218849/snapshot-3000.caffemodel' --infertype='slice' --output_type='image' --test_base='videoset' --model_code='v4-2' --videolength=16
 3689  top
 3690  nvidia-smi
 3691  history > history
 3692  python utils/scavenger.py 
 3693  vim utils/scavenger.py 
 3694  vim utils/scavenger.py  --snapshot=1
 3695  python utils/scavenger.py --snapshot=1
 3696  top
 3697  nvidia-smi
 3698  source set_env.sh ../C3D-v1.1 2
 3699  clear
 3700  python test_video.py --video_deploy_path='prototxt/vo-v4-2-deploy.prototxt' --video_model_path='../training_output/salicon/vo-v4-2-base_lr-0.01-snapshot-20000-display-1-batch-8_1513218849/snapshot-13500.caffemodel' --infertype='slice' --output_type='video' --test_base='videoset' --model_code='v4-2' --videolength=16 --threshold=0.75
 3701  cd /data/sunnycia/SaliencyDataset/Video/LEDOV/LEDOV/..
 3702  ls
 3703  python script_for_classify_data.py 
 3704  wpd
 3705  pwd
 3706  cd LEDOV/
 3707  touch generate_fixation.m
 3708  vim generate_fixation.m 
 3709  to
 3710  top
 3711  cd -
 3712  cd ~/pwd/saliency_on_videoset/Train/scripts/
 3713  python utils/gen_density.py --sigma=32 --fixation_base='/data/sunnycia/SaliencyDataset/Video/LEDOV/fixation' --density_base='/data/sunnycia/SaliencyDataset/Video/LEDOV/density'
 3714  python utils/gen_density.py --sigma=32 --fixation_base='/data/sunnycia/SaliencyDataset/Video/LEDOV/fixation' --density_base='/data/sunnycia/SaliencyDataset/Video/LEDOV/density' --fixationtype='image'
 3715  nvidia-smi
 3716  git statsu
 3717  git status
 3718  git push -u origin master
 3719  nvidia-smi
 3720  source set_env.sh ../caffe-flownet/ 1
 3721  python test_image.py --modelbase='' --testset='mit1003
 3722  python test_image.py --modelpath='../training_output/salicon/train_kldloss-leaky-batch-8_1513739634_usesnapshot_1509584263_snapshot-_iter_100000/snapshot-_iter_200000.caffemodel' --testset='mit1003'  && python test_image.py --modelpath='../training_output/salicon/train_kldloss-base_lr-0.0001-weight_decay-0.000005-momentum-0.95-batch-8_1513602632_usesnapshot_1509584263_snapshot-_iter_100000/snapshot-_iter_200000.caffemodel' --testset='mit1003'
 3723  clear
 3724  python test_image.py --modelpath='../training_output/salicon/train_kldloss-leaky-batch-8_1513739634_usesnapshot_1509584263_snapshot-_iter_100000/snapshot-_iter_200000.caffemodel' --testset='mit1003'  && python test_image.py --modelpath='../training_output/salicon/train_kldloss-base_lr-0.0001-weight_decay-0.000005-momentum-0.95-batch-8_1513602632_usesnapshot_1509584263_snapshot-_iter_100000/snapshot-_iter_200000.caffemodel' --testset='mit1003'
 3725  git status
 3726  python metric/avg_metric.py --metricdir='../metric-matlab'
 3727  nvidia-smi
 3728  git status
 3729  git add --all
 3730  git commit -m "Done for v4-2-resnet model arch and v4-2-resnet-catfeat model arch."
 3731  git push -u origin master
 3732  clear
 3733  to
 3734  top
 3735  nvidia-smi
 3736  clear
 3737  cd pwd/saliency_on_videoset/Train/scripts/
 3738  git status
 3739  git add --all
 3740  git commit -m "Done for v4-2 model, use dconv3d to restruct saliency map"
 3741  git push -u origin master
 3742  source set_env.sh ../caffe-flownet/ 3
 3743  python test_video.py --output_type='video' --test_base='videoset' --model_code='v3' --video_deploy_path='prototxt/vo-v3-2_deploy.prototxt' --video_model_path='../training_output/salicon/vo-v3-2_train_kldloss_withouteuc-batch-1_1513084718/snapshot-_iter_150000.caffemodel' --infertype='slide' 
 3744  python test_video.py --output_type='video' --test_base='videoset' --model_code='v3' --video_deploy_path='prototxt/vo-v3-2_deploy.prototxt' --video_model_path='../training_output/salicon/vo-v3-2_train_kldloss_withouteuc-batch-1_1513084718/snapshot-_iter_150000.caffemodel' --infertype='slide' --videolength=16
 3745  python metric/avg_metric.py /data/sunnycia/saliency_on_videoset/Train/metric-matlab/videoset/
 3746  python metric/avg_metric.py --metricdia='/data/sunnycia/saliency_on_videoset/Train/metric-matlab/videoset/'
 3747  python metric/avg_metric.py --metricdir='/data/sunnycia/saliency_on_videoset/Train/metric-matlab/videoset/'
 3748  python metric/avg_metric.py --metricdir='/data/sunnycia/saliency_on_videoset/Train/metric-matlab/videoset'
 3749  python metric/avg_metric.py --metricdir='metric-matlab'
 3750  python metric/avg_metric.py --metricdir='../metric-matlab'
 3751  clear
 3752  python test_video.py --video_deploy_path='prototxt/vo-v4-2-deplot.prototxt' --video_model_path='../training_output/salicon/vo-v4-2-base_lr-0.01-snapshot-20000-display-1-batch-8_1513218849/snapshot-13500.caffemodel' --infertype='slice' 
 3753  python test_video.py --video_deploy_path='prototxt/vo-v4-2-deplot.prototxt' --video_model_path='../training_output/salicon/vo-v4-2-base_lr-0.01-snapshot-20000-display-1-batch-8_1513218849/snapshot-13500.caffemodel' --infertype='slice' --output_type='video' --test_base='videoset'
 3754  python test_video.py --video_deploy_path='prototxt/vo-v4-2-deplot.prototxt' --video_model_path='../training_output/salicon/vo-v4-2-base_lr-0.01-snapshot-20000-display-1-batch-8_1513218849/snapshot-13500.caffemodel' --infertype='slice' --output_type='video' --test_base='videoset' --model_code='v4-2'
 3755  python test_video.py --video_deploy_path='prototxt/vo-v4-2-deploy.prototxt' --video_model_path='../training_output/salicon/vo-v4-2-base_lr-0.01-snapshot-20000-display-1-batch-8_1513218849/snapshot-13500.caffemodel' --infertype='slice' --output_type='video' --test_base='videoset' --model_code='v4-2'
 3756  source set_env.sh ../C3D-v1.1/ 3
 3757  nvidia-smi
 3758  python test_video.py --video_deploy_path='prototxt/vo-v4-2-deploy.prototxt' --video_model_path='../training_output/salicon/vo-v4-2-base_lr-0.01-snapshot-20000-display-1-batch-8_1513218849/snapshot-13500.caffemodel' --infertype='slice' --output_type='video' --test_base='videoset' --model_code='v4-2'
 3759  python test_video.py --video_deploy_path='prototxt/vo-v4-2-deploy.prototxt' --video_model_path='../training_output/salicon/vo-v4-2-base_lr-0.01-snapshot-20000-display-1-batch-8_1513218849/snapshot-13500.caffemodel' --infertype='slice' --output_type='video' --test_base='videoset' --model_code='v4-2' --videolength=16
 3760  top
 3761  nvidia-smi
 3762  top
 3763  nvidia-smi
 3764  top
 3765  python test_video.py --video_deploy_path='prototxt/vo-v4-2-deploy.prototxt' --video_model_path='../training_output/salicon/vo-v4-2-base_lr-0.01-snapshot-20000-display-1-batch-8_1513218849/snapshot-13500.caffemodel' --infertype='slice' --output_type='video' --test_base='msu' --model_code='v4-2' --videolength=16
 3766  python test_video.py --video_deploy_path='prototxt/vo-v4-2-deploy.prototxt' --video_model_path='../training_output/salicon/vo-v4-2-base_lr-0.01-snapshot-20000-display-1-batch-8_1513218849/snapshot-1500.caffemodel' --infertype='slice' --output_type='video' --test_base='videoset' --model_code='v4-2' --videolength=16
 3767   git status
 3768  git add --all
 3769  git commit -m "add validation plot function. "
 3770  git push -u origin master
 3771  cd ../C3D-v1.1-kldloss/
 3772  make clean
 3773  make -j16 all 
 3774  make -j4 pycaffe
 3775  python test_video.py --video_deploy_path='prototxt/vo-v4-2-deploy.prototxt' --video_model_path='../training_output/salicon/vo-v4-2-fixweight+dropout-base_lr-0.01-snapshot-999999-display-1--batch-8_1513416586/snapshot-9000.caffemodel' --infertype='slice' --output_type='video' --test_base='videoset' --model_code='v4-2' --videolength=16
 3776  cd ../scripts/
 3777  python test_video.py --video_deploy_path='prototxt/vo-v4-2-deploy.prototxt' --video_model_path='../training_output/salicon/vo-v4-2-fixweight+dropout-base_lr-0.01-snapshot-999999-display-1--batch-8_1513416586/snapshot-9000.caffemodel' --infertype='slice' --output_type='video' --test_base='videoset' --model_code='v4-2' --videolength=16
 3778  source set_env.sh ../C3D-v1.1 3
 3779  nvidia-smi
 3780  source set_env.sh ../C3D-v1.1 2
 3781  python test_video.py --video_deploy_path='prototxt/vo-v4-2-deploy.prototxt' --video_model_path='../training_output/salicon/vo-v4-2-fixweight+dropout-base_lr-0.01-snapshot-999999-display-1--batch-8_1513416586/snapshot-9000.caffemodel' --infertype='slice' --output_type='video' --test_base='videoset' --model_code='v4-2' --videolength=16
 3782  python test_video.py --video_deploy_path='prototxt/vo-v4-2-deploy-fixweight+dropout.prototxt' --video_model_path='../training_output/salicon/vo-v4-2-fixweight+dropout-base_lr-0.01-snapshot-999999-display-1--batch-8_1513416586/snapshot-9000.caffemodel' --infertype='slice' --output_type='video' --test_base='videoset' --model_code='v4-2' --videolength=16
 3783  clear
 3784  source set_env.sh ../C3D-v1.1 3
 3785  nvidia-smi
 3786  nvidia-smi 2
 3787  source set_env.sh ../C3D-v1.1 2
 3788  python test_video.py --video_deploy_path='prototxt/vo-v4-2-deploy.prototxt' --video_model_path='../training_output/salicon/vo-v4-2-fixweight+dropout-base_lr-0.01-snapshot-999999-display-1--batch-8_1513416586/snapshot-21600.caffemodel' --infertype='slice' --output_type='image' --test_base='videoset' --model_code='v4-2' --videolength=16
 3789  python test_video.py --video_deploy_path='prototxt/vo-v4-2-deploy.prototxt' --video_model_path='../training_output/salicon/vo-v4-2-fixweight+dropout-base_lr-0.01-snapshot-999999-display-1--batch-8_1513416541/snapshot-0.caffemodel' --infertype='slice' --output_type='image' --test_base='videoset' --model_code='v4-2' --videolength=16
 3790  python test_video.py --video_deploy_path='prototxt/vo-v4-2-deploy.prototxt' --video_model_path='../training_output/salicon/vo-v4-2-stepsize-500-lr_policy-step-base_lr-0.01-snapshot-20000-display-1-batch-8_1513221679/snapshot-31500.caffemodel' --infertype='slice' --output_type='image' --test_base='videoset' --model_code='v4-2' --videolength=16
 3791  python test_video.py --video_deploy_path='prototxt/vo-v4-2-deploy.prototxt' --video_model_path='../training_output/salicon/vo-v4-2-stepsize-500-lr_policy-step-base_lr-0.01-snapshot-20000-display-1-batch-8_1513221679/snapshot-31500.caffemodel' --infertype='slice' --output_type='video' --test_base='videoset' --model_code='v4-2' --videolength=16
 3792  python test_video.py --video_deploy_path='prototxt/vo-v4-2-deploy.prototxt' --video_model_path='../training_output/salicon/vo-v4-2-weight_decay-0.000005-base_lr-0.001-snapshot-999999-display-1-momentum-0.95--batch-8_1513597332/snapshot-6000.caffemodel' --infertype='slice' --output_type='video' --test_base='videoset' --model_code='v4-2' --videolength=16
 3793  python test_video.py --video_deploy_path='prototxt/vo-v4-2-deploy.prototxt' --video_model_path='../training_output/salicon/vo-v4-2-weight_decay-0.000005-base_lr-0.0001-snapshot-999999-display-1-momentum-0.95--batch-8_1513596875/snapshot-5400.caffemodel' --infertype='slice' --output_type='video' --test_base='videoset' --model_code='v4-2' --videolength=16
 3794  python test_video.py --video_deploy_path='prototxt/vo-v4-2-deploy.prototxt' --video_model_path='../training_output/salicon/vo-v4-2-weight_decay-0.000005-base_lr-0.00001-snapshot-999999-display-1-momentum-0.95--batch-8_1513597365/snapshot-6000.caffemodel' --infertype='slice' --output_type='video' --test_base='videoset' --model_code='v4-2' --videolength=16
 3795  python test_video.py --video_deploy_path='prototxt/vo-v4-2-deploy.prototxt' --video_model_path='../training_output/salicon/vo-v4-2-weight_decay-0.000005-base_lr-0.00001-snapshot-999999-display-1-momentum-0.95--batch-8_1513597365/snapshot-6000.caffemodel' --infertype='slice' --output_type='video' --test_base='videoset' --model_code='v4-2' --videolength=16 --threshold=0.75
 3796  clear
 3797  python test_video.py --video_deploy_path='prototxt/vo-v4-2-deploy.prototxt' --video_model_path='../training_output/salicon/vo-v4-2-weight_decay-0.000005-base_lr-0.00001-snapshot-999999-display-1-momentum-0.95--batch-8_1513597365/snapshot-6000.caffemodel' --infertype='slice' --output_type='video' --test_base='videoset' --model_code='v4-2' --videolength=16 --threshold=0.75
 3798  clear
 3799  python test_video.py --video_deploy_path='prototxt/vo-v4-2-deploy.prototxt' --video_model_path='../training_output/salicon/vo-v4-2-base_lr-0.01-snapshot-20000-display-1-batch-8_1513218849/snapshot-13500.caffemodel' --infertype='slice' --output_type='video' --test_base='videoset' --model_code='v4-2' --videolength=16 --threshold=0.75
 3800  python test_video.py --video_deploy_path='prototxt/vo-v4-2-deploy.prototxt' --video_model_path='../training_output/salicon/vo-v4-2-base_lr-0.01-snapshot-20000-display-1-batch-8_1513218849/snapshot-13500.caffemodel' --infertype='slice' --output_type='video' --test_base='videoset' --model_code='v4-2' --videolength=16 --threshold=0.9
 3801  python test_video.py --video_deploy_path='prototxt/vo-v4-2-deploy.prototxt' --video_model_path='../training_output/salicon/vo-v4-2-base_lr-0.01-snapshot-20000-display-1-batch-8_1513218849/snapshot-13500.caffemodel' --infertype='slice' --output_type='video' --test_base='videoset' --model_code='v4-2' --videolength=16 --threshold=0.75
 3802  python test_video.py --video_deploy_path='prototxt/vo-v4-2-deploy.prototxt' --video_model_path='../training_output/salicon/vo-v4-2-base_lr-0.01-snapshot-20000-display-1-batch-8_1513218849/snapshot-13500.caffemodel' --infertype='slice' --output_type='image' --test_base='videoset' --model_code='v4-2' --videolength=16 --threshold=0.75
 3803  top
 3804  nvidia-smi
 3805  python test_video.py --video_deploy_path='prototxt/vo-v4-2-deploy.prototxt' --video_model_path='../training_output/salicon/vo-v4-2-base_lr-0.01-snapshot-20000-display-1-batch-8_1513218849/snapshot-13500.caffemodel' --infertype='slice' --output_type='image' --test_base='videoset' --model_code='v4-2' --videolength=16 --threshold=0.75 
 3806  python utils/VorI/slice_frame.py
 3807  python utils/VorI/slice_frames.py 
 3808  python utils/VorI/slice_frames.py --videobase='/data/sunnycia/SaliencyDataset/Video/LEDOV/videos' --outputbase='/data/sunnycia/SaliencyDataset/Video/LEDOV/frames' 
 3809  cd /data/sunnycia/SaliencyDataset/Video/LEDOV
 3810  rm -rf fixation/
 3811  rm -rf frames/
 3812  cd -
 3813  python utils/VorI/slice_frames.py --videobase='/data/sunnycia/SaliencyDataset/Video/LEDOV/videos' --outputbase='/data/sunnycia/SaliencyDataset/Video/LEDOV/frames' 
 3814  clear
 3815  python utils/VorI/slice_frames.py --videobase='/data/sunnycia/SaliencyDataset/Video/LEDOV/videos' --outputbase='/data/sunnycia/SaliencyDataset/Video/LEDOV/frames' 
 3816  top
 3817  nvidia-smi
 3818  df -h
 3819  top
 3820  ssh root@172.31.70.212
 3821  ssh wangxu@172.31.70.212
 3822  ssh root@172.31.234.205
 3823  cd pwd/saliency_on_videoset/Train/scripts/
 3824  source set_env.sh ../C3D-v1.1 0
 3825  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-resnet.prototxt' --use_model='../pretrained_model/c3d_resnet18_sports1m_r2_iter_2800000.caffemodel' --trainingbase='ledov' --batch=2 --trainingexampleprops=0.9995 --savemodeliter=10 --validiter=10 --snapshotincode=False
 3826  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-resnet.prototxt' --use_model='../pretrained_model/c3d_resnet18_sports1m_r2_iter_2800000.caffemodel' --trainingbase='ledov' --batch=2 --trainingexampleprops=0.9995 --savemodeliter=10 --validiter=10 
 3827  clear
 3828  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-resnet.prototxt' --use_model='../pretrained_model/c3d_resnet18_sports1m_r2_iter_2800000.caffemodel' --trainingbase='ledov' --batch=2 --trainingexampleprops=0.9995 --savemodeliter=2500 --validiter=2500
 3829  nvidia-smi
 3830  top
 3831  nvidia-smi
 3832  clear
 3833  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-resnet.prototxt' --use_model='../pretrained_model/c3d_resnet18_sports1m_r2_iter_2800000.caffemodel' --trainingbase='ledov' --batch=2 --trainingexampleprops=0.9995 --savemodeliter=2500 --validiter=2500
 3834  clear
 3835  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-resnet.prototxt' --use_model='../pretrained_model/c3d_resnet18_sports1m_r2_iter_2800000.caffemodel' --trainingbase='ledov' --batch=2 --trainingexampleprops=0.9995 --savemodeliter=2500 --validiter=2500
 3836  ls
 3837  nvidia-smi
 3838  top
 3839  nvidia-smi
 3840  top
 3841  cd pwd/saliency_on_videoset/Train/scripts/
 3842  git status
 3843  git add --all
 3844  git commit -m "Training baseline with leaky relu"
 3845  clear
 3846  source set_env.sh ../C3D-v1.1 7
 3847  nvidia-smi
 3848  top
 3849  nvidia-smi
 3850  source set_env.sh ../C3D-v1.1 1
 3851  python training_video_voxel_based.py --train_prototxt='prototxt/voo-v4-2-resnet.prototxt'--use_model='../pretrained_model/c3d_resnet18_sports1m_r2_iter_2800000.caffemodel' --trainingbase='msu
 3852  '
 3853  python training_video_voxel_based.py --train_prototxt='prototxt/voo-v4-2-resnet.prototxt'--use_model='../pretrained_model/c3d_resnet18_sports1m_r2_iter_2800000.caffemodel' --trainingbase='msu'
 3854  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-resnet.prototxt'--use_model='../pretrained_model/c3d_resnet18_sports1m_r2_iter_2800000.caffemodel' --trainingbase='msu'
 3855  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-resnet.prototxt' --use_model='../pretrained_model/c3d_resnet18_sports1m_r2_iter_2800000.caffemodel' --trainingbase='msu'
 3856  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-resnet.prototxt' --use_model='../pretrained_model/c3d_resnet18_sports1m_r2_iter_2800000.caffemodel' --trainingbase='msu' --batch=8 --debug=1
 3857  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-resnet.prototxt' --use_model='../pretrained_model/c3d_resnet18_sports1m_r2_iter_2800000.caffemodel' --trainingbase='msu' --batch=2 --debug=1
 3858  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-resnet.prototxt' --use_model='../pretrained_model/c3d_resnet18_sports1m_r2_iter_2800000.caffemodel' --trainingbase='msu' --batch=2 
 3859  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-resnet.prototxt' --use_model='../pretrained_model/c3d_resnet18_sports1m_r2_iter_2800000.caffemodel' --trainingbase='msu' --batch=2 --trainingexampleprops=0.99995
 3860  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-resnet.prototxt' --use_model='../pretrained_model/c3d_resnet18_sports1m_r2_iter_2800000.caffemodel' --trainingbase='msu' --batch=2 --trainingexampleprops=0.9999
 3861  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-resnet.prototxt' --use_model='../pretrained_model/c3d_resnet18_sports1m_r2_iter_2800000.caffemodel' --trainingbase='msu' --batch=2 --trainingexampleprops=0.9995
 3862  clear
 3863  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-resnet.prototxt' --use_model='../pretrained_model/c3d_resnet18_sports1m_r2_iter_2800000.caffemodel' --trainingbase='msu' --batch=2 --trainingexampleprops=0.9995
 3864  clear
 3865  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-resnet.prototxt' --use_model='../pretrained_model/c3d_resnet18_sports1m_r2_iter_2800000.caffemodel' --trainingbase='msu' --batch=2 --trainingexampleprops=0.9995 --trainingbase='ledov'
 3866  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-resnet.prototxt' --use_model='../pretrained_model/c3d_resnet18_sports1m_r2_iter_2800000.caffemodel' --trainingbase='msu' --batch=2 --trainingexampleprops=0.9999 --trainingbase='ledov'
 3867  nvidia-smi
 3868  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-resnet.prototxt' --use_model='../pretrained_model/c3d_resnet18_sports1m_r2_iter_2800000.caffemodel' --trainingbase='msu' --batch=2 --trainingexampleprops=0.9999 --trainingbase='ledov'
 3869  nvidia-smi
 3870  clear
 3871  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-resnet-catfeat.prototxt' --use_model='../pretrained_model/c3d_resnet18_sports1m_r2_iter_2800000.caffemodel' --trainingbase='msu' --batch=2 --trainingexampleprops=0.9995 --trainingbase='ledov' --savemodeliter=2500 --validiter=2500
 3872  clear
 3873  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-resnet-catfeat.prototxt' --use_model='../pretrained_model/c3d_resnet18_sports1m_r2_iter_2800000.caffemodel' --batch=2 --trainingexampleprops=0.9995 --trainingbase='ledov' --savemodeliter=2500 --validiter=2500
 3874  clear
 3875  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-resnet-catfeat.prototxt' --use_model='../pretrained_model/c3d_resnet18_sports1m_r2_iter_2800000.caffemodel' --batch=2 --trainingexampleprops=0.9995 --trainingbase='ledov' --savemodeliter=2500 --validiter=2500
 3876  cd pwd/saliency_on_videoset/Train/
 3877  ls
 3878  nvidia-smi
 3879  top
 3880  clear
 3881  cd caffe
 3882  make -j8 all 
 3883  clear
 3884  top
 3885  nvidia-smi
 3886  clear
 3887  cd ~/pwd/saliency_on_videoset/Train/scripts/
 3888  source set_env.sh ../caffe-flownet/
 3889  nvidia-smi
 3890  export CUDA_VISIBLE_DEVICES=7
 3891  clear
 3892  python training_video_framestack_based.py --train_prototxt='prototxt/vo-v3-2_train_kldloss_withouteuc.prototxt' --use_model='../training_output/salicon/train_kldloss_withouteuc-batch-8_1509584263/snapshot-_iter_100000.caffemodel' --version=2 --keyframeinterv=9 
 3893  clear
 3894  python training_video_framestack_based.py --train_prototxt='prototxt/vo-v3-2_train_kldloss_withouteuc.prototxt' --use_model='../training_output/salicon/train_kldloss_withouteuc-batch-8_1509584263/snapshot-_iter_100000.caffemodel' --version=2 --keyframeinterv=9 
 3895  python training_video_framestack_based.py --train_prototxt='prototxt/vo-v3-2_train_kldloss_withouteuc.prototxt' --use_model='../training_output/salicon/train_kldloss_withouteuc-batch-8_1509584263/snapshot-_iter_100000.caffemodel' --version=2 --keyframeinterv=16 --overlap=15 
 3896  top
 3897  nvidia-smi
 3898  git status
 3899  git add --all
 3900  git commit -m "Done for v4-3-1 model, use kldloss, C3D-v1.1-kldloss, output 1 saliency map, add abs layer to avoid nan loss value"
 3901  git push -u origin master
 3902  top
 3903  nvidia-smi
 3904  clear
 3905  nvidia-smi
 3906  cd ../caffe-master/
 3907  mv src/caffe/ include/
 3908  mv src/caffe/voxel_wise_softmax_loss_layer.hpp include/
 3909  cd include/
 3910  ls
 3911  cd ..
 3912  make -j8 all
 3913  clear
 3914  make clean
 3915  make -j8 all
 3916  make clean
 3917  make -j8 all
 3918  make clean
 3919  make -j8 all
 3920  clear
 3921  nvidia-smi
 3922  top
 3923  nvidia-smi
 3924  clear
 3925  top
 3926  nvidia-smi
 3927  top
 3928  nvidia-smi
 3929  top
 3930  nvidia-smi
 3931  top
 3932  nvidia-smi
 3933  cd ~
 3934  cd pwd/saliency_on_videoset/_Train/
 3935  ls
 3936  git clone https://github.com/cagdasbak/dynamicsaliency.git
 3937  nvidia-smi
 3938  vim ~/.bashrc
 3939  python
 3940  nvidia-smi
 3941  top
 3942  nvidia-smi
 3943  git status
 3944  cd pwd/saliency_on_videoset/Train/scripts/
 3945  git status
 3946  nvidia-smi
 3947  source set_env.sh ../C3D-v1.1 2
 3948  clear
 3949  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2.prototxt' --use_model='../pretrained_model/conv3d_deepnetA_sport1m_iter_1900000' --trainingbase='ledov' --extrainfo='ledovSet'
 3950  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2.prototxt' --use_model='../pretrained_model/conv3d_deepnetA_sport1m_iter_1900000' --trainingbase='ledov' --extramodinfo='ledovSet'
 3951  source set_env.sh ../C3D-v1.1-kldloss/ 2
 3952  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2.prototxt' --use_model='../pretrained_model/conv3d_deepnetA_sport1m_iter_1900000' --trainingbase='ledov' --extramodinfo='ledovSet'
 3953  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2.prototxt' --use_model='../pretrained_model/conv3d_deepnetA_sport1m_iter_1900000_v1.1.caffemodel' --trainingbase='ledov' --extramodinfo='ledovSet'
 3954  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2.prototxt' --use_model='../pretrained_model/conv3d_deepnetA_sport1m_iter_1900000_v1.1.caffemodel' --trainingbase='ledov' --extramodinfo='ledovSet' --trainingexampleprops='1.0'
 3955  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2.prototxt' --use_model='../pretrained_model/conv3d_deepnetA_sport1m_iter_1900000_v1.1.caffemodel' --trainingbase='ledov' --extramodinfo='ledovSet' --trainingexampleprops='1.0' --batch=8
 3956  clear
 3957  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2.prototxt' --use_model='../pretrained_model/conv3d_deepnetA_sport1m_iter_1900000_v1.1.caffemodel' --trainingbase='ledov' --extramodinfo='ledovSet' --trainingexampleprops='1.0' --batch=8
 3958  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2.prototxt' --use_model='../pretrained_model/conv3d_deepnetA_sport1m_iter_1900000_v1.1.caffemodel' --trainingbase='ledov' --extramodinfo='ledovSet' --trainingexampleprops='0.995' --batch=8
 3959  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2.prototxt' --use_model='../pretrained_model/conv3d_deepnetA_sport1m_iter_1900000_v1.1.caffemodel' --trainingbase='ledov' --extramodinfo='ledovSet' --trainingexampleprops='0.9999' --batch=8
 3960  clear
 3961  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2.prototxt' --use_model='../pretrained_model/conv3d_deepnetA_sport1m_iter_1900000_v1.1.caffemodel' --trainingbase='ledov' --extramodinfo='ledovSet' --trainingexampleprops='0.9999' --batch=8
 3962  cd /data/sunnycia/SaliencyDataset/Video/LEDOV
 3963  python rename.py 
 3964  cd -
 3965  clear
 3966  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2.prototxt' --use_model='../pretrained_model/conv3d_deepnetA_sport1m_iter_1900000_v1.1.caffemodel' --trainingbase='ledov' --extramodinfo='ledovSet' --trainingexampleprops='0.995' --batch=8
 3967  clear
 3968  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2.prototxt' --use_model='../pretrained_model/conv3d_deepnetA_sport1m_iter_1900000_v1.1.caffemodel' --trainingbase='ledov' --extramodinfo='ledovSet' --trainingexampleprops='0.995' --batch=8
 3969  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2.prototxt' --use_model='../pretrained_model/conv3d_deepnetA_sport1m_iter_1900000_v1.1.caffemodel' --trainingbase='ledov' --extramodinfo='ledovSet' --trainingexampleprops='0.995' --batch=8 --validiter=2250 --savemodeliter=2250 
 3970  claer
 3971  clear
 3972  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2.prototxt' --use_model='../pretrained_model/conv3d_deepnetA_sport1m_iter_1900000_v1.1.caffemodel' --trainingbase='ledov' --extramodinfo='ledovSet' --trainingexampleprops='0.995' --batch=8 --validiter=2250 --savemodeliter=2250 
 3973  top
 3974  nvidia-smi
 3975  watch -n 0.5 nvidia-smi
 3976  top
 3977  nvidia-smi
 3978  top
 3979  nvidia-smi
 3980  clear
 3981  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2.prototxt' --use_model='../pretrained_model/conv3d_deepnetA_sport1m_iter_1900000_v1.1.caffemodel' --trainingbase='msu' --batch=2
 3982  cd pwd/saliency_on_videoset/Train/scripts/
 3983  source set_env.sh ../C3D-v1.1/ 3
 3984  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2.prototxt' --use_model='../pretrained_model/conv3d_deepnetA_sport1m_iter_1900000_v1.1.caffemodel' --trainingbase='msu' --batch=2 --overlap=8
 3985  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2.prototxt' --use_model='../pretrained_model/conv3d_deepnetA_sport1m_iter_1900000_v1.1.caffemodel' --trainingbase='msu' --batch=2 --overlap=8 --staticsolver=1 --solver_prototxt='prototxt/solver-static.prototxt'
 3986  clear
 3987  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2.prototxt' --use_model='../pretrained_model/conv3d_deepnetA_sport1m_iter_1900000_v1.1.caffemodel' --trainingbase='msu' --batch=2 --overlap=8 --staticsolver=1 --solver_prototxt='prototxt/solver-static.prototxt'
 3988  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2.prototxt' --use_model='../pretrained_model/conv3d_deepnetA_sport1m_iter_1900000_v1.1.caffemodel' --trainingbase='msu' --batch=2 --overlap=8 --staticsolver=1 --solver_prototxt='prototxt/solver-static.prototxt' --batch=2
 3989  clear
 3990  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2.prototxt' --use_model='../pretrained_model/conv3d_deepnetA_sport1m_iter_1900000_v1.1.caffemodel' --trainingbase='msu' --batch=2 --overlap=8 --staticsolver=1 --solver_prototxt='prototxt/solver-static.prototxt' --batch=2
 3991  clear
 3992  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2.prototxt' --use_model='../pretrained_model/conv3d_deepnetA_sport1m_iter_1900000_v1.1.caffemodel' --trainingbase='msu' --batch=2 --overlap=8 --staticsolver=1 --solver_prototxt='prototxt/solver-static.prototxt' --batch=2
 3993  clear
 3994  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2.prototxt' --use_model='../pretrained_model/conv3d_deepnetA_sport1m_iter_1900000_v1.1.caffemodel' --trainingbase='msu' --batch=2 --overlap=8 --staticsolver=1 --solver_prototxt='prototxt/solver-static.prototxt' --batch=2
 3995  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2.prototxt' --use_model='../pretrained_model/conv3d_deepnetA_sport1m_iter_1900000_v1.1.caffemodel' --trainingbase='msu' --batch=2 --overlap=8 --staticsolver=1 --solver_prototxt='prototxt/solver-static.prototxt' --batch=2 --plotiter=10 --validiter=5 --trainingexampleprops=0.99
 3996  clear
 3997  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2.prototxt' --use_model='../pretrained_model/conv3d_deepnetA_sport1m_iter_1900000_v1.1.caffemodel' --trainingbase='msu' --batch=2 --overlap=8 --staticsolver=1 --solver_prototxt='prototxt/solver-static.prototxt' --batch=2 --plotiter=10 --validiter=5 --trainingexampleprops=0.99
 3998  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2.prototxt' --use_model='../pretrained_model/conv3d_deepnetA_sport1m_iter_1900000_v1.1.caffemodel' --trainingbase='msu' --batch=2 --overlap=8 --staticsolver=1 --solver_prototxt='prototxt/solver-static.prototxt' --batch=2 --plotiter=10 --validiter=5 --trainingexampleprops=0.995 
 3999  clear
 4000  ls
 4001  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2.prototxt' --use_model='../pretrained_model/conv3d_deepnetA_sport1m_iter_1900000_v1.1.caffemodel' --trainingbase='msu' --batch=2 --overlap=8 --staticsolver=1 --solver_prototxt='prototxt/solver-static.prototxt' --batch=2 --plotiter=10 --validiter=5 --trainingexampleprops=0.995 
 4002  clear
 4003  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2.prototxt' --use_model='../pretrained_model/conv3d_deepnetA_sport1m_iter_1900000_v1.1.caffemodel' --trainingbase='msu' --batch=2 --overlap=8 --staticsolver=1 --solver_prototxt='prototxt/solver-static.prototxt' --batch=2 --plotiter=10 --validiter=5 --trainingexampleprops=0.995 
 4004  clear
 4005  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2.prototxt' --use_model='../pretrained_model/conv3d_deepnetA_sport1m_iter_1900000_v1.1.caffemodel' --trainingbase='msu' --batch=2 --overlap=8 --staticsolver=1 --solver_prototxt='prototxt/solver-static.prototxt' --batch=2 --plotiter=10 --validiter=5 --trainingexampleprops=0.995 
 4006  clear
 4007  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2.prototxt' --use_model='../pretrained_model/conv3d_deepnetA_sport1m_iter_1900000_v1.1.caffemodel' --trainingbase='msu' --batch=2 --overlap=8 --staticsolver=1 --solver_prototxt='prototxt/solver-static.prototxt' --batch=2 --plotiter=10 --validiter=5 --trainingexampleprops=0.995 
 4008  clear
 4009  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2.prototxt' --use_model='../pretrained_model/conv3d_deepnetA_sport1m_iter_1900000_v1.1.caffemodel' --trainingbase='msu' --batch=2 --overlap=8 --staticsolver=1 --solver_prototxt='prototxt/solver-static.prototxt' --batch=2 --plotiter=10 --validiter=5 --trainingexampleprops=0.995 
 4010  clear
 4011  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2.prototxt' --use_model='../pretrained_model/conv3d_deepnetA_sport1m_iter_1900000_v1.1.caffemodel' --trainingbase='msu' --batch=2 --overlap=8 --staticsolver=1 --solver_prototxt='prototxt/solver-static.prototxt' --batch=2 --plotiter=10 --validiter=5 --trainingexampleprops=0.995 
 4012  clear
 4013  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2.prototxt' --use_model='../pretrained_model/conv3d_deepnetA_sport1m_iter_1900000_v1.1.caffemodel' --trainingbase='msu' --batch=2 --overlap=8 --staticsolver=1 --solver_prototxt='prototxt/solver-static.prototxt' --batch=2 --plotiter=10 --validiter=5 --trainingexampleprops=0.8 
 4014  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2.prototxt' --use_model='../pretrained_model/conv3d_deepnetA_sport1m_iter_1900000_v1.1.caffemodel' --trainingbase='msu' --batch=2 --overlap=8 --staticsolver=1 --solver_prototxt='prototxt/solver-static.prototxt' --batch=2 --plotiter=10 --validiter=5 --trainingexampleprops=0.995
 4015  clear
 4016  clera
 4017  clear
 4018  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2.prototxt' --use_model='../pretrained_model/conv3d_deepnetA_sport1m_iter_1900000_v1.1.caffemodel' --trainingbase='msu' --batch=8 --trainingexampleprops=0.995 --validiter=5 --plotiter=10 --overlap=12
 4019  clear
 4020  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2.prototxt' --use_model='../pretrained_model/conv3d_deepnetA_sport1m_iter_1900000_v1.1.caffemodel' --trainingbase='msu' --batch=8 --trainingexampleprops=0.8 --overlap=12
 4021  clear
 4022  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2.prototxt' --use_model='../pretrained_model/conv3d_deepnetA_sport1m_iter_1900000_v1.1.caffemodel' --trainingbase='msu' --batch=8 --trainingexampleprops=0.8 --overlap=12
 4023  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2.prototxt' --use_model='../pretrained_model/conv3d_deepnetA_sport1m_iter_1900000_v1.1.caffemodel' --trainingbase='msu' --batch=8 --trainingexampleprops=0.998 --overlap=12
 4024  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2.prototxt' --use_model='../pretrained_model/conv3d_deepnetA_sport1m_iter_1900000_v1.1.caffemodel' --trainingbase='msu' --batch=8 --trainingexampleprops=0.998 --overlap=12 --validiter=4 --plotiter=7
 4025  clear
 4026  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2.prototxt' --use_model='../pretrained_model/conv3d_deepnetA_sport1m_iter_1900000_v1.1.caffemodel' --trainingbase='msu' --batch=8 --trainingexampleprops=0.8 --overlap=12
 4027  clear
 4028  source set_env.sh ../caffe-flownet/ 3
 4029  python training_image.py --train_prototxt='prototxt/train_kldloss.prototxt' --usesnapshot='../training_output/salicon/train_kldloss_withouteuc-batch-8_1509584263/snapshot-_iter_100000.solverstte' --batch=8 --dsname='salicon'
 4030  python training_image.py --train_prototxt='prototxt/train_kldloss.prototxt' --usesnapshot='../training_output/salicon/train_kldloss_withouteuc-batch-8_1509584263/snapshot-_iter_100000.solverstate' --batch=8 --dsname='salicon'
 4031  python training_image.py --train_prototxt='prototxt/train_kldloss.prototxt' --use_snapshot='../training_output/salicon/train_kldloss_withouteuc-batch-8_1509584263/snapshot-_iter_100000.solverstate' --batch=8 --dsname='salicon'
 4032  clear
 4033  python training_image.py --train_prototxt='prototxt/train_kldloss.prototxt' --use_snapshot='../training_output/salicon/train_kldloss_withouteuc-batch-8_1509584263/snapshot-_iter_100000.solverstate' --batch=8 --dsname='salicon'
 4034  python training_image.py --train_prototxt='prototxt/train_kldloss-leaky.prototxt' --use_snapshot='../training_output/salicon/train_kldloss_withouteuc-batch-8_1509584263/snapshot-_iter_100000.solverstate' --batch=8 --dsname='salicon'
 4035  clear
 4036  python training_image.py --train_prototxt='prototxt/train_kldloss-leaky.prototxt' --use_snapshot='../training_output/salicon/train_kldloss_withouteuc-batch-8_1509584263/snapshot-_iter_100000.solverstate' --batch=8 --dsname='salicon'
 4037  source set_env.sh ../caffe-master/ 3
 4038  nvidia-smi
 4039  python training_image.py --train_prototxt='prototxt/train_kldloss-leaky.prototxt' --use_snapshot='../training_output/salicon/train_kldloss_withouteuc-batch-8_1509584263/snapshot-_iter_100000.solverstate' --batch=8 --dsname='salicon'
 4040  source set_env.sh ../caffe-flownet/ 3
 4041  python training_image.py --train_prototxt='prototxt/train_kldloss-leaky.prototxt' --use_snapshot='../training_output/salicon/train_kldloss_withouteuc-batch-8_1509584263/snapshot-_iter_100000.solverstate' --batch=8 --dsname='salicon'
 4042  clear
 4043  python training_image.py --train_prototxt='prototxt/train_kldloss-leaky.prototxt' --use_snapshot='../training_output/salicon/train_kldloss_withouteuc-batch-8_1509584263/snapshot-_iter_100000.solverstate' --batch=8 --dsname='salicon'
 4044  python utils/scavenger.py 
 4045  python utils/scavenger.py --snapshot
 4046  python utils/scavenger.py --snapshot=1
 4047  clear
 4048  -------test-leaky-relu performance-improvement-----------
 4049  python training_image.py --train_prototxt='prototxt/train_kldloss-leaky.prototxt' --use_snapshot='../training_output/salicon/train_kldloss_withouteuc-batch-8_1509584263/snapshot-_iter_100000.solverstate' --batch=8 --dsname='salicon'
 4050  watch -n 5 nvidia-smi
 4051  watch -n 1 nvidia-smi
 4052  nvidia-smi
 4053  cd pwd/saliency_on_videoset/Train/scripts/
 4054  watch -n -0.5 nvidia-smi
 4055  source set_env.sh ../C3D-v1.1/ 4
 4056  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2.prototxt' --use_model='../pretrained_model/conv3d_deepnetA_sport1m_iter_1900000_v1.1.caffemodel' --trainingbase='msu' --batch=2
 4057  python training_video_voxel_based.py --solver_prototxt='prototxt/solver-static.prototxt' --train_prototxt='prototxt/vo-v4-2.prototxt' --use_model='../pretrained_model/conv3d_deepnetA_sport1m_iter_1900000_v1.1.caffemodel' --trainingbase='msu' --batch=2 --staticsolver=1
 4058  clear
 4059  python training_video_voxel_based.py --solver_prototxt='prototxt/solver-static.prototxt' --train_prototxt='prototxt/vo-v4-2.prototxt' --use_model='../pretrained_model/conv3d_deepnetA_sport1m_iter_1900000_v1.1.caffemodel' --trainingbase='msu' --batch=2 --staticsolver=1
 4060  python training_video_voxel_based.py --solver_prototxt='prototxt/solver-static.prototxt' --train_prototxt='prototxt/vo-v4-2.prototxt' --use_model='../pretrained_model/conv3d_deepnetA_sport1m_iter_1900000_v1.1.caffemodel' --trainingbase='msu' --batch=2 --staticsolver=1 --batch=8
 4061  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-fixweight+dropout.prototxt' --use_model='../pretrained_model/conv3d_deepnetA_sport1m_iter_1900000_v1.1.caffemodel' --trainingbase='msu' --batch=8 --trainingexampleprops=0.8 --overlap=15 --validiter=1800 --savemodeliter=1800
 4062  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-fixweight+dropout.prototxt' --use_model='../pretrained_model/conv3d_deepnetA_sport1m_iter_1900000_v1.1.caffemodel' --trainingbase='msu' --batch=8 --trainingexampleprops=0.99 --overlap=0 --validiter=1800 --savemodeliter=1800
 4063  clear
 4064  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-fixweight+dropout.prototxt' --use_model='../pretrained_model/conv3d_deepnetA_sport1m_iter_1900000_v1.1.caffemodel' --trainingbase='msu' --batch=8 --trainingexampleprops=0.8 --overlap=15 --validiter=1800 --savemodeliter=1800
 4065  python training_image.py --train_prototxt='prototxt/train_kldloss.prototxt' --use_snapshot='../training_output/salicon/train_kldloss_withouteuc-batch-8_1509584263/snapshot-_iter_100000.solverstate' --batch=8 --dsname='msu'
 4066  source set_env.sh ../caffe-flownet/ 4
 4067  clear
 4068  python training_image.py --train_prototxt='prototxt/train_kldloss.prototxt' --use_snapshot='../training_output/salicon/train_kldloss_withouteuc-batch-8_1509584263/snapshot-_iter_100000.solverstate' --batch=8 --dsname='msu'
 4069  python training_image.py --train_prototxt='prototxt/train_kldloss.prototxt' --use_snapshot='../training_output/salicon/train_kldloss_withouteuc-batch-8_1509584263/snapshot-_iter_100000.solverstate' --batch=8 --dsname='salicon'
 4070  clear
 4071  python training_image.py --train_prototxt='prototxt/train_kldloss.prototxt' --use_snapshot='../training_output/salicon/train_kldloss_withouteuc-batch-8_1509584263/snapshot-_iter_100000.solverstate' --batch=8 --dsname='salicon'
 4072  top
 4073  nvidia-smi
 4074  cd pwd/saliency_on_videoset/Train/scripts/
 4075  source set_env.sh ../C3D-v1.1 4
 4076  python utils/scavenger.py 
 4077  python utils/scavenger.py --snapshot
 4078  python utils/scavenger.py --snapshot=1
 4079  top
 4080  nvidia-smi
 4081  cd pwd/saliency_on_videoset/Train/scripts/
 4082  ls
 4083  source set_env.sh ../C3D-v1.1 7
 4084  history > history
 4085  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2.prototxt' --use_model='../pretrained_model/conv3d_deepnetA_sport1m_iter_1900000_v1.1.caffemodel' --trainingbase='ledov' --batch=2 --validiter=2500 --savemodeliter=2500 --trainingexampleprops=0.95 
 4086  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2.prototxt' --use_model='../pretrained_model/conv3d_deepnetA_sport1m_iter_1900000_v1.1.caffemodel' --trainingbase='ledov' --batch=8 --validiter=2000 --savemodeliter=2000 --trainingexampleprops=0.95 --plotiter=50
 4087  clear
 4088  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2.prototxt' --use_model='../pretrained_model/conv3d_deepnetA_sport1m_iter_1900000_v1.1.caffemodel' --trainingbase='ledov' --batch=8 --validiter=2000 --savemodeliter=2000 --trainingexampleprops=0.995 --plotiter=50
 4089  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2.prototxt' --use_model='../pretrained_model/conv3d_deepnetA_sport1m_iter_1900000_v1.1.caffemodel' --trainingbase='ledov' --batch=8 --validiter=2000 --savemodeliter=2000 --trainingexampleprops=0.995 --plotiter=50 --extramodinfo='fulldens'
 4090  clear && clear
 4091  nvidia-smi
 4092  cd pwd/saliency_on_videoset/Train/scripts/
 4093  source set_env.sh ../C3D-v1.1 6
 4094  clear
 4095  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-resnet-catfeat.prototxt' --use_model='../pretrained_model/c3d_resnet18_sports1m_r2_iter_2800000.caffemodel' --trainingbase='ledov' --batch=8 --validiter=2000 --savemodeliter=2000 --trainingexampleprops=0.995 --plotiter=50
 4096  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-resnet-catfeat.prototxt' --use_model='../pretrained_model/c3d_resnet18_sports1m_r2_iter_2800000.caffemodel' --trainingbase='ledov' --batch=2 --validiter=2000 --savemodeliter=2000 --trainingexampleprops=0.995 --plotiter=50
 4097  clear
 4098  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-resnet-catfeat.prototxt' --use_model='../pretrained_model/c3d_resnet18_sports1m_r2_iter_2800000.caffemodel' --trainingbase='ledov' --batch=2 --validiter=2000 --savemodeliter=2000 --trainingexampleprops=0.995 --plotiter=50
 4099  clear
 4100  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-resnet-catfeat.prototxt' --use_model='../pretrained_model/c3d_resnet18_sports1m_r2_iter_2800000.caffemodel' --trainingbase='ledov' --batch=2 --validiter=2000 --savemodeliter=2000 --trainingexampleprops=0.995 --plotiter=50
 4101  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-resnet-catfeat.prototxt' --use_model='../pretrained_model/c3d_resnet18_sports1m_r2_iter_2800000.caffemodel' --trainingbase='ledov' --batch=2 --validiter=2000 --savemodeliter=2000 --trainingexampleprops=0.995 --plotiter=50 --extramodinfo='fulldens'
 4102  nvidia-smi
 4103  clear
 4104  cd pwd/saliency_on_videoset/Train/scripts/metric/
 4105  ls
 4106  matlab -nodesktop
 4107  clear && clear
 4108  cd ..
 4109  python test_video.py --video_deploy_path='prototxt/vo-v4-2-deploy.prototxt' --video_model_path='../training_output/salicon/vo-v4-2-snapshot-2000-display-1-fulldens-batch-8_1514129167/snapshot-_iter_28000.caffemodel' --infertype='slide' --output_type='video' --test_base='videoset' --model_code='v4-2' --videolength=16
 4110  source set_env.sh ../C3D-v1.1 5
 4111  python test_video.py --video_deploy_path='prototxt/vo-v4-2-deploy.prototxt' --video_model_path='../training_output/salicon/vo-v4-2-snapshot-2000-display-1-fulldens-batch-8_1514129167/snapshot-_iter_28000.caffemodel' --infertype='slide' --output_type='video' --test_base='videoset' --model_code='v4-2' --videolength=16
 4112  nvidia-smi
 4113  top
 4114  python utils/VorI/slice_frames.py 
 4115  python utils/VorI/slice_frames.py --videobase='/data/sunnycia/SaliencyDataset/Video/DIEM/video'
 4116  python utils/VorI/slice_frames.py --videobase='/data/sunnycia/SaliencyDataset/Video/DIEM/video' --outputbase='/data/sunnycia/SaliencyDataset/Video/DIEM/frames'
 4117  matlab -nodesktop
 4118  top
 4119  nvidia-smi
 4120  top
 4121  nvidia-smi
 4122  top
 4123  nvidia-smi
 4124  top
 4125  locate ChairsSDHom.tar.gz
 4126  rlocate
 4127  op
 4128  top
 4129  nvidia-smi
 4130  clear
 4131  python test_video.py --output_type='image' --test_base='videoset' --model_code='v4-2' --videolength=16 --video_deploy_path='prototxt/vo-v4-2-resnet.prototxt' --video_model_path='../training_output/salicon/vo-v4-2-resnet-snapshot-2000-display-1-fulldens-batch-2_1514129205/snapshot-_iter_474000.caffemodel' --infertype='slide'
 4132  top
 4133  nvidia-smi
 4134  top
 4135  cd pwd/saliency_on_videoset/Train/scripts/
 4136  source set_env.sh ../C3D-v1.1 5
 4137  nvidia-si
 4138  nvidia-smi
 4139  clear
 4140  python test_video.py --video_deploy_path='prototxt/vo-v4-2-resnet.prototxt' --video_model_path='../training_output/salicon/vo-v4-2-resnet-snapshot-2000-display-1--batch-2_1514034705/snapshot-_iter_72000.caffemodel' --output_type='image' --model_code='v4-2' --videolength=16 --infertype='slide' --test_base='videoset' && python test_video.py --video_deploy_path='prototxt/vo-v4-2-resnet-catfeat.prototxt.prototxt' --video_model_path='../training_output/salicon/vo-v4-2-resnet-catfeat-snapshot-2000-display-1--batch-2_1514034491/snapshot-_iter_72000.caffemodel' --output_type='image' --model_code='v4-2' --videolength=16 --infertype='slide' --test_base='videoset'
 4141  python test_video.py --video_deploy_path='prototxt/vo-v4-2-resnet-catfeat.prototxt' --video_model_path='../training_output/salicon/vo-v4-2-resnet-catfeat-snapshot-2000-display-1--batch-2_1514034491/snapshot-_iter_72000.caffemodel' --output_type='image' --model_code='v4-2' --videolength=16 --infertype='slide' --test_base='videoset'
 4142  cd utils/
 4143  ls
 4144  touch gen_lmdb.py
 4145  vim gen_lmdb.py 
 4146  cd ..
 4147  top
 4148  nvidia-smi
 4149  clear
 4150  source set_env.sh ../C3D-v1.1 4
 4151  nvidia-smi
 4152  clear
 4153  python test_video.py --video_deploy_path='prototxt/vo-v4-2.prototxt' --video_model_path='../training_output/salicon/vo-v4-2-snapshot-2000-display-1-fulldens-batch-8_1514129167/snapshot-_iter_28000.caffemodel' --infertype='slide' --output_type='video' --test_base='videoset' --model_code='v4-2' --videolength=16
 4154  python test_video.py --video_deploy_path='prototxt/vo-v4-2.prototxt' --video_model_path='../training_output/salicon/vo-v4-2-snapshot-2000-display-1-fulldens-batch-8_1514129167/snapshot-_iter_28000.caffemodel' --infertype='slide' --output_type='image' --test_base='videoset' --model_code='v4-2' --videolength=16
 4155  python test_video.py --video_deploy_path='prototxt/vo-v4-2.prototxt' --video_model_path='../training_output/salicon/vo-v4-2-resnet-base_lr-0.01-snapshot-2000-display-1--batch-2_1514260519_usesnapshot_1514034705_snapshot-_iter_72000/snapshot-_iter_96000.caffemodel' --infertype='slide' --output_type='image' --test_base='videoset' --model_code='v4-2' --videolength=16
 4156  python test_video.py --video_deploy_path='prototxt/vo-v4-2-resnet.prototxt' --video_model_path='../training_output/salicon/vo-v4-2-resnet-base_lr-0.01-snapshot-2000-display-1--batch-2_1514260519_usesnapshot_1514034705_snapshot-_iter_72000/snapshot-_iter_96000.caffemodel' --infertype='slide' --output_type='image' --test_base='videoset' --model_code='v4-2' --videolength=16
 4157  matlab -nodesktop
 4158  clear
 4159  source set_env.sh ../C3D-v1.1 6
 4160  python test_video.py --output_type='image' --test_base='videoset' --model_code='v4-2' --videolength=16 --video_deploy_path='prototxt/vo-v4-2-resnet.prototxt' --video_model_path='../training_output/salicon/vo-v4-2-resnet-catfeat-snapshot-2000-display-1-fulldens-batch-2_1514129183/snapshot-_iter_468000.caffemodel' --infertype='slide'
 4161  python test_video.py --output_type='image' --test_base='videoset' --model_code='v4-2' --videolength=16 --video_deploy_path='prototxt/vo-v4-2-resnet-catfeat.prototxt' --video_model_path='../training_output/salicon/vo-v4-2-resnet-catfeat-snapshot-2000-display-1-fulldens-batch-2_1514129183/snapshot-_iter_468000.caffemodel' --infertype='slide'
 4162  clear
 4163  python test_video.py --output_type='image' --test_base='videoset' --model_code='v4-2' --videolength=16 --video_deploy_path='prototxt/vo-v4-2-resnet-catfeat.prototxt' --video_model_path='../training_output/salicon/vo-v4-2-resnet-catfeat-snapshot-2000-display-1-fulldens-batch-2_1514129183/snapshot-_iter_468000.caffemodel' --infertype='slide'
 4164  clear
 4165  cd pwd/saliency_on_videoset/Train/scripts/
 4166  source set_env.sh ../C3D-v1.1 5
 4167  nvidia-smi
 4168  source set_env.sh ../C3D-v1.1 4
 4169  clear
 4170  python test_video.py --output_type='video' --video_deploy_path='prototxt/vo-v4-2-resnet-catfeat.prototxt' --video_model_path='' --infertype='slide' ----test_base='videoset' --model_code='v4-2' --videolength=16 
 4171  python test_video.py --output_type='video' --video_deploy_path='prototxt/vo-v4-2-resnet-catfeat.prototxt' --video_model_path='../training_output/vo-v4-2-resnet-catfeat-snapshot-2000-display-1--batch-2_1514034491/snapshot-_iter_48000.caffemodel' --infertype='slide' --test_base='videoset' --model_code='v4-2' --videolength=16 
 4172  python test_video.py --output_type='video' --video_deploy_path='prototxt/vo-v4-2-resnet-catfeat.prototxt' --video_model_path='../training_output/salicon/vo-v4-2-resnet-catfeat-snapshot-2000-display-1--batch-2_1514034491/snapshot-_iter_48000.caffemodel' --infertype='slide' --test_base='videoset' --model_code='v4-2' --videolength=16 
 4173  python test_video.py --output_type='video' --video_deploy_path='prototxt/vo-v4-2-resnet-catfeat.prototxt' --video_model_path='../training_output/salicon/vo-v4-2-resnet-catfeat-snapshot-2000-display-1--batch-2_1514034491/snapshot-_iter_48000.caffemodel' --infertype='slice' --test_base='videoset' --model_code='v4-2' --videolength=16 
 4174  python test_video.py --output_type='video' --video_deploy_path='prototxt/vo-v4-2-resnet.prototxt' --video_model_path='vo-v4-2-resnet-snapshot-2000-display-1--batch-2_1514034705/snapshot-_iter_48000.caffemodel' --infertype='slice' --test_base='videoset' --model_code='v4-2' --videolength=16 
 4175  python test_video.py --output_type='video' --video_deploy_path='prototxt/vo-v4-2-resnet.prototxt' --video_model_path='../training_output/salicon/vo-v4-2-resnet-snapshot-2000-display-1--batch-2_1514034705/snapshot-_iter_48000.caffemodel' --infertype='slice' --test_base='videoset' --model_code='v4-2' --videolength=16 
 4176  clear
 4177  python test_video.py --output_type='video' --video_deploy_path='prototxt/vo-v4-2-resnet.prototxt' --video_model_path='../training_output/salicon/vo-v4-2-resnet-snapshot-2000-display-1--batch-2_1514034705/snapshot-_iter_48000.caffemodel' --infertype='slice' --test_base='videoset' --model_code='v4-2' --videolength=16 
 4178  clear
 4179  python test_video.py --output_type='video' --video_deploy_path='prototxt/vo-v4-2.prototxt' --video_model_path='../training_output/salicon/vo-v4-2-snapshot-2000-display-1--batch-8_1514033989/snapshot-_iter_14000.caffemodel' --infertype='slice' --test_base='videoset' --model_code='v4-2' --videolength=16 
 4180  clear
 4181  python test_video.py --output_type='video' --video_deploy_path='prototxt/vo-v4-2-resnet.prototxt' --video_model_path='../training_output/salicon/vo-v4-2-resnet-snapshot-2000-display-1--batch-2_1514034705/snapshot-_iter_48000.caffemodel' --infertype='slice' --test_base='videoset' --model_code='v4-2' --videolength=16 
 4182  clear
 4183  vim utils/scavenger.py 
 4184  python utils/scavenger.py 
 4185  vim utils/scavenger.py 
 4186  python utils/scavenger.py 
 4187  nvidia-smi
 4188  source set_env.sh ../C3D-v1.1 4
 4189  python test_video.py --video_deploy_path='prototxt/vo-v4-2.prototxt' --video_model_path='../training_output/salicon/vo-v4-2-snapshot-2000-display-1--batch-8_1514033989/snapshot-_iter_20000.caffemodel' --output_type='image' --model_code='v4-2' --videoength=16 infertype='slide' 
 4190  python test_video.py --video_deploy_path='prototxt/vo-v4-2.prototxt' --video_model_path='../training_output/salicon/vo-v4-2-snapshot-2000-display-1--batch-8_1514033989/snapshot-_iter_20000.caffemodel' --output_type='image' --model_code='v4-2' --videoength=16 infertype='slide' --test_base='videoset'
 4191  python test_video.py --video_deploy_path='prototxt/vo-v4-2.prototxt' --video_model_path='../training_output/salicon/vo-v4-2-snapshot-2000-display-1--batch-8_1514033989/snapshot-_iter_20000.caffemodel' --output_type='image' --model_code='v4-2' --videoength=16 --infertype='slide' --test_base='videoset'
 4192  python test_video.py --video_deploy_path='prototxt/vo-v4-2.prototxt' --video_model_path='../training_output/salicon/vo-v4-2-snapshot-2000-display-1--batch-8_1514033989/snapshot-_iter_20000.caffemodel' --output_type='image' --model_code='v4-2' --videolength=16 --infertype='slide' --test_base='videoset'
 4193  python test_video.py --video_deploy_path='prototxt/vo-v4-2.prototxt' --video_model_path='../training_output/salicon/vo-v4-2-snapshot-2000-display-1--batch-8_1514033989/snapshot-_iter_20000.caffemodel' --output_type='image' --model_code='v4-2' --videolength=16 --infertype='slide' --test_base='videoset' 
 4194  top
 4195  clear && clear
 4196  top
 4197  nvidia-smi
 4198  top
 4199  nvidia-smi
 4200  clear
 4201  git status
 4202  git add --all
 4203  git commit -m "Done for training v4-2 v4-2-resnet and v4-2-resnet-catfeat, add v4-2-softmax"
 4204  git push -u origin master
 4205  clear
 4206  nvidia-smi
 4207  clear
 4208  top
 4209  nvidia-smi
 4210  clear && clear
 4211  git status
 4212  git add --all
 4213  git commit -m "Tried v4-2-sigmoid, not good. Add generate lmdb util"
 4214  git push -u origin master
 4215  cd /data/sunnycia/saliency_on_videoset/Train/figure/vo-v4-2-resnet-base_lr-0.01-snapshot-2000-display-1--batch-2_1514260519_usesnapshot_1514034705_snapshot-_iter_72000
 4216  python
 4217  nvidia-smi
 4218  cd ~
 4219  cd /data/sunnycia/saliency_on_videoset/Train/figure/vo-v4-2-resnet-snapshot-2000-display-1-fulldens-batch-2_1514129205
 4220  python
 4221  top
 4222  nvidia-smi
 4223  top
 4224  nvidia-smi
 4225  top
 4226  nvidia-smi
 4227  python
 4228  top
 4229  clear && clear
 4230  cd ..
 4231  cd ../scripts/
 4232  python utils/visualize_plotdict.py --plot_dict_path='/data/sunnycia/saliency_on_videoset/Train/figure/vo-v4-2-resnet-catfeat-snapshot-2000-display-1-fulldens-batch-2_1514129183/plot_dict.pkl'
 4233  python utils/visualize_plotdict.py --plot_dict_path='/data/sunnycia/saliency_on_videoset/Train/figure/vo-v4-2-resnet-snapshot-2000-display-1-fulldens-batch-2_1514129205/plot_dict.pkl'
 4234  python utils/visualize_plotdict.py --plot_dict_path='/data/sunnycia/saliency_on_videoset/Train/figure/vo-v4-2-resnet-base_lr-0.01-snapshot-2000-display-1--batch-2_1514260519_usesnapshot_1514034705_snapshot-_iter_72000/plot_dict.pkl'
 4235  python utils/visualize_plotdict.py --plot_dict_path='/data/sunnycia/saliency_on_videoset/Train/figure/vo-v4-2-snapshot-2000-display-1-fulldens-batch-8_1514129167/plot_dict.pkl'
 4236  clear
 4237  python metric/find_best_and_worst.py --metricdir='/data/sunnycia/saliency_on_videoset/Train/metric-matlab/videoset/train_kldloss-kld_weight-100-batch-1_1510102029_usesnapshot_1509584263_snapshot-_iter_100000'
 4238  top
 4239  nvidia-smi
 4240  python metric/find_best_and_worst.py --metricdir='/data/sunnycia/saliency_on_videoset/Train/metric-matlab/videoset/train_kldloss-kld_weight-100-batch-1_1510102029_usesnapshot_1509584263_snapshot-_iter_100000'
 4241  clear && clear
 4242  python metric/find_best_and_worst.py --metricdir='/data/sunnycia/saliency_on_videoset/Train/metric-matlab/videoset/train_kldloss-kld_weight-100-batch-1_1510102029_usesnapshot_1509584263_snapshot-_iter_100000'
 4243  python metric/find_best_and_worst.py --metricdir='/data/sunnycia/saliency_on_videoset/Train/metric-matlab/videoset/train_kldloss-kld_weight-100-batch-1_1510102029_usesnapshot_1509584263_snapshot-_iter_100000' --metricindex=0
 4244  python metric/find_best_and_worst.py --metricdir='/data/sunnycia/saliency_on_videoset/Train/metric-matlab/videoset/train_kldloss-kld_weight-100-batch-1_1510102029_usesnapshot_1509584263_snapshot-_iter_100000' --metricindex=0 --examples=20
 4245  python metric/find_best_and_worst.py --metricdir='/data/sunnycia/saliency_on_videoset/Train/metric-matlab/videoset/train_kldloss-kld_weight-100-batch-1_1510102029_usesnapshot_1509584263_snapshot-_iter_100000' --metricindex=2 --examples=10
 4246  git status
 4247  git add --all
 4248  git commit -m "add utils: visualize plotdict & find best and worst performance of a metric"
 4249  git push -u origin master
 4250  python metric/find_best_and_worst.py --metricdir='/data/sunnycia/saliency_on_videoset/Train/metric-matlab/videoset/train_kldloss-kld_weight-100-batch-1_1510102029_usesnapshot_1509584263_snapshot-_iter_100000' --metricindex=2 --examples=10
 4251  python metric/find_best_and_worst.py --metricdir='/data/sunnycia/saliency_on_videoset/Train/metric-matlab/videoset/train_kldloss-kld_weight-100-batch-1_1510102029_usesnapshot_1509584263_snapshot-_iter_100000' --metricindex=3 --examples=10
 4252  python metric/find_best_and_worst.py --metricdir='/data/sunnycia/saliency_on_videoset/Train/metric-matlab/videoset/train_kldloss-kld_weight-100-batch-1_1510102029_usesnapshot_1509584263_snapshot-_iter_100000' --metricindex=3 --examples=3
 4253  python metric/find_best_and_worst.py --metricdir='/data/sunnycia/saliency_on_videoset/Train/metric-matlab/videoset/train_kldloss-kld_weight-100-batch-1_1510102029_usesnapshot_1509584263_snapshot-_iter_100000' --metricindex=0 --examples=3
 4254  touch metric/findBW.sh
 4255  vim metric/findBW.sh 
 4256  bash metric/findBW.sh 
 4257  python utils/visualize_plotdict.py --plot_dict_path='/data/sunnycia/saliency_on_videoset/Train/figure/vo-v4-2-snapshot-2000-display-1-fulldens-batch-8_1514129167/plot_dict.pkl'
 4258  python utils/visualize_plotdict.py --plot_dict_path='/data/sunnycia/saliency_on_videoset/Train/figure/vo-v4-2-resnet-base_lr-0.01-snapshot-2000-display-1--batch-2_1514260519_usesnapshot_1514034705_snapshot-_iter_72000/plot_dict.pkl'
 4259  python utils/visualize_plotdict.py --plot_dict_path='/data/sunnycia/saliency_on_videoset/Train/figure/vo-v4-2-resnet-snapshot-2000-display-1-fulldens-batch-2_1514129205/plot_dict.pkl'
 4260  df -h
 4261  python utils/visualize_plotdict.py --plot_dict_path='/data/sunnycia/saliency_on_videoset/Train/figure/vo-v4-2-resnet-base_lr-0.01-snapshot-2000-display-1--batch-2_1514260519_usesnapshot_1514034705_snapshot-_iter_72000/plot_dict.pkl'
 4262  python utils/visualize_plotdict.py --plot_dict_path='/data/sunnycia/saliency_on_videoset/Train/figure/vo-v4-2-resnet-snapshot-2000-display-1-fulldens-batch-2_1514129205/plot_dict.pkl'
 4263  python utils/visualize_plotdict.py --plot_dict_path='/data/sunnycia/saliency_on_videoset/Train/figure/vo-v4-2-snapshot-2000-display-1-fulldens-batch-8_1514129167/plot_dict.pkl'
 4264  python ss_test_video.py 
 4265  python
 4266  python ss_test_video.py 
 4267  python
 4268  python ss_test_video.py 
 4269  clear
 4270  python ss_test_video.py 
 4271  top
 4272  python ss_test_video.py 
 4273  python test_video.py --output_type='image' --test_base='videoset' --model_code='v4-2' --videolength=16 --video_deploy_path='prototxt/vo-v4-2-resnet.prototxt' --video_model_path='../training_output/salicon/vo-v4-2-resnet-base_lr-0.01-snapshot-2000-display-1--batch-2_1514260519_usesnapshot_1514034705_snapshot-_iter_72000/snapshot-_iter_454000.caffemodel' --infertype='slide' 
 4274  matlab -nodesktop
 4275  cd pwd/saliency_on_videoset/Train/scripts/
 4276  source set_env.sh ../C3D-v1.1-kldloss/ 4
 4277  nvidia-smi
 4278  cler
 4279  clear
 4280  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-resnet-kldloss.prototxt' --use_model='../pretrained_model/c3d_resnet18_sports1m_r2_iter_2800000.caffemodel' --trainingbase='ledov' --batch=2 --validiter=2000 --savemodeliter=2000 --trainingexampleprops=0.995 --plotiter=50
 4281  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-resnet-kldloss.prototxt' --use_model='../pretrained_model/c3d_resnet18_sports1m_r2_iter_2800000.caffemodel' --trainingbase='ledov' --batch=2 --validiter=2000 --savemodeliter=2000 --trainingexampleprops=0.99995 --plotiter=50
 4282  clear
 4283  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-resnet-kldloss.prototxt' --use_model='../pretrained_model/c3d_resnet18_sports1m_r2_iter_2800000.caffemodel' --trainingbase='ledov' --batch=2 --validiter=2000 --savemodeliter=2000 --trainingexampleprops=0.99995 --plotiter=50
 4284  clear
 4285  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-resnet-kldloss.prototxt' --use_model='../pretrained_model/c3d_resnet18_sports1m_r2_iter_2800000.caffemodel' --trainingbase='ledov' --batch=2 --validiter=2000 --savemodeliter=2000 --trainingexampleprops=0.995 --plotiter=50
 4286  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-resnet-kldloss.prototxt' --use_model='../pretrained_model/c3d_resnet18_sports1m_r2_iter_2800000.caffemodel' --trainingbase='ledov' --batch=2 --validiter=2000 --savemodeliter=2000 --trainingexampleprops=0.99995 --plotiter=50
 4287  clear
 4288  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-resnet-kldloss.prototxt' --use_model='../pretrained_model/c3d_resnet18_sports1m_r2_iter_2800000.caffemodel' --trainingbase='ledov' --batch=2 --validiter=2000 --savemodeliter=2000 --trainingexampleprops=0.99995 --plotiter=50
 4289  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-resnet-kldloss.prototxt' --use_model='../pretrained_model/c3d_resnet18_sports1m_r2_iter_2800000.caffemodel' --trainingbase='ledov' --batch=2 --validiter=2000 --savemodeliter=2000 --trainingexampleprops=0.995 --plotiter=50
 4290  clear
 4291  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-resnet-kldloss.prototxt' --use_model='../pretrained_model/c3d_resnet18_sports1m_r2_iter_2800000.caffemodel' --trainingbase='ledov' --batch=2 --validiter=2000 --savemodeliter=2000 --trainingexampleprops=0.995 --plotiter=50
 4292  cd   /data/sunnycia/SaliencyDataset/Video/LEDOV
 4293  python check_density.py 
 4294  clear
 4295  clearw
 4296  clear
 4297  cd -
 4298  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-resnet-kldloss.prototxt' --use_model='../pretrained_model/c3d_resnet18_sports1m_r2_iter_2800000.caffemodel' --trainingbase='ledov' --batch=2 --validiter=2000 --savemodeliter=2000 --trainingexampleprops=0.995 --plotiter=50
 4299  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-softmax.prototxt' --use_model='../pretrained_model/conv3d_deepnetA_sport1m_iter_1900000_v1.1.caffemodel' --trainingbase='ledov' --batch=8 --validiter=2000 --savemodeliter=2000 --trainingexampleprops=0.995 --plotiter=50
 4300  clear
 4301  python utils/scavenger.py 
 4302  python utils/scavenger.py --snapshot=1
 4303  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-softmax.prototxt' --use_model='../pretrained_model/conv3d_deepnetA_sport1m_iter_1900000_v1.1.caffemodel' --trainingbase='ledov' --batch=8 --validiter=2000 --savemodeliter=2000 --trainingexampleprops=0.995 --plotiter=50
 4304  python utils/scavenger.py 
 4305  python utils/scavenger.py --snapshot=1
 4306  clear
 4307  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-softmax.prototxt' --use_model='../pretrained_model/conv3d_deepnetA_sport1m_iter_1900000_v1.1.caffemodel' --trainingbase='ledov' --batch=8 --validiter=2000 --savemodeliter=2000 --trainingexampleprops=0.995 --plotiter=50
 4308  clear
 4309  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-sigmoid.prototxt' --use_model='../pretrained_model/conv3d_deepnetA_sport1m_iter_1900000_v1.1.caffemodel' --trainingbase='ledov' --batch=8 --validiter=2000 --savemodeliter=2000 --trainingexampleprops=0.995 --plotiter=50
 4310  clear
 4311  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-resnet.prototxt' --usesnapshot='../training_output/salicon/vo-v4-2-resnet-snapshot-2000-display-1--batch-2_1514034705/snapshot-_iter_72000.solverstate' --trainingbase='ledov' --batch=8 --validiter=2000 --savemodeliter=2000 --trainingexampleprops=0.995 --plotiter=50
 4312  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-resnet.prototxt' --use_snapshot='../training_output/salicon/vo-v4-2-resnet-snapshot-2000-display-1--batch-2_1514034705/snapshot-_iter_72000.solverstate' --trainingbase='ledov' --batch=8 --validiter=2000 --savemodeliter=2000 --trainingexampleprops=0.995 --plotiter=50
 4313  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-resnet.prototxt' --use_snapshot='../training_output/salicon/vo-v4-2-resnet-snapshot-2000-display-1--batch-2_1514034705/snapshot-_iter_72000.solverstate' --trainingbase='ledov' --batch=2 --validiter=2000 --savemodeliter=2000 --trainingexampleprops=0.995 --plotiter=50
 4314  clear
 4315  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-resnet.prototxt' --use_snapshot='../training_output/salicon/vo-v4-2-resnet-snapshot-2000-display-1--batch-2_1514034705/snapshot-_iter_72000.solverstate' --trainingbase='ledov' --batch=2 --validiter=2000 --savemodeliter=2000 --trainingexampleprops=0.995 --plotiter=50
 4316  clear
 4317  claer
 4318  clear
 4319  python utils/scavenger.py 
 4320  clear
 4321  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-resnet.prototxt' --use_snapshot='../training_output/salicon/vo-v4-2-resnet-snapshot-2000-display-1--batch-2_1514034705/snapshot-_iter_72000.solverstate' --trainingbase='ledov' --batch=2 --validiter=2000 --savemodeliter=2000 --trainingexampleprops=0.995 --plotiter=50
 4322  clear
 4323  matlab -nodesktop
 4324  cd /data/sunnycia/SaliencyDataset/Video/Hollywood2
 4325  ls
 4326  tar xf Hollywood2-actions.tar.gz 
 4327  tar xf Hollywood2-scenes.tar.gz
 4328  cd ../Coutort1/
 4329  unzip ERB3_Stimuli.zip 
 4330  cd /data/sunnycia/saliency_on_videoset/Train/scripts/metric
 4331  cd ..
 4332  python metric/metric_distribution.py --metricdir='' --outputdir='' --metricname='cc'
 4333  python metric/metric_distribution.py --metricdir='../metric-matlab/videoset/vo-v4-2-resnet-base_lr-0.01-snapshot-2000-display-1--batch-2_1514260519_usesnapshot_1514034705_snapshot-_iter_72000_snapshot-_iter_454000_threshold0' --outputdir='../metric_distribution' --metricname='cc'
 4334  python metric/metric_distribution.py --metricdir='../metric-matlab/videoset/vo-v4-2-resnet-base_lr-0.01-snapshot-2000-display-1--batch-2_1514260519_usesnapshot_1514034705_snapshot-_iter_72000_snapshot-_iter_454000_threshold0' --outputdir='../metric_distribution' --metricname='sauc'
 4335  python metric/metric_distribution.py --metricdir='../metric-matlab/videoset/vo-v4-2-resnet-base_lr-0.01-snapshot-2000-display-1--batch-2_1514260519_usesnapshot_1514034705_snapshot-_iter_72000_snapshot-_iter_454000_threshold0' --outputdir='../metric_distribution' --metricname='auc_jud'
 4336  top
 4337  nvidia-smi
 4338  python metric/metric_distribution.py --metricdir='../metric-matlab/videoset/vo-v4-2-resnet-base_lr-0.01-snapshot-2000-display-1--batch-2_1514260519_usesnapshot_1514034705_snapshot-_iter_72000_snapshot-_iter_454000_threshold0' --outputdir='../metric_distribution' --metricname='auc_jud'
 4339  bash metric/metric_distribution.sh vo-v4-2-resnet-base_lr-0.01-snapshot-2000-display-1--batch-2_1514260519_usesnapshot_1514034705_snapshot-_iter_72000_snapshot-_iter_454000_threshold0
 4340  vim metric/metric_distribution.sh 
 4341  bash metric/metric_distribution.sh vo-v4-2-resnet-base_lr-0.01-snapshot-2000-display-1--batch-2_1514260519_usesnapshot_1514034705_snapshot-_iter_72000_snapshot-_iter_454000_threshold0
 4342  vim metric/metric_distribution.sh 
 4343  bash metric/metric_distribution.sh vo-v4-2-resnet-base_lr-0.01-snapshot-2000-display-1--batch-2_1514260519_usesnapshot_1514034705_snapshot-_iter_72000_snapshot-_iter_454000_threshold0
 4344  bash metric/metric_distribution.sh ../metric-matlab/videoset/vo-v4-2-resnet-base_lr-0.01-snapshot-2000-display-1--batch-2_1514260519_usesnapshot_1514034705_snapshot-_iter_72000_snapshot-_iter_454000_threshold0
 4345  bash metric/metric_distribution.sh ../metric-matlab/videoset/vo-v4-2-resnet-base_lr-0.01-snapshot-2000-display-1--batch-2_1514260519_usesnapshot_1514034705_snapshot-_iter_72000_snapshot-_iter_96000_threshold0
 4346  bash metric/metric_distribution.sh ../metric-matlab/videoset/vo-v4-2-snapshot-2000-display-1-fulldens-batch-8_1514129167_snapshot-_iter_28000_threshold0 && bash metric/metric_distribution.sh ../metric-matlab/videoset/vo-v4-2-snapshot-2000-display-1-fulldens-batch-8_1514129167 &&  bash metric/metric_distribution.sh ../metric-matlab/videoset/vo-v4-2-resnet-catfeat-snapshot-2000-display-1--batch-2_1514034491_snapshot-_iter_72000_threshold0 && bash metric/metric_distribution.sh ../metric-matlab/videoset/vo-v4-2-snapshot-999999-display-1-ledovSet-batch-8_1513764025_snapshot-11250_threshold0
 4347  nvidia-smi
 4348  top
 4349  python ss_test_video.py
 4350  source set_env.sh ../C3D-v1.1-kldloss/ 6
 4351  nvidia-smi
 4352  python ss_test_video.py
 4353  clear
 4354  python ss_test_video.py
 4355  df -h
 4356  cd /data/sunnycia/SaliencyDataset/Video
 4357  cd GAZECOM/
 4358  ls
 4359  unzip movies-m2t.zip 
 4360  mkdir movies && mv *m2t movies
 4361  mkdir gaze && cd gaze && unzip ../gaze.zip
 4362  mkdir images && cd images && unzip ../static-images.zip 
 4363  cd ..
 4364  cd /data/sunnycia/SaliencyDataset/Video/GAZECOM
 4365  mkdir images && cd images && unzip ../static-images.zip 
 4366  top
 4367  nvidia-smi
 4368  top
 4369  nvidia-smi
 4370  top
 4371  cd /data/sunnycia/saliency_on_videoset/Train/scripts
 4372  nvidia-smi
 4373  source set_env.sh ../C3D-v1.1 0
 4374  python ss_test_video.py 
 4375  top
 4376  nvidia-smi
 4377  top
 4378  nvidia-smi
 4379  top
 4380  nvidi-asmi
 4381  cd pwd/saliency_on_videoset/Train/scripts
 4382  python utils/gen_density.py --sigma=32 --fixation_base='/data/sunnycia/SaliencyDataset/Video/DIEM/fixation_map/image' --density_base='/data/sunnycia/SaliencyDataset/Video/DIEM/density/image' --fixationtype='image'
 4383  cd pwd/saliency_on_videoset/_Train/
 4384  ls
 4385  git clone https://github.com/ZhaofanQiu/pseudo-3d-residual-networks.git
 4386  cd ../Train/scripts/
 4387  ls
 4388  cd ..
 4389  ls
 4390  cp /data/sunnycia/saliency_on_videoset/_Train/pseudo-3d-residual-networks/caffe_add_layers/src/*.cpp caffe-master/src/caffe/layers/
 4391  cp /data/sunnycia/saliency_on_videoset/_Train/pseudo-3d-residual-networks/caffe_add_layers/src/*.cu caffe-master/src/caffe/layers/
 4392  cp /data/sunnycia/saliency_on_videoset/_Train/pseudo-3d-residual-networks/caffe_add_layers/include/*.hpp caffe-master/include/caffe/layers/
 4393  cd caffe-master/
 4394  ls
 4395  make clean
 4396  cp /data/sunnycia/saliency_on_videoset/_Train/pseudo-3d-residual-networks/caffe_add_layers/caffe.proto src/caffe/proto/
 4397  make clean && make -j8 all && make pycaffe
 4398  make clean
 4399  make clean && make -j2 all && make pycaffe
 4400  make clean && make -j8 all && make pycaffe
 4401  vim Makefile.config
 4402  make clean && make -j8 all && make pycaffe
 4403  make -j8 pycaffe
 4404  make clean && make -j8 all && make -j8 pycaffe
 4405  cd ..
 4406  rm -rf caffe-master/
 4407  git clone https://github.com/BVLC/caffe.git
 4408  ls
 4409  cd caffe
 4410  make -j8 all
 4411  make clean
 4412  cd ..
 4413  rm -rf caffe
 4414  git clone https://github.com/BVLC/caffe.git
 4415  ls
 4416  unzip caffe-master.zip 
 4417  cd caffe-master/
 4418  cp Makefile.config.example Makefile.config
 4419  vim Makefile.config
 4420  make -j8 pycaffe
 4421  make -j8 all
 4422  vim Makefile.config
 4423  make -j8 all
 4424  make clean
 4425  make -j8 all
 4426  make -j8 pycaffe
 4427  clear
 4428  make clean
 4429  make -j16 all
 4430  make clean
 4431  make -j2 all && make -j2 pycaffe
 4432  make clean
 4433  make -j4 all && make -j4 pycaffe
 4434  top
 4435  nvidia-smi
 4436  top
 4437  ls
 4438  clear
 4439  source set_env.sh ../C3D-v1.1 4
 4440  nvidia-smi
 4441  clear
 4442  top
 4443  nvidia-smi
 4444  clear
 4445  nvidia-smi
 4446  clear
 4447  top
 4448  nvidia-smi
 4449  clear
 4450  source set_env.sh ../C3D-v1.1 4
 4451  clear
 4452  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-softmaxloss.prototxt' --use_model='../pretrained_model/conv3d_deepnetA_sport1m_iter_1900000_v1.1.caffemodel' --trainingbase='ledov' --batch=4 --validiter=2000 --savemodeliter=2000 --trainingexampleprops=0.995 --plotiter=50
 4453  clear && clear
 4454  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-softmaxloss.prototxt' --use_model='../pretrained_model/conv3d_deepnetA_sport1m_iter_1900000_v1.1.caffemodel' --trainingbase='ledov' --batch=4 --validiter=2000 --savemodeliter=2000 --trainingexampleprops=0.995 --plotiter=50
 4455  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-softmaxloss.prototxt' --use_model='../pretrained_model/conv3d_deepnetA_sport1m_iter_1900000_v1.1.caffemodel' --trainingbase='ledov' --batch=2 --validiter=2000 --savemodeliter=2000 --trainingexampleprops=0.995 --plotiter=50
 4456  clear && clear
 4457  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-softmaxloss.prototxt' --use_model='../pretrained_model/conv3d_deepnetA_sport1m_iter_1900000_v1.1.caffemodel' --trainingbase='ledov' --batch=2 --validiter=2000 --savemodeliter=2000 --trainingexampleprops=0.995 --plotiter=50
 4458  clear
 4459  top
 4460  nvidia-smi
 4461  python test_video.py --video_deploy_path='prototxt/vo-v4-2-resnet.prototxt' --video_model_path='../training_output/salicon/vo-v4-2-resnet-dropout-snapshot-2000-display-1-dropout_fulldens-batch-2_1514857787/snapshot-_iter_26000.caffemodel' --infertype='slide' --output_type='image' --test_base='videoset' --model_code='v4-2' --videolength=16 
 4462  nvidia-smi
 4463  source set_env.sh ../C3D-v1.1 6
 4464  python test_video.py --video_deploy_path='prototxt/vo-v4-2-resnet.prototxt' --video_model_path='../training_output/salicon/vo-v4-2-resnet-dropout-snapshot-2000-display-1-dropout_fulldens-batch-2_1514857787/snapshot-_iter_26000.caffemodel' --infertype='slide' --output_type='image' --test_base='videoset' --model_code='v4-2' --videolength=16 
 4465  matlab -nodesktop
 4466  cd metric/
 4467  matlab -nodesktop -nodisplay -nosplash -r "run("metric_video_base.m")
 4468  matlab -nodesktop -nodisplay -nosplash -r "run("metric_video_base.m")"
 4469  matlab -nodesktop -nodisplay -nosplash -r "metric_video_base.m"
 4470  matlab -nodesktop -nodisplay -nosplash -r "run("metric_video_base")"
 4471  matlab -nodesktop -nodisplay -nosplash -r "metric_video_base;exit()"
 4472  matlab -nodesktop -nodisplay -nosplash -r "metric_statistics;exit()"
 4473  matlab -nodesktop -nodisplay -nosplash
 4474  cd pwd/saliency_on_videoset/Train/scripts
 4475  source set_env.sh ../C3D-v1.1 5
 4476  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-resnet.prototxt' --use_model='../pretrained_model/c3d_resnet18_sports1m_r2_iter_2800000.caffemodel' --trainingbase='ledov' --batch=2 --validiter=2000 --savemodeliter=2000 --trainingexampleprops=0.995 --plotiter=50
 4477  clear
 4478  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-resnet.prototxt' --use_model='../pretrained_model/c3d_resnet18_sports1m_r2_iter_2800000.caffemodel' --trainingbase='ledov' --batch=2 --validiter=2000 --savemodeliter=2000 --trainingexampleprops=0.995 --plotiter=50
 4479  clear
 4480  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-resnet.prototxt' --use_model='../pretrained_model/c3d_resnet18_sports1m_r2_iter_2800000.caffemodel' --trainingbase='ledov' --batch=2 --validiter=2000 --savemodeliter=2000 --trainingexampleprops=0.995 --plotiter=50
 4481  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-resnet.prototxt' --use_model='../pretrained_model/c3d_resnet18_sports1m_r2_iter_2800000.caffemodel' --trainingbase='ledov' --batch=2 --validiter=2000 --savemodeliter=2000 --trainingexampleprops=0.995 --plotiter=50 --extramodinfo='fulldens'
 4482  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-resnet-dropout.prototxto' --use_model='../pretrained_model/c3d_resnet18_sports1m_r2_iter_2800000.caffemodel' --trainingbase='ledov' --batch=2 --validiter=2000 --savemodeliter=2000 --trainingexampleprops=0.995 --plotiter=50 --extramodinfo='dropout_fulldens'
 4483  clear && clear
 4484  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-resnet-dropout.prototxto' --use_model='../pretrained_model/c3d_resnet18_sports1m_r2_iter_2800000.caffemodel' --trainingbase='ledov' --batch=2 --validiter=2000 --savemodeliter=2000 --trainingexampleprops=0.995 --plotiter=50 --extramodinfo='dropout_fulldens'
 4485  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-resnet-dropout.prototxt' --use_model='../pretrained_model/c3d_resnet18_sports1m_r2_iter_2800000.caffemodel' --trainingbase='ledov' --batch=2 --validiter=2000 --savemodeliter=2000 --trainingexampleprops=0.995 --plotiter=50 --extramodinfo='dropout_fulldens'
 4486  clear && clear
 4487  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-resnet-dropout.prototxt' --use_model='../pretrained_model/c3d_resnet18_sports1m_r2_iter_2800000.caffemodel' --trainingbase='ledov' --batch=2 --validiter=2000 --savemodeliter=2000 --trainingexampleprops=0.995 --plotiter=50 --extramodinfo='dropout_fulldens'
 4488  clear && clear
 4489  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-resnet-dropout.prototxt' --use_model='../pretrained_model/c3d_resnet18_sports1m_r2_iter_2800000.caffemodel' --trainingbase='ledov' --batch=2 --validiter=2000 --savemodeliter=2000 --trainingexampleprops=0.995 --plotiter=50 --extramodinfo='dropout_fulldens'
 4490  clear && clear
 4491  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-resnet-dropout.prototxt' --use_model='../pretrained_model/c3d_resnet18_sports1m_r2_iter_2800000.caffemodel' --trainingbase='ledov' --batch=2 --validiter=2000 --savemodeliter=2000 --trainingexampleprops=0.995 --plotiter=50 --extramodinfo='dropout_fulldens'
 4492  python test_video.py --output_type='image' --test_base='gazecom' --model_code'v4-2' --videolength=16 --video_model_path='../training_output/salicon/vo-v4-2-resnet-dropout-snapshot-2000-display-1-dropout_fulldens-batch-2_1514857787/snapshot-_iter_26000.caffemodel' --video_deploy_path='prototxt/vo-v4-2-resnet.prototxt' --infertype='slide' 
 4493  python test_video.py --output_type='image' --test_base='gazecom' --model_code='v4-2' --videolength=16 --video_model_path='../training_output/salicon/vo-v4-2-resnet-dropout-snapshot-2000-display-1-dropout_fulldens-batch-2_1514857787/snapshot-_iter_26000.caffemodel' --video_deploy_path='prototxt/vo-v4-2-resnet.prototxt' --infertype='slide' 
 4494  python test_video.py --output_type='image' --test_base='gazecom' --model_code='v4-2' --videolength=16 --video_model_path='../training_output/salicon/vo-v4-2-resnet-dropout-snapshot-2000-display-1-dropout_fulldens-batch-2_1514857787/snapshot-_iter_26000.caffemodel' --video_deploy_path='prototxt/vo-v4-2-resnet.prototxt' --infertype='slide' && python test_video.py --output_type='image' --test_base='gazecom' --model_code='v4-2' --videolength=16 --video_model_path='../training_output/salicon/vo-v4-2-resnet-dropout-snapshot-2000-display-1-dropout_fulldens-batch-2_1514857787/snapshot-_iter_50000.caffemodel' --video_deploy_path='prototxt/vo-v4-2-resnet.prototxt' --infertype='slide' && python test_video.py --output_type='image' --test_base='gazecom' --model_code='v4-2' --videolength=16 --video_model_path='../training_output/salicon/vo-v4-2-resnet-dropout-snapshot-2000-display-1-dropout_fulldens-batch-2_1514857787/snapshot-_iter_100000.caffemodel' --video_deploy_path='prototxt/vo-v4-2-resnet.prototxt' --infertype='slide'
 4495  nvidia-smi
 4496  top
 4497  nvidia-smi
 4498  top
 4499  nvidia-smi
 4500  top
 4501  cd pwd/saliency_on_videoset/Train/scripts/
 4502  python test_video.py --output_type='image' --test_base='diem' --model_code='v4-2' --videolength=16 --video_deploy_path='prototxt/vo-v4-2-resnet.prototxt' --video_model_path='../training_output/salicon/vo-v4-2-resnet-dropout-snapshot-2000-display-1-dropout_fulldens-batch-2_1514857787/snapshot-_iter_26000.caffemodel' --infertype='slide' --inferoverlap=15
 4503  source set_env.sh ../C3D-v1.1 7
 4504  nvidia-smi
 4505  source set_env.sh ../C3D-v1.1 4
 4506  python test_video.py --output_type='image' --test_base='diem' --model_code='v4-2' --videolength=16 --video_deploy_path='prototxt/vo-v4-2-resnet.prototxt' --video_model_path='../training_output/salicon/vo-v4-2-resnet-dropout-snapshot-2000-display-1-dropout_fulldens-batch-2_1514857787/snapshot-_iter_26000.caffemodel' --infertype='slide' --inferoverlap=15
 4507  clear && clear
 4508  python test_video.py --output_type='image' --test_base='diem' --model_code='v4-2' --videolength=16 --video_deploy_path='prototxt/vo-v4-2-resnet.prototxt' --video_model_path='../training_output/salicon/vo-v4-2-resnet-dropout-snapshot-2000-display-1-dropout_fulldens-batch-2_1514857787/snapshot-_iter_26000.caffemodel' --infertype='slide' --inferoverlap=15
 4509  cd /data/sunnycia/SaliencyDataset/Video/MSU/videos
 4510  mv *_right.avi ../right_videos/
 4511  cd ../saliency_map/vo-v4-2-resnet-dropout-snapshot-2000-display-1-dropout_fulldens-batch-2_1514857787_snapshot-_iter_26000_threshold0/
 4512  rm -rf *_right
 4513  cd ../..
 4514  python gen_fixation.py 
 4515  top
 4516  cd /data/sunnycia/saliency_on_videoset/_Model
 4517  clear
 4518  matlab -nodesktop -nodisplay -nosplash
 4519  nvidia-smi
 4520  cd pwd/saliency_on_videoset/Train/
 4521  cd scripts/
 4522  source set_env.sh ../C3D-v1.1 3
 4523  clear
 4524  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-resnet-dropout01.prototxt' --use_model='../pretrained_model/c3d_resnet18_sports1m_r2_iter_2800000.caffemodel' --trainingbase='ledov' --batch=2 --validiter=2000 --savemodeliter=2000 --trainingexampleprops=0.995 --plotiter=50 --extramodinfo='01dropout_fulldens'
 4525  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-resnet-dropout.prototxt' --use_model='../pretrained_model/c3d_resnet18_sports1m_r2_iter_2800000.caffemodel' --trainingbase='ledov' --batch=2 --validiter=4000 --savemodeliter=4000 --trainingexampleprops=0.99 --plotiter=200 --extramodinfo='lowbaselr_05dropout_fulldens'
 4526  top
 4527  nvidia-smi
 4528  top
 4529  nvidia-smi
 4530  cd pwd/saliency_on_videoset/Train/scripts/
 4531  cd metric/
 4532  matlab -nodesktop -nodisplay
 4533  cd ..
 4534  python ss_test_video.py 
 4535  source set_env.sh ../C3D-v1.1
 4536  source set_env.sh ../C3D-v1.1 6
 4537  python ss_test_video.py 
 4538  clear && clear
 4539  python ss_test_video.py 
 4540  clear && clear
 4541  python ss_test_video.py 
 4542  nvidia-smi
 4543  export CUDA_VISIBLE_DEVICES=6
 4544  python ss_test_video.py 
 4545  python test_video.py --video_deploy_path='prototxt/vo-v4-2-resnet.prototxt' --video_model_path='../training_output/salicon/vo-v4-2-resnet-dropout01-snapshot-2000-display-1-01dropout_fulldens-batch-2_1514964788/snapshot-_iter_100000.caffemodel' --infertype='slide' --output_type='image' --test_base='videoset' --model_code='v4-2' --videolength=16  
 4546  source set_env.sh ../C3D-v1.1 6
 4547  python test_video.py --video_deploy_path='prototxt/vo-v4-2-resnet.prototxt' --video_model_path='../training_output/salicon/vo-v4-2-resnet-dropout01-snapshot-2000-display-1-01dropout_fulldens-batch-2_1514964788/snapshot-_iter_100000.caffemodel' --infertype='slide' --output_type='image' --test_base='videoset' --model_code='v4-2' --videolength=16  
 4548  nvidia-smi
 4549  python test_video.py --video_deploy_path='prototxt/vo-v4-2-resnet.prototxt' --video_model_path='../training_output/salicon/vo-v4-2-resnet-dropout-snapshot-2000-display-1-dropout_fulldens-batch-2_1514857787/snapshot-_iter_26000.caffemodel' --infertype='slide' --output_type='image' --test_base='ledov' --model_code='v4-2' --videolength=16
 4550  cd pwd/saliency_on_videoset/Train/scripts/
 4551  source set_env.sh ../C3D-v1.1 0
 4552  python test_video.py --video_deploy_path='prototxt/vo-v4-2-resnet.prototxt' --video_model_path='../training_output/salicon/vo-v4-2-resnet-dropout-snapshot-2000-display-1-dropout_fulldens-batch-2_1514857787/snapshot-_iter_26000.caffemodel' --infertype='slide' --output_type='image' --test_base='ledov' --model_code='v4-2' --videolength=16
 4553  python test_video.py --video_deploy_path='prototxt/vo-v4-2-resnet.prototxt' --video_model_path='../training_output/salicon/vo-v4-2-resnet-dropout-snapshot-2000-display-1-dropout_fulldens-batch-2_1514857787/snapshot-_iter_26000.caffemodel' --infertype='slide' --output_type='image' --test_base='msu' --model_code='v4-2' --videolength=16
 4554  python ss_test_video.py 
 4555  clear && clear
 4556  python ss_test_video.py 
 4557  top
 4558  nvidia-smi
 4559  top
 4560  nvidia-smi
 4561  df -h
 4562  nvidia-smi
 4563  top
 4564  nvidia-smi
 4565  cd /data/sunnycia/SaliencyDataset/Video/GAZECOM
 4566  python gen_fixation.py 
 4567  clear && clear
 4568  cd -
 4569  python utils/gen_density.py --sigma=32 --fixation_base='/data/sunnycia/SaliencyDataset/Video/GAZECOM/fixations' --density_base='/data/sunnycia/SaliencyDataset/Video/GAZECOM/density' --fixationtype='image'
 4570  python utils/VorI/one2all.py --videodirbase='/data/sunnycia/SaliencyDataset/Video/GAZECOM/fixations' --alldir='/data/sunnycia/SaliencyDataset/Video/GAZECOM/All_in_one/fixations'
 4571  clear && clear
 4572  git status
 4573  git add --all
 4574  git commit -m "find best & worst batch script; metric_distribution script; small scale test script; add dropout prototxt;"
 4575  git push -u origin master
 4576  clear && clear
 4577  matlab -nodesktop -nosplash -nodisplay
 4578  cd pwd/saliency_on_videoset/Train/scripts/
 4579  source set_env.sh ../C3D-v1.1 7
 4580  python ss_test_video.py 
 4581  ssh qiudan@172.31.234.205
 4582  source set_env.sh ../C3D-v1.1 7
 4583  python test_video.py --video_deploy_path='prototxt/vo-v4-2-resnet.prototxt' --video_model_path='../training_output/salicon/vo-v4-2-resnet-dropout01-snapshot-2000-display-1-01dropout_fulldens-batch-2_1514964788/snapshot-_iter_150000.caffemodel' --infertype='slide' --output_type='image' --test_base='videoset' --model_code='v4-2' --videolength=16
 4584  top
 4585  python test_video.py --video_deploy_path='prototxt/vo-v4-2-resnet.prototxt' --video_model_path='../training_output/salicon/vo-v4-2-resnet-dropout01-snapshot-2000-display-1-01dropout_fulldens-batch-2_1514964788/snapshot-_iter_150000.caffemodel' --infertype='slide' --output_type='image' --test_base='videoset' --model_code='v4-2' --videolength=16 --inferoverlap=8
 4586  cd pwd/saliency_on_videoset/Train/scripts/
 4587  clear
 4588  source set_env.sh ../C3D-v1.1 7
 4589  python test_video.py --video_deploy_path='prototxt/vo-v4-2-resnet.prototxt' --video_model_path='../training_output/salicon/vo-v4-2-resnet-dropout01-snapshot-2000-display-1-01dropout_fulldens-batch-2_1514964788/snapshot-_iter_150000.caffemodel' --infertype='slide' --output_type='image' --test_base='videoset' --model_code='v4-2' --videolength=16 --inferoverlap=12
 4590  cd pwd/saliency_on_videoset/Train/scripts/
 4591  ls
 4592  top
 4593  clear
 4594  python test_video.py --video_deploy_path='prototxt/vo-v4-2-resnet.prototxt' --video_model_path='../training_output/salicon/vo-v4-2-resnet-dropout01-snapshot-2000-display-1-01dropout_fulldens-batch-2_1514964788/snapshot-_iter_150000.caffemodel' --infertype='slide' --output_type='image' --test_base='videoset' --model_code='v4-2' --videolength=16 --inferoverlap=14
 4595  source set_env.sh ../C3D-v1.1 4
 4596  python test_video.py --video_deploy_path='prototxt/vo-v4-2-resnet.prototxt' --video_model_path='../training_output/salicon/vo-v4-2-resnet-dropout01-snapshot-2000-display-1-01dropout_fulldens-batch-2_1514964788/snapshot-_iter_150000.caffemodel' --infertype='slide' --output_type='image' --test_base='videoset' --model_code='v4-2' --videolength=16 --inferoverlap=14
 4597  top
 4598  cd pwd/saliency_on_videoset/Train/scripts/
 4599  python utils/dsutil/fixmat2img.py --matdir='/data/sunnycia/SaliencyDataset/Video/MSU/fixation/mat_allinone' --imgdir='/data/sunnycia/SaliencyDataset/Video/MSU/fixation/image_allinone'
 4600  top
 4601  nvidia-smi
 4602  top
 4603  nvidia-smi
 4604  cd /data/sunnycia/SaliencyDataset/Video/SFU_etdb
 4605  matlab 
 4606  cd /data/sunnycia/saliency_on_videoset/Train/scripts
 4607  python utils/VorI/slice_frames.py --videobase='/data/sunnycia/SaliencyDataset/Video/GAZECOM/movies' --outputbase='/data/sunnycia/SaliencyDataset/Video/GAZECOM/frames'
 4608  clear && clear
 4609  python utils/VorI/slice_frames.py --videobase='/data/sunnycia/SaliencyDataset/Video/GAZECOM/movies' --outputbase='/data/sunnycia/SaliencyDataset/Video/GAZECOM/frames'
 4610  cd /data/sunnycia/SaliencyDataset/Video/GAZECOM
 4611  python gen_fixation.py 
 4612  clear
 4613  python gen_fixation.py 
 4614  clear && clear
 4615  python gen_fixation.py 
 4616  cd /data/sunnycia/saliency_on_videoset/Train/scripts
 4617  python utils/gen_density.py --sigma=32 --fixation_base='' --density_base='' --fixationtype='image'
 4618  python utils/gen_density.py --sigma=32 --fixation_base='/data/sunnycia/SaliencyDataset/Video/GAZECOM/fixations' --density_base='/data/sunnycia/SaliencyDataset/Video/GAZECOM/density' --fixationtype='image'
 4619  cd ../
 4620  cd ../_Train/
 4621  ls
 4622  cd OMCNN_2CLSTM/
 4623  ls
 4624  python test.py --videodir='/data/sunnycia/SaliencyDataset/Video/GAZECOM/videos' --outputdir='/data/sunnycia/SaliencyDataset/Video/GAZECOM/saliency_map/xu_lstm' --outputtype='image'
 4625  export CUDA_VISIBLE_DEVICES=6
 4626  nvidia-smi
 4627  python test.py --videodir='/data/sunnycia/SaliencyDataset/Video/GAZECOM/videos' --outputdir='/data/sunnycia/SaliencyDataset/Video/GAZECOM/saliency_map/xu_lstm' --outputtype='image'
 4628  python test.py --videodir='/data/sunnycia/SaliencyDataset/Video/MSU/videos' --outputdir='/data/sunnycia/SaliencyDataset/Video/MSU/saliency_map/xu_lstm' --outputtype='image'
 4629  top
 4630  nvidia-smi
 4631  top
 4632  nvidia-smi
 4633  pwd
 4634  cd ../../Train/scripts/
 4635  git status
 4636  git add --all
 4637  git commit -m "combine metric statistics function into metirc_video_base script"
 4638  git push -u origin master
 4639  top
 4640  nvidia-smi
 4641  top
 4642  nvidia-smi
 4643  python
 4644  source set_env.sh ../C3D-v1.1 6
 4645  python utils/model_guardian.py --modeldir='/data/sunnycia/saliency_on_videoset/Train/training_output/salicon/vo-v4-2-resnet-dropout-weight_decay-0.000005-base_lr-0.00001-snapshot-4000-display-1-lowbaselr_05dropout_fulldens-batch-2_1515212244' --modeliter=20000
 4646  python utils/model_guardian.py --modeldir='' --modeliter=50000
 4647  python utils/model_guardian.py --modeldir='/data/sunnycia/saliency_on_videoset/Train/training_output/salicon/vo-v4-2-resnet-dropout01-snapshot-2000-display-1-01dropout_fulldens-batch-2_1514964788' --modeliter=50000
 4648  clear && clear
 4649  python utils/model_guardian.py --modeldir='/data/sunnycia/saliency_on_videoset/Train/training_output/salicon/vo-v4-2-resnet-dropout-weight_decay-0.000005-base_lr-0.00001-snapshot-4000-display-1-lowbaselr_05dropout_fulldens-batch-2_1515212244' --modeliter=20000
 4650  clear && clear
 4651  cd metric/
 4652  matlab -nodesktop -nodisplay
 4653  cd ..
 4654  top
 4655  nvidia-smi
 4656  clear && clear
 4657  python top
 4658  top
 4659  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-dropout.prototxt' --user_model='../pretrained_model/conv3d_deepnetA_sport1m_iter_1900000_v1.1.caffemodel' --trainingbase='ledov' --batch=2 --trainingexamplepropx=0.999 --savemodeliter=4000 --validiter=4000 --plotiter=200
 4660  source set_env.sh ../C3D-v1.1 5
 4661  clear && claer
 4662  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-dropout.prototxt' --user_model='../pretrained_model/conv3d_deepnetA_sport1m_iter_1900000_v1.1.caffemodel' --trainingbase='ledov' --batch=2 --trainingexamplepropx=0.999 --savemodeliter=4000 --validiter=4000 --plotiter=200
 4663  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-dropout.prototxt' --use_model='../pretrained_model/conv3d_deepnetA_sport1m_iter_1900000_v1.1.caffemodel' --trainingbase='ledov' --batch=2 --trainingexamplepropx=0.999 --savemodeliter=4000 --validiter=4000 --plotiter=200
 4664  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-dropout.prototxt' --use_model='../pretrained_model/conv3d_deepnetA_sport1m_iter_1900000_v1.1.caffemodel' --trainingbase='ledov' --batch=2 --trainingexampleprops=0.999 --savemodeliter=4000 --validiter=4000 --plotiter=200 
 4665  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-resnet-dropout.prototxt' --use_model='../pretrained_model/conv3d_deepnetA_sport1m_iter_1900000_v1.1.caffemodel' --trainingbase='ledov' --batch=2 --trainingexampleprops=0.999 --savemodeliter=4000 --validiter=4000 --plotiter=200 
 4666  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-resnet-dropout.prototxt' --use_model='../pretrained_model/c3d_resnet18_sports1m_r2_iter_2800000.caffemodel' --trainingbase='ledov' --batch=2 --trainingexampleprops=0.999 --savemodeliter=4000 --validiter=4000 --plotiter=200 
 4667  clear && clear
 4668  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-resnet-dropout.prototxt' --use_model='../pretrained_model/c3d_resnet18_sports1m_r2_iter_2800000.caffemodel' --trainingbase='ledov' --batch=2 --trainingexampleprops=0.999 --savemodeliter=4000 --validiter=4000 --plotiter=200 
 4669  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-resnet-dropout.prototxt' --use_model='../pretrained_model/c3d_resnet18_sports1m_r2_iter_2800000.caffemodel' --trainingbase='ledov' --batch=2 --trainingexampleprops=0.99 --savemodeliter=4000 --validiter=4000 --plotiter=200 
 4670  cd pwd/saliency_on_videoset/Train/scripts/
 4671  clear
 4672  source set_env.sh ../C3D-v1.1 6
 4673  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-resnet-dropout.prototxt' --solver_prototxt='prototxt/solver-static.prototxt' --staticsolver=True --use_model='../pretrained_model/c3d_resnet18_sports1m_r2_iter_2800000.caffemodel' --trainingbase='ledov' --batch=2 --trainingexampleprops=0.99 --savemodeliter=4000 --validiter=4000 --plotiter=200
 4674  top
 4675  nvidia-smi
 4676  cd pwd/saliency_on_videoset/Train/scripts/
 4677  source set_env.sh ../C3D-v1.1 7
 4678  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-resnet-dropout.prototxt' --use_model='../pretrained_model/c3d_resnet18_sports1m_r2_iter_2800000.caffemodel' --trainingbase='ledov' --batch=2 --trainingexampleprops=0.999 --savemodeliter=4000 --validiter=4000 --plotiter=200
 4679  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-resnet-dropout.prototxt' --use_model='../pretrained_model/c3d_resnet18_sports1m_r2_iter_2800000.caffemodel' --trainingbase='ledov' --batch=2 --trainingexampleprops=0.99 --savemodeliter=4000 --validiter=4000 --plotiter=200
 4680  clear && clear
 4681  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-resnet-dropout.prototxt' --use_model='../pretrained_model/c3d_resnet18_sports1m_r2_iter_2800000.caffemodel' --trainingbase='ledov' --batch=2 --trainingexampleprops=0.99 --savemodeliter=4000 --validiter=4000 --plotiter=200
 4682  cd pwd/saliency_on_videoset/Train/scripts/
 4683  nvidia-smi
 4684  source set_env.sh ../C3D-v1.1 6
 4685  history > history
 4686  python test_video.py --video_deploy_path='prototxt/vo-v4-2-resnet.prototxt' --video_model_path='../training_output/salicon/vo-v4-2-resnet-dropout01-snapshot-2000-display-1-01dropout_fulldens-batch-2_1514964788/snapshot-_iter_150000.caffemodel' --infertype='slide' --output_type='image' --test_base='videoset' --model_code='v4-2' --videolength=16 --inferoverlap=8
 4687  python test_video.py --video_deploy_path='prototxt/vo-v4-2-resnet.prototxt' --video_model_path='../training_output/salicon/vo-v4-2-resnet-dropout-snapshot-2000-display-1-dropout_fulldens-batch-2_1514857787/snapshot-_iter_26000.caffemodel' --infertype='slide' --output_type='image' --test_base='videoset' --model_code='v4-2' --videolength=16 --inferoverlap=8 && python test_video.py --video_deploy_path='prototxt/vo-v4-2-resnet.prototxt' --video_model_path='../training_output/salicon/vo-v4-2-resnet-dropout-snapshot-2000-display-1-dropout_fulldens-batch-2_1514857787/snapshot-_iter_26000.caffemodel' --infertype='slide' --output_type='image' --test_base='videoset' --model_code='v4-2' --videolength=16 --inferoverlap=12 && python test_video.py --video_deploy_path='prototxt/vo-v4-2-resnet.prototxt' --video_model_path='../training_output/salicon/vo-v4-2-resnet-dropout-snapshot-2000-display-1-dropout_fulldens-batch-2_1514857787/snapshot-_iter_26000.caffemodel' --infertype='slide' --output_type='image' --test_base='videoset' --model_code='v4-2' --videolength=16 --inferoverlap=14
 4688  top
 4689  nvidia-smi
 4690  top
 4691  nvidia-smi
 4692  git status
 4693  git add --all
 4694  git commit -m "add model_guradian"
 4695  git push -u origin master
 4696  top
 4697  df -h
 4698  cd metric/
 4699  matlab -nodesktop
 4700  clear && clear
 4701  matlab -nodesktop -nodisplay
 4702  top
 4703  cd pwd/saliency_on_videoset/Train/scripts/
 4704  python utils/model_guardian.py --modeldir='/data/sunnycia/saliency_on_videoset/Train/training_output/salicon/vo-v4-2-resnet-dropout-weight_decay-0.000005-base_lr-0.00001-snapshot-4000-display-1--batch-2_1515225254' --modeliter=20000
 4705  nvidia-smi
 4706  source set_env.sh ../C3D-v1.1 4
 4707  python utils/model_guardian.py --modeldir='/data/sunnycia/saliency_on_videoset/Train/training_output/salicon/vo-v4-2-resnet-dropout-weight_decay-0.000005-base_lr-0.00001-snapshot-4000-display-1--batch-2_1515225254' --modeliter=20000
 4708  cd pwd/saliency_on_videoset/Train/scripts/
 4709  ls
 4710  locate LSTMconv_prefinal_loss05_dp075_075MC100-200000.data-00000-of-00001
 4711  cd /data/sunnycia/saliency_on_videoset/_Train/OMCNN_2CLSTM
 4712  nvidia-smi
 4713  top
 4714  export CUDA_VISIBLE_DEVICES=0
 4715  python test.py --videodir='/data/sunnycia/SaliencyDataset/Video/DIEM/videos' --outputdir='/data/sunnycia/SaliencyDataset/Video/DIEM/saliency_map' --outputtype='image'
 4716  python test.py --videodir='/data/sunnycia/SaliencyDataset/Video/DIEM/videos' --outputdir='/data/sunnycia/SaliencyDataset/Video/DIEM/saliency_map/xu-lstm' --outputtype='image'
 4717  clear && clear
 4718  python test.py --videodir='/data/sunnycia/SaliencyDataset/Video/DIEM/videos' --outputdir='/data/sunnycia/SaliencyDataset/Video/DIEM/saliency_map/xu-lstm' --outputtype='image'
 4719  cd 
 4720  cd /data/sunnycia/SaliencyDataset/Video/MSU
 4721  python gen_fixation.py 
 4722  cd /data/sunnycia/saliency_on_videoset/Train/scripts/data/sunnycia/saliency_on_videoset/Train/scripts
 4723  cd /data/sunnycia/saliency_on_videoset/Train/scripts
 4724  python utils/dsutil/fixmat2img.py --matdir='/data/sunnycia/SaliencyDataset/Video/MSU/fixation/mat' --imgdir='/data/sunnycia/SaliencyDataset/Video/MSU/fixation/image_convert'
 4725  cd ..
 4726  cd ../_Model/
 4727  matlab -nodesktop -nodisplay
 4728  top
 4729  nvidia-smi
 4730  top
 4731  nvidia-smi
 4732  df -h
 4733  top
 4734  nvidia-smi
 4735  top
 4736  nvidia-smi
 4737  top
 4738  nvidia-smi
 4739  top
 4740  nvidia-smi
 4741  top
 4742  clear
 4743  matlab -nodesktop -nodisplay
 4744  cd /data/sunnycia/SaliencyDataset/Video/Coutort2
 4745  unzip ERB4_Stimuli.zip 
 4746  matlab -nodesktop -nodisplay
 4747  top
 4748  nvidia-smi
 4749  cd ../Coutort2
 4750  python generate_fixation.py 
 4751  ssh sunnycia@172.31.234.248
 4752  clear && clear
 4753  ls
 4754  cd pwd/saliency_on_videoset/Train/scripts/
 4755  python utils/model_guardian.py --modeldir='/data/sunnycia/saliency_on_videoset/Train/training_output/salicon/vo-v4-2-resnet-dropout-weight_decay-0.000005-base_lr-0.0001-snapshot-4000-display-1--batch-2_1515247477' --modeliter=20000
 4756  source set_env.sh ../C3D-v1.1 4
 4757  python utils/model_guardian.py --modeldir='/data/sunnycia/saliency_on_videoset/Train/training_output/salicon/vo-v4-2-resnet-dropout-weight_decay-0.000005-base_lr-0.0001-snapshot-4000-display-1--batch-2_1515247477' --modeliter=20000
 4758  nvidia-smi
 4759  top
 4760  nvidia-smi
 4761  top
 4762  nvidia-smi
 4763  df -h
 4764  top
 4765  nvidia-smi
 4766  clear
 4767  ssh qiudan@172.31.234.205
 4768  cd pwd/saliency_on_videoset/Train/scripts/
 4769  git status
 4770  python utils/scavenger.py 
 4771  python utils/scavenger.py --snapshot
 4772  python utils/scavenger.py --snapshot=1
 4773  clear && clear
 4774  top
 4775  nvidia-smi
 4776  top
 4777  clear
 4778  python utils/dsutil/slice_frames.py 
 4779  python utils/dsutil/slice_frames.py --videobase='/data/sunnycia/SaliencyDataset/Video/Coutort1/videos' --outputbase='/data/sunnycia/SaliencyDataset/Video/Coutort1/frames'
 4780  cd /data/sunnycia/SaliencyDataset/Video/Coutort1
 4781  python generate_fixation.py 
 4782  clear && clear
 4783  python generate_fixation.py 
 4784  clear && clear
 4785  python generate_fixation.py 
 4786  clear && clear
 4787  python generate_fixation.py 
 4788  clear && python generate_fixation.py 
 4789  clear && clear
 4790  python generate_fixation.py 
 4791  clear && clear
 4792  python generate_fixation.py 
 4793  top
 4794  python generate_fixation.py 
 4795  df -h
 4796  python generate_fixation.py 
 4797  cd /data/sunnycia/saliency_on_videoset/Train/scripts
 4798  python utils/dsutil/gen_density.py 
 4799  python utils/dsutil/gen_density.py --fixation_base='/data/sunnycia/SaliencyDataset/Video/Coutort1/fixation' --sigma=32 --fixationtype='image' --density_base='/data/sunnycia/SaliencyDataset/Video/Coutort1/density'
 4800  top
 4801  clear
 4802  python utils/dsutil/gen_density.py 
 4803  python utils/dsutil/gen_density.py --sigma=32 --fixation_base='/data/sunnycia/SaliencyDataset/Video/Coutort2/fixation' --density_base='/data/sunnycia/SaliencyDataset/Video/Coutort2/density' --fixationtype='image'
 4804  cd pwd/saliency_on_videoset/Train/scripts/
 4805  source set_env.sh ../C3D-v1.1 4
 4806  python utils/model_guardian.py --modeldir='/data/sunnycia/saliency_on_videoset/Train/training_output/salicon/vo-v4-2-static-resnet-dropout' --modeliter=20000
 4807  nvidia-smi
 4808  cd pwd/saliency_on_videoset/Train/scripts/
 4809  source set_env.sh ../C3D-v1.1 7
 4810  clear && clear
 4811  python test_video.py --video_deploy_path='prototxt/vo-v4-2-resnet.prototxt' --video_model_path='../training_output/salicon/vo-v4-2-resnet-dropout-snapshot-2000-display-1-dropout_fulldens-batch-2_1514857787/snapshot-_iter_26000.caffemodel' --infertype='slide' --output_type='image' --test_base='gazecom' --model_code='v4-2' --videolength=16 --inferoverlap=8 && python test_video.py --video_deploy_path='prototxt/vo-v4-2-resnet.prototxt' --video_model_path='../training_output/salicon/vo-v4-2-resnet-dropout-snapshot-2000-display-1-dropout_fulldens-batch-2_1514857787/snapshot-_iter_26000.caffemodel' --infertype='slide' --output_type='image' --test_base='gazecom' --model_code='v4-2' --videolength=16 --inferoverlap=12 && python test_video.py --video_deploy_path='prototxt/vo-v4-2-resnet.prototxt' --video_model_path='../training_output/salicon/vo-v4-2-resnet-dropout-snapshot-2000-display-1-dropout_fulldens-batch-2_1514857787/snapshot-_iter_26000.caffemodel' --infertype='slide' --output_type='image' --test_base='gazecom' --model_code='v4-2' --videolength=16 --inferoverlap=14
 4812  clear && clear
 4813  top
 4814  nvidia-smi
 4815  top
 4816  nvidia-smi
 4817  cd metric/
 4818  clear && clear
 4819  matlab -nodesktop -nodisplay
 4820  top
 4821  cd pwd/saliency_on_videoset/
 4822  cd Train/scripts/metric/
 4823  clear
 4824  matlab -nodesktop -nodisplay
 4825  nvidia-smi
 4826  cd pwd/saliency_on_videoset/Train/scripts/
 4827  clear
 4828  top
 4829  nvidia-smi
 4830  clear && clear
 4831  cd /data/sunnycia/saliency_on_videoset/Train/caffe-master
 4832  make clean && make -j8 all
 4833  top
 4834  cd ~/pwd/saliency_on_videoset/Train/scripts/
 4835  ls
 4836  cd /data/sunnycia/saliency_on_videoset/Train/metric-matlab/diem
 4837  cd ..
 4838  cd metric
 4839  ls
 4840  cd ..
 4841  cd scripts/metric/
 4842  matlab -nodesktop -nodisplay
 4843  clear && clear
 4844  matlab -nodesktop -nodisplay
 4845  cd pwd/saliency_on_videoset/Train/scripts/
 4846  python utils/watcher.py 
 4847  top
 4848  nvidia-smi
 4849  source set_env.sh ../C3D-v1.1 5
 4850  python utils/weight_visualization.py --modelpath='/data/sunnycia/saliency_on_videoset/Train/training_output/salicon/vo-v4-2-resnet-dropout-snapshot-2000-display-1-dropout_fulldens-batch-2_1514857787/snapshot-_iter_26000.caffemodel' --deploypath='prototxt/vo-v4-2-resnet.prototxt' --outputdir='./' --layer='conv1' --type='3d'
 4851  python utils/weight_visualization.py --modelpath='/data/sunnycia/saliency_on_videoset/Train/training_output/salicon/vo-v4-2-resnet-dropout-snapshot-2000-display-1-dropout_fulldens-batch-2_1514857787/snapshot-_iter_26000.caffemodel' --deploypath='prototxt/vo-v4-2-resnet.prototxt' --outputdir='./conv1.jpg' --layer='conv1' --type='3d'
 4852  python utils/weight_visualization.py --modelpath='/data/sunnycia/saliency_on_videoset/Train/training_output/salicon/vo-v4-2-resnet-dropout-snapshot-2000-display-1-dropout_fulldens-batch-2_1514857787/snapshot-_iter_26000.caffemodel' --deploypath='prototxt/vo-v4-2-resnet.prototxt' --outputpath='./conv1.jpg' --layer='conv1' --type='3d'
 4853  python utils/weight_visualization.py --modelpath='/data/sunnycia/saliency_on_videoset/Train/pretrained_model/c3d_resnet18_sports1m_r2_iter_2800000.caffemodel' --deploypath='/data/sunnycia/saliency_on_videoset/Train/pretrained_model/deploy_p3d_resnet_sports1m.prototxt' --outputpath='./conv1.jpg' --layer='conv1' --type='3d'
 4854  python utils/weight_visualization.py --modelpath='/data/sunnycia/saliency_on_videoset/Train/pretrained_model/c3d_resnet18_sports1m_r2_iter_2800000.caffemodel' --deploypath='/data/sunnycia/saliency_on_videoset/Train/pretrained_model/c3d_resnet18_ucf101_feature_extraction.prototxt' --outputpath='./conv1.jpg' --layer='conv1' --type='3d'
 4855  python utils/weight_visualization.py --modelpath='/data/sunnycia/saliency_on_videoset/Train/training_output/salicon/vo-v4-2-resnet-dropout-snapshot-2000-display-1-dropout_fulldens-batch-2_1514857787/snapshot-_iter_26000.caffemodel' --deploypath='prototxt/vo-v4-2-resnet.prototxt' --outputpath='./conv1-new.jpg' --layer='conv1' --type='3d'
 4856  python utils/weight_visualization.py --modelpath='/data/sunnycia/saliency_on_videoset/Train/training_output/salicon/vo-v4-2-resnet-dropout-snapshot-2000-display-1-dropout_fulldens-batch-2_1514857787/snapshot-_iter_26000.caffemodel' --deploypath='prototxt/vo-v4-2-resnet.prototxt' --outputpath='./conv1-new.jpg' --layer='res5b_branch2b' --type='3d'
 4857  python utils/weight_visualization.py --modelpath='/data/sunnycia/saliency_on_videoset/Train/training_output/salicon/vo-v4-2-resnet-dropout-snapshot-2000-display-1-dropout_fulldens-batch-2_1514857787/snapshot-_iter_26000.caffemodel' --deploypath='prototxt/vo-v4-2-resnet.prototxt' --outputpath='./conv1-new.jpg' --layer='res2a_branch1' --type='3d'
 4858  python utils/weight_visualization.py --modelpath='/data/sunnycia/saliency_on_videoset/Train/training_output/salicon/vo-v4-2-resnet-dropout-snapshot-2000-display-1-dropout_fulldens-batch-2_1514857787/snapshot-_iter_26000.caffemodel' --deploypath='prototxt/vo-v4-2-resnet.prototxt' --outputpath='./conv1-new.jpg' --layer='res2a_branch2a' --type='3d'
 4859  python utils/weight_visualization.py --modelpath='/data/sunnycia/saliency_on_videoset/Train/pretrained_model/c3d_resnet18_sports1m_r2_iter_2800000.caffemodel' --deploypath='/data/sunnycia/saliency_on_videoset/Train/pretrained_model/c3d_resnet18_ucf101_feature_extraction.prototxt' --outputpath='./conv1.jpg' --layer='res2a_branch2a' --type='3d'
 4860  python utils/weight_visualization.py --modelpath='/data/sunnycia/saliency_on_videoset/Train/pretrained_model/c3d_resnet18_sports1m_r2_iter_2800000.caffemodel' --deploypath='/data/sunnycia/saliency_on_videoset/Train/pretrained_model/c3d_resnet18_ucf101_feature_extraction.prototxt' --outputpath='./conv1.jpg' --layer='conv1' --type='3d'
 4861  python utils/weight_visualization.py --modelpath='/data/sunnycia/saliency_on_videoset/Train/pretrained_model/c3d_resnet18_sports1m_r2_iter_2800000.caffemodel' --deploypath='/data/sunnycia/saliency_on_videoset/Train/pretrained_model/c3d_resnet18_ucf101_feature_extraction.prototxt' --outputpath='./conv1.jpg' --layer='res5b_branch2a' --type='3d'
 4862  python visualization_featuremap.py --videopath='/data/sunnycia/SaliencyDataset/Video/VideoSet/Videos/videos_origin/videoSRC001.avi' --deploypath='prototxt/vo-v4-2-resnet.prototxt' --modelpath='/data/sunnycia/saliency_on_videoset/Train/training_output/salicon/vo-v4-2-resnet-dropout-snapshot-2000-display-1-dropout_fulldens-batch-2_1514857787/snapshot-_iter_26000.caffemodel' --layername='conv1' 
 4863  python utils/weight_visualization.py --modelpath='/data/sunnycia/saliency_on_videoset/Train/pretrained_model/c3d_resnet18_sports1m_r2_iter_2800000.caffemodel' --deploypath='/data/sunnycia/saliency_on_videoset/Train/pretrained_model/c3d_resnet18_ucf101_feature_extraction.prototxt' --outputpath='./conv1.jpg' --layer='res5b_branch2a' --type='3d'
 4864  python visualization_featuremap.py --videopath='/data/sunnycia/SaliencyDataset/Video/VideoSet/Videos/videos_origin/videoSRC001.avi' --deploypath='prototxt/vo-v4-2-resnet.prototxt' --modelpath='/data/sunnycia/saliency_on_videoset/Train/training_output/salicon/vo-v4-2-resnet-dropout-snapshot-2000-display-1-dropout_fulldens-batch-2_1514857787/snapshot-_iter_26000.caffemodel' --layername='conv1' 
 4865  df - h
 4866  python visualization_featuremap.py --videopath='/data/sunnycia/SaliencyDataset/Video/VideoSet/Videos/videos_origin/videoSRC001.avi' --deploypath='prototxt/vo-v4-2-resnet.prototxt' --modelpath='/data/sunnycia/saliency_on_videoset/Train/training_output/salicon/vo-v4-2-resnet-dropout-snapshot-2000-display-1-dropout_fulldens-batch-2_1514857787/snapshot-_iter_26000.caffemodel' --layername='res2b' 
 4867  python visualization_featuremap.py --videopath='/data/sunnycia/SaliencyDataset/Video/VideoSet/Videos/videos_origin/videoSRC001.avi' --deploypath='prototxt/vo-v4-2-resnet.prototxt' --modelpath='/data/sunnycia/saliency_on_videoset/Train/training_output/salicon/vo-v4-2-resnet-dropout-snapshot-2000-display-1-dropout_fulldens-batch-2_1514857787/snapshot-_iter_26000.caffemodel'
 4868  python visualization_featuremap.py --videopath='/data/sunnycia/SaliencyDataset/Video/VideoSet/Videos/videos_origin/videoSRC041.avi' --deploypath='prototxt/vo-v4-2-resnet.prototxt' --modelpath='/data/sunnycia/saliency_on_videoset/Train/training_output/salicon/vo-v4-2-resnet-dropout-snapshot-2000-display-1-dropout_fulldens-batch-2_1514857787/snapshot-_iter_26000.caffemodel'
 4869  python visualization_featuremap.py --videopath='/data/sunnycia/SaliencyDataset/Video/VideoSet/Videos/videos_origin/videoSRC041.avi' --deploypath='prototxt/vo-v4-2-resnet.prototxt' --modelpath='/data/sunnycia/saliency_on_videoset/Train/training_output/salicon/vo-v4-2-resnet-dropout-snapshot-2000-display-1-dropout_fulldens-batch-2_1514857787/snapshot-_iter_126000.caffemodel'
 4870  ssh qiudan@172.31.234.248
 4871  clear && clear
 4872  git status
 4873  git add --all
 4874  git push -u origin master
 4875  git commit -m "add feature map visualization function. add jigsaw util"
 4876  git push -u origin master
 4877  ssh qiudan@172.31.234.248
 4878  clear && clear
 4879  ssh qiudan@172.31.234.248
 4880  du -h
 4881  du --help
 4882  du -d=1
 4883  du -d=1 /
 4884  du --max-depth=1
 4885  du --max-depth=1 /home/
 4886  su
 4887  top
 4888  top
 4889  nvidia-smi
 4890  top
 4891  nvidia-smi
 4892  top
 4893  nvidia-smi
 4894  top
 4895  cd /data/sunnycia/saliency_on_videoset/_Model/Surprise-iLab-saliency-20140505
 4896  bash configure
 4897  make core'
 4898  make core
 4899  make clean
 4900  make core
 4901  make clean
 4902  bash configure
 4903  make core
 4904  make clean
 4905  ./configure
 4906  make -j4
 4907  su
 4908  make -j4
 4909  make clean
 4910  -j4 ./configure
 4911  ./configure -j2
 4912  ./configure
 4913  make clean
 4914  ./configure
 4915  svn
 4916  cd /data/sunnycia/saliency_on_videoset/Train/scripts
 4917  source set_env.sh ../C3D-v1.1 6
 4918  nvidia-smi
 4919  top
 4920  clear
 4921  nvidia-smi
 4922  clear
 4923  source set_env.sh ../C3D-v1.1 4
 4924  python utils/weight_visualization.py 
 4925  python utils/weight_visualization.py --modelpath='../training_output/salicon/vo-v4-2-resnet-dropout-snapshot-2000-display-1-dropout_fulldens-batch-2_1514857787/snapshot-_iter_26000.caffemodel' --deploypath='prototxt/vo-v4-2-resnet.prototxt' --outputpath='./conv1.jpg' --layer='conv1'
 4926  python utils/weight_visualization.py --modelpath='../training_output/salicon/vo-v4-2-resnet-dropout-snapshot-2000-display-1-dropout_fulldens-batch-2_1514857787/snapshot-_iter_26000.caffemodel' --deploypath='prototxt/vo-v4-2-resnet.prototxt' --outputpath='./conv1.jpg' --layer='conv1' -h
 4927  python utils/weight_visualization.py --modelpath='../training_output/salicon/vo-v4-2-resnet-dropout-snapshot-2000-display-1-dropout_fulldens-batch-2_1514857787/snapshot-_iter_26000.caffemodel' --deploypath='prototxt/vo-v4-2-resnet.prototxt' --outputpath='./conv1.jpg' --layer='conv1' type='3d'
 4928  python utils/weight_visualization.py --modelpath='../training_output/salicon/vo-v4-2-resnet-dropout-snapshot-2000-display-1-dropout_fulldens-batch-2_1514857787/snapshot-_iter_26000.caffemodel' --deploypath='prototxt/vo-v4-2-resnet.prototxt' --outputpath='./conv1.jpg' --layer='conv1' --type='3d'
 4929  python utils/weight_visualization.py --modelpath='../training_output/salicon/vo-v4-2-resnet-dropout-snapshot-2000-display-1-dropout_fulldens-batch-2_1514857787/snapshot-_iter_26000.caffemodel' --deploypath='prototxt/vo-v4-2-resnet.prototxt' --outputpath='./res5b_branch2b.jpg' --layer='res5b_branch2b' --type='3d'
 4930  python utils/weight_visualization.py --modelpath='../training_output/salicon/vo-v4-2-resnet-dropout-snapshot-2000-display-1-dropout_fulldens-batch-2_1514857787/snapshot-_iter_26000.caffemodel' --deploypath='prototxt/vo-v4-2-resnet.prototxt' --outputpath='./res2b_branch2b.jpg' --layer='res2b_branch2b' --type='3d'
 4931  python utils/weight_visualization.py --modelpath='../training_output/salicon/vo-v4-2-resnet-dropout-snapshot-2000-display-1-dropout_fulldens-batch-2_1514857787/snapshot-_iter_26000.caffemodel' --deploypath='prototxt/vo-v4-2-resnet.prototxt' --outputpath='./deconv1.jpg' --layer='deconv1' --type='3d'
 4932  python utils/weight_visualization.py --modelpath='../training_output/salicon/vo-v4-2-resnet-dropout-snapshot-2000-display-1-dropout_fulldens-batch-2_1514857787/snapshot-_iter_26000.caffemodel' --deploypath='prototxt/vo-v4-2-resnet.prototxt' --outputpath='./predict.jpg' --layer='predict' --type='3d'
 4933  top
 4934  clear
 4935  python utils/weight_visualization.py --modelpath='../training_output/salicon/vo-v4-2-resnet-dropout-snapshot-2000-display-1-dropout_fulldens-batch-2_1514857787/snapshot-_iter_26000.caffemodel' --deploypath='prototxt/vo-v4-2-resnet.prototxt' --outputpath='./deconv2.jpg' --layer='deconv2' --type='3d'
 4936  python visualization_featuremap.py -h
 4937  python visualization_featuremap.py --videopath='' --deploypath='' --modelpath=''
 4938  python visualization_featuremap.py --videopath='/data/sunnycia/SaliencyDataset/Video/VideoSet/Videos/videos_origin/videoSRC041.avi' --deploypath='prototxt/vo-v4-2-resnet.prototxt' --modelpath='../training_output/salicon/vo-v4-2-resnet-dropout-snapshot-2000-display-1-dropout_fulldens-batch-2_1514857787/snapshot-_iter_26000.caffemodel'
 4939  cd /data/sunnycia/SaliencyDataset/Video/Hollywood2
 4940  rm -rf Hollywood2
 4941  df -h
 4942  tar -xzf Hollywood2-scenes.tar.gz 
 4943  rm -rf Hollywood2
 4944  gunzip Hollywood2-scenes.tar.gz 
 4945  cd ~/pwd/saliency_on_videoset/
 4946  cd ..
 4947  pwd
 4948  cd /data/sunnycia/SaliencyDataset/
 4949  cd ~/pwd/saliency_on_videoset/_Model/
 4950  matlab -nodesktop -nodisplay
 4951  matlab -nodeskop -nodisplay
 4952  top
 4953  top
 4954  cd pwd/saliency_on_videoset/_Model/
 4955  matlab -nodesktop -nodisplay
 4956  top
 4957  nvidia-smi
 4958  top
 4959  cd pwd/saliency_on_videoset/_Model/
 4960  matlab -nodesktop -nodisplay
 4961  matlab
 4962  matlab -nodesktop -nodisplay
 4963  clear && clear
 4964  cd /data/sunnycia/saliency_on_videoset/_Model
 4965  mkdir OBDL && mv kvbs_cvpr2015.rar OBDL && cd OBDL && unzip kvbs_cvpr2015.rar
 4966  pwd
 4967  ls
 4968  unrar kvbs_cvpr2015.rar 
 4969  unrar x kvbs_cvpr2015.rar 
 4970  cd DATA/
 4971  matlab -nodesktop -nodispaly
 4972  matlab -nodesktop -nodisplay
 4973  cd ../../
 4974  cd ../Train/
 4975  cd -
 4976  python gen_saliency_SALICON.py -h
 4977  python gen_saliency_SALICON.py --gpu=4 --framebase='/data/sunnycia/SaliencyDataset/Video/GAZECOM/frames' --outputbase='/data/sunnycia/SaliencyDataset/Video/GAZECOM/saliency_map/SALICON' && python gen_saliency_SALICON.py --gpu=4 --framebase='/data/sunnycia/SaliencyDataset/Video/MSU/frames' --outputbase='/data/sunnycia/SaliencyDataset/Video/MSU/saliency_map/SALICON'
 4978  top
 4979  cd ../Train/scripts/metric/
 4980  matlab -nodesktop -nodisplay
 4981  ls /home
 4982  pwd
 4983  ls
 4984  top
 4985  clear
 4986  cd pwd/saliency_on_videoset/Train/scripts/
 4987  git status
 4988  git push -u origin master
 4989  top
 4990  df -h
 4991  su
 4992  cd /data/sunnycia/saliency_on_videoset/Train/C3D-v1.1-kldloss
 4993  make clean
 4994  make -j4 all
 4995  make clean
 4996  make -j4 all
 4997  make -j8 pycaffe
 4998  cd ..
 4999  cd scripts/
 5000  cd prototxt/
 5001  ls
 5002  cd ..
 5003  clear
 5004  cd pwd/saliency_on_videoset/Train/scripts/
 5005  git stauts
 5006  git status
 5007  git add --all
 5008  git commit -m "add calculate process fps function"
 5009  top
 5010  su
 5011  top
 5012  cd ..
 5013  cd ~/pwd/
 5014  ls
 5015  git clone https://github.com/iamaaditya/image-compression-cnn.git
 5016  python
 5017  su
 5018  python
 5019  su
 5020  python
 5021  clear && clear
 5022  su
 5023  clear
 5024  python
 5025  clear
 5026  cd pwd/saliency_on_videoset/Train/scripts/
 5027  claer
 5028  source set_env.sh ../C3D-v1.1-tmp/ 3
 5029  nvidia-smi
 5030  top
 5031  nvidia-smi
 5032  top
 5033  cd pwd/saliency_on_videoset/Train/scripts/
 5034  python utils/dsutil/one2all.py 
 5035  python utils/dsutil/one2all.py --videodirbase='/data/sunnycia/SaliencyDataset/Video/Coutort2/fixation' --alldir='/data/sunnycia/SaliencyDataset/Video/Coutort2/fixation_all'
 5036  python  utils/dsutil/slice_frames.py 
 5037  python  utils/dsutil/slice_frames.py --videobase='/data/sunnycia/SaliencyDataset/Video/Coutort2/videos' --outputbase='/data/sunnycia/SaliencyDataset/Video/Coutort2/frames'
 5038  cd /data/sunnycia/saliency_on_videoset/_Train/OMCNN_2CLSTM
 5039  export CUDA_VISIBLE_DEVICES=4 && python test.py --videodir='/data/sunnycia/SaliencyDataset/Video/Coutort2/videos' --outputdir='/data/sunnycia/SaliencyDataset/Video/Coutort2/saliency_map' --outputtype='image'
 5040  export CUDA_VISIBLE_DEVICES=4 && python test.py --videodir='/data/sunnycia/SaliencyDataset/Video/Coutort2/videos' --outputdir='/data/sunnycia/SaliencyDataset/Video/Coutort2/saliency_map/xu_lstm' --outputtype='image'
 5041  top
 5042  cd /data/sunnycia/saliency_on_videoset/Train/scripts
 5043  clear
 5044  python utils/model_guardian.py 
 5045  source set_env.sh  ../C3D-v1.1 4
 5046  nvidia-smi
 5047  source set_env.sh  ../C3D-v1.1 4
 5048  python utils/model_guardian.py 
 5049  cd /data/sunnycia/saliency_on_videoset/Train/figure/vo-v4-2-resnet-bn-base_lr-0.01--batch-2_1515676931
 5050  python
 5051  cd -
 5052  python utils/model_guardian.py 
 5053  source set_env.sh ../C3D-v1.1 4python utils/model_guardian.py --modeldir='/data/sunnycia/saliency_on_videoset/Train/training_output/salicon/vo-v4-2-resnet-bn-base_lr-0.0001-snapshot-4000--batch-2_1515726293' --modeliter=20000
 5054  source set_env.sh ../C3D-v1.1 4 && python utils/model_guardian.py --modeldir='/data/sunnycia/saliency_on_videoset/Train/training_output/salicon/vo-v4-2-resnet-bn-base_lr-0.0001-snapshot-4000--batch-2_1515726293' --modeliter=20000
 5055  top
 5056  gem
 5057  ruby -v && gem -v && nodejs -v && jekyll -v &&  python --version
 5058  su
 5059  nodejs -v
 5060  nodejs
 5061  su
 5062  cd pwd/saliency_on_videoset/Train/scripts/
 5063  nvidia-smi
 5064  source set_env.sh ../C3D-v1.1 4
 5065  python utils/model_guardian.py --help
 5066  python utils/model_guardian.py --modeldir='/data/sunnycia/saliency_on_videoset/Train/training_output/salicon/vo-v4-2-resnet-fixc2-drop-weight_decay-0.000005-base_lr-0.0001-snapshot-4000-finetunefrom26k-batch-2_1515819089' --modeliter=20000
 5067  clear
 5068  cd /data/sunnycia/sunnycia.github.io/_posts/
 5069  ls
 5070  touch 2018-01-20-how-i-established-this-blog.md
 5071  ls
 5072  cd ..
 5073  ls
 5074  rm -rf *
 5075  git clone https://github.com/sharu725/krishna.git
 5076  cp -R  krishna/* ./ && rm -rf krishna/
 5077  ls
 5078  jekyll server
 5079  git add --all && git commit -m "change to krishna theme" 
 5080  git push -u origin master
 5081  clear
 5082  ls
 5083  git pull
 5084  ls
 5085  cd ..
 5086  rm -rf sunnycia.github.io/
 5087  top
 5088  su
 5089  history
 5090  top
 5091  nvidia-smi
 5092  clear
 5093  top
 5094  nvidia-smi
 5095  su
 5096  ruby -v
 5097  jekyll -v
 5098  matlab -v
 5099  matlab -nodisplay -nodesktop
 5100  python
 5101  su
 5102  go -v
 5103  go
 5104  go help
 5105  go version
 5106  top
 5107  nvidia-smi
 5108  su
 5109  python3
 5110  clear
 5111  nvidia-smi
 5112  cd /data/sunnycia/image_compression_challenge/_Train
 5113  unzip ImageCompression-master.zip 
 5114  cd ImageCompression-master/
 5115  ls
 5116  nvidia-smi
 5117  top
 5118  nvidia-smi
 5119  export CUDA_VISIBLE_DEVICES=2
 5120  python test_imp.py 
 5121  rar -h
 5122  unrar -h
 5123  unrar --help
 5124  unrar -help
 5125  unrar 
 5126  unrar x pycaffe.rar 
 5127  touce set_env.sh
 5128  touch set_env.sh
 5129  vim set_env.sh 
 5130  nvidia-smi
 5131  source set_env.sh 2
 5132  python
 5133  cd /data/sunnycia/saliency_on_videoset/Train/scripts
 5134  source set_env.sh ../C3D-v1.1 2
 5135  python
 5136  cd -
 5137  source set_env.sh 0
 5138  ls
 5139  rm -rf pycaffe*
 5140  git clone https://github.com/taesikna/DPS.git
 5141  cd DPS/
 5142  ls
 5143  cp Makefile.config.example Makefile.config
 5144  vim Makefile.config
 5145  make -j8 all && make -j4 pycaffe
 5146  cd ..
 5147  vim set_env.sh 
 5148  source set_env.sh 2
 5149  python
 5150  source set_env.sh DPS/ 2
 5151  nvidia-smi
 5152  python test_imp.py 
 5153  python
 5154  ls
 5155  rm -rf DPS/
 5156  git clone https://github.com/sonack/my_caffe.git
 5157  unzip my_caffe-master.zip 
 5158  cd my_caffe-master/
 5159  ls
 5160  cp Makefile.config.example Makefile.config
 5161  vim Makefile.config
 5162  make -j8 all && make -j4 pycaffe
 5163  cd ..
 5164  source set_env.sh ./my_caffe-master 2
 5165  python test_imp.py 
 5166  [A
 5167  python test_imp.py 
 5168  ls
 5169  python test_entropy_encoder.py 
 5170  python binary_encoder.py
 5171  python create_lmdb_for_imp_map.py 
 5172  python test_
 5173  python test_imp.py 
 5174  touch read_caffemodel.py
 5175  vim read_caffemodel.py 
 5176  python read_caffemodel.py 
 5177  vim read_caffemodel.py 
 5178  python read_caffemodel.py 
 5179  vim read_caffemodel.py 
 5180  python read_caffemodel.py 
 5181  vim read_caffemodel.py 
 5182  python read_caffemodel.py 
 5183  python test_imp.py 
 5184  python read_caffemodel.py 
 5185  python test_imp.py 
 5186  nvidia-smi
 5187  top
 5188  cd ..
 5189  ls
 5190  cd ..
 5191  ls
 5192  cd _Train/
 5193  ls
 5194  git clone https://github.com/uclouvain/openjpeg.git
 5195  ls
 5196  unzip openjpeg-2.3.0.zip 
 5197  cd openjpeg-2.3.0/
 5198  mkdir build && cd build 
 5199  cmake .. -DCMAKE_BUILD_TYPE=Release && make -j4
 5200  su
 5201  cd ..
 5202  cd /data/sunnycia/image_compression_challenge/dataset
 5203  opj_compress -i KODAK_PNG/kodim22.png -o kodim22.jpeg
 5204  opj_compress -i KODAK_PNG/kodim22.png -o kodim22.j2k
 5205  opj_decompress -i kodim22.j2k kodim.jpeg
 5206  opj_decompress -i kodim22.j2k -o kodim.jpeg
 5207  opj_decompress -i kodim22.j2k -o kodim.png
 5208  libpng
 5209  ssh qiudan@172.31.234.205
 5210  clear
 5211  wget http://193.205.194.113/RAISE/TIFF/r00b3931bt.TIF
 5212  ls
 5213  rm -rf r00b3931bt.TIF 
 5214  ls
 5215  cd RAISE-1k/
 5216  python get_raise.py 
 5217  vim ~/.bashrc
 5218  vim ~/.wgetrc
 5219  source ~/.wgetrc 
 5220  python get_raise.py 
 5221  top
 5222  nvidia-smi
 5223  cd /data/sunnycia/image_compression_challenge/utils
 5224  ls
 5225  git clone https://github.com/Rolinh/VQMT.git
 5226  ls
 5227  cd VQMT/
 5228  ls
 5229  make -j2
 5230  ls
 5231  ls build/
 5232  ls build/bin/
 5233  ls build/bin/Release/
 5234  vqmt
 5235  vim ~/.bashrc
 5236  source ~/.bashrc
 5237  cd /data/sunnycia/image_compression_challenge/dataset/RAISE-1k
 5238  python get_raise.py raise_1k_url-5.txt
 5239  su
 5240  top
 5241  nvidia-smi
 5242  top
 5243  su
 5244  nvidia-smi
 5245  top
 5246  nvidia-smi
 5247  claer
 5248  clear
 5249  top
 5250  nvidia-smi
 5251  ssh sunnycia@172.31.234.250
 5252  clear && clear
 5253  svn
 5254  cd /data/sunnycia/image_compression_challenge/_Train
 5255  svn export https://github.com/tensorflow/models/tree/master/research/compression compression_tfnn
 5256  cd tfnn_compression/image_encoder/
 5257  tar xf compression_residual_gru-2016-08-23.tar.gz 
 5258  python
 5259  python encoder.py --input_image='example.png' --output_codes=output.npz --iteration=2 --model='model/residual_gru.pb' 
 5260  nvidia-smi
 5261  export CUDA_VISIBLE_DEVICES=0
 5262  python encoder.py --input_image='example.png' --output_codes=output.npz --iteration=2 --model='model/residual_gru.pb' 
 5263  python decoder.py --input_codes='output.npz' --output_directory='output' --model='model/residual_gru.pb'
 5264  python encoder.py --input_image='example.png' --output_codes=output.npz --iteration=16 --model='model/residual_gru.pb' 
 5265  python encoder.py --input_image='example.png' --output_codes=output.npz --iteration=15 --model='model/residual_gru.pb' 
 5266  nvidia-smi
 5267  export CUDA_VISIBLE_DEVICES=
 5268  export CUDA_VISIBLE_DEVICES=1
 5269  python encoder.py --input_image='example.png' --output_codes=output.npz --iteration=15 --model='model/residual_gru.pb' 
 5270  python decoder.py --input_codes='output.npz' --output_directory='output' --model='model/residual_gru.pb'
 5271  cd /data/sunnycia/image_compression_challenge/_Train
 5272  unzip KDU7A2_Demo_Apps_for_Centos7-x86-64_170827.zip 
 5273  cd KDU7A2_Demo_Apps_for_Centos7-x86-64_170827/
 5274  vim ~/.bashrc
 5275  source ~/.bashrc
 5276  kdu_compress -h
 5277  kdu_compress
 5278  cd /data/sunnycia/image_compression_challenge/_Train/ImageCompression-master
 5279  ls
 5280  cd ..
 5281  cd /data/sunnycia/image_compression_challenge/dataset
 5282  opj_compress -i kodim22.png -o kodim22.jp2
 5283  opj_decompress  -i kodim22.jp2 -o kodim22-output.png
 5284  opj_compress -i kodim22.png -o kodim22.jp2 -r 20
 5285  ls
 5286  opj_compress -ImgDir KODAK_PNG/ -OutFor JP2 -r 200
 5287  cd ..
 5288  python compress_image.py --input_dir='/data/sunnycia/image_compression_challenge/dataset/KODAK_PNG' --output_dir='/data/sunnycia/image_compression_challenge/compressed_set/KODAK/jpeg2000/compression_ration_200' --ratio=200 --output_dir='' --codec='jpeg2000'
 5289  python compress_image.py --input_dir='/data/sunnycia/image_compression_challenge/dataset/KODAK_PNG' --output_dir='/data/sunnycia/image_compression_challenge/compressed_set/KODAK/jpeg2000/compression_ration_200' --ratio=200 --codec='jpeg2000'
 5290  bash jpeg2000_compress.sh 
 5291  python
 5292  clear
 5293  python
 5294  su
 5295  python -m visdom.server
 5296  cd /data/sunnycia/image_compression_challenge/dataset/RAISE-1k
 5297  python get_raise.py 
 5298  python get_raise.py raise_1k_url-1.txt 
 5299  python
 5300  python -m visdom.server
 5301  df -h
 5302  su
 5303  clear
 5304  top
 5305  nvidia-smi
 5306  clear
 5307  ssh chenzihao@172.31.234.205
 5308  python
 5309  su
 5310  ssh chenzihao@172.31.234.205
 5311  clear
 5312  cd /data/sunnycia/image_compression_challenge
 5313  bash jpeg_compress.sh 
 5314  bash jpeg2000_compress.sh 
 5315  cd /data/sunnycia/image_compression_challenge/utils
 5316  git clone https://github.com/aizvorski/video-quality.git
 5317  cd /data/sunnycia/image_compression_challenge/utils/video-quality/demo
 5318  python jpg_demo.py 
 5319  gm
 5320  ls
 5321  python
 5322  cd ../..
 5323  cd ..
 5324  bash jpeg_compress.sh 
 5325  python image_metric.py --ref_dir='/data/sunnycia/image_compression_challenge/dataset/CLIC_PRO' --cps_dir='/data/sunnycia/image_compression_challenge/compressed_set/CLIC_PRO/jpeg' && python image_metric.py --ref_dir='/data/sunnycia/image_compression_challenge/dataset/CLIC_PRO' --cps_dir='/data/sunnycia/image_compression_challenge/compressed_set/CLIC_PRO/jpeg2000'
 5326  python image_metric.py --ref_dir='/data/sunnycia/image_compression_challenge/dataset/CLIC_PRO' --cps_dir='/data/sunnycia/image_compression_challenge/compressed_set/CLIC_PRO/jpeg'
 5327  top
 5328  cd /data/sunnycia/image_compression_challenge
 5329  bash jpeg2000_compress.sh 
 5330  top
 5331  top
 5332  clear
 5333  ssh qiudan@172.31.234.205
 5334  cd pwd/saliency_on_videoset/Train/scripts/
 5335  git status
 5336  git add --all
 5337  git commit -m "Add bn after deconvolution 3d"
 5338  git push -u origin master
 5339  history > history
 5340  source set_env.sh ../C3D-v1.1 6
 5341  nvidia-smi
 5342  .prototxt' --use_model='../pretrained_model/c3d_resnet18_sports1m_r2_iter_2800000.caffemodel' --trainingbase='ledov' --batch=2 --trainingexampleprops=0.99 --savemodeliter=4000 --validiter=4000 --plotiter=200
 5343  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-resnet-bn.prototxt' --use_model='../pretrained_model/c3d_resnet18_sports1m_r2_iter_2800000.caffemodel' --trainingbase='ledov' --batch=2 --trainingexampleprops=0.99 --savemodeliter=4000 --validiter=4000 --plotiter=200
 5344  python utils/scavenger.py 
 5345  python utils/scavenger.py --snapshot=1
 5346  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-resnet-bn.prototxt' --use_model='../pretrained_model/c3d_resnet18_sports1m_r2_iter_2800000.caffemodel' --trainingbase='ledov' --batch=2 --trainingexampleprops=0.99 --savemodeliter=4000 --validiter=4000 --plotiter=200
 5347  python utils/scavenger.py --snapshot=1
 5348  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-resnet-bn.prototxt' --use_model='../pretrained_model/c3d_resnet18_sports1m_r2_iter_2800000.caffemodel' --trainingbase='ledov' --batch=2 --trainingexampleprops=0.99 --savemodeliter=4000 --validiter=4000 --plotiter=200
 5349  python utils/scavenger.py 
 5350  python utils/scavenger.py --snapshot=1
 5351  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-resnet-bn.prototxt' --use_model='../pretrained_model/c3d_resnet18_sports1m_r2_iter_2800000.caffemodel' --trainingbase='ledov' --batch=2 --trainingexampleprops=0.99 --savemodeliter=4000 --validiter=4000 --plotiter=200
 5352  python utils/scavenger.py 
 5353  python utils/scavenger.py --snapshot=1
 5354  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-resnet-bn.prototxt' --use_model='../pretrained_model/c3d_resnet18_sports1m_r2_iter_2800000.caffemodel' --trainingbase='ledov' --batch=2 --trainingexampleprops=0.99 --savemodeliter=4000 --validiter=4000 --plotiter=200
 5355  python utils/scavenger.py --snapshot=1
 5356  python utils/scavenger.py 
 5357  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-resnet-bn.prototxt' --use_model='../pretrained_model/c3d_resnet18_sports1m_r2_iter_2800000.caffemodel' --trainingbase='ledov' --batch=2 --trainingexampleprops=0.99 --savemodeliter=4000 --validiter=4000 --plotiter=200
 5358  python utils/scavenger.py 
 5359  python utils/scavenger.py --snapshot=1
 5360  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-resnet-bn.prototxt' --use_model='../pretrained_model/c3d_resnet18_sports1m_r2_iter_2800000.caffemodel' --trainingbase='ledov' --batch=2 --trainingexampleprops=0.99 --savemodeliter=4000 --validiter=4000 --plotiter=200
 5361  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-resnet-catfeat-bnorm.prototxt' --use_model='../pretrained_model/c3d_resnet18_sports1m_r2_iter_2800000.caffemodel' --trainingbase='ledov' --batch=2 --trainingexampleprops=0.99 --savemodeliter=4000 --validiter=4000 --plotiter=200
 5362  clear && clear
 5363  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-resnet-catfeat-bnorm.prototxt' --use_model='../pretrained_model/c3d_resnet18_sports1m_r2_iter_2800000.caffemodel' --trainingbase='ledov' --batch=2 --trainingexampleprops=0.99 --savemodeliter=4000 --validiter=4000 --plotiter=200
 5364  top
 5365  nvidia-smi
 5366  cd pwd/saliency_on_videoset/Train/scripts/
 5367  source set_env.sh ../C3D-v1.1
 5368  python test_video.py 
 5369  source set_env.sh ../C3D-v1.1 5
 5370  python test_video.py --output_type='image' --test_base='coutort2' --model_code='v4-2' --videolength=16 --video_deploy_path='prototxt/vo-v4-2-resnet.prototxt' --video_model_path='../training_output/salicon/vo-v4-2-resnet-dropout-snapshot-2000-display-1-dropout_fulldens-batch-2_1514857787/snapshot-_iter_26000.caffemodel' --infertype='slide' --inferoverlap=15 
 5371  python utils/dsutil/gen_density.py 
 5372  python utils/dsutil/gen_density.py --fixationtype='image' --sigma=32 --fixation_base='/data/sunnycia/SaliencyDataset/Video/Coutort2/fixation' --density_base='/data/sunnycia/SaliencyDataset/Video/Coutort2/density'
 5373  cd metric/
 5374  matlab -nodesktop -nodisplay
 5375  cd /data/sunnycia/saliency_on_videoset/_Model
 5376  python gen_saliency_SALICON.py --gpu=3
 5377  python gen_saliency_SALICON.py --gpu=3 --framebase='/data/sunnycia/SaliencyDataset/Video/DIEM/frames' --outputbase='/data/sunnycia/SaliencyDataset/Video/DIEM/saliency_map/SALICON'
 5378  cd /data/sunnycia/SaliencyDataset/Video/DIEM
 5379  python frames_rename.py 
 5380  clear
 5381  cd -
 5382  python gen_saliency_SALICON.py --gpu=3 --framebase='/data/sunnycia/SaliencyDataset/Video/DIEM/frames' --outputbase='/data/sunnycia/SaliencyDataset/Video/DIEM/saliency_map/SALICON'
 5383  python gen_saliency_SALICON.py --gpu=4 --framebase='/data/sunnycia/SaliencyDataset/Video/DIEM/frames' --outputbase='/data/sunnycia/SaliencyDataset/Video/DIEM/saliency_map/SALICON'
 5384  python gen_saliency_SALICON.py --gpu=3 --framebase='/data/sunnycia/SaliencyDataset/Video/DIEM/frames' --outputbase='/data/sunnycia/SaliencyDataset/Video/DIEM/saliency_map/SALICON'
 5385  cd ../Train/scripts/metric/
 5386  clear && clear
 5387  matlab -nodesktop -nodisplay
 5388  clear && clear
 5389  cd ..
 5390  python training_video_voxel_based.py -h
 5391  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-resnet-dropout-kldloss.prototxt' --use_model='../pretrained_model/c3d_resnet18_sports1m_r2_iter_2800000.caffemodel' --plotiter=200 --validiter=4000 --savemodeliter=4000 --trainingexampleprops=0.99 --trainingbase='ledov' --videolength=16 --batch=2
 5392  source set_env.sh ../C3D-v1.1-kldloss/ 4
 5393  nvidia-smi
 5394  source set_env.sh ../C3D-v1.1-kldloss/ 5
 5395  clear && clear
 5396  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-resnet-dropout-kldloss.prototxt' --use_model='../pretrained_model/c3d_resnet18_sports1m_r2_iter_2800000.caffemodel' --plotiter=200 --validiter=4000 --savemodeliter=4000 --trainingexampleprops=0.99 --trainingbase='ledov' --videolength=16 --batch=2
 5397  python utils/scavenger.py 
 5398  python utils/scavenger.py --snapshot
 5399  python utils/scavenger.py --snapshot=1
 5400  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-resnet-dropout-kldloss.prototxt' --use_model='../pretrained_model/c3d_resnet18_sports1m_r2_iter_2800000.caffemodel' --plotiter=200 --validiter=4000 --savemodeliter=4000 --trainingexampleprops=0.99 --trainingbase='ledov' --videolength=16 --batch=2
 5401  python utils/scavenger.py 
 5402  python utils/scavenger.py --snapshot=1
 5403  clear && clear
 5404  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-resnet-dropout-kldloss.prototxt' --use_model='../pretrained_model/c3d_resnet18_sports1m_r2_iter_2800000.caffemodel' --plotiter=200 --validiter=4000 --savemodeliter=4000 --trainingexampleprops=0.99 --trainingbase='ledov' --videolength=16 --batch=2
 5405  clear && clear
 5406  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-resnet-dropout-kldloss.prototxt' --use_model='../pretrained_model/c3d_resnet18_sports1m_r2_iter_2800000.caffemodel' --plotiter=200 --validiter=4000 --savemodeliter=4000 --trainingexampleprops=0.99 --trainingbase='ledov' --videolength=16 --batch=2
 5407  nvidia-smi
 5408  source set_env.sh ../C3D-v1.1-tmp/ 3
 5409  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-resnet-catfeat-highlr.prototxt' --use_model='../pretrained_model/c3d_resnet18_sports1m_r2_iter_2800000.caffemodel' --plotiter=200 --validiter=4000 --savemodeliter=4000 --trainingexampleprops=0.99 --trainingbase='ledov' --videolength=16 --batch=2
 5410  clear && clear
 5411  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-resnet-catfeat-dropout.prototxt' --use_model='../pretrained_model/c3d_resnet18_sports1m_r2_iter_2800000.caffemodel' --plotiter=200 --validiter=4000 --savemodeliter=4000 --trainingexampleprops=0.99 --trainingbase='ledov' --videolength=16 --batch=2
 5412  cd pwd/saliency_on_videoset/Train/scripts/
 5413  cd metric/
 5414  matlab -nodesktop -nodisplay
 5415  top
 5416  cd ..
 5417  source set_env.sh ../C3D-v1.1 7
 5418  nvidia-smi
 5419  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-resnet-dropout.prototxt' --use_snapshot='/data/sunnycia/saliency_on_videoset/Train/training_output/salicon/vo-v4-2-resnet-dropout-weight_decay-0.000005-base_lr-0.0001-snapshot-4000-display-1--batch-2_1515247477/snapshot-_iter_272000.solverstate' --trainingbase='ledov' --batch=2 --trainingexampleprops=0.99 --savemodeliter=4000 --validiter=4000 --plotiter=200
 5420  top
 5421  nvidia-smi
 5422  top
 5423  nvidia-smi
 5424  watch -h
 5425  watch -n 1 nvidia-smi
 5426  to
 5427  top
 5428  nvidia-smi
 5429  su
 5430  ssh qiudan@172.31.234.205
 5431  su
 5432  cd /data/zhangpp/
 5433  ls
 5434  cd ..
 5435  ls /data
 5436  cd data/
 5437  ls -l
 5438  chmod 755 *
 5439  su
 5440  clear
 5441  df -h
 5442  clear
 5443  cd sunnycia/saliency_on_videoset/Train/scripts/
 5444  python calc_fps.py 
 5445  top
 5446  clear
 5447  su
 5448  clear
 5449  pwd
 5450  top
 5451  su
 5452  clear
 5453  gym
 5454  python
 5455  cd metric/
 5456  matlab -nodesktop -nodisplay
 5457  matlab 
 5458  cd /data/sunnycia/SaliencyDataset/Video/VideoSet/ImageSet/Seperate/density_fc
 5459  python rename.py 
 5460  cd -
 5461  matlab -nodesktop -nodisplay
 5462  cd -
 5463  matlab 
 5464  matlab -nodesktop -nodisplay
 5465  clear && clear
 5466  matlab -nodesktop -nodisplay
 5467  clear && clear
 5468  cd ..
 5469  python utils/model_guardian.py -h
 5470  source set_env.sh ../C3D-v1.1-kldloss/ 4
 5471  python utils/model_guardian.py --modeliter=20000 --modeldir='/data/sunnycia/saliency_on_videoset/Train/training_output/salicon/vo-v4-2-resnet-dropout-kldloss-snapshot-4000--batch-2_1516181888'
 5472  clear && clear
 5473  source set_env.sh ../C3D-v1.1 3
 5474  nvidia-smi
 5475  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-resnet-catfeat.prototxt' --use_model='../pretrained_model/c3d_resnet18_sports1m_r2_iter_2800000.caffemodel' --plotiter=200 --validiter=4000 --savemodeliter=4000 --trainingexampleprops=0.99 --trainingbase='ledov' --videolength=16 --batch=2
 5476  cd ../../
 5477  cd Train/
 5478  cp C3D-v1.1 C3D-v1.1-tmp
 5479  cp -R C3D-v1.1 C3D-v1.1-tmp
 5480  cd C3D-v1.1-tmp/
 5481  make clean
 5482  make all && make -j2 pycaffe
 5483  cd scripts/
 5484  pwd
 5485  cd ../../scripts/
 5486  source set_env.sh ../C3D-v1.1-tmp/ 4
 5487  clear clear
 5488  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-resnet-catfeat.prototxt' --use_model='../pretrained_model/c3d_resnet18_sports1m_r2_iter_2800000.caffemodel' --plotiter=200 --validiter=4000 --savemodeliter=4000 --trainingexampleprops=0.99 --trainingbase='ledov' --videolength=16 --batch=2
 5489  clear && clear
 5490  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-resnet-catfeat.prototxt' --use_model='../pretrained_model/c3d_resnet18_sports1m_r2_iter_2800000.caffemodel' --plotiter=200 --validiter=4000 --savemodeliter=4000 --trainingexampleprops=0.99 --trainingbase='ledov' --videolength=16 --batch=2
 5491  top
 5492  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-resnet-catfeat.prototxt' --use_model='../pretrained_model/c3d_resnet18_sports1m_r2_iter_2800000.caffemodel' --plotiter=200 --validiter=4000 --savemodeliter=4000 --trainingexampleprops=0.99 --trainingbase='ledov' --videolength=16 --batch=2
 5493  top
 5494  cd pwd/saliency_on_videoset/Train/scripts/
 5495  ls
 5496  python training_video_voxel_based.py 
 5497  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-resnet-fixc2-drop.prototxt' 
 5498  python training_video_voxel_based.py 
 5499  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-resnet-fixc2-drop.prototxt' --use_model='/data/sunnycia/saliency_on_videoset/Train/training_output/salicon/vo-v4-2-resnet-dropout-snapshot-2000-display-1-dropout_fulldens-batch-2_1514857787/snapshot-_iter_26000.caffemodel' --plotiter=200 --validiter=4000 --savemodeliter=4000 --trainingexampleprops=0.99 --trainingbase='ledov' --videolength=16 --overlap=15 --extramodinfo='finetunefrom26k'
 5500  source set_env.sh ../C3D-v1.1 5
 5501  nvidia-smi
 5502  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-resnet-fixc2-drop.prototxt' --use_model='/data/sunnycia/saliency_on_videoset/Train/training_output/salicon/vo-v4-2-resnet-dropout-snapshot-2000-display-1-dropout_fulldens-batch-2_1514857787/snapshot-_iter_26000.caffemodel' --plotiter=200 --validiter=4000 --savemodeliter=4000 --trainingexampleprops=0.99 --trainingbase='ledov' --videolength=16 --overlap=15 --extramodinfo='finetunefrom26k'
 5503  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-resnet-fixc2-drop.prototxt' --use_model='/data/sunnycia/saliency_on_videoset/Train/training_output/salicon/vo-v4-2-resnet-dropout-snapshot-2000-display-1-dropout_fulldens-batch-2_1514857787/snapshot-_iter_26000.caffemodel' --plotiter=200 --validiter=4000 --savemodeliter=4000 --trainingexampleprops=0.99 --trainingbase='ledov' --videolength=16 --overlap=15 --extramodinfo='finetunefrom26k' --batch=2
 5504  nvidia-smi
 5505  top
 5506  cd /data/sunnycia/
 5507  ls
 5508  cd image_compression_challenge/
 5509  clear
 5510  top
 5511  nvidia-smi
 5512  clear
 5513  python plot_scatter.py -h
 5514  python plot_scatter.py --dataset='KODAK' --ref_image_dir='/data/sunnycia/image_compression_challenge/dataset/KODAK'
 5515  python plot_scatter.py --dataset='KODAK' --ref_image_dir='/data/sunnycia/image_compression_challenge/dataset/KODAK' 
 5516  cd utils/
 5517  python a_little_test.py 
 5518  top
 5519  nvidia-smi
 5520  cd .
 5521  cd ..
 5522  python plot_scatter.py --dataset='KODAK' --ref_image_dir='/data/sunnycia/image_compression_challenge/dataset/KODAK'
 5523  cd /data/sunnycia/image_compression_challenge/utils/yuvtools
 5524  matlab -nodesktop
 5525  firefox
 5526  top
 5527  cd /data/sunnycia/image_compression_challenge/
 5528  python image_metric.py --ref_dir='/data/sunnycia/image_compression_challenge/dataset/CLIC_MOB' --cps_dir='/data/sunnycia/image_compression_challenge/compressed_set/CLIC_MOB/jpeg' 
 5529  VQMT
 5530  cd utils/
 5531  ls
 5532  cd VQMT/
 5533  ls
 5534  cd build/
 5535  ls
 5536  cd bin/
 5537  ls
 5538  cd Release/
 5539  ls
 5540  vqmt
 5541  vqmt -v
 5542  vqmt -h
 5543  vqmt --help
 5544  clear
 5545  pwd
 5546  vim ~/.bashrc
 5547  cd ../../..
 5548  cd ..
 5549  vqmt
 5550  bash webp_compress.sh KODAK
 5551  python image_metric.py -h
 5552  python image_metric.py --ref_dir='/data/sunnycia/image_compression_challenge/dataset/KODAK' --cps_dir='/data/sunnycia/image_compression_challenge/compressed_set/KODAK/jpeg' --color_space='YVU'
 5553  python plot_scatter.py --dataset='KODAK' --ref_image_dir='/data/sunnycia/image_compression_challenge/dataset/KODAK' --metric_dir='./' --metric_name='YUV-psnr' --metric_index=11 --debug=True
 5554  python plot_scatter.py --dataset='KODAK' --ref_image_dir='/data/sunnycia/image_compression_challenge/dataset/KODAK' --metric_dir='./' --metric_name='YUV-psnr' --metric_index=11
 5555  python plot_scatter.py --dataset='KODAK' --ref_image_dir='/data/sunnycia/image_compression_challenge/dataset/KODAK' --metric_dir='./' --metric_name='YUV-ssim' --metric_index=15 
 5556  vim /usr/local/gpu_stuff
 5557  clear
 5558  cd /data/sunnycia/image_compression_challenge
 5559  clear
 5560  vim plotly_demo.py 
 5561  python plotly_demo.py 
 5562  ls ~/.ssh
 5563   python image_metric.py --ref_dir='/data/sunnycia/image_compression_challenge/dataset/CLIC_MOB' --cps_dir='/data/sunnycia/image_compression_challenge/compressed_set/CLIC_MOB/webp'
 5564  bash jpeg2000_compress.sh KODAK
 5565  python image_metric.py -h
 5566  python image_metric.py --ref_dir='/data/sunnycia/image_compression_challenge/dataset/KODAK' --cps_dir='/data/sunnycia/image_compression_challenge/compressed_set/KODAK/jpeg2000'
 5567  vqmd
 5568  vqmt
 5569  vqmt /data/sunnycia/image_compression_challenge/compressed_set/KODAK_YUV/jpeg/kodim24_quality_100_768_512_444.yuv /data/sunnycia/image_compression_challenge/dataset/KODAK_YUV/kodim24_768_512_444.yuv 512 768 1 1 results PSNR SSIM MSSIM VIFP
 5570  vqmt /data/sunnycia/image_compression_challenge/compressed_set/KODAK_YUV/jpeg/kodim24_quality_10_768_512_444.yuv /data/sunnycia/image_compression_challenge/dataset/KODAK_YUV/kodim24_768_512_444.yuv 512 768 1 1 results PSNR SSIM MSSIM VIFP
 5571  vqmt /data/sunnycia/image_compression_challenge/compressed_set/KODAK_YUV/jpeg/kodim24_quality_10_768_512_444.yuv /data/sunnycia/image_compression_challenge/dataset/KODAK_YUV/kodim24_768_512_444.yuv 512 768 1 1 results PSNR SSIM MSSIM VIFP PSNRHVS PSNRHVSM
 5572  cd /data/sunnycia/image_compression_challenge/_Train/HM-16.9/bin
 5573  ls
 5574  TAppEncoderStatic
 5575  ./TAppEncoderStatic
 5576  ./TAppEncoderStatic -i /data/sunnycia/image_compression_challenge/dataset/KODAK/kodim24.png -o ./kodim24.png -b kodim24.scc --InputChromaFormat=444 --ConformanceWindowMode=1 -wdt= 768 -hgt 512 -fr 1 -f 1 -q 47 -InputColourSpaceConvert=RGBtoGBR >> kodim24_result.txt
 5577  ./TAppEncoderStatic -i /data/sunnycia/image_compression_challenge/dataset/KODAK/kodim24.png -o ./kodim24.png -b kodim24.scc --InputChromaFormat=444 --ConformanceWindowMode=1 -wdt 768 -hgt 512 -fr 1 -f 1 -q 47 -InputColourSpaceConvert=RGBtoGBR >> kodim24_result.txt
 5578  ./TAppEncoderStatic -i /data/sunnycia/image_compression_challenge/dataset/KODAK/kodim24.png -o ./kodim24.png -b kodim24.scc --InputChromaFormat=444 --ConformanceWindowMode=1 -wdt 768 -hgt 512 -fr 1 -f 1 -q 47 -InputColourSpaceConvert RGBtoGBR >> kodim24_result.txt
 5579  ./TAppEncoderStatic -i /data/sunnycia/image_compression_challenge/dataset/KODAK/kodim24.png -o ./kodim24.png -b kodim24.scc --InputChromaFormat=444 --ConformanceWindowMode=1 -wdt 768 -hgt 512 -fr 1 -f 1 -q 47 --InputColourSpaceConvert RGBtoGBR >> kodim24_result.txt
 5580  ./TAppEncoderStatic -c ../cfg/per-sequence/WordEditing_RGB.cfg -i /data/sunnycia/image_compression_challenge/dataset/KODAK/kodim24.png -o ./kodim24.png -b kodim24.scc --InputChromaFormat=444 --ConformanceWindowMode=1 -wdt 768 -hgt 512 -fr 1 -f 1 -q 47 --InputColourSpaceConvert RGBtoGBR >> kodim24_result.txt
 5581  ./TAppEncoderStatic -c ../cfg/per-sequence/WordEditing_RGB.cfg -i /data/sunnycia/image_compression_challenge/dataset/KODAK/kodim24.png -o ./kodim24.png -b kodim24.scc --InputColourSpaceConvert=RGBtoGBR --InputChromaFormat=444 --ConformanceWindowMode=1 -wdt 768 -hgt 512 -fr 1 -f 1 -q 47 >> kodim24_result.txt
 5582  ./TAppEncoderStatic -c ../cfg/encoder_intra_main_rext.cfg -i /data/sunnycia/image_compression_challenge/dataset/KODAK/kodim24.png -o ./kodim24.png -b kodim24.scc --InputColourSpaceConvert=RGBtoGBR --InputChromaFormat=444 --ConformanceWindowMode=1 -wdt 768 -hgt 512 -fr 1 -f 1 -q 47 >> result.txt
 5583  ./TAppEncoderStatic -c ../cfg/encoder_intra_main.cfg -i /data/sunnycia/image_compression_challenge/dataset/KODAK/kodim24.png -o ./kodim24.png -b kodim24.scc --InputColourSpaceConvert=RGBtoGBR --InputChromaFormat=444 --ConformanceWindowMode=1 -wdt 768 -hgt 512 -fr 1 -f 1 -q 47 >> result.txt
 5584  ./TAppEncoderStatic -c ../cfg/encoder_intra_main.cfg -i /data/sunnycia/image_compression_challenge/dataset/KODAK/kodim24.png -o ./kodim24.png -b kodim24.scc --InputColourSpaceConvert=RGBtoGBR --InputChromaFormat=444 --ConformanceWindowMode=1 -wdt 768 -hgt 512 -fr 30 -f 1 -q 47 >> result.txt
 5585  ./TAppEncoderStatic -c ../cfg/encoder_lowdelay_main_rext.cfg -i /data/sunnycia/image_compression_challenge/dataset/KODAK/kodim24.png -o ./kodim24.png -b kodim24.scc --InputColourSpaceConvert=RGBtoGBR --InputChromaFormat=444 --ConformanceWindowMode=1 -wdt 768 -hgt 512 -fr 1 -f 1 -q 47 >> result.txt
 5586  ./TAppEncoderStatic -c ../cfg/encoder_lowdelay_main_rext.cfg -i /data/sunnycia/image_compression_challenge/dataset/KODAK/kodim24.png -o ./kodim24.png -b kodim24.scc --InputColourSpaceConvert=RGBtoGBR --InputChromaFormat=444 --ConformanceWindowMode=1 -SourceWidth=768 -SourceHeight=512 -fr 1 -f 1 -q 47 >> result.txt
 5587  ./TAppEncoderStatic -c ../cfg/encoder_lowdelay_main_rext.cfg -i /data/sunnycia/image_compression_challenge/dataset/KODAK/kodim24.png -o ./kodim24.png -b kodim24.scc --InputColourSpaceConvert=RGBtoGBR --InputChromaFormat=444 --ConformanceWindowMode=1 --SourceWidth=768 --SourceHeight=512 -fr 1 -f 1 -q 47 >> result.txt
 5588  python
 5589  cd /data/sunnycia/image_compression_challenge
 5590  pwd
 5591  python image_metric.py -h
 5592  python image_metric.py --ref_dir='/data/sunnycia/image_compression_challenge/dataset/KODAK' --cps_dir='/data/sunnycia/image_compression_challenge/compressed_set/KODAK/jpeg' --color_space='YUV'
 5593  python image_metric.py --ref_dir='/data/sunnycia/image_compression_challenge/dataset/KODAK' --cps_dir='/data/sunnycia/image_compression_challenge/compressed_set/KODAK/jpeg' --color_space='YVU'
 5594  python image_metric.py --ref_dir='/data/sunnycia/image_compression_challenge/dataset/KODAK' --cps_dir='/data/sunnycia/image_compression_challenge/compressed_set/KODAK/jpeg2000' --color_space='YVU'
 5595  python image_metric.py --ref_dir='/data/sunnycia/image_compression_challenge/dataset/KODAK' --cps_dir='/data/sunnycia/image_compression_challenge/compressed_set/KODAK/webp' --color_space='YVU'
 5596  python image_metric.py --ref_dir='/data/sunnycia/image_compression_challenge/dataset/KODAK' --cps_dir='/data/sunnycia/image_compression_challenge/compressed_set/KODAK/webp' --color_space='YVU' && python image_metric.py --ref_dir='/data/sunnycia/image_compression_challenge/dataset/KODAK' --cps_dir='/data/sunnycia/image_compression_challenge/compressed_set/KODAK/jpeg' --color_space='YVU'&& python image_metric.py --ref_dir='/data/sunnycia/image_compression_challenge/dataset/KODAK' --cps_dir='/data/sunnycia/image_compression_challenge/compressed_set/KODAK/jpeg2000' --color_space='YVU'
 5597  bash jpeg2000_compress.sh KODAK
 5598  python image_metric.py --ref_dir='/data/sunnycia/image_compression_challenge/dataset/KODAK' --cps_dir='/data/sunnycia/image_compression_challenge/compressed_set/KODAK/jpeg2000' --color_space='YVU'
 5599  cd /data/sunnycia/image_compression_challenge/compressed_set/KODAK/jpeg2000
 5600  python
 5601  ls
 5602  cd /data/sunnycia/image_compression_challenge/dataset
 5603  convert kodim22-ori.png -quality 50 jp2.jp2
 5604  python
 5605  cd ..
 5606  bash jpeg_compress.sh KODAK
 5607  bash jpeg2000_compress.sh KODAK
 5608  python image_metric.py --ref_dir='/data/sunnycia/image_compression_challenge/dataset/KODAK' --cps_dir='/data/sunnycia/image_compression_challenge/compressed_set/KODAK/jpeg2000' --color_space='YVU' && python image_metric.py --ref_dir='/data/sunnycia/image_compression_challenge/dataset/KODAK' --cps_dir='/data/sunnycia/image_compression_challenge/compressed_set/KODAK/webp' --color_space='YVU'
 5609  bash hevc-jem_compress.sh /data/sunnycia/image_compression_challenge/dataset/KODAK_YUV /data/sunnycia/image_compression_challenge/compressed_set/KODAK/hevc /data/sunnycia/image_compression_challenge/compressed_set/KODAK/hevc_result
 5610  clear
 5611  bash hevc_compress.sh /data/sunnycia/image_compression_challenge/dataset/KODAK_YUV /data/sunnycia/image_compression_challenge/compressed_set/KODAK/hevc /data/sunnycia/image_compression_challenge/compressed_set/KODAK/hevc_result
 5612  bash hevc_compress.sh /data/sunnycia/image_compression_challenge/dataset/KODAK_YUV /data/sunnycia/image_compression_challenge/compressed_set/KODAK/hevc /data/sunnycia/image_compression_challenge/compressed_set/KODAK/hevc_recon /data/sunnycia/image_compression_challenge/compressed_set/KODAK/hevc_result
 5613  python image_metric.py -h
 5614  python image_metric.py --ref_dir='/data/sunnycia/image_compression_challenge/dataset/KODAK' --cps_dir=' ' --color_space='YVU' --codec='hevc' 
 5615  python image_metric.py --ref_dir='/data/sunnycia/image_compression_challenge/dataset/KODAK' --cps_dir=' ' --color_space='YVU' --codec='hevc' --hevc_result_dir='/data/sunnycia/image_compression_challenge/compressed_set/KODAK/hevc_result'
 5616  python plot_scatter.py -h
 5617  python plot_scatter.py --dataset='KODAK' --ref_image_dir='/data/sunnycia/image_compression_challenge/dataset/KODAK' --metric_dir='./' --metric_name='psnr'
 5618  python plot_scatter.py --dataset='KODAK' --ref_image_dir='/data/sunnycia/image_compression_challenge/dataset/KODAK' --metric_dir='./' --metric_name='Y-psnr' --metric_index=5
 5619  python plot_scatter.py --dataset='KODAK' --ref_image_dir='/data/sunnycia/image_compression_challenge/dataset/KODAK' --metric_dir='./' --metric_name='Y-psnr' --metric_index=5 --debug=False
 5620  python plot_scatter.py --dataset='KODAK' --ref_image_dir='/data/sunnycia/image_compression_challenge/dataset/KODAK' --metric_dir='./' --metric_name='Y-psnr' --metric_index=5
 5621  python plot_scatter.py --dataset='KODAK' --ref_image_dir='/data/sunnycia/image_compression_challenge/dataset/KODAK' --metric_dir='./' --metric_name='YUV-psnr' --metric_index=11 --debug=True
 5622  bash hevc-jem_compress.sh /data/sunnycia/image_compression_challenge/dataset/KODAK_YUV /data/sunnycia/image_compression_challenge/compressed_set/KODAK/jem_hevc /data/sunnycia/image_compression_challenge/compressed_set/KODAK/jem_hevc_recon /data/sunnycia/image_compression_challenge/compressed_set/KODAK/jem_hevc_result
 5623  python image_metric.py -h
 5624  python image_metric.py --ref_dir='/data/sunnycia/image_compression_challenge/dataset/KODAK' --cps_dir=' ' --color_space='YVU' --codec='jem_hevc' --hevc_result_dir='/data/sunnycia/image_compression_challenge/compressed_set/KODAK/jem_hevc_result'
 5625  python image_metric.py --ref_dir='/data/sunnycia/image_compression_challenge/dataset/KODAK' --cps_dir=' ' --color_space='YVU' --codec='hevc-jem' --hevc_result_dir='/data/sunnycia/image_compression_challenge/compressed_set/KODAK/jem_hevc_result'
 5626  python plot_scatter.py --dataset='KODAK' --ref_image_dir='/data/sunnycia/image_compression_challenge/dataset/KODAK' --metric_dir='./' --metric_name='YUV-psnr' --metric_index=11 --debug=True
 5627  python plot_scatter.py --dataset='KODAK' --ref_image_dir='/data/sunnycia/image_compression_challenge/dataset/KODAK' --metric_dir='./metric_data' --metric_name='Y-psnr' --metric_index=8 --debug=True --output_dir='./metric_data/KODAK-YPSNR'
 5628  bc
 5629  python -m visdom.server
 5630  clear
 5631  cd pwd/saliency_on_videoset/
 5632  cd ..
 5633  ls
 5634  cd /data/sunnycia/
 5635  ls
 5636  cd image_compression_challenge/
 5637  ls
 5638  python image_metric.py -h
 5639  python image_metric.py --ref_dir='/data/sunnycia/image_compression_challenge/dataset/CLIC_MOB' --cps_dir='/data/sunnycia/image_compression_challenge/compressed_set/CLIC_MOB/jpeg2000' 
 5640  ssh qiudan@172.31.234.248
 5641  clear
 5642  cd /data/sunnycia/image_compression_challenge/
 5643  bash hevc_compress.sh /data/sunnycia/image_compression_challenge/dataset/CLIC_MOB_YUV /data/sunnycia/image_compression_challenge/compress_set/CLIC_MOB_YUV
 5644  cd /data/sunnycia/image_compression_challenge/dataset
 5645  cd ..
 5646  bash jpeg2000_compress.sh 
 5647  bash jpeg2000_compress.sh CLIP_PRO && bash jpeg2000_compress.sh CLIP_MOB
 5648  clear && clear
 5649  bash jpeg2000_compress.sh CLIC_PRO && bash jpeg2000_compress.sh CLIC_MOB
 5650  bash hevc_compress.sh /data/sunnycia/image_compression_challenge/dataset/CLIC_PRO_YUV /data/sunnycia/image_compression_challenge/compress_set/CLIC_PRO_YUV
 5651  vqmt
 5652  vqmt -h
 5653  vqmt --help
 5654  cd /data/sunnycia/image_compression_challenge/dataset
 5655  vqmt kodim22-ori.png kodim22.png 512 768 
 5656  vqmt kodim22-ori.png kodim22.png 512 768 1 1 results PSNR SSIM
 5657  vqmt kodim22-ori.png kodim22-ori.png 512 768 1 1 results PSNR SSIM
 5658  matlab -nodesktop -nodisplay
 5659  jpeg
 5660  ffempg
 5661  ffmpeg
 5662  ls
 5663  pwd
 5664  cd ..
 5665  man ffmpeg >ffmpeg.txt
 5666  ls
 5667  cd dataset/
 5668  ls
 5669  ffmpeg -i kodim-ori.png -compression_level=50 -o jpeg.jpeg
 5670  ffmpeg -i kodim-ori.png --compression_level=50 -o jpeg.jpeg
 5671  ffmpeg -i kodim-ori.png -o jpeg.jpeg
 5672  ffmpeg -i kodim-ori.png jpeg.jpeg
 5673  ls
 5674  ffmpeg -i kodim22-ori.png jpeg.jpeg
 5675  ffmpeg -i kodim22-ori.png jpeg.jpeg -compression_level=100
 5676  ffmpeg -i kodim22-ori.png jpeg.jpeg compression_level=100
 5677  ffmpeg -i kodim22-ori.png jpeg.jpeg compression_level=50
 5678  su
 5679  clear
 5680  cd /data/sunnycia/image_compression_challenge/_Train
 5681  python jpeg_compression.py 
 5682  su
 5683  clear
 5684  python jpeg_compression.py --input_dir='../dataset/KODAK_PNG/' --output_dir='./output' --quality=50
 5685  python jpeg_compression.py --input_dir='../dataset/KODAK_PNG/' --output_dir='./output' --quality=1
 5686  gimp
 5687  help screen
 5688  screen -h
 5689  python jpeg_compression.py --input_dir='../dataset/KODAK_PNG/' --output_dir='./output' --quality=1
 5690  python img_compression_benchmark.py --input_dir='../dataset/KODAK_PNG/' --output_dir='./output' --quality=1
 5691  python img_compression_benchmark.py --input_dir='../dataset/KODAK_PNG/' --output_dir='./output' --quality=1 --codec='jpeg'
 5692  python img_compression_benchmark.py --input_dir='../dataset/KODAK_PNG/' --output_dir='./output' --quality=100 --codec='jpeg'
 5693  touch kodak.sh
 5694  vim kodak.sh 
 5695  bash kodak.sh 
 5696  ls -la
 5697  cd ..dataset/
 5698  ls
 5699  cd ..
 5700  rm -rf ..dataset/
 5701  bash kodak.sh 
 5702  bash kodak.sh jpeg
 5703  bash kodak.sh webp
 5704  bash kodak.sh jpeg
 5705  bash kodak.sh webp
 5706  cd ..
 5707  matlab -nodesktop -nodisplay
 5708  matlab -nodesktop
 5709  bash compress.sh jpeg
 5710  matlab -nodesktop
 5711  python
 5712  python image_metric.py 
 5713  python image_metric.py -h
 5714  python image_metric.py --ref_dir='/data/sunnycia/image_compression_challenge/dataset/KODAK_PNG' --cps_dir='/data/sunnycia/image_compression_challenge/compressed_set/KODAK/jpeg' --output_path=''
 5715  bash jpeg_compress.sh 
 5716  python image_metric.py --ref_dir='/data/sunnycia/image_compression_challenge/dataset/KODAK_PNG' --cps_dir='/data/sunnycia/image_compression_challenge/compressed_set/KODAK/jpeg'
 5717  python image_metric.py --ref_dir='/data/sunnycia/image_compression_challenge/dataset/KODAK_PNG' --cps_dir='/data/sunnycia/image_compression_challenge/compressed_set/KODAK/jpeg2000'
 5718  bash jpeg_compress.sh CLIC_PRO && bash jpeg_compress.sh CLIC_MOB
 5719  rm -rf /data/sunnycia/image_compression_challenge/compressed_set/CLIC_MOB/jpeg
 5720  rm -rf /data/sunnycia/image_compression_challenge/compressed_set/CLIC_MOB/jpeg2000/
 5721  bash jpeg_compress.sh CLIC_PRO && bash jpeg_compress.sh CLIC_MOB
 5722  clear && clear
 5723  cd _Train/
 5724  ls
 5725  cd HM-16.9/
 5726  ./bin/TAppEncoderStatic -c cfg\encoder_lowdelay_main.cfg -i sci_yuv\Im-7_719_904_444.yuv -o rec\Im-7_719_904_444_scc_.yuv -b stream\Im-7_719_904_444_scc_qp47.scc --InputChromaFormatqp47=444 --ConformanceWindowMode=1 -wdt 719 -hgt 904 -fr 30 -f 1 -q 47 >> result\Im-7_719_904_444_scc_qp47.txt
 5727  ./bin/TAppEncoderStatic -c cfg\encoder_lowdelay_main.cfg -i /data/sunnycia/image_compression_challenge/dataset/KODAK_YUV/kodim24_768_512_444.yuv -o hey.yuv -b yo.scc --InputChromaFormat=444 --ConformanceWindowMode=1 -wdt  -hgt 904 -fr 30 -f 1 -q 47 
 5728  ./bin/TAppEncoderStatic -c cfg\encoder_lowdelay_main.cfg -i /data/sunnycia/image_compression_challenge/dataset/KODAK_YUV/kodim24_768_512_444.yuv -o hey.yuv -b yo.scc --InputChromaFormat=444 --ConformanceWindowMode=1 -wdt 768  -hgt 512 -fr 30 -f 1 -q 47 
 5729  ./bin/TAppEncoderStatic -c cfg/encoder_lowdelay_main.cfg -i /data/sunnycia/image_compression_challenge/dataset/KODAK_YUV/kodim24_768_512_444.yuv -o hey.yuv -b yo.scc --InputChromaFormat=444 --ConformanceWindowMode=1 -wdt 768  -hgt 512 -fr 30 -f 1 -q 47 
 5730  ./bin/TAppEncoderStatic -c cfg/encoder_lowdelay_main.cfg -i /data/sunnycia/image_compression_challenge/dataset/KODAK_YUV/kodim24_768_512_444.yuv -o hey.yuv -b yo.scc --InputChromaFormat=420 --ConformanceWindowMode=1 -wdt 768  -hgt 512 -fr 30 -f 1 -q 47 
 5731  ./bin/TAppEncoderStatic -c cfg/encoder_lowdelay_main_rext.cfg -i /data/sunnycia/image_compression_challenge/dataset/KODAK_YUV/kodim24_768_512_444.yuv -o hey.yuv -b yo.scc --InputChromaFormat=444 --ConformanceWindowMode=1 -wdt 768  -hgt 512 -fr 30 -f 1 -q 47 
 5732  ./bin/TAppEncoderStatic -c cfg/encoder_lowdelay_main_rext.cfg -i /data/sunnycia/image_compression_challenge/dataset/KODAK_YUV/kodim24_768_512_444.yuv -o hey.yuv -b yo.scc --InputChromaFormat=444 --ConformanceWindowMode=1 -wdt 768  -hgt 512  -f 1 -q 47 
 5733  ./bin/TAppEncoderStatic -c cfg/encoder_lowdelay_main_rext.cfg -i /data/sunnycia/image_compression_challenge/dataset/KODAK_YUV/kodim24_768_512_444.yuv -o hey.yuv -b yo.scc --InputChromaFormat=444 --ConformanceWindowMode=1 -wdt 768  -hgt 512  -f 1 -q 47 -fr 1
 5734  ./bin/TAppEncoderStatic -c cfg/encoder_lowdelay_main_rext.cfg -i /data/sunnycia/image_compression_challenge/dataset/KODAK_YUV/kodim24_768_512_444.yuv -o hey.yuv -b yo.scc --InputChromaFormat=444 --ConformanceWindowMode=1 -wdt 768  -hgt 512  -f 1 -q 15 -fr 1
 5735  ./bin/TAppEncoderStatic -c cfg/encoder_lowdelay_main_rext.cfg -i /data/sunnycia/image_compression_challenge/dataset/KODAK_YUV/kodim24_768_512_444.yuv -o hey.yuv -b yo.scc --InputChromaFormat=444 --ConformanceWindowMode=1 -wdt 768  -hgt 512  -f 1 -q 15 -fr 1 >> result.txt
 5736  ./bin/TAppEncoderStatic -c cfg/encoder_lowdelay_main_rext.cfg -i /data/sunnycia/image_compression_challenge/dataset/KODAK_YUV/kodim24_768_512_444.yuv  --InputChromaFormat=444 --ConformanceWindowMode=1 -wdt 768  -hgt 512  -f 1 -q 15 -fr 1
 5737  cd ../..
 5738  python hevc_compress.py -h
 5739  python hevc_compress.py --yuv_dir='/data/sunnycia/image_compression_challenge/dataset/KODAK_YUV' --result_dir='/data/sunnycia/image_compression_challenge/compressed_set/KODAK_YUV' --qp=50
 5740  clear && clear
 5741  python hevc_compress.py --yuv_dir='/data/sunnycia/image_compression_challenge/dataset/KODAK_YUV' --result_dir='/data/sunnycia/image_compression_challenge/compressed_set/KODAK_YUV' --qp=50
 5742  bash hevc_compress.sh /data/sunnycia/image_compression_challenge/dataset/KODAK_YUV /data/sunnycia/image_compression_challenge/compressed_set/KODAK_YUV
 5743  vim hevc_compress.sh 
 5744  bash hevc_compress.sh /data/sunnycia/image_compression_challenge/dataset/KODAK_YUV /data/sunnycia/image_compression_challenge/compressed_set/KODAK_YUV
 5745  bash jpeg2000_compress.sh CLIC_MOB
 5746  top
 5747  nvidia-smi
 5748  cd /data/sunnycia/image_compression_challenge/_Train/image-compression-cnn-master
 5749  nvidia-smi
 5750  export CUDA_VISIBLE_DEVICES=7
 5751  clear
 5752  python generate_map.py image.png 
 5753  python combine_images.py -image image.png -map output/msroi_map.jpg 
 5754  pip install webp-converter
 5755  clear
 5756  su
 5757  webpc
 5758  webp
 5759  su
 5760  clear
 5761  nvcc
 5762  nvcc -version
 5763  nvcc -v
 5764  nvcc --help
 5765  vim /etc/profile
 5766  nvcc
 5767  vim ~/.bashrc
 5768  to
 5769  top
 5770  nvidia-smi
 5771  top
 5772  kill -9 33546
 5773  top
 5774  nvidia-smi
 5775  clear
 5776  export CUDA_VISIBLE_DEVICES=7
 5777  python _batch_roi.py --img_dir='/data/sunnycia/image_compression_challenge/dataset/KODAK' --roi_dir='/data/sunnycia/image_compression_challenge/dataset/KODAK_ROI'
 5778  convert -h
 5779  python combine_images.py -image image.png -map output/msroi_map.jpg 
 5780  cd ..
 5781  svn checkout 
 5782  svn checkout https://jvet.hhi.fraunhofer.de/svn/svn_HMJEMSoftware/tags/HM-16.6-JEM-7.1/doc/
 5783  clear
 5784  cd image-compression-cnn-master/
 5785  cd ..
 5786  python compress_image.py -h
 5787  python compress_image.py --input_dir='/data/sunnycia/image_compression_challenge/dataset/KODAK' --output_dir='/data/sunnycia/image_compression_challenge/compressed_set/KODAK/webp' --quality=50 --codec='webp' 
 5788  bash webp_compress.sh KODAK
 5789  bash webp_compress.sh CLIC_PRO && bash webp_compress.sh CLIC_MOB
 5790  python
 5791  su
 5792  clear
 5793  vim plotly_demo.py
 5794  python plotly_demo.py 
 5795  python
 5796  vim plotly_demo.py
 5797  python plotly_demo.py 
 5798  vim ~/.plotly/.credentials 
 5799  python plotly_demo.py 
 5800  vim plotly_demo.py 
 5801  top
 5802  nvidia-smi
 5803  clear
 5804  python image_metric.py -h
 5805  python image_metric.py --ref_dir=/data/sunnycia/image_compression_challenge/dataset/CLIC_PRO'' --cps_dir='/data/sunnycia/image_compression_challenge/compress_set/CLIC_PRO/jpeg'
 5806  clear
 5807  python image_metric.py --ref_dir=/data/sunnycia/image_compression_challenge/dataset/CLIC_PRO'' --cps_dir='/data/sunnycia/image_compression_challenge/compressed_set/CLIC_PRO/jpeg'
 5808  pwd
 5809  to
 5810  top
 5811  nvidia-smi
 5812  cd pwd/
 5813  pwd
 5814  git clone https://github.com/iamaaditya/image-compression-cnn.git
 5815  ls
 5816  cd /data/sunnycia/pwd
 5817  unzip image-compression-cnn-master.zip 
 5818  cd image-compression-cnn-master/
 5819  ls
 5820  python generate_map.py image.png 
 5821  export CUDA_VISIBLE_DEVICES=3
 5822  nvidia-smi
 5823  python generate_map.py image.png 
 5824  python generate_map.py -h
 5825  python generate_map.py image.png out.png
 5826  python combine_images.py -image image.png -map output/msroi_map.jpg 
 5827  python combine_images.py -image image.png -map output/msroi_map.jpg -print_metircs
 5828  python combine_images.py -image image.png -map output/msroi_map.jpg -print_metrics
 5829  python combine_images.py -image image.png -map output/msroi_map.jpg -print_metrics=1
 5830  su
 5831  gem install jekyll
 5832  su
 5833  pwd
 5834  cd /data/sunnycia/
 5835  ls
 5836  pwd
 5837  git clone https://github.com/sunnycia/sunnycia.github.io
 5838  ls
 5839  cd sunnycia.github.io/
 5840  ls
 5841  rm -rf *
 5842  git clone https://github.com/poole/hyde.git
 5843  ls
 5844  mv hyde/* ./
 5845  ls
 5846  rm -rf hyde/
 5847  ls
 5848  git status
 5849  git add --all
 5850  git commit -m "Add hyde jekyll theme"
 5851  git push -u origin maser
 5852  git push -u origin master
 5853  ls
 5854  git status
 5855  cd _posts/
 5856  ls
 5857  touch 2018-01-18-hello-world.md
 5858  cd ..
 5859  jekyll serve
 5860  jekyll serve --incremental
 5861  firefox
 5862  git status
 5863  git add --all
 5864  git status
 5865  git commit -m "first post"
 5866  git push -u origin master
 5867  git remote add origin https://github.com/sunnycia/sunnycia.github.io.git
 5868  git push -u origin master
 5869  vim _config.yml 
 5870  git add --all
 5871  git commit -m "I'm from future"
 5872  git push -u origin master
 5873  cd ..
 5874  jekyll sunnycia.github.io/
 5875  cd sunnycia.github.io/
 5876  jekyll -h
 5877  jekyll server
 5878  vim _config.yml 
 5879  jekyll server
 5880  top
 5881  clear
 5882  rm -rf *
 5883  ls
 5884  git clone https://github.com/poole/poole.git
 5885  ls
 5886  cp -R poole/* ./
 5887  ls
 5888  rm -rf poole/
 5889  ls
 5890  jekyll server
 5891  su
 5892  jekyll server
 5893  jekyll server --incremental
 5894  git add --all
 5895  git commit -m "Change theme"
 5896  git push -u origin master
 5897  cd _posts/
 5898  ls
 5899  cd ..
 5900  rm -rf *
 5901  git clone https://github.com/poole/hyde.git && cp hyde/* ./ && rm -rf hyde
 5902  ls
 5903  cp -R hyde/* ./ && rm -rf hyde
 5904  ls
 5905  git add --all && git commit -m "Change to hyde theme"
 5906  git push -u origin master
 5907  ls
 5908  jekyll server
 5909  su
 5910  jekyll server
 5911  su
 5912  jekyll server
 5913  git add --all
 5914  git commit -m "Debug Hyde theme"
 5915  git push -u origin master
 5916  rm -rf CNAME 
 5917  git add --all
 5918  git commit -m "Debug Hyde theme 2 "
 5919  git push -u origin master
 5920  jekyll server
 5921  git add --all && git commit -m "Edit info"
 5922  git push -u origin master
 5923  gem sourse -l
 5924  gem sorce -l
 5925  gem source -l
 5926  su
 5927  git status
 5928  df -h
 5929  ln -s /data/sunnycia/sunnycia.github.io ~/sunnycia.github.io
 5930  ls ~
 5931  cd /data/sunnycia/saliency_on_videoset/Train/scripts
 5932  python utils/vizutil/image_table.py -h
 5933  python utils/vizutil/image_table.py --output_path='./msu.jpg' --image_base='/data/sunnycia/SaliencyDataset/Video/MSU/frames' --padding=10
 5934  python utils/vizutil/image_table.py --output_path='./msu.jpg' --image_base='/data/sunnycia/SaliencyDataset/Video/MSU/frames' --padding=5
 5935  python utils/vizutil/image_table.py --output_path='./diem.jpg' --image_base='/data/sunnycia/SaliencyDataset/Video/DIEM/frames' --padding=5
 5936  python utils/vizutil/image_table.py --output_path='./MSU.jpg' --image_base='/data/sunnycia/SaliencyDataset/Video/MSU/frames' --padding=5
 5937  python utils/vizutil/image_table.py --output_path='./diem.jpg' --image_base='/data/sunnycia/SaliencyDataset/Video/DIEM/frames' --padding=5
 5938  python utils/vizutil/image_table.py --output_path='./GAZECOM.jpg' --image_base='/data/sunnycia/SaliencyDataset/Video/GAZECOM/frames' --padding=5
 5939  python utils/vizutil/image_table.py --output_path='./videoset.jpg' --image_base='/data/sunnycia/SaliencyDataset/Video/VideoSet/ImageSet/Seperate/frame' --padding=5
 5940  cd /data/sunnycia/SaliencyDataset/Video/DIEM
 5941  python 
 5942  ssh qiudan@172.31.234.248
 5943  clear
 5944  cd -
 5945  git stauts
 5946  git status
 5947  git add --all
 5948  git commit -m "add new feature concat network. add image table ffunction."
 5949  git push -u origin master
 5950  docker
 5951  cd /data/sunnycia/saliency_on_videoset/Train/figure/vo-v4-2-resnet-catfeat-snapshot-4000--batch-2_1516237828
 5952  ls
 5953  python
 5954  clear
 5955  cd /data/sunnycia/image_compression_challenge/compressed_set/CLIC_PRO/webp
 5956  cd /data/sunnycia/image_compression_challenge
 5957  nvidia-smi
 5958  top
 5959  nvidia-smi
 5960  kill -9 24019
 5961  clear
 5962  ls
 5963  python image_metric.py -h
 5964  python image_metric.py --ref_dir='/data/sunnycia/image_compression_challenge/dataset/KODAK' --cps_dir='/data/sunnycia/image_compression_challenge/compressed_set/KODAK/webp' && python image_metric.py --ref_dir='/data/sunnycia/image_compression_challenge/dataset/CLIC_PRO' --cps_dir='/data/sunnycia/image_compression_challenge/compressed_set/CLIC_PRO/webp' 
 5965  python image_metric.py --ref_dir='/data/sunnycia/image_compression_challenge/dataset/CLIC_PRO' --cps_dir='/data/sunnycia/image_compression_challenge/compressed_set/CLIC_PRO/webp'
 5966  clear && clear
 5967  python image_metric.py --ref_dir='/data/sunnycia/image_compression_challenge/dataset/CLIC_PRO' --cps_dir='/data/sunnycia/image_compression_challenge/compressed_set/CLIC_PRO/webp'
 5968  su
 5969  firefox
 5970  su
 5971  cd pwd/saliency_on_videoset/Train/
 5972  mv ../Tobii/ ../_Tobii
 5973  ls ..
 5974  cd scripts/
 5975  ls
 5976  python ss_test_video.py -h
 5977  source set_env.sh ../C3D-v1.1-tmp/ 3
 5978  nvidia-smi
 5979  source set_env.sh ../C3D-v1.1-tmp/ 5
 5980  python ss_test_video.py -h
 5981  python utils/model_guardian.py -h
 5982  python utils/model_guardian.py --modeldir='/data/sunnycia/saliency_on_videoset/Train/training_output/salicon/vo-v4-2-resnet-catfeat-snapshot-4000--batch-2_1516237828' --modeliter=116000
 5983  python utils/model_guardian.py --modeldir='/data/sunnycia/saliency_on_videoset/Train/training_output/salicon/vo-v4-2-resnet-catfeat-snapshot-4000--batch-2_1516237828' --modeliter=116000 --protocode=2
 5984  nvidia-smi
 5985  d f-h
 5986  df -h
 5987  ls utils/
 5988  ls utils/vizutil/
 5989  python utils/vizutil/visualization_weight.py -h
 5990  python utils/vizutil/visualization_weight.py -h --type='3d' --modelpath='heaven' --deploypath='' --outputpath='' --layer=''
 5991  python utils/model_guardian.py --modeldir='/data/sunnycia/saliency_on_videoset/Train/training_output/salicon/vo-v4-2-resnet-catfeat-snapshot-4000--batch-2_1516237828' --modeliter=164000 --protocode=2
 5992  nvidia-smi
 5993  python utils/model_guardian.py --modeldir='/data/sunnycia/saliency_on_videoset/Train/training_output/salicon/vo-v4-2-resnet-catfeat-snapshot-4000--batch-2_1516237828' --modeliter=212000 --protocode=2
 5994  python utils/model_guardian.py --modeldir='/data/sunnycia/saliency_on_videoset/Train/training_output/salicon/vo-v4-2-resnet-catfeat-dropout-snapshot-4000--batch-2_1516517784' --modeliter=44000 --protocode=2
 5995  cd /data/sunnycia/image_compression_challenge/CLIC_dataset
 5996  unzip mobile_*
 5997  unzip mobile_train.zip 
 5998  unzip professional_train.zip 
 5999  top
 6000  nvidia-smi
 6001  clear
 6002  cd -
 6003  python utils/model_guardian.py --modeldir='/data/sunnycia/saliency_on_videoset/Train/training_output/salicon/vo-v4-2-resnet-fixc2-drop-weight_decay-0.000005-base_lr-0.0001-snapshot-4000-finetunefrom26k-batch-2_1515819089' --modeliter=584000 --protocode=1
 6004  python utils/model_guardian.py --modeldir='/data/sunnycia/saliency_on_videoset/Train/training_output/salicon/vo-v4-2-resnet-catfeat-snapshot-4000--batch-2_1516237828' --modeliter=268000 --protocode=2
 6005  python utils/model_guardian.py --modeldir='/data/sunnycia/saliency_on_videoset/Train/training_output/salicon/vo-v4-2-resnet-dropout-weight_decay-0.000005-base_lr-0.0001-snapshot-4000--batch-2_1515773757_usesnapshot_1515247477_snapshot-_iter_272000' --modeliter=89200 --protocode=1
 6006  python utils/model_guardian.py --modeldir='/data/sunnycia/saliency_on_videoset/Train/training_output/salicon/vo-v4-2-resnet-dropout-weight_decay-0.000005-base_lr-0.0001-snapshot-4000--batch-2_1515773757_usesnapshot_1515247477_snapshot-_iter_272000' --modeliter=892000 --protocode=1
 6007  top
 6008  nvidia-smi
 6009  clear
 6010  nvidia-smi
 6011  clear
 6012  python test_video.py --video_deploy_path='prototxt/vo-v4-2-resnet-deploy.prototxt' --video_model_path='../training_output/salicon/vo-v4-2-resnet-fixc2-drop-weight_decay-0.000005-base_lr-0.0001-snapshot-4000-finetunefrom26k-batch-2_1515819089/snapshot-_iter_656000.caffemodel' --infertype='slide' --output_type='image' --test_base='videoset' --model_code='v4-2' --videolength=16
 6013  cd metric/
 6014  matlab -nodesktop -nodisplay
 6015  cd ..
 6016  python utils/model_guardian.py --modeldir='/data/sunnycia/saliency_on_videoset/Train/training_output/salicon/vo-v4-2-resnet-catfeat-bnorm-snapshot-4000--batch-2_1516724056' --modeliter=120000 --protocode=2
 6017  nvidia-smi
 6018  source set_env.sh 7
 6019  nvidia-smi
 6020  python utils/model_guardian.py --modeldir='/data/sunnycia/saliency_on_videoset/Train/training_output/salicon/vo-v4-2-resnet-catfeat-bnorm-snapshot-4000--batch-2_1516724056' --modeliter=120000 --protocode=2
 6021  source set_env.sh 1
 6022  python utils/model_guardian.py --modeldir='/data/sunnycia/saliency_on_videoset/Train/training_output/salicon/vo-v4-2-resnet-catfeat-bnorm-snapshot-4000--batch-2_1516724056' --modeliter=120000 --protocode=2
 6023  source set_env.sh ../C3D-v1.1-tmp/ 7
 6024  python utils/model_guardian.py --modeldir='/data/sunnycia/saliency_on_videoset/Train/training_output/salicon/vo-v4-2-resnet-catfeat-bnorm-snapshot-4000--batch-2_1516724056' --modeliter=120000 --protocode=2
 6025  cd /data/sunnycia/image_compression_challenge/_Train
 6026  unzip image-compression-cnn-master.zip 
 6027  unzip benchmark.zip 
 6028  ls
 6029  svn -h
 6030  svn https://hevc.hhi.fraunhofer.de/svn/svn_HEVCSoftware/tags/HM-16.9/
 6031  svn export https://hevc.hhi.fraunhofer.de/svn/svn_HEVCSoftware/tags/HM-16.9/
 6032  svn checkout
 6033  svn checkout https://hevc.hhi.fraunhofer.de/svn/svn_HEVCSoftware/tags/HM-16.9/
 6034  tar xf HM-16.9.tar.gz 
 6035  cd /data/sunnycia/image_compression_challenge/_Train/HM-16.9/build/linux
 6036  make -j3
 6037  cd /data/sunnycia/image_compression_challenge/_Train/HM-16.9/bin
 6038  ./TAppDecoderAnalyserStatic
 6039  TAppEncoderStatic
 6040  ./TAppEncoderStatic
 6041  ./TAppEncoderStatic > TAppEncoderStatic_usage.txt
 6042  cd /data/sunnycia/image_compression_challenge/utils/yuvtools
 6043  matlab -nodesktop -nodisplay
 6044  clear && clear
 6045  cd ../..
 6046  cd _Train/
 6047  tar xf HM-16.6-JEM-7.1.tar.gz 
 6048  ls
 6049  cd /data/sunnycia/image_compression_challenge/_Train/HM-16.6-JEM-7.1/build/linux
 6050  make -j4
 6051  cd /data/sunnycia/image_compression_challenge/_Train/HM-16.6-JEM-7.1/doc
 6052  make
 6053  cd /data/sunnycia/image_compression_challenge
 6054  python image_metric.py -h
 6055  python image_metric.py --ref_dir='/data/sunnycia/image_compression_challenge/dataset/KODAK' --cps_dir='/data/sunnycia/image_compression_challenge/compressed_set/CLIC_PRO/jpeg2000'
 6056  python image_metric.py --ref_dir='/data/sunnycia/image_compression_challenge/dataset/CLIC_PRO' --cps_dir='/data/sunnycia/image_compression_challenge/compressed_set/CLIC_PRO/jpeg2000'
 6057  firefox
 6058  clear
 6059  cd /data/sunnycia/image_compression_challenge/
 6060  cd _Train/image-compression-cnn/
 6061  python _batch_roi.py -h
 6062  python _batch_roi.py --img_dir='/data/sunnycia/image_compression_challenge/dataset/KODAK' --roi_dir='/data/sunnycia/image_compression_challenge/dataset/KODAK_ROI'
 6063  nvidia-smi
 6064  export CUDA_VISIBLE_DEVICES=7
 6065  python _batch_roi.py --img_dir='/data/sunnycia/image_compression_challenge/dataset/KODAK' --roi_dir='/data/sunnycia/image_compression_challenge/dataset/KODAK_ROI'
 6066  ls
 6067  convert -colorspace sRGB -filter Lanczos -interlace Plane -type truecolor -quality 5 image.png wht.jpg
 6068  convert -colorspace sRGB -filter Lanczos -interlace Plane -type truecolor -quality 11 image.png wht.jpg
 6069  convert -colorspace sRGB -filter Lanczos -interlace Plane -type truecolor -quality 51 image.png wht.jpg
 6070  python
 6071  cd ..
 6072  ls
 6073  clear
 6074  cd utils/
 6075  ls
 6076  git clone https://github.com/Anserw/Bjontegaard_metric.git
 6077  ls
 6078  cd Bjontegaard_metric/
 6079  ls
 6080  python demo.py 
 6081  cd ..
 6082  git clone https://github.com/serge-m/bjontegaard2.git
 6083  cd ..
 6084  python calc_bdbr_bdpsnr.py -h
 6085  pytho calc_bdbr_bdpsnr.py --dataset=KODAK --ref_image_dir='/data/sunnycia/image_compression_challenge/dataset/KODAK' 
 6086  python calc_bdbr_bdpsnr.py --dataset=KODAK --ref_image_dir='/data/sunnycia/image_compression_challenge/dataset/KODAK' 
 6087  history > history
 6088  top
 6089  cd /data/sunnycia/image_compression_challenge/dataset/RAISE-1k
 6090  python get_raise.py raise_1k_url-3.txt
 6091  top
 6092  nvidia-mis
 6093  nvidia-smi
 6094  cd /data/sunnycia/image_compression_challenge/
 6095  ls
 6096  python image_metric.py -h
 6097  python image_metric.py --ref_dir='/data/sunnycia/image_compression_challenge/dataset/KODAK' --cps_dir='/data/sunnycia/image_compression_challenge/compressed_set/KODAK/tfrnn' --color_space='YVU' --codec='tfrnn' 
 6098  python plot_scatter.py --dataset='KODAK' --ref_image_dir='/data/sunnycia/image_compression_challenge/dataset/KODAK' --metric_dir='./metric_data' --metric_name='Y-psnr' --metric_index=8 --debug=True --output_dir='./metric_data/KODAK-YPSNR' 
 6099  python plot_scatter.py --dataset='KODAK' --ref_image_dir='/data/sunnycia/image_compression_challenge/dataset/KODAK' --metric_dir='./metric_data' --metric_name='Y-psnr' --metric_index=8  --output_dir='./metric_data/KODAK-YPSNR' 
 6100  cd /data/sunnycia/image_compression_challenge/utils/yuvtools
 6101  matlab -nodesktop -nodisplay
 6102  top
 6103  cd ..
 6104  bash hevc-jem_compress.sh /data/sunnycia/image_compression_challenge/dataset/KODAK_YUV /data/sunnycia/image_compression_challenge/compressed_set/KODAK/ffffjem_hevc /data/sunnycia/image_compression_challenge/compressed_set/KODAK/ffffjem_hevc_recon /data/sunnycia/image_compression_challenge/compressed_set/KODAK/ffffjem_hevc_result
 6105  su
 6106  ls
 6107  clear
 6108  cd /data/sunnycia/image_compression_challenge/utils/yuvtools
 6109  matlab -nodesktop -nodisplay
 6110  cd /data/sunnycia/image_compression_challenge/dataset/RAISE-1k
 6111  python get_raise.py raise_1k_url-4.txt
 6112  cd /data/sunnycia/image_compression_challenge/dataset/RAISE-1k
 6113  python get_raise.py raise_1k_url-2.txt
 6114  cd /data/sunnycia/
 6115  cd image_compression_challenge/
 6116  history >history
 6117  cd /data/sunnycia/image_compression_challenge/_Train/tfnn_compression/image_encoder
 6118  python encoder.py --input_image='example.png' --output_codes=output_codes.pkl --iteration=15 --model=model/residual_gru.pb
 6119  export CUDA_VISIBLE_DEVICES=7
 6120  top
 6121  nvidia-smi
 6122  python encoder.py --input_image='example.png' --output_codes=output_codes.pkl --iteration=15 --model=model/residual_gru.pb
 6123  python decoder.py --input_codes=output_codes.pkl --iteration=15 --output_directory=output --model=model/residual_gru.pb
 6124  python encoder.py --input_image='example.png' --output_codes=output_codes.pkl --iteration=15 --model=model/residual_gru.pb
 6125  python compress.py -h
 6126  python compress.py --oridir='/data/sunnycia/image_compression_challenge/dataset/KODAK' --cps_dir='/data/sunnycia/image_compression_challenge/compressed_set/KODAK/tfrnn'
 6127  python compress.py --ori_dir='/data/sunnycia/image_compression_challenge/dataset/KODAK' --cps_dir='/data/sunnycia/image_compression_challenge/compressed_set/KODAK/tfrnn'
 6128  top
 6129  nvidia-smi
 6130  clear
 6131  cd ../..
 6132  cd ..
 6133  bash hevc_compress.sh ./dataset/KODAK_YUV420 ./compressed_set/KODAK/hevc420 ./compressed_set/KODAK/hevc420_recon 
 6134  bash hevc_compress.sh ./dataset/KODAK_YUV420 ./compressed_set/KODAK/hevc420 ./compressed_set/KODAK/hevc420_recon ./compressed_set/KODAK/hevc420_result
 6135  bash hevc_compress.sh dataset/KODAK_YUV420 compressed_set/KODAK/hevc420 compressed_set/KODAK/hevc420_recon compressed_set/KODAK/hevc420_result
 6136  bash hevc_compress.sh /data/sunnycia/image_compression_challenge/dataset/KODAK_YUV420 /data/sunnycia/image_compression_challenge/compressed_set/KODAK/hevc420 /data/sunnycia/image_compression_challenge/compressed_set/KODAK/hevc420_recon /data/sunnycia/image_compression_challenge/compressed_set/KODAK/hevc420_result
 6137  bash hevc_compress.sh /data/sunnycia/image_compression_challenge/dataset/CLIC_PRO_YUV420 /data/sunnycia/image_compression_challenge/compressed_set/CLIC_PRO/hevc420 /data/sunnycia/image_compression_challenge/compressed_set/CLIC_PRO/hevc420_recon /data/sunnycia/image_compression_challenge/compressed_set/CLIC_PRO/hevc420_result
 6138  python yuv_import.py 768x512
 6139  pip install YUV
 6140  pip install yuv
 6141  python
 6142  cd /data/sunnycia/image_compression_challenge/utils/yuvtools
 6143  ls
 6144  matlab -nodesktop -nodisplay
 6145  cd /data/sunnycia/image_compression_challenge/_Train/ARCNN
 6146  unzip ARCNN.zip 
 6147  ls
 6148  unzip AR-CNN\ test\ code.zip 
 6149  ls
 6150  cd ..
 6151  ls
 6152  git clone https://github.com/limuhit/TrimmedConvolution.git
 6153  clear
 6154  top
 6155  nvidia-smi
 6156  ls
 6157  top
 6158  nvidia-smi
 6159  watch -n 5 nvidia-smi
 6160  ping 172.31.234.250
 6161  ping 172.31.234.248
 6162  top
 6163  ls
 6164  top
 6165  nvidia-smi
 6166  su
 6167  ifconfig
 6168  top
 6169  nvidia-smi
 6170  nvidia
 6171  su
 6172  to
 6173  top
 6174  nvidia-smi
 6175  top
 6176  nvidia-smi
 6177  cd /data/sunnycia/SaliencyDataset/Video/MSU
 6178  tar cf frames frames.tar.gz
 6179  tar cf frames.tar.gz frames
 6180  nvidia-smi
 6181  cd /data/sunnycia/image_compression_challenge/Train/scripts/data/sunnycia/image_compression_challenge/Train/scripts
 6182  cd /data/sunnycia/image_compression_challenge/Train/scripts
 6183  pwd
 6184  clear
 6185  export CUDA_VISIBLE_DEVICES=7
 6186  python training.py --training_data_dir='/data/sunnycia/image_compression_challenge/dataset/CLIC_PRO' --valid_data_dir=''
 6187  clear && clear
 6188  python training.py --training_data_dir='/data/sunnycia/image_compression_challenge/dataset/CLIC_PRO' --valid_data_dir=''
 6189  clear
 6190  topq
 6191  top
 6192  clear
 6193  cd /data/sunnycia
 6194  tar cf image_compression_challenge.tar.gz image_compression_challenge
 6195  top
 6196  cd /data/sunnycia/image_compression_challenge/dataset/KODAK
 6197  python
 6198  cd /data/sunnycia/image_compression_challenge/Train/scripts
 6199  python Dataset.py 
 6200  clear
 6201  python Dataset.py 
 6202  python
 6203  python Dataset.py 
 6204  export CUDA_VISIBLE_DEVICES=7
 6205  nvidia-smi
 6206  export CUDA_VISIBLE_DEVICES=7
 6207  python training.py 
 6208  python training.py --training_data_dir='/data/sunnycia/image_compression_challenge/dataset/CLIC_PRO'
 6209  python training.py --training_data_dir='/data/sunnycia/image_compression_challenge/dataset/CLIC_PRO' --valid_data_dir=''
 6210  pwd
 6211  vim ~/.bashrc
 6212  ssh chenzihao@172.31.70.212
 6213  ssh wangxu@172.31.70.212
 6214  clear
 6215  vim ~/.bashrc
 6216  ssh chenzihao@172.31.70.212
 6217  clear
 6218  nvidia-smi
 6219  cd /data/sunnycia/image_compression_challenge/Train/scripts
 6220  python encoder.py 
 6221  python -m
 6222  python -m 'import caffe;caffe.__version__'
 6223  python -m 'import caffe;  caffe.__version__'
 6224  python -m 'import caffe,  caffe.__version__'
 6225  python -m 'caffe.__version__'
 6226  python -m 'caffe'
 6227  pytho -c 'import caffe;caffe.__version__'
 6228  python -c 'import caffe;caffe.__version__'
 6229  python -c 'import caffe; print caffe.__version__'
 6230  python -c 'import gym as g;print g.__version__'
 6231  python
 6232  python model.py 
 6233  source set_env.sh ../caffe-master 4
 6234  python model.py 
 6235  clear
 6236  python model.py 
 6237  clear && clear
 6238  python model.py 
 6239  python
 6240  python solver.py 
 6241  python training.py --training_data_dir='/data/sunnycia/image_compression_challenge/dataset/CLIC_PRO' --valid_data_dir='' --train_prototxt='prototxt/cwic_train.prototxt' --pretrained_model=''
 6242  python
 6243  python training.py --training_data_dir='/data/sunnycia/image_compression_challenge/dataset/CLIC_PRO' --valid_data_dir='' --train_prototxt='prototxt/cwic_train.prototxt' --pretrained_model=''
 6244  python inference.py 
 6245  clear && clear
 6246  cd /data/sunnycia/image_compression_challenge/_Train/ImageCompression 
 6247  python test_imp.py 
 6248  source set_env.sh my_caffe-master 6
 6249  python test_imp.py 
 6250  cd -
 6251  python inference.py 
 6252  df -h
 6253  python inference.py 
 6254  python visualization_weight.py --modelpath='cwic_training_output/snapshot-_iter_1064000.caffemodel' --deploypath='prototxt/cwic_deploy.prototxt' --outputpath='conv1.jpg' --type='2d' --layer='conv1'
 6255  python visualization_weight.py --modelpath='cwic_training_output/snapshot-_iter_1064000.caffemodel' --deploypath='prototxt/cwic_deploy.prototxt' --outputpath='conv1.jpg' --type='2d' --layer='conv2'
 6256  cd /data/sunnycia/image_compression_challenge/_Train/ImageCompression
 6257  cd -
 6258  python visualization_weight.py --modelpath='/data/sunnycia/image_compression_challenge/_Train/ImageCompression/model/cmp/5.caffemodel' --deploypath='prototxt/cwic_deploy.prototxt' --outputpath='conv1.jpg' --type='2d' --layer='conv2'
 6259  python visualization_weight.py --modelpath='/data/sunnycia/image_compression_challenge/_Train/ImageCompression/model/cmp/1.caffemodel' --deploypath='prototxt/cwic_deploy.prototxt' --outputpath='conv1.jpg' --type='2d' --layer='conv2'
 6260  python inference.py 
 6261  python training.py --training_data_dir='/data/sunnycia/image_compression_challenge/dataset/CLIC_PRO' --valid_data_dir='' --train_prototxt='prototxt/cwic_train.prototxt' --pretrained_model=''
 6262  python inference.py 
 6263  su
 6264  python
 6265  su
 6266  python
 6267  su
 6268  python
 6269  top
 6270  python visualization_weight.py --modelpath='/data/sunnycia/image_compression_challenge/_Train/ImageCompression/model/cmp/1.caffemodel' --deploypath='prototxt/cwic_deploy.prototxt' --outputpath='conv1.jpg' --type='2d' --layer='conv2'
 6271  python visualization_weight.py --modelpath='cwic_training_output/snapshot-_iter_1064000.caffemodel' --deploypath='prototxt/cwic_deploy.prototxt' --outputpath='conv1.jpg' --type='2d' --layer='conv2'
 6272  python visualization_weight.py --modelpath='cwic_training_output/snapshot-_iter_1064000.caffemodel' --deploypath='prototxt/cwic_deploy.prototxt' --outputpath='conv1.jpg' --type='2d' --layer='conv1'
 6273  python visualization_weight.py --modelpath='cwic_training_output/snapshot-_iter_1164000.caffemodel' --deploypath='prototxt/cwic_deploy.prototxt' --outputpath='conv1.jpg' --type='2d' --layer='conv1'
 6274  python visualization_weight.py --modelpath='cwic_training_output/snapshot-_iter_1164000.caffemodel' --deploypath='prototxt/cwic_deploy.prototxt' --outputpath='conv1.jpg' --type='2d' --layer='inv_conv4'
 6275  python visualization_weight.py --modelpath='cwic_training_output/snapshot-_iter_1164000.caffemodel' --deploypath='prototxt/cwic_deploy.prototxt' --outputpath='conv1.jpg' --type='2d' --layer='pdata'
 6276  su 
 6277  nvidia-smi
 6278  tar -cf density.tar.gz density
 6279  cd /data/sunnycia/SaliencyDataset/Video/MSU
 6280  tar -cf density.tar.gz density
 6281  top
 6282  pwd
 6283  ls
 6284  ssh wangxu@172.31.70.212
 6285  ssh chenzihao@172.31.70.212
 6286  ssh root@172.31.70.212
 6287  ssh wangxu@172
 6288  ssh wangxu@172.31.70.212
 6289  ssh chenzihao@172.31.70.212
 6290  ssh wangxu@172.31.70.212
 6291  ssh chenzihao@172.31.70.212
 6292  ssh zhouyu@172.31.70.212
 6293  pwd
 6294  ssh chenzihao@172.31.70.212
 6295  ssh wangxu@172.31.70.212
 6296  ssh chenzihao@172.31.70.212
 6297  ssh wangxu@172.31.70.212
 6298  ssh chenzh@172.31.70.212
 6299  ssh wangxu@172.31.70.212
 6300  ssh chenzihao@172.31.70.212
 6301  ssh wangxu@172.31.70.212
 6302  ssh chenzihao@172.31.70.212
 6303  ssh wangxu@172.31.70.212
 6304  ls
 6305  cd /data/sunnycia/image_compression_challenge/Train/scripts
 6306  unzip my_caffe-master.zip 
 6307  ls
 6308  cd my_caffe-master/
 6309  ls
 6310  make -j8 all && make pycaffe
 6311  cp Makefile.config.example Makefile.config
 6312  vim Makefile.config
 6313  make -j8 all && make pycaffe
 6314  cd ..
 6315  ls
 6316  nvidia-smi
 6317  source set_env.sh my_caffe 6
 6318  python
 6319  clear
 6320  python training.py --training_data_dir='/data/sunnycia/image_compression_challenge/dataset/CLIC_PRO' --valid_data_dir='' --train_prototxt='prototxt/cwic_train.prototxt' --pretrained_model='' 
 6321  ssh chenzihao@172.31.70.212
 6322  ssh wangxu@172.31.70.212
 6323  clear
 6324  python training.py --training_data_dir='/data/sunnycia/image_compression_challenge/dataset/CLIC_PRO' --valid_data_dir='' --train_prototxt='prototxt/cwic_train.prototxt' --pretrained_model='' 
 6325  ssh chenzihao@172.31.70.212
 6326  python training.py --training_data_dir='/data/sunnycia/image_compression_challenge/dataset/CLIC_PRO' --valid_data_dir='' --train_prototxt='prototxt/cwic_train.prototxt' --pretrained_model='' 
 6327   free -h
 6328  nvidia-smi
 6329  clear
 6330  source set_env.sh my_caffe 6
 6331  cd my_caffe/
 6332  make clean
 6333  vim Makefile.config
 6334  make -j16 all && make -j4 pycaffe
 6335  pip install --user --upgrade protobuf==3.1.0.post1
 6336  cd ..
 6337  python training.py --training_data_dir='/data/sunnycia/image_compression_challenge/dataset/CLIC_PRO' --valid_data_dir='' --train_prototxt='prototxt/cwic_train.prototxt' --pretrained_model='' 
 6338  cd my_caffe/
 6339  make install
 6340  make test
 6341  make -j8 test
 6342  python training.py --training_data_dir='/data/sunnycia/image_compression_challenge/dataset/CLIC_PRO' --valid_data_dir='' --train_prototxt='prototxt/cwic_train.prototxt' --pretrained_model='' 
 6343  cd ..
 6344  python training.py --training_data_dir='/data/sunnycia/image_compression_challenge/dataset/CLIC_PRO' --valid_data_dir='' --train_prototxt='prototxt/cwic_train.prototxt' --pretrained_model='' 
 6345  python training.py --training_data_dir='/data/sunnycia/image_compression_challenge/dataset/KODAK' --valid_data_dir='' --train_prototxt='prototxt/cwic_train.prototxt' --pretrained_model='' 
 6346  cd my_caffe/
 6347  vim Makefile.config
 6348  make clean
 6349  make -j8 all && make pycaffe
 6350  cd ..
 6351  python training.py --training_data_dir='/data/sunnycia/image_compression_challenge/dataset/KODAK' --valid_data_dir='' --train_prototxt='prototxt/cwic_train.prototxt' --pretrained_model='' 
 6352  nvidia-smi
 6353  source set_env.sh my_caffe 4
 6354  python training.py --training_data_dir='/data/sunnycia/image_compression_challenge/dataset/KODAK' --valid_data_dir='' --train_prototxt='prototxt/cwic_train.prototxt' --pretrained_model='' 
 6355  cd my_caffe/
 6356  make runtest
 6357  make -j8 runtest
 6358  cd ..
 6359  python training.py --training_data_dir='/data/sunnycia/image_compression_challenge/dataset/KODAK' --valid_data_dir='' --train_prototxt='prototxt/cwic_train.prototxt' --pretrained_model='' 
 6360  cd ..
 6361  cd ../_Train/
 6362  ls
 6363  cd ImageCompression/
 6364  ls
 6365  source set_env.sh my_caffe-master 4
 6366  python test_imp.py 
 6367  cd ../..
 6368  cd _Train/
 6369  cd ../Train/
 6370  unzip caffe-master.zip 
 6371  ls
 6372  cd caffe-master/
 6373  cp Makefile.config.example Makefile.config
 6374  vim Makefile.config
 6375  make -j8 all
 6376  cd ..
 6377  unzip caffe-master.zip 
 6378  cd caffe-master/
 6379  cp Makefile.config.example Makefile.config
 6380  make -j8 all
 6381  make clean
 6382  vim Makefile.config
 6383  make
 6384  make pycaffe
 6385  cd ..
 6386  cd scripts/
 6387  source set_env.sh ../caffe-master 4
 6388  python training.py --training_data_dir='/data/sunnycia/image_compression_challenge/dataset/KODAK' --valid_data_dir='' --train_prototxt='prototxt/cwic_train.prototxt' --pretrained_model='' 
 6389  source set_env.sh my_caffe 4
 6390  python training.py --training_data_dir='/data/sunnycia/image_compression_challenge/dataset/KODAK' --valid_data_dir='' --train_prototxt='prototxt/cwic_train.prototxt' --pretrained_model='' 
 6391  source set_env.sh ../my_caffe 4
 6392  python training.py --training_data_dir='/data/sunnycia/image_compression_challenge/dataset/KODAK' --valid_data_dir='' --train_prototxt='prototxt/cwic_train.prototxt' --pretrained_model='' 
 6393  source set_env.sh ../caffe-master 4
 6394  python training.py --training_data_dir='/data/sunnycia/image_compression_challenge/dataset/KODAK' --valid_data_dir='' --train_prototxt='prototxt/cwic_train.prototxt' --pretrained_model='' 
 6395  cd ../caffe-master/
 6396  vim Makefile.config
 6397  make clean
 6398  make -j2 all && make -j2 pycaffe
 6399  make clean
 6400  make -j2
 6401  make clean
 6402  make && make pycaffe
 6403  cd ..
 6404  cd scripts/
 6405  python training.py --training_data_dir='/data/sunnycia/image_compression_challenge/dataset/KODAK' --valid_data_dir='' --train_prototxt='prototxt/cwic_train.prototxt' --pretrained_model='' 
 6406  cd ../caffe-master/
 6407  make clean
 6408  vim Makefile.config
 6409  make -j8 all
 6410  vim /etc/profile
 6411  make clean
 6412  vim Makefile.config
 6413  make 
 6414  make clean
 6415  make -j4
 6416  make clean
 6417  make
 6418  cd ../scripts/
 6419  python training.py --training_data_dir='/data/sunnycia/image_compression_challenge/dataset/KODAK' --valid_data_dir='' --train_prototxt='prototxt/cwic_train.prototxt' --pretrained_model='' 
 6420  cd ../caffe-master/
 6421  make -j8 pycaffe
 6422  cd ../scripts/
 6423  python training.py --training_data_dir='/data/sunnycia/image_compression_challenge/dataset/KODAK' --valid_data_dir='' --train_prototxt='prototxt/cwic_train.prototxt' --pretrained_model='' 
 6424  cd ../caffe-master/
 6425  make clean
 6426  cd ../scripts/
 6427  cd -
 6428  make
 6429  make clean
 6430  make
 6431  make clean
 6432  make
 6433   make clean
 6434  make
 6435  make clean
 6436  make
 6437  cd -
 6438  python training.py --training_data_dir='/data/sunnycia/image_compression_challenge/dataset/KODAK' --valid_data_dir='' --train_prototxt='prototxt/cwic_train.prototxt' --pretrained_model='' 
 6439  cd -
 6440  make pycaffe
 6441  cd -
 6442  python training.py --training_data_dir='/data/sunnycia/image_compression_challenge/dataset/KODAK' --valid_data_dir='' --train_prototxt='prototxt/cwic_train.prototxt' --pretrained_model='' 
 6443  cd -
 6444  source set_env.sh ../caffe-master 4
 6445  cd -
 6446  source set_env.sh ../caffe-master 4
 6447  python training.py --training_data_dir='/data/sunnycia/image_compression_challenge/dataset/KODAK' --valid_data_dir='' --train_prototxt='prototxt/cwic_train.prototxt' --pretrained_model='' 
 6448  cd -
 6449  make clean
 6450  make -j8 all && make -j8 pycaffe
 6451  cd -
 6452  python training.py --training_data_dir='/data/sunnycia/image_compression_challenge/dataset/KODAK' --valid_data_dir='' --train_prototxt='prototxt/cwic_train.prototxt' --pretrained_model='' 
 6453  cd -
 6454  make clean
 6455  make -j8 all && make -j8 pycaffe
 6456  cd -
 6457  python training.py --training_data_dir='/data/sunnycia/image_compression_challenge/dataset/KODAK' --valid_data_dir='' --train_prototxt='prototxt/cwic_train.prototxt' --pretrained_model='' 
 6458  cd -
 6459  make clean
 6460  make -j8 all && make -j8 pycaffe
 6461  cd -
 6462  python training.py --training_data_dir='/data/sunnycia/image_compression_challenge/dataset/KODAK' --valid_data_dir='' --train_prototxt='prototxt/cwic_train.prototxt' --pretrained_model='' 
 6463  cd -
 6464  make clean
 6465  make -j8 all && make -j8 pycaffe
 6466  cd -
 6467  python training.py --training_data_dir='/data/sunnycia/image_compression_challenge/dataset/KODAK' --valid_data_dir='' --train_prototxt='prototxt/cwic_train.prototxt' --pretrained_model='' 
 6468  cd -
 6469  make clean
 6470  make -j8 all && make -j8 pycaffe
 6471  cd -
 6472  python training.py --training_data_dir='/data/sunnycia/image_compression_challenge/dataset/KODAK' --valid_data_dir='' --train_prototxt='prototxt/cwic_train.prototxt' --pretrained_model='' 
 6473  cd -
 6474  make clean
 6475  make -j8 all && make -j8 pycaffe
 6476  cd -
 6477  python training.py --training_data_dir='/data/sunnycia/image_compression_challenge/dataset/KODAK' --valid_data_dir='' --train_prototxt='prototxt/cwic_train.prototxt' --pretrained_model='' 
 6478  cd -
 6479  make clean
 6480  make -j16 all && make -j16 pycaffe
 6481  cd -
 6482  python training.py --training_data_dir='/data/sunnycia/image_compression_challenge/dataset/KODAK' --valid_data_dir='' --train_prototxt='prototxt/cwic_train.prototxt' --pretrained_model='' 
 6483  cd -
 6484  make clean
 6485  make -j16 all && make -j16 pycaffe
 6486  make clean
 6487  make -j16 all && make -j16 pycaffe
 6488  cd -
 6489  python training.py --training_data_dir='/data/sunnycia/image_compression_challenge/dataset/KODAK' --valid_data_dir='' --train_prototxt='prototxt/cwic_train.prototxt' --pretrained_model='' 
 6490  cd -
 6491  make clean
 6492  make -j16 all && make -j16 pycaffe
 6493  cd -
 6494  python training.py --training_data_dir='/data/sunnycia/image_compression_challenge/dataset/KODAK' --valid_data_dir='' --train_prototxt='prototxt/cwic_train.prototxt' --pretrained_model='' 
 6495  cd -
 6496  make clean
 6497  make -j16 all && make -j16 pycaffe
 6498  make clean
 6499  make -j16 all && make -j16 pycaffe
 6500  make clean
 6501  make -j16 all && make -j16 pycaffe
 6502  make clean
 6503  make -j16 all && make -j16 pycaffe
 6504  make clean
 6505  make -j16 all && make -j16 pycaffe
 6506  make clean
 6507  make -j16 all && make -j16 pycaffe
 6508  cd -
 6509  python training.py --training_data_dir='/data/sunnycia/image_compression_challenge/dataset/KODAK' --valid_data_dir='' --train_prototxt='prototxt/cwic_train.prototxt' --pretrained_model='' 
 6510  cd -
 6511  make clean
 6512  make -j16 all && make -j16 pycaffe
 6513  make clean
 6514  make -j16 all && make -j16 pycaffe
 6515  cd -
 6516  python training.py --training_data_dir='/data/sunnycia/image_compression_challenge/dataset/KODAK' --valid_data_dir='' --train_prototxt='prototxt/cwic_train.prototxt' --pretrained_model='' 
 6517  nvidia-smi
 6518  cd -
 6519  make clean
 6520  make -j16 all && make -j16 pycaffe
 6521  cd -
 6522  python training.py --training_data_dir='/data/sunnycia/image_compression_challenge/dataset/KODAK' --valid_data_dir='' --train_prototxt='prototxt/cwic_train.prototxt' --pretrained_model='' 
 6523  cd -
 6524  make clean
 6525  make -j16 all && make -j16 pycaffe
 6526  cd -
 6527  python training.py --training_data_dir='/data/sunnycia/image_compression_challenge/dataset/KODAK' --valid_data_dir='' --train_prototxt='prototxt/cwic_train.prototxt' --pretrained_model='' 
 6528  clear && clear
 6529  python training.py --training_data_dir='/data/sunnycia/image_compression_challenge/dataset/CLIC_PRO' --valid_data_dir='' --train_prototxt='prototxt/cwic_train.prototxt' --pretrained_model='' 
 6530  top
 6531  su
 6532  python
 6533  su
 6534  python
 6535  vim ~/.bashrc
 6536  ldconfig
 6537  python
 6538  cd /data/sunnycia/image_compression_challenge/Train/scripts
 6539  history > history
 6540  su
 6541  python training.py --training_data_dir='/data/sunnycia/image_compression_challenge/dataset/CLIC_PRO' --valid_data_dir='' --train_prototxt='prototxt/cwic_train.prototxt' --pretrained_model='' --snapshot_dir='cwic_training_output_fixw0001'
 6542  python
 6543  cd ..
 6544  ls
 6545  cd caffe-master/
 6546  make clean
 6547  make -j16 all && make -j8 pycaffe
 6548  vim Makefile.config
 6549  make -j16 all && make -j8 pycaffe
 6550  make clean
 6551  make -j16 all && make -j8 pycafef
 6552  make clean
 6553  make -j8 all
 6554  top
 6555  nvidia-smi
 6556  make
 6557  make -j8
 6558  boost
 6559  make clean
 6560  make -j8
 6561  source ~/.bashrc
 6562  make clean
 6563  make -j8 all
 6564  vim ~/.bashrc
 6565  source ~/.bashrc
 6566  make -j8 all
 6567  vim ~/.bashrc
 6568  source ~/.bashrc
 6569  vim /etc/profile
 6570  su
 6571  clear && clear
 6572  python
 6573  top
 6574  nvidia-smi
 6575  top
 6576  python
 6577  ls /usr/local
 6578  vim /etc/profile
 6579  vim ~?.bashrc
 6580  vim ~/.bashrc
 6581  source ~/.bashrc
 6582  cd /data/sunnycia/image_compression_challenge/_Train/ImageCompression
 6583  ls
 6584  python read_caffemodel.py 
 6585  clear && clear
 6586  top
 6587  nvidia-smi
 6588  clear && clear
 6589  top
 6590  nvidia-smi
 6591  cd /data/sunnycia/image_compression_challenge/_Train/ImageCompression
 6592  cd /data/sunnycia/image_compression_challenge/Train/scripts
 6593  python inference.py 
 6594  source set_env.sh ../caffe-master 4
 6595  python inference.py 
 6596  python visualize_featuremap.py 
 6597  python visualize_featuremap.py --image_path='kodim16-imp.png' --deploypath='prototxt/cwic_deploy.prototxt' --modelpath='cwic_training_output_fixw0001_ADAM/snapshot-_iter_170000.caffemodel'
 6598  python visualize_featuremap.py --image_path='kodim16.png' --deploypath='prototxt/cwic_deploy.prototxt' --modelpath='cwic_training_output_fixw0001_ADAM/snapshot-_iter_170000.caffemodel'
 6599  python visualize_featuremap.py --image_path='kodim16.png' --deploypath='prototxt/cwic_train.prototxt' --modelpath='cwic_training_output_fixw0001_ADAM/snapshot-_iter_170000.caffemodel'
 6600  python inference.py 
 6601  python visualize_featuremap.py --image_path='kodim16.png' --deploypath='prototxt/cwic_train.prototxt' --modelpath='cwic_training_output_fixw0001_ADAM/snapshot-_iter_170000.caffemodle'
 6602  python visualize_featuremap.py --image_path='kodim16.png' --deploypath='prototxt/cwic_train.prototxt' --modelpath='cwic_training_output_fixw0001_ADAM/cwic_training_output_fixw0001_ADAM/snapshot-_iter_60000.caffemodel'
 6603  python visualize_featuremap.py --image_path='kodim16.png' --deploypath='prototxt/cwic_train.prototxt' --modelpath='cwic_training_output_fixw0001_ADAM/snapshot-_iter_60000.caffemodel'
 6604  python visualize_featuremap.py --image_path='kodim16.png' --deploypath='prototxt/cwic_train.prototxt' --modelpath='cwic_training_output_fixw0001_ADAM/cwic_training_output_fixw0001_ADAM/snapshot-_iter_60000.caffemodel'
 6605  python visualize_featuremap.py --image_path='kodim16.png' --deploypath='prototxt/cwic_train.prototxt' --modelpath='cwic_training_output_fixw0001_ADAM/snapshot-_iter_60000.caffemodel'
 6606  python visualize_featuremap.py --image_path='kodim16.png' --deploypath='prototxt/cwic_deploy.prototxt' --modelpath='cwic_training_output_fixw0001_ADAM/snapshot-_iter_60000.caffemodel'
 6607  python inference.py 
 6608  cat ~/.bashrc
 6609  python visualize_featuremap.py --image_path='kodim23.png'
 6610  python visualize_featuremap.py --image_path='kodim18.png'
 6611  cd /data/sunnycia/image_compression_challenge/Train/scripts
 6612  source set_env.sh ../caffe-master 6
 6613  clear && clear
 6614  python training.py --training_data_dir='/data/sunnycia/image_compression_challenge/dataset/CLIC_MOB' --valid_data_dir='' --train_prototxt='prototxt/cwic_train.prototxt' --pretrained_model='' --snapshot_dir='cwic_training_output_fixw0001_ADAM_cmprto-048' --batch=16  --compression_ratio=0.48
 6615  clear && clear
 6616  python training.py --training_data_dir='/data/sunnycia/image_compression_challenge/dataset/CLIC_MOB' --valid_data_dir='' --train_prototxt='prototxt/cwic_train.prototxt' --pretrained_model='' --snapshot_dir='cwic_training_output_fixw0001_ADAM_cmprto-048' --batch=16  --compression_ratio=0.48 --use_snapshot='cwic_training_output_fixw0001_ADAM_cmprto-048/snapshot-_iter_290000.solverstate'
 6617  clear && clear
 6618  python training.py --training_data_dir='/data/sunnycia/image_compression_challenge/dataset/CLIC_MOB' --valid_data_dir='' --train_prototxt='prototxt/cwic_train.prototxt' --snapshot_dir='cwic_training_output_fixw00001_ADAM_cmprto-048' --compression_ratio=0.48 --pretrained_model='cwic_training_output_fixw0001_ADAM_cmprto-048/snapshot-_iter_200000.solverstate' --base_lr=0.00001 --batch=64
 6619  clear && clear
 6620  python training.py --training_data_dir='/data/sunnycia/image_compression_challenge/dataset/CLIC_MOB' --valid_data_dir='' --train_prototxt='prototxt/cwic_train.prototxt' --snapshot_dir='cwic_training_output_fixw00001_ADAM_cmprto-048' --compression_ratio=0.48 --pretrained_model='cwic_training_output_fixw0001_ADAM_cmprto-048/snapshot-_iter_200000.caffemodel' --base_lr=0.00001 --batch=64
 6621  cd /data/sunnycia/image_compression_challenge/Train/scripts
 6622  source set_env.sh ../caffe-master 5
 6623  python inference.py 
 6624  clear && clear
 6625  python training.py --training_data_dir='/data/sunnycia/image_compression_challenge/dataset/CLIC_MOB' --valid_data_dir='' --train_prototxt='prototxt/cwic_train.prototxt' --pretrained_model='' --snapshot_dir='cwic_training_output_fixw0001_ADAM_cmprto-011' --batch=16  --compression_ratio=0.11
 6626  clear && clear
 6627  source set_env.sh ../caffe-master 5
 6628  python training.py --training_data_dir='/data/sunnycia/image_compression_challenge/dataset/CLIC_MOB' --valid_data_dir='' --train_prototxt='prototxt/cwic_train.prototxt' --pretrained_model='' --snapshot_dir='cwic_training_output_fixw0001_ADAM_cmprto-011' --batch=16  --compression_ratio=0.11
 6629  clear && clear
 6630  python training.py --training_data_dir='/data/sunnycia/image_compression_challenge/dataset/CLIC_MOB' --valid_data_dir='' --train_prototxt='prototxt/cwic_train.prototxt' --pretrained_model='' --snapshot_dir='cwic_training_output_fixw0001_ADAM_cmprto-011' --batch=16  --compression_ratio=0.11 --use_snapshot='cwic_training_output_fixw0001_ADAM_cmprto-011/snapshot-_iter_20000.solverstate'
 6631  clear && clear
 6632  python training.py --training_data_dir='/data/sunnycia/image_compression_challenge/dataset/CLIC_MOB' --valid_data_dir='' --train_prototxt='prototxt/cwic_train.prototxt' --snapshot_dir='cwic_training_output_fixw00001_ADAM_cmprto-011' --compression_ratio=0.11 --pretrained_model='cwic_training_output_fixw00001_ADAM_cmprto-011/snapshot-_iter_200000.caffemodel' --base_lr=0.00001 --batch=64
 6633  clear && clear
 6634  python training.py --training_data_dir='/data/sunnycia/image_compression_challenge/dataset/CLIC_MOB' --valid_data_dir='' --train_prototxt='prototxt/cwic_train.prototxt' --snapshot_dir='cwic_training_output_fixw00001_ADAM_cmprto-011' --compression_ratio=0.11 --pretrained_model='cwic_training_output_fixw0001_ADAM_cmprto-011/snapshot-_iter_200000.caffemodel' --base_lr=0.00001 --batch=64
 6635  nvidia-smi
 6636  cd /data/sunnycia/image_compression_challenge/Train/scripts
 6637  clear && clear
 6638  python training.py --training_data_dir='/data/sunnycia/image_compression_challenge/datas      et/CLIC_MOB' --valid_data_dir='' --train_prototxt='prototxt/cwic_train.prototxt' --pretrained_model='' --snapshot_dir=      'cwic_training_output_fixw0001_ADAM_cmprto-018' --batch=16  --compression_ratio=0.18
 6639  python training.py --training_data_dir='/data/sunnycia/image_compression_challenge/dataset/CLIC_MOB' --valid_data_dir='' --train_prototxt='prototxt/cwic_train.prototxt' --pretrained_model='' --snapshot_dir='cwic_training_output_fixw0001_ADAM_cmprto-018' --batch=16  --compression_ratio=0.18
 6640  source set_env.sh ../caffe-master 6
 6641  python training.py --training_data_dir='/data/sunnycia/image_compression_challenge/dataset/CLIC_MOB' --valid_data_dir='' --train_prototxt='prototxt/cwic_train.prototxt' --pretrained_model='' --snapshot_dir='cwic_training_output_fixw0001_ADAM_cmprto-018' --batch=16  --compression_ratio=0.18
 6642  source set_env.sh ../caffe-master 4
 6643  clear && clear
 6644  python training.py --training_data_dir='/data/sunnycia/image_compression_challenge/dataset/CLIC_MOB' --valid_data_dir='' --train_prototxt='prototxt/cwic_train.prototxt' --pretrained_model='' --snapshot_dir='cwic_training_output_fixw0001_ADAM_cmprto-018' --batch=16  --compression_ratio=0.18
 6645  clear && clear
 6646  python training.py --training_data_dir='/data/sunnycia/image_compression_challenge/dataset/CLIC_MOB' --valid_data_dir='' --train_prototxt='prototxt/cwic_train.prototxt' --pretrained_model='' --snapshot_dir='cwic_training_output_fixw0001_ADAM_cmprto-018' --batch=16  --compression_ratio=0.18 --use_snapshot='cwic_training_output_fixw0001_ADAM_cmprto-018/snapshot-_iter_120000.solverstate'
 6647  clear && clear
 6648  python training.py --training_data_dir='/data/sunnycia/image_compression_challenge/dataset/CLIC_MOB' --valid_data_dir='' --train_prototxt='prototxt/cwic_train.prototxt' --snapshot_dir='cwic_training_output_fixw00001_ADAM_cmprto-018' --compression_ratio=0.18 --pretrained_model='cwic_training_output_fixw00001_ADAM_cmprto-018/snapshot-_iter_200000.caffemodel' --base_lr=0.00001 --batch=64
 6649  clear && clear
 6650  python training.py --training_data_dir='/data/sunnycia/image_compression_challenge/dataset/CLIC_MOB' --valid_data_dir='' --train_prototxt='prototxt/cwic_train.prototxt' --snapshot_dir='cwic_training_output_fixw00001_ADAM_cmprto-018' --compression_ratio=0.18 --pretrained_model='cwic_training_output_fixw0001_ADAM_cmprto-018/snapshot-_iter_200000.caffemodel' --base_lr=0.00001 --batch=64
 6651  cd /data/sunnycia/image_compression_challenge/Train/scripts
 6652  clear && clear
 6653  python training.py --training_data_dir='/data/sunnycia/image_compression_challenge/dataset/CLIC_MOB' --valid_data_dir='' --train_prototxt='prototxt/cwic_train.prototxt' --pretrained_model='' --snapshot_dir='cwic_training_output_fixw0001_ADAM_cmprto-018' --batch=16  --compression_ratio=0.18
 6654  source set_env.sh ../caffe-master 6
 6655  python training.py --training_data_dir='/data/sunnycia/image_compression_challenge/dataset/CLIC_MOB' --valid_data_dir='' --train_prototxt='prototxt/cwic_train.prototxt' --pretrained_model='' --snapshot_dir='cwic_training_output_fixw0001_ADAM_cmprto-018' --batch=16  --compression_ratio=0.18
 6656  python training.py --training_data_dir='/data/sunnycia/image_compression_challenge/dataset/CLIC_MOB' --valid_data_dir='' --train_prototxt='prototxt/cwic_train.prototxt' --pretrained_model='' --snapshot_dir='cwic_training_output_fixw0001_ADAM_cmprto-028' --batch=16  --compression_ratio=0.28
 6657  source set_env.sh ../caffe-master 3
 6658  clear && clear
 6659  python training.py --training_data_dir='/data/sunnycia/image_compression_challenge/dataset/CLIC_MOB' --valid_data_dir='' --train_prototxt='prototxt/cwic_train.prototxt' --pretrained_model='' --snapshot_dir='cwic_training_output_fixw0001_ADAM_cmprto-028' --batch=16  --compression_ratio=0.28
 6660  clear && clear
 6661  python training.py --training_data_dir='/data/sunnycia/image_compression_challenge/dataset/CLIC_MOB' --valid_data_dir='' --train_prototxt='prototxt/cwic_train.prototxt' --pretrained_model='' --snapshot_dir='cwic_training_output_fixw0001_ADAM_cmprto-028' --batch=16  --compression_ratio=0.28 --use_snapshot='/snapshot-_iter_220000.solverstate'
 6662  python training.py --training_data_dir='/data/sunnycia/image_compression_challenge/dataset/CLIC_MOB' --valid_data_dir='' --train_prototxt='prototxt/cwic_train.prototxt' --pretrained_model='' --snapshot_dir='cwic_training_output_fixw0001_ADAM_cmprto-028' --batch=16  --compression_ratio=0.28 --use_snapshot='cwic_training_output_fixw0001_ADAM_cmprto-028/snapshot-_iter_220000.solverstate'
 6663  clear && clear
 6664  python training.py --training_data_dir='/data/sunnycia/image_compression_challenge/dataset/CLIC_MOB' --valid_data_dir='' --train_prototxt='prototxt/cwic_train.prototxt' --snapshot_dir='cwic_training_output_fixw00001_ADAM_cmprto-028' --compression_ratio=0.28 --pretrained_model='cwic_training_output_fixw0001_ADAM_cmprto-028/snapshot-_iter_200000.solverstate' --base_lr=0.00001 --batch=64
 6665  clear && clear
 6666  python training.py --training_data_dir='/data/sunnycia/image_compression_challenge/dataset/CLIC_MOB' --valid_data_dir='' --train_prototxt='prototxt/cwic_train.prototxt' --snapshot_dir='cwic_training_output_fixw00001_ADAM_cmprto-028' --compression_ratio=0.28 --pretrained_model='cwic_training_output_fixw0001_ADAM_cmprto-028/snapshot-_iter_200000.caffemodel' --base_lr=0.00001 --batch=64
 6667  cd /data/sunnycia/image_compression_challenge/Train/scripts
 6668  nvidia-smi
 6669  source set_env.sh ../caffe-master 5
 6670  clear && clear
 6671  python training.py --training_data_dir='/data/sunnycia/image_compression_challenge/dataset/CLIC_MOB' --valid_data_dir='' --train_prototxt='prototxt/cwic_train.prototxt' --pretrained_model='' --snapshot_dir='cwic_training_output_fixw0001_ADAM_cmprto-068' --batch=16  --compression_ratio=0.68
 6672  clear && clear
 6673  source set_env.sh ../caffe-master 7
 6674  python training.py --training_data_dir='/data/sunnycia/image_compression_challenge/dataset/CLIC_MOB' --valid_data_dir='' --train_prototxt='prototxt/cwic_train.prototxt' --pretrained_model='' --snapshot_dir='cwic_training_output_fixw0001_ADAM_cmprto-068' --batch=16  --compression_ratio=0.68
 6675  clear && clear
 6676  python training.py --training_data_dir='/data/sunnycia/image_compression_challenge/dataset/CLIC_MOB' --valid_data_dir='' --train_prototxt='prototxt/cwic_train.prototxt' --pretrained_model='' --snapshot_dir='cwic_training_output_fixw0001_ADAM_cmprto-068' --batch=16  --compression_ratio=0.68 --use_shapshot='cwic_training_output_fixw0001_ADAM_cmprto-068/snapshot-_iter_20000.solverstate'
 6677  python training.py --training_data_dir='/data/sunnycia/image_compression_challenge/dataset/CLIC_MOB' --valid_data_dir='' --train_prototxt='prototxt/cwic_train.prototxt' --pretrained_model='' --snapshot_dir='cwic_training_output_fixw0001_ADAM_cmprto-068' --batch=16  --compression_ratio=0.68 --use_snapshot='cwic_training_output_fixw0001_ADAM_cmprto-068/snapshot-_iter_20000.solverstate'
 6678  clear && clear
 6679  python training.py --training_data_dir='/data/sunnycia/image_compression_challenge/dataset/CLIC_MOB' --valid_data_dir='' --train_prototxt='prototxt/cwic_train.prototxt' --pretrained_model='' --snapshot_dir='cwic_training_output_fixw0001_ADAM_cmprto-068' --batch=16  --compression_ratio=0.68 --use_snapshot='cwic_training_output_fixw0001_ADAM_cmprto-068/snapshot-_iter_20000.solverstate'
 6680  clear && clear
 6681  python training.py --training_data_dir='/data/sunnycia/image_compression_challenge/dataset/CLIC_MOB' --valid_data_dir='' --train_prototxt='prototxt/cwic_train.prototxt' --snapshot_dir='cwic_training_output_fixw00001_ADAM_cmprto-068' --compression_ratio=0.68 --pretrained_model='cwic_training_output_fixw0001_ADAM_cmprto-068/snapshot-_iter_200000.caffemodel' --base_lr=0.00001 --batch=64
 6682  python
 6683  nvidia-smi
 6684  cd /data/sunnycia/image_compression_challenge/Train/scripts
 6685  python training.py --training_data_dir='/data/sunnycia/image_compression_challenge/dataset/CLIC_MOB' --valid_data_dir='' --train_prototxt='prototxt/cwic_train.prototxt' --pretrained_model='' --snapshot_dir='cwic_training_output_fixw0001_ADAM' --batch=16
 6686  source set_env.sh ../caffe-master 5
 6687  clear && clear
 6688  python training.py --training_data_dir='/data/sunnycia/image_compression_challenge/dataset/CLIC_MOB' --valid_data_dir='' --train_prototxt='prototxt/cwic_train.prototxt' --pretrained_model='' --snapshot_dir='cwic_training_output_fixw0001_ADAM' --batch=16
 6689  source set_env.sh ../caffe-master 4
 6690  clear && clear
 6691  python training.py --training_data_dir='/data/sunnycia/image_compression_challenge/dataset/CLIC_MOB' --valid_data_dir='' --train_prototxt='prototxt/cwic_train.prototxt' --pretrained_model='' --snapshot_dir='cwic_training_output_fixw0001_ADAM' --batch=16
 6692  python training.py --training_data_dir='/data/sunnycia/image_compression_challenge/dataset/CLIC_MOB' --valid_data_dir='' --train_prototxt='prototxt/cwic_train.prototxt' --pretrained_model='' --snapshot_dir='cwic_training_output_fixw0001_ADAM' --batch=16 --use_snapshot='cwic_training_output_fixw0001_ADAM/snapshot-_iter_110000.solverstate'
 6693  clear && clear
 6694  python training.py --training_data_dir='/data/sunnycia/image_compression_challenge/dataset/CLIC_MOB' --valid_data_dir='' --train_prototxt='prototxt/cwic_train.prototxt' --pretrained_model='' --snapshot_dir='cwic_training_output_fixw0001_ADAM' --batch=16 --use_snapshot='cwic_training_output_fixw0001_ADAM/snapshot-_iter_110000.solverstate'
 6695  clear && clear
 6696  python training.py --training_data_dir='/data/sunnycia/image_compression_challenge/dataset/CLIC_MOB' --valid_data_dir='' --train_prototxt='prototxt/cwic_train.prototxt' --pretrained_model='' --snapshot_dir='cwic_training_output_fixw0001_ADAM' --batch=16 --use_snapshot='cwic_training_output_fixw0001_ADAM/snapshot-_iter_110000.solverstate'
 6697  clear && clear
 6698  python training.py --training_data_dir='/data/sunnycia/image_compression_challenge/dataset/CLIC_MOB' --valid_data_dir='' --train_prototxt='prototxt/cwic_train.prototxt' --pretrained_model='' --snapshot_dir='cwic_training_output_fixw0001_ADAM' --batch=16 --use_snapshot='cwic_training_output_fixw0001_ADAM/snapshot-_iter_110000.solverstate'
 6699  clear && clear
 6700  python training.py --training_data_dir='/data/sunnycia/image_compression_challenge/dataset/CLIC_MOB' --valid_data_dir='' --train_prototxt='prototxt/cwic_train.prototxt' --pretrained_model='' --snapshot_dir='cwic_training_output_fixw0001_ADAM' --batch=16 --use_snapshot='cwic_training_output_fixw0001_ADAM/snapshot-_iter_110000.solverstate'
 6701  clear && clear
 6702  python training.py --training_data_dir='/data/sunnycia/image_compression_challenge/dataset/CLIC_MOB' --valid_data_dir='' --train_prototxt='prototxt/cwic_train.prototxt' --pretrained_model='' --snapshot_dir='cwic_training_output_fixw0001_ADAM' --batch=16 --use_snapshot='cwic_training_output_fixw0001_ADAM/snapshot-_iter_110000.solverstate'
 6703  clear && clear
 6704  python training.py --training_data_dir='/data/sunnycia/image_compression_challenge/dataset/CLIC_MOB' --valid_data_dir='' --train_prototxt='prototxt/cwic_train.prototxt' --snapshot_dir='cwic_training_output_fixw00001_ADAM' --pretrained_model='cwic_training_output_fixw0001_ADAM/snapshot-_iter_200000.caffemodel' --base_lr=0.00001 --batch=64
 6705  cd /data/sunnycia/image_compression_challenge/Train/caffe-master
 6706  make clean
 6707  make -j8 all
 6708  vim Makefile.config
 6709  make clean
 6710  make -j8 all
 6711  cd .
 6712  cd ..
 6713  cd scripts/
 6714  clear && clear
 6715  python
 6716  vim ~/.bashrc
 6717  clear
 6718  source set_env.sh ../caffe-master 7
 6719  nvidia-smi
 6720  python
 6721  cd ../caffe-master/
 6722  make pycaffe
 6723  cd -
 6724  clear
 6725  history > history
 6726  top
 6727  python training.py --training_data_dir='/data/sunnycia/image_compression_challenge/dataset/CLIC_MOB' --valid_data_dir='' --train_prototxt='prototxt/cwic_train.prototxt' --pretrained_model='' --snapshot_dir='cwic_training_output_fixw0001'
 6728  clear && clear
 6729  python training.py --training_data_dir='/data/sunnycia/image_compression_challenge/dataset/KODAK' --valid_data_dir='' --train_prototxt='prototxt/cwic_train.prototxt' --pretrained_model='' --snapshot_dir='cwic_training_output_fixw0001'
 6730  clear && clear
 6731  python
 6732  clear && clear
 6733  python training.py --training_data_dir='/data/sunnycia/image_compression_challenge/dataset/KODAK' --valid_data_dir='' --train_prototxt='prototxt/cwic_train.prototxt' --pretrained_model='' --snapshot_dir='cwic_training_output_fixw0001' --batch=1
 6734  clear && clear
 6735  python training.py --training_data_dir='/data/sunnycia/image_compression_challenge/dataset/CLIC_MOB' --valid_data_dir='' --train_prototxt='prototxt/cwic_train.prototxt' --pretrained_model='' --snapshot_dir='cwic_training_output_fixw0001' --batch=16
 6736  source set_env.sh ../caffe-master 4
 6737  clear && clear
 6738  python training.py --training_data_dir='/data/sunnycia/image_compression_challenge/dataset/CLIC_MOB' --valid_data_dir='' --train_prototxt='prototxt/cwic_train.prototxt' --pretrained_model='' --snapshot_dir='cwic_training_output_fixw0001' --batch=16
 6739  clear && clear
 6740  python training.py --training_data_dir='/data/sunnycia/image_compression_challenge/dataset/CLIC_MOB' --valid_data_dir='' --train_prototxt='prototxt/cwic_train.prototxt' --pretrained_model='' --snapshot_dir='cwic_training_output_fixw0001' --batch=16
 6741  clear && clear
 6742  top
 6743  nvidia-smi
 6744  top
 6745  free -h
 6746  top
 6747  nvidia-smi
 6748  top
 6749  nvidia-smi
 6750  python visualization_weight.py --modelpath='cwic_training_output_fixw0001_ADAM_cmprto-028/snapshot-_iter_220000.caffemodel' --deploypath='prototxt/cwic_deploy.prototxt' --outputpath='conv1.jpg' --type='2d' --layer='conv1'
 6751  python visualization_weight.py --modelpath='cwic_training_output_fixw0001_ADAM_cmprto-028/snapshot-_iter_220000.caffemodel' --deploypath='prototxt/cwic_deploy.prototxt' --outputpath='conv1.jpg' --type='2d' --layer='conv2'
 6752  python visualization_weight.py --modelpath='cwic_training_output_fixw0001_ADAM_cmprto-028/snapshot-_iter_220000.caffemodel' --deploypath='prototxt/cwic_deploy.prototxt' --outputpath='conv1.jpg' --type='2d' --layer='conv3'
 6753  python visualization_weight.py --modelpath='cwic_training_output_fixw0001_ADAM_cmprto-028/snapshot-_iter_220000.caffemodel' --deploypath='prototxt/cwic_deploy.prototxt' --outputpath='conv1.jpg' --type='2d' --layer='conv4'
 6754  python visualization_weight.py --modelpath='cwic_training_output_fixw0001_ADAM_cmprto-028/snapshot-_iter_220000.caffemodel' --deploypath='prototxt/cwic_deploy.prototxt' --outputpath='conv1.jpg' --type='2d' --layer='blk1_branch2b'
 6755  python visualization_weight.py --modelpath='cwic_training_output_fixw0001_ADAM_cmprto-028/snapshot-_iter_220000.caffemodel' --deploypath='prototxt/cwic_deploy.prototxt' --outputpath='conv1.jpg' --type='2d' --layer='blk1_branch2c'
 6756  python visualization_weight.py --modelpath='cwic_training_output_fixw0001_ADAM_cmprto-028/snapshot-_iter_220000.caffemodel' --deploypath='prototxt/cwic_deploy.prototxt' --outputpath='conv1.jpg' --type='2d' --layer='conv1'
 6757  cd /data/sunnycia/image_compression_challenge/Train/scripts
 6758  clear
 6759  cd /data/sunnycia/image_compression_challenge/_Train/ImageCompression
 6760  python create_lmdb_for_binary_codes.py 
 6761  clear && clear
 6762  nvidia-smi
 6763  source set_env.sh my_caffe-master 6
 6764  python create_lmdb_for_binary_codes.py 
 6765  python test_entropy_encoder.py 
 6766  python create_lmdb_for_binary_codes.py 
 6767  python test_entropy_encoder.py 
 6768  python create_lmdb_for_binary_codes.py 
 6769  cd /data/sunnycia/image_compression_challenge/_Train/ImageCompression/my_caffe-master/src/caffe/layers
 6770  make clean
 6771  cd ../../..
 6772  make clean
 6773  make -j8 all && make -j4 pycaffe
 6774    make clean
 6775  make all
 6776  vim Makefile.config
 6777  make clean
 6778  make
 6779   source ~/.bashrc
 6780  make
 6781  make clean
 6782   source ~/.bashrc
 6783  make
 6784  $CUDA_HOME
 6785  vim Makefile
 6786  vim Makefile.config
 6787  make clean
 6788  make
 6789  clear && clear
 6790  cd -
 6791  cd /data/sunnycia/image_compression_challenge/_Train/ImageCompression
 6792  python test_entropy_encoder.py 
 6793  cd -
 6794  cd my_caffe-master/
 6795  make pycaffe
 6796  cd ..
 6797  python test_entropy_encoder.py 
 6798  python create_lmdb_for_binary_codes.py 
 6799  nvidia-smi
 6800  source set_env.sh my_caffe-master 7
 6801  python create_lmdb_for_binary_codes.py 
 6802  cd -
 6803  make clean
 6804  make -j8 all && make pycaffe
 6805  cd -
 6806  python create_lmdb_for_binary_codes.py 
 6807  nvidia-smi
 6808  source set_env.sh my_caffe-master 5
 6809  python create_lmdb_for_binary_codes.py 
 6810  cd -
 6811  make clean
 6812  make -j8 all && make pycaffe
 6813  cd -
 6814  python create_lmdb_for_binary_codes.py 
 6815  clear && clear
 6816  python create_lmdb_for_binary_codes.py 
 6817  cd my_caffe-master/
 6818  make clean
 6819  make -j8 all && make pycaffe
 6820  ssh chenzihao@172.31.70.212
 6821  clear && clear
 6822  cd ..
 6823  python create_lmdb_for_binary_codes.py 
 6824   python test_entropy_encoder.py 
 6825  clear && clear
 6826  python test_entropy_encoder.py 
 6827  vim ~/.bashrc
 6828  source ~/.bashrc
 6829  python
 6830  ssh chenzihao@172.31.70.212
 6831  clear
 6832  cd my_caffe-master/
 6833  make clean
 6834  python -m tensorflow.tensorboard --logdir=./results/
 6835  clear
 6836  tensorboard --logdir=./results/
 6837  ssh chenzihao@172.31.70.212
 6838  clear && clear
 6839  make -j8 all
 6840  cd ..
 6841  python create_lmdb_for_binary_codes.py 
 6842  cd -
 6843  make pycaffe
 6844  cd -
 6845  python create_lmdb_for_binary_codes.py 
 6846  su
 6847  cd my_caffe-master/
 6848  make clean
 6849  make -j8 all && make pycaffe
 6850  make clean
 6851  make -j8 all && make pycaffe
 6852  cd ..
 6853  python create_lmdb_for_binary_codes.py 
 6854  cd -
 6855  make clean
 6856  make -j8 all && make pycaffe
 6857  make clean
 6858  make -j8 all && make pycaffe
 6859  cd -
 6860  python create_lmdb_for_binary_codes.py 
 6861  cd my_caffe-master/
 6862  make clean
 6863  make -j8 all && make pycaffe
 6864  make clean
 6865  make -j8 all && make pycaffe
 6866  cd -
 6867  python create_lmdb_for_binary_codes.py 
 6868  cd -
 6869  make clean
 6870  make -j8 all && make pycaffe
 6871  cd -
 6872  python create_lmdb_for_binary_codes.py 
 6873  python hack_entropy_pack.py 
 6874  clear && clear
 6875  python hack_entropy_pack.py > hack_output.txt
 6876  python create_lmdb_for_binary_codes.py 
 6877  python binary_encoder.py
 6878  python create_lmdb_for_binary_codes.py 
 6879  cd /data/sunnycia/image_compression_challenge/Train/scripts
 6880  source set_env.sh ../caffe-master 5
 6881  python training.py --training_data_dir='/data/sunnycia/image_compression_challenge/dataset/CLIC_MOB' --valid_data_dir='' --train_prototxt='prototxt/cwic_train.prototxt' --snapshot_dir='cwic_training_output_fixw00001_ADAM_cmprto-018' --compression_ratio=0.18 --use_snapshot='cwic_training_output_fixw00001_ADAM_cmprto-018/snapshot-_iter_90000.solverstate' --base_lr=0.00001 --batch=64
 6882  top
 6883  nvidia-smi
 6884  cd /data/sunnycia/image_compression_challenge/Train/scripts
 6885  history > history
 6886  python training.py --training_data_dir='/data/sunnycia/image_compression_challenge/dataset/CLIC_MOB' --valid_data_dir='' --train_prototxt='prototxt/cwic_train.prototxt' --snapshot_dir='cwic_training_output_fixw00001_ADAM' --pretrained_model='cwic_training_output_fixw0001_ADAM/snapshot-_iter_200000.caffemodel' --base_lr=0.00001 --batch=64
 6887  clear && clear
 6888  source set_env.sh ../caffe-master 4
 6889  python training.py --training_data_dir='/data/sunnycia/image_compression_challenge/dataset/CLIC_MOB' --valid_data_dir='' --train_prototxt='prototxt/cwic_train.prototxt' --snapshot_dir='cwic_training_output_fixw00001_ADAM' --use_snapshot='cwic_training_output_fixw00001_ADAM/snapshot-_iter_80000.solverstate' --base_lr=0.00001 --batch=64
 6890  vim ~/.bashrc
 6891  pwd
 6892  ssh chenzihao@172.31.70.212
 6893  ssh wangxu@172.31.70.212
 6894  ssh chenzihao@172.31.70.212
 6895  clear
 6896  cd /data/sunnycia/image_compression_challenge/_Train/ImageCompression
 6897  python create_lmdb_for_binary_codes.py 
 6898  source set_env.sh ./my_caffe-master 7
 6899  python create_lmdb_for_binary_codes.py 
 6900  clear
 6901  cd /data/sunnycia/image_compression_challenge/_Train/TrimmedConvolution
 6902  top
 6903  nvidia-smi
 6904  clear
 6905  cd /data/sunnycia/image_compression_challenge/_Train/TrimmedConvolution/experiment1\
 6906  python train.py 
 6907  python test.py 
 6908  cd cmp/
 6909  unrar -e trained_model_for_binary_codes.rar 
 6910  unrar trained_model_for_binary_codes.rar 
 6911  unrar x  trained_model_for_binary_codes.rar 
 6912  cd -
 6913  python test.py 
 6914  cd ..
 6915  unzip caffe-master.zip 
 6916  cd caffe-master/
 6917   make clean
 6918  make -j8 all && make pycaffe
 6919  pwd
 6920  make -j8 all && make pycaffe
 6921  make clean
 6922  make
 6923  make clean
 6924  make
 6925  make clean
 6926  make -j8 all && make pycaffe
 6927  makeclean
 6928  make clean
 6929  make -j8 all && make pycaffe
 6930  vim Makefile.config
 6931  make clean
 6932  make -j8 all && make pycaffe
 6933  cd ..
 6934  cd /data/sunnycia/image_compression_challenge/_Train/TrimmedConvolution/experiment1
 6935  source  set_env.sh ../caffe-master 7
 6936  vim set_env.sh 
 6937  source  set_env.sh ../caffe-master 7
 6938  nvidia-smi
 6939  top
 6940  python test.py 
 6941  python extract_data.py 
 6942  cd ../caffe-master/
 6943  make clean
 6944  make -j8 all && make pycaffe
 6945  cd -
 6946  python extract_data.py 
 6947  top
 6948  nvidia-smi
 6949  ls
 6950  python generate_lmdb_image_dataset.py --image_dir='/data/sunnycia/image_compression_challenge/dataset/KODAK' 
 6951  python
 6952  python generate_lmdb_image_dataset.py 
 6953  python generate_lmdb_image_dataset.py --image_dir='/data/sunnycia/image_compression_challenge/dataset/KODAK' 
 6954  top
 6955  nvidia-smi
 6956  clear && cleawr
 6957  ls
 6958  python extract_data.py 
 6959  python generate_lmdb_image_dataset.py 
 6960  python generate_lmdb_image_dataset.py --image_dir='/data/sunnycia/image_compression_challenge/dataset/KODAK' 
 6961  python extract_data.py 
 6962  cd -
 6963  make clean
 6964  make -j8 all
 6965  cd -
 6966  python extract_data.py 
 6967  cd -
 6968  make pycaffe
 6969  cd -
 6970  python extract_data.py 
 6971  cd -
 6972  make clean
 6973  make -j8 all && make pycaffe
 6974   cd -
 6975  python extract_data.py 
 6976  python extract_imap.py 
 6977  python train.py 
 6978  top
 6979  nvidia-smi
 6980  top
 6981  nvidia-smi
 6982  top
 6983  nvidia-smi
 6984  ssh chenzihao@172.31.70.212
 6985  clear
 6986  cat ~/.bashrc
 6987  git clone nvidia-smi
 6988  nnvidia-smi
 6989  nvidia-smi
 6990  top
 6991  nvidia-smi
 6992  cd /data/sunnycia/image_compression_challenge/_Train/TrimmedConvolution/experiment2
 6993  python test_lossless_compression.py 
 6994  free -h
 6995  top
 6996  top
 6997  cd /data/sunnycia/image_compression_challenge/_Train/TrimmedConvolution
 6998  ls
 6999  cd experiment
 7000  cd experiment1/
 7001  ls
 7002  source set_env.sh ../caffe-master 7
 7003  nvidia-smi
 7004  top
 7005  python train.py 
 7006  clear
 7007  cd /data/sunnycia/image_compression_challenge/_Train/TrimmedConvolution/experiment2
 7008  python test_lossless_compression.py 
 7009  source set_env.sh ../caffe-master 7
 7010  nvidia-smi
 7011  top
 7012  python test_lossless_compression.py 
 7013  nvidia-smi
 7014  top
 7015  nvidia-smi
 7016  python test_lossless_compression.py 
 7017  nvidia-smi
 7018  top
 7019  nvidia-smi
 7020  python test_lossless_compression.py 
 7021  top
 7022  nvidia-smi
 7023  python test_lossless_compression.py 
 7024  source set_env.sh ../caffe-master 4
 7025  python test_lossless_compression.py 
 7026  nvidia-smi
 7027  top
 7028  nvidia-smi
 7029  top
 7030  nvidia-smi
 7031  python test_lossless_compression.py 
 7032  watch -n 0.5 nvidia-smi
 7033  source set_env.sh ../caffe-master 7
 7034  python test_lossless_compression.py 
 7035  source set_env.sh ../caffe-master 6
 7036  vim set_env.sh 
 7037  python test_lossless_compression.py 
 7038  python
 7039  python test_lossless_compression.py 
 7040  cd ../experiment1/
 7041  python extract_data.py 
 7042  source set_env.sh ../caffe-master 6
 7043  python extract_data.py 
 7044  ls
 7045  watch -n 0.5 nvidia-smi
 7046  cd /data/sunnycia/image_compression_challenge/Train/scripts
 7047  source set_env.sh ../caffe-master 5
 7048  python inference.py 
 7049  python generate_lmdb_image_dataset.py --image_dir='/data/sunnycia/image_compression_challenge/dataset/CLIC_PRO' --lmdb_dir='dataset/clic_pro'
 7050  cd TCAE/
 7051  mv ../generate_lmdb_image_dataset.py ./
 7052  ls
 7053  python generate_lmdb_image_dataset.py --image_dir='/data/sunnycia/image_compression_challenge/dataset/CLIC_PRO' --lmdb_dir='dataset/clic_pro'
 7054  python generate_lmdb_image_dataset.py --image_dir='/data/sunnycia/image_compression_challenge/dataset/CLIC_PRO' --lmdb_dir='../dataset/clic_pro'
 7055  python extract_code_data.py 
 7056  pwd
 7057  source set_env.sh ../caffe-master 6
 7058  python extract_code_data.py 
 7059  cd -
 7060  python extract_code_data.py 
 7061  python
 7062  cd ..
 7063  cat set_env.sh 
 7064  source set_env.sh ../caffe-master 6
 7065  python
 7066  source set_env.sh /data/sunnycia/image_compression_challenge/Train/caffe-master 6
 7067  cd TCAE/
 7068  python extract_code_data.py 
 7069  clear && claer
 7070  cd TCAE/
 7071  python extract_code_data.py 
 7072  clear && claer
 7073  python extract_code_data.py 
 7074  clear && clear
 7075  cd /data/sunnycia/image_compression_challenge/Train/scripts/TCAE
 7076  top
 7077  nvidia-smi
 7078  python training.py 
 7079  source set_env.sh caffe-master/ 7
 7080  nvidia-smi
 7081  python training.py 
 7082  clear && clear
 7083  python training.py 
 7084  clear && clear
 7085  python training.py 
 7086  source set_env.sh ../../caffe-master 7
 7087  python training.py 
 7088  cd ../../caffe-master/
 7089  make pycaffe
 7090  cd -
 7091  clear && clear
 7092  python training.py 
 7093  clear && clear
 7094  python training.py 
 7095  cd /data/sunnycia/image_compression_challenge/_Train/tfnn_compression/entropy_coder/dataset
 7096  clear && clear
 7097  export CUDA_VISIBLE_DEVICES=7
 7098  nvidia-smi
 7099  cd ..
 7100  `python ./dataset/gen_synthetic_dataset.py --dataset_dir=/tmp/dataset/
 7101  --count=20000
 7102  python ./dataset/gen_synthetic_dataset.py --dataset_dir=./syndataset/ --count=20000
 7103  python ./dataset/gen_synthetic_dataset.py --dataset_dir=./syndataset/ --count=20
 7104  python ./dataset/gen_synthetic_dataset.py --dataset_dir=./syndataset/ --count=20000
 7105  python ./core/entropy_coder_train.py --task=0
 7106  python ./core/entropy_coder_train.py --task=0 --train_dir=./entropy_coder_train/ --model=progressive --model_config=./configs/synthetic/model_config.json --train_config=./configs/synthetic/train_config.json --input_config=./configs/synthetic/input_config.json
 7107  export PYTHONPATH=${PYTHONPATH}:/data/sunnycia/image_compression_challenge/_Train/tfnn_compression
 7108  python ./core/entropy_coder_train.py --task=0 --train_dir=./entropy_coder_train/ --model=progressive --model_config=./configs/synthetic/model_config.json --train_config=./configs/synthetic/train_config.json --input_config=./configs/synthetic/input_config.json
 7109  nvidia-smi
 7110  python ./core/entropy_coder_train.py --task=0 --train_dir=./entropy_coder_train/ --model=progressive --model_config=./configs/synthetic/model_config.json --train_config=./configs/synthetic/train_config.json --input_config=./configs/synthetic/input_config.json
 7111  df -h
 7112  su
 7113  clear && clear
 7114  python ./core/entropy_coder_train.py --task=0 --train_dir=./entropy_coder_train/ --model=progressive --model_config=./configs/synthetic/model_config.json --train_config=./configs/synthetic/train_config.json --input_config=./configs/synthetic/input_config.json
 7115  ls
 7116  cd /data/sunnycia/image_compression_challenge/Train/scripts/TCAE
 7117  ls
 7118  python generate_lmdb_image_dataset.py 
 7119  python generate_lmdb_image_dataset.py --image_dir='/data/sunnycia/image_compression_challenge/dataset/KODAK' --lmdb_dir='../dataset/kodak'
 7120  sources set_env.sh ./caffe-master/ 6
 7121  source set_env.sh ./caffe-master/ 6
 7122  nvidia-smi
 7123  python testing.py 
 7124  python extract_code_data.py 
 7125  python testing.py 
 7126  cd /data/sunnycia/image_compression_challenge/_Train/TrimmedConvolution/caffe-master
 7127  make clean
 7128  vim Makefile.config
 7129  make -j8 all && make pycaffe
 7130  vim Makefile.config
 7131  vim /tmp/tmpxft_0000587b_00000000-17_cudnn_conv_layer.compute_61.cpp1.ii
 7132  make clean
 7133  make -j8 all && make pycaffe
 7134  make clean
 7135  make 
 7136  make clean
 7137  make
 7138  cd ..
 7139  ls
 7140  unzip caffe-master.zip 
 7141  cd cafe
 7142  cd caffe-master/
 7143  cp Makefile.config.example Makefile.config
 7144  vim Makefile.config
 7145  make -j8 all
 7146  vim Makefile.config
 7147  make clean
 7148  make -j8 all
 7149  make clean
 7150  make -j8 all
 7151  make clean
 7152  make -j8 all
 7153  make clean
 7154  make -j8 all
 7155  make clean
 7156  make -j8 all
 7157  make clean
 7158  make -j8 all
 7159  make clean
 7160  make -j8 all
 7161  vim Makefile.config
 7162  make clean
 7163  make -j8 all
 7164  vim Makefile.config
 7165  cd ..
 7166  rm -rf caffe-master
 7167  unzip caffe-master.zip 
 7168  cd caffe-master/
 7169  cp Makefile.config.example Makefile.config
 7170  vim Makefile.config
 7171  cd..
 7172  cd ..
 7173  cp *.cpp caffe-master/src/caffe/layers/
 7174  cp *.cu *.cpp caffe-master/src/caffe/layers/
 7175  ls -t caffe-master/src/caffe/layers/
 7176  cp M*.hpp caffe-master/include/
 7177  ls
 7178  cp m*.hpp caffe-master/include/
 7179  cp b*.hpp caffe-master/include/caffe/layers/
 7180  vim caffe-master/src/caffe/proto/caffe.proto 
 7181  cd caffe-master/
 7182  make -j8 all
 7183  make clean
 7184  make -j8 all
 7185  make clean
 7186  make -j8 all
 7187  vim Makefile.config
 7188  make clean
 7189  vim Makefile.config
 7190  make -j8 all
 7191  ls /usr/local/cuda-8.0/include/
 7192  gcc -v
 7193  cd ..
 7194  cd experiment1
 7195  ls
 7196  cd /data/sunnycia/image_compression_challenge/Train/scripts
 7197  ls
 7198  cd TCAE/
 7199  ls
 7200  ls ../..
 7201  rm -rf ../../caffe-master
 7202  cp /data/sunnycia/image_compression_challenge/_Train/TrimmedConvolution/caffe-master ../..
 7203  cp -R /data/sunnycia/image_compression_challenge/_Train/TrimmedConvolution/caffe-master ../..
 7204  source set_env.sh ../../caffe-master 6
 7205  nvidia-smi
 7206  top
 7207  nvidia-smi
 7208  source set_env.sh ../../caffe-master 7
 7209  ls
 7210  history > history
 7211  cd ../../caffe-master/
 7212  make clean
 7213  make -j8 all && make -j2 pycaffe
 7214  df-h
 7215  df -h
 7216  ssh chenzihao@172.31.70.212
 7217  cd /data/sunnycia/image_compression_challenge/_Train
 7218  git clone https://github.com/ajayjain/video-compression.git
 7219  cd video-compression/
 7220  bash download_data.sh 
 7221  top
 7222  nvidia-smi
 7223  du -h --max-depth=1  /data/sunnycia
 7224  du -h --max-depth=1 /data/sunnycia/SaliencyDataset
 7225  du -h --max-depth=1 /data/sunnycia/saliency_on_videoset/
 7226  du -h --max-depth=1 /data/sunnycia/saliency_on_videoset/Train/
 7227  du -h --max-depth=1 /data/sunnycia/SaliencyDataset/Video/
 7228  du -h --max-depth=1 /data/sunnycia/SaliencyDataset/Video/DIEM/
 7229  rm -rf /data/sunnycia/SaliencyDataset/Video/DIEM/fixation_map/mat/
 7230  du -h --max-depth=1  /data/sunnycia
 7231  du -h --max-depth=1  /data/sunnycia/SaliencyDataset/
 7232  du -h --max-depth=1  /data/sunnycia/SaliencyDataset/Video/
 7233  df -h
 7234  du -h --max-depth=1  /data/sunnycia/SaliencyDataset/Video/VideoSet/
 7235  du -h --max-depth=1  /data/sunnycia/SaliencyDataset/Video/VideoSet/Results/
 7236  du -h --max-depth=1  /data/sunnycia/SaliencyDataset/Video/VideoSet/Results/saliency_map/
 7237  du -h --max-depth=1  /data/sunnycia
 7238  df -h
 7239  du -h --max-depth=1  /data/sunnycia
 7240  df -h
 7241  cd /data/sunnycia/image_compression_challenge/Train/scripts
 7242  su
 7243  ls
 7244  cd ~
 7245  git clone --recursive https://github.com/caffe2/caffe2.git && cd caffe2
 7246  vim ~/.bashrc
 7247  ls
 7248  vim ~/.bashrc
 7249  source ~/.bashrc
 7250  python
 7251  conda install -c caffe2 caffe2
 7252  conda install -c caffe2 caffe2-cuda9.0-cudnn7
 7253  conda update conda
 7254  conda install -c caffe2 caffe2
 7255   python
 7256  conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free/
 7257  conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main/
 7258  conda config --set show_channel_urls yes
 7259  conda install -c caffe2 caffe2
 7260  python
 7261  conda remove caffe2
 7262  conda remove caffe2 caffe
 7263  conda remove caffe2 caffe2
 7264  conda install -c caffe2 caffe2-cuda9.0-cudnn7
 7265  python 
 7266  jupyter notebook
 7267  conda remove -c caffe2 caffe2-cuda9.0-cudnn7
 7268  clear && clear
 7269  cd /data/sunnycia/image_compression_challenge/_Train/tfnn_compression/entropy_coder
 7270  history > history
 7271  df -h
 7272  python ./core/entropy_coder_train.py --task=0 --train_dir=./entropy_coder_train/ --model=progressive --model_config=./configs/synthetic/model_config.json --train_config=./configs/synthetic/train_config.json --input_config=./configs/synthetic/input_config.json
 7273  python
 7274  vim ~/.bashrc
 7275  source ~/.bashrc
 7276  python ./core/entropy_coder_train.py --task=0 --train_dir=./entropy_coder_train/ --model=progressive --model_config=./configs/synthetic/model_config.json --train_config=./configs/synthetic/train_config.json --input_config=./configs/synthetic/input_config.json
 7277  cd /data/sunnycia/image_compression_challenge/_Train
 7278  git clone https://github.com/jigar23/CABAC.git
 7279  cd /data/sunnycia/image_compression_challenge/_Train/tfnn_compression/entropy_coder
 7280  python ./core/entropy_coder_train.py --task=0 --train_dir=./entropy_coder_train/ --model=progressive --model_config=./configs/synthetic/model_config.json --train_config=./configs/synthetic/train_config.json --input_config=./configs/synthetic/input_config.json
 7281  vim set_env.sh
 7282  python ./core/entropy_coder_train.py --task=0 --train_dir=./entropy_coder_train/ --model=progressive --model_config=./configs/synthetic/model_config.json --train_config=./configs/synthetic/train_config.json --input_config=./configs/synthetic/input_config.json
 7283  source set_env.sh
 7284  python ./core/entropy_coder_train.py --task=0 --train_dir=./entropy_coder_train/ --model=progressive --model_config=./configs/synthetic/model_config.json --train_config=./configs/synthetic/train_config.json --input_config=./configs/synthetic/input_config.json
 7285  nvidia-smi
 7286  export CUDA_VISIBLE_DEVICE=6
 7287  python ./core/entropy_coder_train.py --task=0 --train_dir=./entropy_coder_train/ --model=progressive --model_config=./configs/synthetic/model_config.json --train_config=./configs/synthetic/train_config.json --input_config=./configs/synthetic/input_config.json
 7288  export CUDA_VISIBLE_DEVICES=6
 7289  python ./core/entropy_coder_train.py --task=0 --train_dir=./entropy_coder_train/ --model=progressive --model_config=./configs/synthetic/model_config.json --train_config=./configs/synthetic/train_config.json --input_config=./configs/synthetic/input_config.json
 7290  cd /data/sunnycia/image_compression_challenge/_Train/tfnn_compression/entropy_coder
 7291  clear
 7292  python ./core/entropy_coder_train.py --task=0 --train_dir=./entropy_coder_train/ --model=progressive --model_config=./configs/synthetic/model_config.json --train_config=./configs/synthetic/train_config.json --input_config=./configs/synthetic/input_config.json
 7293  source set_env.sh 
 7294  python ./core/entropy_coder_train.py --task=0 --train_dir=./entropy_coder_train/ --model=progressive --model_config=./configs/synthetic/model_config.json --train_config=./configs/synthetic/train_config.json --input_config=./configs/synthetic/input_config.json
 7295  cd lib/
 7296  ls
 7297  python blocks_entropy_coding_test.py 
 7298  nvida-smi
 7299  nvidia-smi
 7300  clear
 7301  source ../set_env.sh 
 7302  python blocks_entropy_coding_test.py 
 7303  export CUDA_VISIBLE_DEVICES=5
 7304  nvidia-smi
 7305  export CUDA_VISIBLE_DEVICES=7
 7306  export CUDA_VISIBLE_DEVICES=5
 7307  export CUDA_VISIBLE_DEVICES=7
 7308  python blocks_entropy_coding_test.py 
 7309  cd ..
 7310  python ./core/entropy_coder_train.py --task=0 --train_dir=./entropy_coder_train/ --model=progressive --model_config=./configs/synthetic/model_config.json --train_config=./configs/synthetic/train_config.json --input_config=./configs/synthetic/input_config.json
 7311  python core/entropy_coder_single.py 
 7312  python core/entropy_coder_single.py --model=progressive --model_config=
 7313  python core/entropy_coder_single.py --model=progressive --model_config=configs/synthetics/model_config.json
 7314  python core/entropy_coder_single.py --model=progressive --model_config=configs/synthetics/model_config.json --iteration=15
 7315  python core/entropy_coder_single.py --model=progressive --model_config='configs/synthetics/model_config.json' --iteration=15
 7316  python core/entropy_coder_single.py --model=progressive --model_config='configs/synthetics/model_config.json' --iteration=15 
 7317  cd dataset/
 7318  python gen_synthetic_single.py --sample_filename='synthetic_dataset_single'
 7319  cd ..
 7320  python core/entropy_coder_single.py --model=progressive --model_config='configs/synthetics/model_config.json' --iteration=15 --input_codes='dataset/synthetic_dataset_single'
 7321  python core/entropy_coder_single.py --model=progressive --model_config='configs/synthetic/model_config.json' --iteration=15 --input_codes='dataset/synthetic_dataset_single'
 7322  python core/entropy_coder_single.py --model=progressive --model_config='configs/synthetic/model_config.json' --iteration=15 --input_codes='dataset/synthetic_dataset_single' --check_point='entropy_coder_train'
 7323  python core/entropy_coder_single.py --model=progressive --model_config='configs/synthetic/model_config.json' --iteration=15 --input_codes='dataset/synthetic_dataset_single' --check_point='entropy_coder_train/checkpoint'
 7324  python core/entropy_coder_single.py --model=progressive --model_config='configs/synthetic/model_config.json' --iteration=15 --input_codes='dataset/synthetic_dataset_single' --check_point='entropy_coder_train/model.ckpt-354157.meta'
 7325  python core/entropy_coder_single.py --model=progressive --model_config='configs/synthetic/model_config.json' --iteration=15 --input_codes='dataset/synthetic_dataset_single' --checkpoint='entropy_coder_train/model.ckpt-354157.meta'
 7326  python core/entropy_coder_single.py --model=progressive --model_config='configs/synthetic/model_config.json' --iteration=15 --input_codes='dataset/synthetic_dataset_single' --checkpoint='entropy_coder_train/checkpoint'
 7327  python core/entropy_coder_single.py --model=progressive --model_config='configs/synthetic/model_config.json' --iteration=15 --input_codes='dataset/synthetic_dataset_single' --checkpoint='entropy_coder_train/model.ckpt-354157.meta'
 7328  python core/entropy_coder_single.py --model=progressive --model_config='configs/synthetic/model_config.json' --iteration=15 --input_codes='dataset/synthetic_dataset_single' --checkpoint='entropy_coder_train/model.ckpt-354157.index'
 7329  python
 7330  vim ~/.bashrc
 7331  top
 7332  nvidia-smi
 7333  tpo
 7334  top
 7335  df -h
 7336  pwd
 7337  ls
 7338  cd pwd/
 7339  ls
 7340  cd saliency_on_videoset/
 7341  ls
 7342  cd _Train/
 7343  ls
 7344  cd dynamicsaliency/
 7345  ls
 7346  git pull
 7347  ls -la
 7348  cd models/
 7349  ls
 7350  cat readme 
 7351  cd ../..
 7352  r -rf dynamicsaliency/
 7353  rm -rf dynamicsaliency/
 7354  git clone https://github.com/cagdasbak/dynamicsaliency.git
 7355  vim ~/.bahsrc
 7356  vim ~/.bashrc
 7357  ls -la ~
 7358  su
 7359  cd /home/sunnycia/pwd/slice_video
 7360  python slice_video.py 
 7361  python slice_video.py --video_path='1.mp4' --slice_num=10 --output_dir=slice_output
 7362  python
 7363  python slice_video.py --video_path='1.mp4' --slice_num=10 --output_dir=slice_output
 7364  python slice_video.py --video_path='2.mp4' --slice_num=13 --output_dir=slice_output
 7365  python slice_video.py --video_path='2.mp4' --slice_num=12 --output_dir=slice_output
 7366  cXX
 7367  CXX
 7368  clear
 7369  pwd
 7370  cd ../..
 7371  ls
 7372  cd pwd/
 7373  ls
 7374  cd saliency_on_videoset/
 7375  ls
 7376  cd /data/sunnycia
 7377  ls
 7378  cd saliency_on_videoset/
 7379  ls
 7380  cd _Utils/
 7381  ls
 7382  git clone https://github.com/infant-cognition-tampere/gazeclassifier-py.git
 7383  git clone https://github.com/tmalsburg/saccades.git
 7384  git clone https://github.com/EyeStimuli/FixationSaccade
 7385  git clone https://github.com/EyeStimuli/FixationSaccade.git
 7386  ls
 7387  cd saccades/
 7388  l
 7389  ls
 7390  make
 7391  cd .
 7392  cd ..
 7393  ls
 7394  python
 7395  pip install gazeclassifier
 7396  pip install --upgrade pip
 7397  su
 7398  python
 7399  vim ~/.bashrc
 7400  source ~/.bashrc
 7401  python
 7402  cd gazeclassifier-py/
 7403  python setup.py  install
 7404  python
 7405  make clean
 7406  python setup.py
 7407  python setup.py -h
 7408  python setup.py uninstall
 7409  python setup.py clean
 7410  python setup.py install
 7411  cd ..
 7412  su
 7413  ls
 7414  rm -rf gazeclassifier-py/
 7415  su
 7416  git clone https://github.com/infant-cognition-tampere/gazeclassifier-py.git
 7417  cd gazeclassifier-py/
 7418  python setup.py install
 7419  python
 7420  pip uninstall scikit-learn
 7421  pip install scikit-learn==0.17
 7422  pip install --upgrade pip
 7423  python
 7424  cd~
 7425  cd ~
 7426  ls
 7427  cd /data/sunnycia/saliency_on_videoset/Train/scripts/utils/vizutil
 7428  touch visualize_raw_coordinate.py
 7429  vim ~/.bashrc
 7430  top
 7431  su
 7432  cd /data/sunnycia
 7433  python
 7434  vim ~/.bashrc
 7435  source ~/.bashrc
 7436  python
 7437  sudo useradd liuxh
 7438  clear && clear
 7439  cd /data/sunnycia
 7440  python gen_voinfo.py 
 7441  python 4_gen_fixation.py 
 7442  python 3_gen_video.py 
 7443  python 4_gen_fixation.py 
 7444  python 3_gen_video.py 
 7445  top
 7446  df -h
 7447  cd /data/SaliencyDataset/Video/ActionInTheEye/Hollywood2
 7448  python rename.py 
 7449  top
 7450  cd /data/sunnycia/saliency_on_videoset/Train/scripts
 7451  source set_env.sh ../C3D-v1.1 5
 7452  nvidia-smi
 7453  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-resnet-1deconv.prototxt' --use_model='../pretrained_model/c3d_resnet18_sports1m_r2_iter_2800000.caffemodel' --plotiter=200 --validiter=4000 --savemodeliter=4000 --trainingexampleprops=0.99 --trainingbase='ledov' --videolength=16 --overlap=15 --extramodinfo='with_1_3d-deconv' --batch=2
 7454  claer && clear
 7455  clear && clear
 7456  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-resnet-1deconv.prototxt' --use_model='../pretrained_model/c3d_resnet18_sports1m_r2_iter_2800000.caffemodel' --plotiter=200 --validiter=4000 --savemodeliter=4000 --trainingexampleprops=0.99 --trainingbase='hollywood' --videolength=16 --overlap=15 --extramodinfo='with_1_3d-deconv' --batch=2
 7457  clear && clear
 7458  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-resnet-dropout.prototxt' --use_model='../pretrained_model/c3d_resnet18_sports1m_r2_iter_2800000.caffemodel' --plotiter=200 --validiter=4000 --savemodeliter=4000 --trainingexampleprops=0.99 --trainingbase='hollywood' --videolength=16 --overlap=15 --extramodinfo='hollywood' --batch=2
 7459  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-resnet-dropout.prototxt' --use_model='../pretrained_model/c3d_resnet18_sports1m_r2_iter_2800000.caffemodel' --plotiter=200 --validiter=4000 --savemodeliter=4000 --trainingexampleprops=0.999 --trainingbase='hollywood' --videolength=16 --overlap=15 --extramodinfo='hollywood' --batch=2
 7460  cd -
 7461  python rename.py 
 7462  clear && clear
 7463  python rename.py 
 7464  cd -
 7465  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-resnet-dropout.prototxt' --use_model='../pretrained_model/c3d_resnet18_sports1m_r2_iter_2800000.caffemodel' --plotiter=200 --validiter=4000 --savemodeliter=4000 --trainingexampleprops=0.999 --trainingbase='hollywood' --videolength=16 --overlap=15 --extramodinfo='hollywood' --batch=2
 7466  cd -
 7467  python rename.py 
 7468  clear && clear
 7469  cd -
 7470  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-resnet-dropout.prototxt' --use_model='../pretrained_model/c3d_resnet18_sports1m_r2_iter_2800000.caffemodel' --plotiter=200 --validiter=4000 --savemodeliter=4000 --trainingexampleprops=0.999 --trainingbase='hollywood' --videolength=16 --overlap=15 --extramodinfo='hollywood' --batch=2
 7471  clear && clear
 7472  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-resnet-dropout.prototxt' --use_model='../pretrained_model/c3d_resnet18_sports1m_r2_iter_2800000.caffemodel' --plotiter=200 --validiter=4000 --savemodeliter=4000 --trainingexampleprops=0.999 --trainingbase='hollywood' --videolength=16 --overlap=15 --extramodinfo='hollywood' --batch=2
 7473  clear && clear
 7474  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-resnet-dropout.prototxt' --use_model='../pretrained_model/c3d_resnet18_sports1m_r2_iter_2800000.caffemodel' --plotiter=200 --validiter=4000 --savemodeliter=4000 --trainingexampleprops=0.999 --trainingbase='hollywood' --videolength=16 --overlap=15 --extramodinfo='hollywood' --batch=2
 7475  cd /data/sunnycia/saliency_on_videoset/Train/scripts
 7476  source set_env.sh ../C3D-v1.1 5
 7477  nvidia-smi
 7478  clear && clear
 7479  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v5-sigmoid.prototxt' --use_model='../pretrained_model/c3d_resnet18_sports1m_r2_iter_2800000.caffemodel' --plotiter=200 --validiter=4000 --savemodeliter=4000 --trainingexampleprops=0.99 --trainingbase='ledov' --videolength=16 --overlap=15 --extramodelinfo='sigmoid_activate_function' --batch=2
 7480  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v5-sigmoid.prototxt' --use_model='../pretrained_model/c3d_resnet18_sports1m_r2_iter_2800000.caffemodel' --plotiter=200 --validiter=4000 --savemodeliter=4000 --trainingexampleprops=0.99 --trainingbase='ledov' --videolength=16 --overlap=15 --extramodinfo='sigmoid_activate_function' --batch=2
 7481  top
 7482  df -h
 7483  ldd
 7484  cd /data/sunnycia/saliency_on_videoset/_Train/hogmbhdetector-1.0.0-x86_64
 7485  ldd /data/sunnycia/saliency_on_videoset/_Train/hogmbhdetector-1.0.0-x86_64/bin/run_detector 
 7486  libpng
 7487  su
 7488  top
 7489  df -h
 7490  cd /data/sunnycia/saliency_on_videoset/Train
 7491  ls
 7492  history > history
 7493  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v5-sigmoid.prototxt' --use_model='../pretrained_model/c3d_resnet18_sports1m_r2_iter_2800000.caffemodel' --plotiter=200 --validiter=4000 --savemodeliter=4000 --trainingexampleprops=0.99 --trainingbase='ledov' --videolength=16 --overlap=15 --extramodinfo='sigmoid_activate_function' --batch=2
 7494  cd scripts/
 7495  ls
 7496  source set_env.sh ../C3D-v1.1 7
 7497  nvidia-smi
 7498  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-resnet-1deconv.prototxt' --use_model='../pretrained_model/c3d_resnet18_sports1m_r2_iter_2800000.caffemodel' --plotiter=200 --validiter=4000 --savemodeliter=4000 --trainingexampleprops=0.99 --trainingbase='ledov' --videolength=16 --overlap=15 --extramodinfo='with_1_3d-deconv' --batch=2
 7499  clear && clear
 7500  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-resnet-1deconv.prototxt' --use_model='../pretrained_model/c3d_resnet18_sports1m_r2_iter_2800000.caffemodel' --plotiter=200 --validiter=4000 --savemodeliter=4000 --trainingexampleprops=0.99 --trainingbase='ledov' --videolength=16 --overlap=15 --extramodinfo='with_1_3d-deconv' --batch=2
 7501  python utils/scavenger.py 
 7502  python utils/scavenger.py -h
 7503  python utils/scavenger.py --figure=True
 7504  python utils/scavenger.py --snapshot=True
 7505  clear && cleawr
 7506  df -h
 7507  python utils/scavenger.py --snapshot=True
 7508  clear && clear
 7509  ls
 7510  ls -a
 7511  vim .gitconfig
 7512  ls
 7513  cd pwd/saliency_on_videoset/_Train/
 7514  ls
 7515  git clone git@github.com:cagdasbak/dynamicsaliency.git
 7516  cd /data/sunnycia/saliency_on_videoset/_Train/dynamicsaliency
 7517  top
 7518  nvidia-smi
 7519  ssh zhangpp@172.31.234.205
 7520  cd /data/sunnycia/saliency_on_videoset/Train/scripts
 7521  history > history
 7522  top
 7523  clear
 7524  source set_env.sh ../C3D-v1.1 7
 7525  nvidia-smi
 7526  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v5-resnet-fixc2-drop.prototxt' --use_model='/data/sunnycia/saliency_on_videoset/Train/training_output/salicon/vo-v4-2-resnet-dropout-snapshot-2000-display-1-dropout_fulldens-batch-2_1514857787/snapshot-_iter_26000.caffemodel' --plotiter=200 --validiter=4000 --savemodeliter=4000 --trainingexampleprops=0.99 --trainingbase='ledov' --videolength=16 --overlap=15 --extramodinfo='finetunefrom26k' --batch=2
 7527  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-resnet-fixc2-drop.prototxt' --use_model='/data/sunnycia/saliency_on_videoset/Train/training_output/salicon/vo-v4-2-resnet-dropout-snapshot-2000-display-1-dropout_fulldens-batch-2_1514857787/snapshot-_iter_26000.caffemodel' --plotiter=200 --validiter=4000 --savemodeliter=4000 --trainingexampleprops=0.99 --trainingbase='ledov' --videolength=16 --overlap=15 --extramodinfo='finetunefrom26k' --batch=2
 7528  claer && clear
 7529  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-resnet-fixc2-drop.prototxt' --use_model='/data/sunnycia/saliency_on_videoset/Train/training_output/salicon/vo-v4-2-resnet-dropout-snapshot-2000-display-1-dropout_fulldens-batch-2_1514857787/snapshot-_iter_26000.caffemodel' --plotiter=200 --validiter=4000 --savemodeliter=4000 --trainingexampleprops=0.99 --trainingbase='ledov' --videolength=16 --overlap=15 --extramodinfo='finetunefrom26k' --batch=2
 7530  clear && clear
 7531  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v5.prototxt' --use_model='/data/sunnycia/saliency_on_videoset/Train/training_output/salicon/vo-v4-2-resnet-dropout-snapshot-2000-display-1-dropout_fulldens-batch-2_1514857787/snapshot-_iter_26000.caffemodel' --plotiter=200 --validiter=4000 --savemodeliter=4000 --trainingexampleprops=0.99 --trainingbase='ledov' --videolength=16 --overlap=15 --extramodinfo='finetunefrom26k' --batch=2
 7532  clear && clear
 7533  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v5.prototxt' --use_model='/data/sunnycia/saliency_on_videoset/Train/training_output/salicon/vo-v4-2-resnet-dropout-snapshot-2000-display-1-dropout_fulldens-batch-2_1514857787/snapshot-_iter_26000.caffemodel' --plotiter=200 --validiter=4000 --savemodeliter=4000 --trainingexampleprops=0.99 --trainingbase='ledov' --videolength=16 --overlap=15 --extramodinfo='finetunefrom26k' --batch=2
 7534  clear && clear
 7535  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v5.prototxt' --use_model='/data/sunnycia/saliency_on_videoset/Train/training_output/salicon/vo-v4-2-resnet-dropout-snapshot-2000-display-1-dropout_fulldens-batch-2_1514857787/snapshot-_iter_26000.caffemodel' --plotiter=200 --validiter=4000 --savemodeliter=4000 --trainingexampleprops=0.99 --trainingbase='ledov' --videolength=16 --overlap=15 --extramodinfo='finetunefrom26k' --batch=2
 7536  clear && clear
 7537  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v5.prototxt' --use_model='../pretrained_model/c3d_resnet18_sports1m_r2_iter_2800000.caffemodel' --plotiter=200 --validiter=4000 --savemodeliter=4000 --trainingexampleprops=0.99 --trainingbase='ledov' --videolength=16 --overlap=15 --extramodinfo='finetunefrom26k' --batch=2
 7538  vim ~/.bashrc
 7539  vim /etc/profile
 7540  top
 7541  cd /data/sunnycia/saliency_on_videoset/Train/scripts
 7542  history > history
 7543  source set_env.sh ../C3D-v1.1 7
 7544  nvidia-smi
 7545  source set_env.sh ../C3D-v1.1 4
 7546  python test_video.py  --output_type='image' --test_base='videoset' --model_code='v4-2' --videolength=16 --inferoverlap=15 --video_deploy_path='prototxt/vo-v4-2-resnet-deploy-softmax'  --video_model_path='../training_output/salicon/vo-v4-2-resnet-dropout-snapshot-2000-display-1-dropout_fulldens-batch-2_1514857787/snapshot-_iter_26000.caffemodel' --infertype='slide' 
 7547  python test_video.py  --output_type='image' --test_base='videoset' --model_code='v4-2' --videolength=16 --inferoverlap=15 --video_deploy_path='prototxt/vo-v4-2-resnet-deploy-softmax.prototxt'  --video_model_path='../training_output/salicon/vo-v4-2-resnet-dropout-snapshot-2000-display-1-dropout_fulldens-batch-2_1514857787/snapshot-_iter_26000.caffemodel' --infertype='slide' 
 7548  su
 7549  ssh liuxh@172.31.234.205
 7550  su
 7551  cd /data/SaliencyDataset/Video/Hollywood2
 7552  git clone /data/SaliencyDataset/Video/Hollywood2
 7553  git clone https://github.com/CigdemK/thesis.git
 7554  cd /data/sunnycia/saliency_on_videoset/Train/scripts
 7555  history > history
 7556  git add .
 7557  git add --all
 7558  git commit 'regular commit'
 7559  git commit -m 'regular commit'
 7560  git push -u origin master
 7561  python utils/vizutil/visualization_weight.py --modelpath=/data/sunnycia/saliency_on_videoset/Train/pretrained_model/c3d_resnet18_sports1m_r2_iter_2800000.caffemodel --deploypath=/data/sunnycia/saliency_on_videoset/Train/pretrained_model/c3d_resnet18_ucf101_feature_extraction.prototxt --type=3d --layer=conv1 --outputpath=conv1.jpg 
 7562  python utils/vizutil/split_rgb.py --imagepath=conv1.jpg
 7563  python utils/vizutil/split_rgb.py --image_path=conv1.jpg
 7564  cd /data/sunnycia/action_recognition/_Train
 7565  git clone https://github.com/kenshohara/3D-ResNets-PyTorch.git
 7566  df -h
 7567  cd /data/sunnycia/action_recognition/dataset
 7568  wget http://ec2-52-11-11-89.us-west-2.compute.amazonaws.com/files/activity_net.v1-3.min.json
 7569  cd download_utils/
 7570  git clone https://github.com/activitynet/ActivityNet.githttps://github.com/activitynet/ActivityNet.git
 7571  git clone https://github.com/activitynet/ActivityNet.git
 7572  pwd
 7573  mkdir ../AcitivityNet_1_3
 7574  cd ActivityNet/
 7575  ls
 7576  cd Crawler/
 7577  ls
 7578  chmod +x fetch_activitynet_videos.sh 
 7579  ./fetch_activitynet_videos.sh ../../../AcitivityNet_1_3/ ../../../activity_net.v1-3.min.json 
 7580  su
 7581  ./fetch_activitynet_videos.sh ../../../AcitivityNet_1_3/ ../../../activity_net.v1-3.min.json 
 7582  top
 7583  pwd
 7584  cd ~/pwd/saliency_on_videoset/
 7585  ls
 7586  cd _Train/
 7587  ls
 7588  cd _Util/
 7589  ls
 7590  git clone https://github.com/rreece/gmm.git
 7591  ls
 7592  cd gmm/
 7593  ls
 7594  python generate_toy_data.py 
 7595  ls
 7596  ls -l img
 7597  python auto_gmm.py 
 7598  git reset
 7599  ls
 7600  git status
 7601  git checkout
 7602  ls
 7603  git show
 7604  git check 9dd1e4433e760d2605def89f0c7b0d4bd5843737
 7605  git checkout 9dd1e4433e760d2605def89f0c7b0d4bd5843737
 7606  ls
 7607  git clean -fd
 7608  ls
 7609  python auto_gmm.py 
 7610  df -h
 7611  cd ~/pwd/saliency_on_videoset/
 7612  ls
 7613  cd /data/SaliencyDataset/
 7614  ls
 7615  cd Video/
 7616  ls
 7617  cd ActionInTheEye/ls
 7618  cd ActionInTheEye/
 7619  ls
 7620  cd UCF/
 7621  ls
 7622  unzip gaze_ucfsa.zip 
 7623  ls
 7624  pwd
 7625  unzip ucf_sports_actions.zip 
 7626  cd /data/sunnycia/saliency_on_videoset/_Train
 7627  unzip hogmbhdetector-1.0.0-x86_64.zip 
 7628  cd /data/sunnycia/saliency_on_videoset/_Train/hogmbhdetector-1.0.0-x86_64
 7629  cd matlab/
 7630  matlab -nodesktop -nodisplay
 7631  matlab
 7632  cd ../bin/
 7633  ./run_detector 
 7634  cd ../matlab/
 7635  ls
 7636  matlab 
 7637  cd /data/SaliencyDataset/Video/ActionInTheEye
 7638  cd Hollywood2/
 7639  ls
 7640  tar -xf Hollywood2-actions.tar.gz 
 7641  unzip gaze_hollywood2.zip 
 7642  ls
 7643  df -h
 7644  pwd
 7645  cd ..
 7646  ls
 7647  cd Hollywood2/
 7648  ls
 7649  tar xf Hollywood2-scenes.tar.gz 
 7650  cd /data/SaliencyDataset/Video/ActionInTheEye/Hollywood2/thesis
 7651  matlab -nodesktop
 7652  ls
 7653  pwd
 7654  matlab -nodesktop -nodisplay
 7655  cd ..
 7656  ls
 7657  cd thesis/
 7658  matlab -nodesktop -nodisplay
 7659  matlab
 7660  su
 7661  matlab -nodeskopt -nodisplay
 7662  matlab -nodesktop -nodisplay
 7663  top
 7664  clear && clear
 7665  nvidia-smi
 7666  top
 7667  clear && clear
 7668  df -h
 7669  top
 7670  cd /data/sunnycia/saliency_on_videoset/Train/scripts/utils/vizutil
 7671  python inference_comparison.py --output_path='test.jpg' --wildcards_record='wildcards_record.txt' 
 7672  python inference_comparison.py --output_path='msu_inference.jpg' --wildcards_record='wildcards_record.txt' 
 7673  python inference_comparison.py --output_path='diem_inference.jpg' --wildcards_record='diem_wildcards_record.txt' 
 7674  python inference_comparison.py --output_path='gazecom_inference.jpg' --wildcards_record='gazecom_wildcards_record.txt' 
 7675  top
 7676  nvidia-smi
 7677  cd /data/SaliencyDataset/Video/ActionInTheEye/Hollywood2/density
 7678  unzip density.zip 
 7679  cd ../fixation/
 7680  unzip fixation.zip 
 7681  rm -rf fixation.zip 
 7682  cd -
 7683  rm -rf density.zip 
 7684  df -h
 7685  cd /data/SaliencyDataset/Video/ActionInTheEye/Hollywood2/Hollywood2-actions
 7686  mv AVIClips/*autoauto*.avi ./autoauto/
 7687  cd /data/sunnycia/saliency_on_videoset/Train/scripts/utils/dsutil
 7688  python slice_frames.py --videobase='/data/SaliencyDataset/Video/ActionInTheEye/Hollywood2/Hollywood2-actions/AVIClips' --outputbase='/data/SaliencyDataset/Video/ActionInTheEye/Hollywood2/frames' --zerofill=5 
 7689  top
 7690  nvidia-smi
 7691  cd /data/sunnycia/saliency_on_videoset/Train/scripts/utils/dsutil
 7692  python combine_frames.py --framedir='actioncliptest00001_fixation' --outputdir='test00001.avi' --videolength=8 --resolution=(576,304) 
 7693  python combine_frames.py --framedir='actioncliptest00001_fixation' --outputdir='test00001.avi' --videolength=8 --resolution='(576,304) '
 7694  python combine_frames.py --framedir='actioncliptest00001_fixation' --outputdir='test00001.avi' --videolength=8 --resolution='(576.,304.)'
 7695  python combine_frames.py --framedir='actioncliptest00001_fixation' --outputdir='test00001.avi' --videolength=8. --resolution='(576.,304.)'
 7696  python combine_frames.py --framedir='actioncliptest00001_fixation' --outputdir='test00001.avi' --videolength='8' --resolution='(576.,304.)'
 7697  python combine_frames.py --framedir='actioncliptest00001_fixation' --outputdir='test00001.avi' --videolength='8' 
 7698  python combine_frames.py --framedir='actioncliptest00001_fixation' --outputdir='./' --videolength='8' 
 7699  python 
 7700  python
 7701  vim ~/.bahsrc
 7702  vim ~/.bashrc
 7703  nvidia-smi
 7704  cd /data/sunnycia/saliency_on_videoset/Train/scripts
 7705  ls
 7706  python test_video.py --video_deploy_path='prototxt/vo-v5_deploy.prototxt' --video_model_path='./training_output/salicon/vo-v5-snapshot-4000-finetunefrom26k-batch-2_1521799733/snapshot-_iter_48000.caffemodel' --infertype='slide' --output_type='image' --test_base='videoset' --model_code='v4-2' --videolength=16
 7707  python test_video.py --video_deploy_path='prototxt/vo-v5_deploy.prototxt' --video_model_path='../training_output/salicon/vo-v5-snapshot-4000-finetunefrom26k-batch-2_1521799733/snapshot-_iter_48000.caffemodel' --infertype='slide' --output_type='image' --test_base='videoset' --model_code='v4-2' --videolength=16
 7708  source set_env.sh ../C3D-v1.1 6
 7709  nvidia-smi
 7710  python test_video.py --video_deploy_path='prototxt/vo-v5_deploy.prototxt' --video_model_path='../training_output/salicon/vo-v5-snapshot-4000-finetunefrom26k-batch-2_1521799733/snapshot-_iter_48000.caffemodel' --infertype='slide' --output_type='image' --test_base='videoset' --model_code='v4-2' --videolength=16
 7711  nvidia-smi
 7712  python test_video.py --video_deploy_path='prototxt/vo-v5_deploy.prototxt' --video_model_path='../training_output/salicon/vo-v5-snapshot-4000-finetunefrom26k-batch-2_1521799733/snapshot-_iter_48000.caffemodel' --infertype='slide' --output_type='image' --test_base='videoset' --model_code='v4-2' --videolength=16
 7713  source set_env.sh ../C3D-v1.1-tmp 6
 7714  python test_video.py --video_deploy_path='prototxt/vo-v5_deploy.prototxt' --video_model_path='../training_output/salicon/vo-v5-snapshot-4000-finetunefrom26k-batch-2_1521799733/snapshot-_iter_48000.caffemodel' --infertype='slide' --output_type='image' --test_base='videoset' --model_code='v4-2' --videolength=16
 7715  source set_env.sh ../C3D-v1.1 6
 7716  python test_video.py --video_deploy_path='prototxt/vo-v5_deploy.prototxt' --video_model_path='../training_output/salicon/vo-v5-snapshot-4000-finetunefrom26k-batch-2_1521799733/snapshot-_iter_48000.caffemodel' --infertype='slide' --output_type='image' --test_base='videoset' --model_code='v4-2' --videolength=16
 7717  source set_env.sh ../C3D-v1.1 6
 7718  python test_video.py --video_deploy_path='prototxt/vo-v5_deploy.prototxt' --video_model_path='../training_output/salicon/vo-v5-snapshot-4000-finetunefrom26k-batch-2_1521799733/snapshot-_iter_48000.caffemodel' --infertype='slide' --output_type='image' --test_base='videoset' --model_code='v4-2' --videolength=16
 7719  python test_video.py --video_deploy_path='prototxt/vo-v5-sigmoid_deploy.prototxt' --video_model_path='../training_output/salicon/vo-v5-sigmoid-snapshot-4000-sigmoid_activate_function-batch-2_1521887606/snapshot-_iter_32000.caffemodel' --infertype='slide' --output_type='image' --test_base='videoset' --model_code='v4-2' --videolength=16
 7720   cd /data/sunnycia/saliency_on_videoset/Train/C3D-v1.1-tmp
 7721  python test_video.py --video_deploy_path='prototxt/vo-v5-sigmoid_deploy.prototxt' --video_model_path='../training_output/salicon/vo-v5-sigmoid-snapshot-4000-sigmoid_activate_function-batch-2_1521887606/snapshot-_iter_32000.caffemodel' --infertype='slide' --output_type='image' --test_base='videoset' --model_code='v4-2' --videolength=16
 7722  cd /data/sunnycia/saliency_on_videoset/Train/scripts/prototxt
 7723  cd ..
 7724  python test_video.py --video_deploy_path='prototxt/vo-v5-sigmoid_deploy.prototxt' --video_model_path='../training_output/salicon/vo-v5-sigmoid-snapshot-4000-sigmoid_activate_function-batch-2_1521887606/snapshot-_iter_32000.caffemodel' --infertype='slide' --output_type='image' --test_base='videoset' --model_code='v4-2' --videolength=16
 7725  source set_env.sh ../C3D-v1.1-tmp/
 7726  python test_video.py --video_deploy_path='prototxt/vo-v5-sigmoid_deploy.prototxt' --video_model_path='../training_output/salicon/vo-v5-sigmoid-snapshot-4000-sigmoid_activate_function-batch-2_1521887606/snapshot-_iter_32000.caffemodel' --infertype='slide' --output_type='image' --test_base='videoset' --model_code='v4-2' --videolength=16
 7727  source set_env.sh ../C3D-v1.1-tmp/ 6
 7728  nvidia-smi
 7729  python test_video.py --video_deploy_path='prototxt/vo-v5-sigmoid_deploy.prototxt' --video_model_path='../training_output/salicon/vo-v5-sigmoid-snapshot-4000-sigmoid_activate_function-batch-2_1521887606/snapshot-_iter_32000.caffemodel' --infertype='slide' --output_type='image' --test_base='videoset' --model_code='v4-2' --videolength=16
 7730  cd /data/sunnycia/saliency_on_videoset/Train/C3D-v1.1-tmp
 7731  make clean
 7732  make -j8 all && make pycaffe
 7733  vim Makefile.config
 7734  make clean
 7735  make -j8 all && make pycaffe
 7736  cd -
 7737  python test_video.py --video_deploy_path='prototxt/vo-v5-sigmoid_deploy.prototxt' --video_model_path='../training_output/salicon/vo-v5-sigmoid-snapshot-4000-sigmoid_activate_function-batch-2_1521887606/snapshot-_iter_32000.caffemodel' --infertype='slide' --output_type='image' --test_base='videoset' --model_code='v4-2' --videolength=16
 7738  cd -
 7739  python test_video.py --video_deploy_path='prototxt/vo-v5-sigmoid_deploy.prototxt' --video_model_path='../training_output/salicon/vo-v5-sigmoid-snapshot-4000-sigmoid_activate_function-batch-2_1521887606/snapshot-_iter_32000.caffemodel' --infertype='slide' --output_type='image' --test_base='videoset' --model_code='v4-2' --videolength=16
 7740  cd /data/sunnycia/saliency_on_videoset/Train/scripts
 7741  python utils/analyse_vomodel_metric.py --metricdir='/data/sunnycia/saliency_on_videoset/_Metric_results/nopar/final/_Result_1_fc_6/train_kldloss-kld_weight-100-batch-1_1510102029_usesnapshot_1509584263_snapshot-_iter_100000' --salvodir='/data/sunnycia/SaliencyDataset/Video/VideoSet/Results/saliency_video/image_model_result/train_kldloss-kld_weight-100-batch-1_1510102029_usesnapshot_1509584263_snapshot-_iter_100000' --metvobase='/data/sunnycia/saliency_on_videoset/Train/analyse_vomodel/train_kldloss-kld_weight-100-batch-1_1510102029_usesnapshot_1509584263_snapshot-_iter_100000' --outputbase='../all_visualization' 
 7742   top
 7743  gcc -v
 7744  top
 7745  nvidia-smi
 7746  clear
 7747  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-resnet-slicekldloss.prototxt' --use_model='../training_output/salicon/vo-v4-2-resnet-dropout-snapshot-2000-display-1-dropout_fulldens-batch-2_1514857787/snapshot-_iter_26000.caffemodel' --plotiter=200 --validiter=4000 --savemodeliter=4000 --trainingexampleprops=0.99 --trainingbase='ledov' --videolength=16 --overlap=15 --extramodinfo='slice_clip_kld' --batch=2
 7748  clear && clear
 7749  source set_env.sh ../C3D-v1.1 6
 7750  nvidia-smi
 7751  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-resnet-slicekldloss.prototxt' --use_model='../training_output/salicon/vo-v4-2-resnet-dropout-snapshot-2000-display-1-dropout_fulldens-batch-2_1514857787/snapshot-_iter_26000.caffemodel' --plotiter=200 --validiter=4000 --savemodeliter=4000 --trainingexampleprops=0.99 --trainingbase='ledov' --videolength=16 --overlap=15 --extramodinfo='slice_clip_kld' --batch=2
 7752  source set_env.sh ../C3D-v1.1-kldloss/ 6
 7753  clear && clear
 7754  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-resnet-slicekldloss.prototxt' --use_model='../training_output/salicon/vo-v4-2-resnet-dropout-snapshot-2000-display-1-dropout_fulldens-batch-2_1514857787/snapshot-_iter_26000.caffemodel' --plotiter=200 --validiter=4000 --savemodeliter=4000 --trainingexampleprops=0.99 --trainingbase='ledov' --videolength=16 --overlap=15 --extramodinfo='slice_clip_kld' --batch=2
 7755  source set_env.sh ../C3D-v1.1-tmp/ 6
 7756  clear && clear
 7757  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-resnet-slicekldloss.prototxt' --use_model='../training_output/salicon/vo-v4-2-resnet-dropout-snapshot-2000-display-1-dropout_fulldens-batch-2_1514857787/snapshot-_iter_26000.caffemodel' --plotiter=200 --validiter=4000 --savemodeliter=4000 --trainingexampleprops=0.99 --trainingbase='ledov' --videolength=16 --overlap=15 --extramodinfo='slice_clip_kld' --batch=2
 7758  source set_env.sh ../C3D-v1.1-kldloss/ 6
 7759  clear && clear
 7760  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-resnet-slicekldloss.prototxt' --use_model='../training_output/salicon/vo-v4-2-resnet-dropout-snapshot-2000-display-1-dropout_fulldens-batch-2_1514857787/snapshot-_iter_26000.caffemodel' --plotiter=200 --validiter=4000 --savemodeliter=4000 --trainingexampleprops=0.99 --trainingbase='ledov' --videolength=16 --overlap=15 --extramodinfo='slice_clip_kld' --batch=2
 7761  cd ../C3D-v1.1-kldloss/
 7762  make clean
 7763  make -j8 all && make pycaffe
 7764  vim Makefile.config
 7765  make -j8 all && make pycaffe
 7766  cd -
 7767  clear && clear
 7768  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-resnet-slicekldloss.prototxt' --use_model='../training_output/salicon/vo-v4-2-resnet-dropout-snapshot-2000-display-1-dropout_fulldens-batch-2_1514857787/snapshot-_iter_26000.caffemodel' --plotiter=200 --validiter=4000 --savemodeliter=4000 --trainingexampleprops=0.99 --trainingbase='ledov' --videolength=16 --overlap=15 --extramodinfo='slice_clip_kld' --batch=2
 7769  clear && clear
 7770  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-resnet-slicekldloss.prototxt' --use_model='../training_output/salicon/vo-v4-2-resnet-dropout-snapshot-2000-display-1-dropout_fulldens-batch-2_1514857787/snapshot-_iter_26000.caffemodel' --plotiter=200 --validiter=4000 --savemodeliter=4000 --trainingexampleprops=0.99 --trainingbase='ledov' --videolength=16 --overlap=15 --extramodinfo='slice_clip_kld' --batch=2
 7771  clear && clear
 7772  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-resnet-slicekldloss.prototxt' --use_model='../training_output/salicon/vo-v4-2-resnet-dropout-snapshot-2000-display-1-dropout_fulldens-batch-2_1514857787/snapshot-_iter_26000.caffemodel' --plotiter=200 --validiter=4000 --savemodeliter=4000 --trainingexampleprops=0.9999 --trainingbase='ledov' --videolength=16 --overlap=15 --extramodinfo='slice_clip_kld' --batch=2
 7773  clear && clear
 7774  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-resnet-slicekldloss.prototxt' --use_model='../training_output/salicon/vo-v4-2-resnet-dropout-snapshot-2000-display-1-dropout_fulldens-batch-2_1514857787/snapshot-_iter_26000.caffemodel' --plotiter=200 --validiter=4000 --savemodeliter=4000 --trainingexampleprops=0.9999 --trainingbase='ledov' --videolength=16 --overlap=15 --extramodinfo='slice_clip_kld' --batch=2 
 7775  clear & clear 
 7776  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-resnet-slicekldloss.prototxt' --use_model='../training_output/salicon/vo-v4-2-resnet-dropout-snapshot-2000-display-1-dropout_fulldens-batch-2_1514857787/snapshot-_iter_26000.caffemodel' --plotiter=200 --validiter=4000 --savemodeliter=4000 --trainingexampleprops=0.9999 --trainingbase='ledov' --videolength=16 --overlap=15 --extramodinfo='slice_clip_kld' --batch=2 
 7777  clear && clear
 7778  df -h
 7779  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-resnet-dropout.prototxt' --use_model='../training_output/salicon/vo-v4-2-resnet-dropout-snapshot-2000-display-1-dropout_fulldens-batch-2_1514857787/snapshot-_iter_26000.caffemodel' --plotiter=200 --validiter=4000 --savemodeliter=4000 --trainingexampleprops=0.9999 --trainingbase='ledov' --videolength=16 --overlap=15 --extramodinfo='data_aug' --batch=2 --data_augmentation=True
 7780  clear && clear
 7781  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-resnet-dropout.prototxt' --use_model='../training_output/salicon/vo-v4-2-resnet-dropout-snapshot-2000-display-1-dropout_fulldens-batch-2_1514857787/snapshot-_iter_26000.caffemodel' --plotiter=200 --validiter=4000 --savemodeliter=4000 --trainingexampleprops=0.9999 --trainingbase='ledov' --videolength=16 --overlap=15 --extramodinfo='data_aug' --batch=2 --data_augmentation=True
 7782  clear && clear
 7783  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-resnet-dropout.prototxt' --use_model='../training_output/salicon/vo-v4-2-resnet-dropout-snapshot-2000-display-1-dropout_fulldens-batch-2_1514857787/snapshot-_iter_26000.caffemodel' --plotiter=200 --validiter=4000 --savemodeliter=4000 --trainingexampleprops=0.9999 --trainingbase='ledov' --videolength=16 --overlap=15 --extramodinfo='data_aug' --batch=2 --data_augmentation=True
 7784  clear && clear
 7785  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-resnet-dropout.prototxt' --use_model='../pretrained_model/c3d_resnet18_sports1m_r2_iter_2800000.caffemodel' --plotiter=200 --validiter=4000 --savemodeliter=4000 --trainingexampleprops=0.9999 --trainingbase='ledov' --videolength=16 --overlap=15 --extramodinfo='data_aug' --batch=2 --data_augmentation=True
 7786  clear && cleawr
 7787  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-resnet-dropout.prototxt' --use_model='../pretrained_model/c3d_resnet18_sports1m_r2_iter_2800000.caffemodel' --plotiter=200 --validiter=4000 --savemodeliter=4000 --trainingexampleprops=0.995 --trainingbase='ledov' --videolength=16 --overlap=15 --extramodinfo='data_aug' --batch=2 --data_augmentation=True
 7788  df -h
 7789  clear && clear
 7790  df -h
 7791  clear
 7792  cd /data/sunnycia/saliency_on_videoset/Train/experiment/lec30_fixation_saccade
 7793  python plot_xy.py 
 7794  clear && clear
 7795  python plot_xy.py 
 7796  cd /data/sunnycia/saliency_on_videoset/Train/scripts/utils/dsutil
 7797  clear
 7798  python dataset_information.py --video_directory=/data/SaliencyDataset/Video/GAZECOM/videos
 7799  python dataset_information.py --video_directory=/data/SaliencyDataset/Video/DIEM/videos
 7800  python dataset_information.py --video_directory=/data/SaliencyDataset/Video/ActionInTheEye/Hollywood2/Hollywood2-actions/AVIClips
 7801  cd /data/SaliencyDataset/Video/ActionInTheEye/VOC
 7802  tar -xf VOCtrainval_11-May-2012.tar 
 7803  cd -
 7804  python dataset_information.py --video_directory=/data/SaliencyDataset/Video/LEDOV/videos
 7805  python dataset_information.py --video_directory=/data/SaliencyDataset/Video/MSU/videos
 7806  python dataset_information.py --video_directory=/data/SaliencyDataset/Video/ActionInTheEye/UCF/videos
 7807  python dataset_information.py --video_directory=/data/SaliencyDataset/Video/GAZECOM/videos
 7808  python dataset_information.py --video_directory=/data/SaliencyDataset/Video/DIEM/videos
 7809  python dataset_information.py --video_directory=/data/SaliencyDataset/Video/ActionInTheEye/UCF/videos
 7810  python dataset_information.py --video_directory=/data/SaliencyDataset/Video/MSU/videos
 7811  python dataset_information.py --video_directory=/data/SaliencyDataset/Video/LEDOV/videos
 7812  python dataset_information.py --video_directory=/data/SaliencyDataset/Video/ActionInTheEye/Hollywood2/Hollywood2-actions/AVIClips
 7813  python dataset_information.py --video_directory=/data/SaliencyDataset/Video/ActionInTheEye/UCF/videos
 7814  top
 7815  nvidia-smi
 7816  df -h
 7817  top
 7818  nvidia-smi
 7819  clear && cleawr
 7820  cd /data/sunnycia/saliency_on_videoset/Train_2/dataset
 7821  python generate_dataset_for_one_subject.py 
 7822  pwd
 7823  ls
 7824  cd ..
 7825  python flicker.py 
 7826  df-h
 7827  clear
 7828  df -h
 7829  top
 7830  nvidia-smi
 7831  python flicker.py 
 7832  python flicker.py
 7833  python
 7834  python flicker.py 
 7835  cd /data/sunnycia/saliency_on_videoset/Train_2/experiment/lec30_fixation_saccade
 7836  python plot_xy.py 
 7837  top
 7838  df -h
 7839  top
 7840  claer && clear
 7841  clear && clear
 7842  top
 7843  cd /data/sunnycia/saliency_on_videoset/Train_2
 7844  python generate_dataset.py 
 7845  cd /data/sunnycia/saliency_on_videoset/Train_2
 7846  python generate_dataset.py 
 7847  clear && clear
 7848  top
 7849  python generate_dataset.py 
 7850  clear && clear
 7851  python generate_dataset.py 
 7852  clear && clear
 7853  python generate_dataset.py 
 7854  clear && clear
 7855  python generate_dataset.py 
 7856  clear && clear
 7857  python generate_dataset.py 
 7858  python analysis_label.py 
 7859  python calc_mean_map.py 
 7860  clear && clear
 7861  python calc_mean_map.py 
 7862  nvidia-smi
 7863  top
 7864  export CUDA_VISIBLE_DEVICES=7
 7865  python training.py
 7866  export CUDA_VISIBLE_DEVICES=7
 7867  python training.py
 7868  export CUDA_VISIBLE_DEVICES=7
 7869  python training.py
 7870  clear && clear
 7871  python training.py
 7872  ls
 7873  mkdir reference
 7874  cd reference/
 7875  git clone https://github.com/sniklaus/pytorch-sepconv.git
 7876  cd pytorch-sepconv/
 7877  ls
 7878  bash install.bash
 7879  ping 172.31.80.63
 7880  vim ~/.bashrc
 7881  source ~/.bashrc
 7882  vim install.bash 
 7883  bash install.bash 
 7884  cd.
 7885  cd ..
 7886  rm -rf pytorch-sepconv/
 7887  git clone https://github.com/sniklaus/pytorch-sepconv.git
 7888  cd pytorch-sepconv/
 7889  ls
 7890  bash install.bash 
 7891  cd /data/sunnycia/saliency_on_videoset/Train_2/reference/pytorch-sepconv
 7892  bash install.bash 
 7893  vim ~/.bashrc
 7894  su
 7895  source ~/.bashrc
 7896  bash install.bash 
 7897  cd /data/sunnycia/saliency_on_videoset/Train_2/try_lstm/tf_mnist_lstm
 7898  python training.py 
 7899  nvidia-smi
 7900  export CUDA_VISIBLE_DEVICES=7
 7901  python training.py 
 7902   
 7903  python training.py 
 7904  top
 7905  nvidia-smi
 7906  df -h
 7907  cd /data/sunnycia/saliency_on_videoset/Train_2
 7908  python generate_dataset.py 
 7909  top
 7910  nvidia-smi
 7911  export CUDA_VISIBLE_DEVICES=6
 7912  python testing.py 
 7913  top
 7914  python testing.py 
 7915  clear && clear
 7916  python testing.py 
 7917  cd /data/sunnycia/saliency_on_videoset/Train_2/reference/pytorch-sepconv
 7918  ls
 7919  python run.py --model lf --first ./images/first.png --second ./images/second.png --out ./result.png
 7920  python run.py --model lf --first ./images/frame_137.jpg --second ./images/frame_139.jpg --out ./result.png
 7921  python run.py --model lf --first ./density/frame_00007.jpg --second ./density/frame_00008.jpg --out ./result.png
 7922  python run.py --model lf --first ./images/frame_137.jpg --second ./images/frame_139.jpg --out ./result.png
 7923  python run.py --model lf --first ./density/frame_00007.jpg --second ./density/frame_00008.jpg --out ./result.png
 7924  python run.py --model lf --first ./density/frame_00007.jpg --second ./density/frame_00008.jpg --out ./result.png --channel='grey'
 7925  python run.py --model lf --first ./density/frame_00007.jpg --second ./density/frame_00008.jpg --out ./result.png --channel=grey
 7926  python run.py --model lf --first ./density/frame_00007.jpg --second ./density/frame_00008.jpg --out ./result.png --channel='grey'
 7927  python run.py --model lf --first ./density/frame_00007.jpg --second ./density/frame_00008.jpg --out ./result.png --channel grey
 7928  cd ..
 7929  ls
 7930  python inference.py 
 7931  cd /data/sunnycia/saliency_on_videoset/Train_2
 7932  python inference.py 
 7933  cd     print "Total frame:", len(frame_list)
 7934  cd /data/sunnycia/saliency_on_videoset/Train_2
 7935  python inference.py 
 7936  c d/data/sunnycia/saliency_on_videoset/Train_2
 7937  cd /data/sunnycia/saliency_on_videoset/Train_2
 7938  python inference.py 
 7939  nvidia-smi
 7940  export CUDA_VISIBLE_DEVICES=7
 7941  python inference.py 
 7942  cd /data/sunnycia/saliency_on_videoset/Train_2
 7943  python inference.py 
 7944  cd /data/sunnycia/saliency_on_videoset/Train_2
 7945  python inference.py 
 7946  top
 7947  nvidia-smi
 7948  cd /data/sunnycia/saliency_on_videoset/Train_2
 7949  python inference.py 
 7950  cd /data/sunnycia/saliency_on_videoset/Train_2
 7951  python inference.py 
 7952  cd 
 7953  cd /data/sunnycia/saliency_on_videoset/Train_2
 7954  python inference.py 
 7955  cd /data/sunnycia/saliency_on_videoset/Train_2
 7956  python inference.py 
 7957  cd /data/sunnycia/saliency_on_videoset/Train_2
 7958  python inference.py 
 7959  cd /data/sunnycia/saliency_on_videoset/Train_2
 7960  python inference.py 
 7961  cd /data/sunnycia/saliency_on_videoset/Train_2
 7962  python
 7963  vim ~/.bashrc
 7964  python
 7965  python inference.py 
 7966  cd 
 7967  *  tensorflow (1.5.0), caffe (1.0.0-rc3)         *
 7968  *  mxnet (0.9.5), keras (2.0.8), theano (0.9.0)  *
 7969  *                                                *
 7970  *  Port note:                                    *
 7971  *  18-01-22: open 4321                           *
 7972  *  Update memo:                                  *
 7973  cd /data/sunnycia/saliency_on_videoset/Train_2
 7974  python debug.py 
 7975  python inference.py 
 7976  cd /data/sunnycia/saliency_on_videoset/Train_2
 7977  python inference.py 
 7978  cd /data/sunnycia/saliency_on_videoset/Train_2
 7979  python inference.py 
 7980  cd /data/sunnycia/saliency_on_videoset/Train_2
 7981  python inference.py 
 7982  cd /data/sunnycia/saliency_on_videoset/Train_2
 7983  python inference.py 
 7984  cd /data/sunnycia/saliency_on_videoset/Train_2
 7985  python debug.py 
 7986  python
 7987  vim ~/.bashrc
 7988  source ~/.bashrc
 7989  top
 7990  nvidia-smi
 7991  cd /data/sunnycia/saliency_on_videoset/Train/scripts/prototxt
 7992  top
 7993  cd /data/sunnycia/saliency_on_videoset/Train/C3D-v1.0
 7994  ls
 7995  make clean
 7996  vim Makefile.config
 7997  make -j8 all
 7998  ls
 7999  cd python
 8000  python
 8001  cd ..
 8002  make -j4 pycaffe
 8003  python3
 8004  alias python=python3
 8005  python
 8006  make pycaffe
 8007  vim Makefile.config
 8008  ls  /usr/local/include/py*
 8009  cd /usr/local/include/python2.7
 8010  ls /usr/local/py*
 8011  ls /usr/local/lib/python2.7/
 8012  whereis python
 8013  ls /usr/bin/python2.7
 8014  ls /usr/bin/
 8015  clear && clear
 8016  python
 8017  alias python=python2
 8018  python
 8019  vim Makefile.config
 8020  make clean
 8021  make -j8 all
 8022  make pycaffe
 8023  cd python/
 8024  python
 8025  cd ..
 8026  make clean
 8027  cd ..
 8028  cd scripts/
 8029  ls
 8030  cd ..
 8031  history > history
 8032  cd scripts/
 8033  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-resnet-voxelloss-dropout.prototxt' --use_model='../pretrained_model/c3d_resnet18_sports1m_r2_iter_2800000.caffemodel' --plotiter=200 --validiter=4000 --savemodeliter=4000 --trainingexampleprops=0.995 --trainingbase='ledov' --videolength=16 --overlap=15 --extramodinfo='data_aug' --batch=2 --data_augmentation=True
 8034  nvidia-smi
 8035  source set_env.sh ../C3D-v1.0/
 8036  source set_env.sh ../C3D-v1.0/ 7
 8037  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-resnet-voxelloss-dropout.prototxt' --use_model='../pretrained_model/c3d_resnet18_sports1m_r2_iter_2800000.caffemodel' --plotiter=200 --validiter=4000 --savemodeliter=4000 --trainingexampleprops=0.995 --trainingbase='ledov' --videolength=16 --overlap=15 --extramodinfo='data_aug' --batch=2 --data_augmentation=True
 8038  cd ../C3D-v1.0/python/
 8039  python
 8040  cd ..
 8041  make clean
 8042  make -j8 all
 8043  make -j2 pycaffe
 8044  cd python/
 8045  import caffe
 8046  python
 8047  cd /data/sunnycia/saliency_on_videoset/Train/scripts/utils/dsutil
 8048  python gen_density.py --sigma=32 --fixation_base=/data/SaliencyDataset/Video/VideoSet/ImageSet/Seperate/fixation --density_base=/data/SaliencyDataset/Video/VideoSet/ImageSet/Seperate/density --fixationtype=image
 8049  top
 8050  nvidia-smi
 8051  top
 8052  cd ..
 8053  python test_video.py --video_deploy_path='prototxt/vo-v4-2-resnet-l1loss-dropout.prototxt' --video_model_path='../training_output/salicon/vo-v4-2-resnet-l1loss-dropout-snapshot-4000-data_aug-batch-2_1526869047/snapshot-_iter_120000.caffemodel' --infertype='slide' --output_type='image' --test_base='gazecom' --model_code='v4-2' --videolength=16
 8054  nvidia-smi
 8055  source set_env.sh ../C3D-v1.1-tmp/ 4
 8056  python test_video.py --video_deploy_path='prototxt/vo-v4-2-resnet-l1loss-dropout.prototxt' --video_model_path='../training_output/salicon/vo-v4-2-resnet-l1loss-dropout-snapshot-4000-data_aug-batch-2_1526869047/snapshot-_iter_120000.caffemodel' --infertype='slide' --output_type='image' --test_base='gazecom' --model_code='v4-2' --videolength=16
 8057  python test_video.py --video_deploy_path='prototxt/vo-v4-2-resnet-l1loss-dropout.prototxt' --video_model_path='../training_output/salicon/vo-v4-2-resnet-l1loss-dropout-snapshot-4000-data_aug-batch-2_1526869047/snapshot-_iter_120000.caffemodel' --infertype='slide' --output_type='image' --test_base='videoset' --model_code='v4-2' --videolength=16
 8058  python test_video.py --video_deploy_path='prototxt/vo-v4-2-resnet-l1loss-dropout.prototxt' --video_model_path='../training_output/salicon/vo-v4-2-resnet-l1loss-dropout-snapshot-4000-data_aug-batch-2_1526869047/snapshot-_iter_120000.caffemodel' --infertype='slide' --output_type='image' --test_base='ledov' --model_code='v4-2' --videolength=16
 8059  su
 8060  clear && clear
 8061  vim ~/.bashrc
 8062  python
 8063  su
 8064  python test_videoclip_over_finetune.py --working_directory='/data/sunnycia/saliency_on_videoset/Train/training_output/finetune/1526869047_snapshot-_iter_500000/videoset_1527423754' --dataset='videoset' --result_path='/data/sunnycia/saliency_on_videoset/Train/training_output/finetune/1526869047_snapshot-_iter_500000/videoset_1527423754/test_result'
 8065  vim ~/.bashrc
 8066  su
 8067  python
 8068  clear && clear
 8069  python test_videoclip_over_finetune.py --working_directory='/data/sunnycia/saliency_on_videoset/Train/training_output/finetune/1526869047_snapshot-_iter_500000/videoset_1527423754' --dataset='videoset' --result_path='/data/sunnycia/saliency_on_videoset/Train/training_output/finetune/1526869047_snapshot-_iter_500000/videoset_1527423754/test_result'
 8070  clear && clear
 8071  python test_videoclip_over_finetune.py --working_directory='/data/sunnycia/saliency_on_videoset/Train/training_output/finetune/1526869047_snapshot-_iter_500000/videoset_1527423754' --dataset='videoset' --result_path='/data/sunnycia/saliency_on_videoset/Train/training_output/finetune/1526869047_snapshot-_iter_500000/videoset_1527423754/test_result'
 8072  clear && clear
 8073  python test_videoclip_over_finetune.py --working_directory='/data/sunnycia/saliency_on_videoset/Train/training_output/finetune/1526869047_snapshot-_iter_500000/videoset_1527423754' --dataset='videoset' --result_path='/data/sunnycia/saliency_on_videoset/Train/training_output/finetune/1526869047_snapshot-_iter_500000/videoset_1527423754/test_result'
 8074  clear && clear
 8075  python test_videoclip_over_finetune.py --working_directory='/data/sunnycia/saliency_on_videoset/Train/training_output/finetune/1526869047_snapshot-_iter_500000/videoset_1527423754' --dataset='videoset' --result_path='/data/sunnycia/saliency_on_videoset/Train/training_output/finetune/1526869047_snapshot-_iter_500000/videoset_1527423754/test_result'
 8076  clear && clear
 8077  python test_videoclip_over_finetune.py --working_directory='/data/sunnycia/saliency_on_videoset/Train/training_output/finetune/1526869047_snapshot-_iter_500000/videoset_1527423754' --dataset='videoset' --result_path='/data/sunnycia/saliency_on_videoset/Train/training_output/finetune/1526869047_snapshot-_iter_500000/videoset_1527423754/test_result'
 8078  nvidia-smi
 8079  top
 8080  nvidia-smi
 8081  export CUDA_VISIBLE_DEVICES=6
 8082  python test_videoclip_over_finetune.py --working_directory='/data/sunnycia/saliency_on_videoset/Train/training_output/finetune/1526869047_snapshot-_iter_500000/videoset_1527423754' --dataset='videoset' --result_path='/data/sunnycia/saliency_on_videoset/Train/training_output/finetune/1526869047_snapshot-_iter_500000/videoset_1527423754/test_result'
 8083  clear && clear
 8084  python test_videoclip_over_finetune.py --working_directory='/data/sunnycia/saliency_on_videoset/Train/training_output/finetune/1526869047_snapshot-_iter_500000/videoset_1527423754' --dataset='videoset' --result_path='/data/sunnycia/saliency_on_videoset/Train/training_output/finetune/1526869047_snapshot-_iter_500000/videoset_1527423754/test_result'
 8085  cd ..
 8086  df -h
 8087  cd scripts/
 8088  python ss_test_video.py 
 8089  python test_video.py --video_deploy_path='prototxt/vo-v4-2-resnet-deploy.prototxt' --video_model_path='../training_output/salicon/vo-v4-2-resnet-l1loss-dropout-snapshot-4000-data_aug-batch-2_1526869047/snapshot-_iter_100000.caffemodel' --infertype='slide' --output_type='image' --test_base='videoset' --model_code='v4-2' --videolength=16
 8090  vim /etc/profole
 8091  vim /etc/profile
 8092  vim ~/.bashrc
 8093  source ~/.bashrc
 8094  top
 8095  clear
 8096  cd /data/SaliencyDataset/VideoSeg
 8097  git clone https://github.com/davisvideochallenge/davis.git
 8098  ls
 8099  cd davis/
 8100  ls
 8101  cd data/
 8102  ls
 8103  bash get_davis.sh 
 8104  bash get_davis_results.sh 
 8105  df -h
 8106  cp -R
 8107  cp -R /data/SaliencyDataset/Video/VideoSet/jnd3-data/density/sigma32/ /data/SaliencyDataset/Video/VideoSet/Results/saliency_map
 8108  cd /data/sunnycia/saliency_on_videoset/Train/scripts/metric
 8109  clear 
 8110  matlab -nodesktop -nodisplay
 8111  matlab
 8112  matlab -nodesktop -nodisplay
 8113  top
 8114  cd ..
 8115  cd utils/dsutil/
 8116   python convert_img_type.py --base='/data/SaliencyDataset/Video/VideoSet/Results/saliency_map/UNCERTAINTY'
 8117   python convert_img_type.py --base='/data/SaliencyDataset/Video/VideoSet/Results/saliency_map/uncertainty'
 8118  cd -
 8119  cd /data/sunnycia/saliency_on_videoset/Train/scripts/utils/vizutil
 8120  python vis_dataset.py 
 8121  cd /data/SaliencyDataset/Video/VideoSet/ImageSet/Seperate
 8122  python rename.py 
 8123  cd -
 8124  python vis_dataset.py 
 8125  locate sam_viz
 8126  python vis_dataset.py 
 8127  cd ..
 8128  git clone /data/sunnycia/saliency_on_videoset/Train/scripts/utils
 8129  git clone https://github.com/sethoscope/heatmap.git
 8130  cd heatmap/
 8131  heatmap.py --points plainfile -o map.png --width 100
 8132  python heatmap.py --points plainfile -o map.png --width 100
 8133  heatmap.py -o map.png --width 100 track*.gpx extras.csv morepoints.shp
 8134  pytthon heatmap.py -o map.png --width 100 track*.gpx extras.csv morepoints.shp
 8135  python heatmap.py -o map.png --width 100 track*.gpx extras.csv morepoints.shp
 8136  python random_example.py 
 8137  cd -
 8138  python vis_dataset.py 
 8139  cd vizutil/
 8140  python vis_dataset.py 
 8141  top
 8142  nvidia-smi
 8143  clear
 8144  python vis_dataset.py 
 8145  cd /data/SaliencyDataset/Video/VideoSet/ImageSet/Seperate
 8146  python rename.py 
 8147  top
 8148  cd /data/sunnycia/saliency_on_videoset/Train/scripts/utils/vizutil
 8149  python vis_dataset.py 
 8150  top
 8151  cd ../..
 8152  source set_env.sh ../C3D-v1.1-tmp/ 7
 8153  clear && clear
 8154  python test_video.py --video_deploy_path='prototxt/^Crototxt' --video_model_path='../training_output/salicon/vo-v5-sigmoid-snapshot-4000-sigmoid_activate_function-batch-2_1521887606/snapshot-_iter_32000.caffemodel' --infertype='slide' --output_type='image' --test_base='gazecom' --model_code='v4-2' --videolength=16
 8155  python test_video.py --video_deploy_path='prototxt/vo-v4-2-resnet-l1loss-deploy.prototxt' --video_model_path='../training_output/salicon/vo-v4-2-resnet-l1loss-dropout-snapshot-10000-data_aug-batch-2_1527144891/snapshot-_iter_50000.caffemodel' --infertype='slide' --output_type='image' --test_base='gazecom' --model_code='v4-2' --videolength=16
 8156  python test_video.py --video_deploy_path='prototxt/vo-v4-2-resnet-l1loss-deploy.prototxt' --video_model_path='../training_output/salicon/vo-v4-2-resnet-l1loss-dropout-snapshot-10000-data_aug-batch-2_1527144891/snapshot-_iter_50000.caffemodel' --infertype='slide' --output_type='image' --test_base='videoset' --model_code='v4-2' --videolength=16
 8157  top
 8158  nvidia-smi
 8159  source set_env.sh ../C3D-v1.1-tmp/ 3
 8160  python finetune_test_video.py --pretrained_model='/data/sunnycia/saliency_on_videoset/Train/training_output/salicon/vo-v4-2-resnet-l1loss-dropout-snapshot-4000-data_aug-batch-2_1526869047/snapshot-_iter_500000.caffemodel' --network_prototxt='prototxt/vo-v4-2-resnet-l1loss-deploy.prototxt' --solver_prototxt='prototxt/solver-static.prototxt' --epoch=10 --dataset='videoset' --fold=10 
 8161  clear && clear
 8162  python finetune_test_video.py --pretrained_model='/data/sunnycia/saliency_on_videoset/Train/training_output/salicon/vo-v4-2-resnet-l1loss-dropout-snapshot-4000-data_aug-batch-2_1526869047/snapshot-_iter_500000.caffemodel' --network_prototxt='prototxt/vo-v4-2-resnet-l1loss-deploy.prototxt' --solver_prototxt='prototxt/solver-static.prototxt' --epoch=10 --dataset='videoset' --fold=10 
 8163  clear && clear
 8164  python finetune_test_video.py --pretrained_model='/data/sunnycia/saliency_on_videoset/Train/training_output/salicon/vo-v4-2-resnet-l1loss-dropout-snapshot-4000-data_aug-batch-2_1526869047/snapshot-_iter_500000.caffemodel' --network_prototxt='prototxt/vo-v4-2-resnet-l1loss-deploy.prototxt' --solver_prototxt='prototxt/solver-static.prototxt' --epoch=10 --dataset='videoset' --fold=10 
 8165  clear && clear
 8166  python finetune_test_video.py --pretrained_model='/data/sunnycia/saliency_on_videoset/Train/training_output/salicon/vo-v4-2-resnet-l1loss-dropout-snapshot-4000-data_aug-batch-2_1526869047/snapshot-_iter_500000.caffemodel' --network_prototxt='prototxt/vo-v4-2-resnet-l1loss-deploy.prototxt' --solver_prototxt='prototxt/solver-static.prototxt' --epoch=10 --dataset='videoset' --fold=10 
 8167  clear && clear
 8168  python finetune_test_video.py --pretrained_model='/data/sunnycia/saliency_on_videoset/Train/training_output/salicon/vo-v4-2-resnet-l1loss-dropout-snapshot-4000-data_aug-batch-2_1526869047/snapshot-_iter_500000.caffemodel' --network_prototxt='prototxt/vo-v4-2-resnet-l1loss-deploy.prototxt' --solver_prototxt='prototxt/solver-static.prototxt' --epoch=1 --dataset='videoset' --fold=5 --metric_iter=200 
 8169  python finetune_test_video.py --pretrained_model='/data/sunnycia/saliency_on_videoset/Train/training_output/salicon/vo-v4-2-resnet-l1loss-dropout-snapshot-4000-data_aug-batch-2_1526869047/snapshot-_iter_500000.caffemodel' --network_prototxt='prototxt/vo-v4-2-resnet-l1loss-deploy.prototxt' --solver_prototxt='prototxt/solver-static.prototxt' --epoch=10 --dataset='videoset' --fold=10 --metric_iter=500 
 8170  clear && clear
 8171  python finetune_test_video.py --pretrained_model='/data/sunnycia/saliency_on_videoset/Train/training_output/salicon/vo-v4-2-resnet-l1loss-dropout-snapshot-4000-data_aug-batch-2_1526869047/snapshot-_iter_500000.caffemodel' --network_prototxt='prototxt/vo-v4-2-resnet-l1loss-deploy.prototxt' --solver_prototxt='prototxt/solver-static.prototxt' --epoch=10 --dataset='videoset' --fold=10 --metric_iter=500 
 8172  clear && clear
 8173  python finetune_test_video.py --pretrained_model='/data/sunnycia/saliency_on_videoset/Train/training_output/salicon/vo-v4-2-resnet-l1loss-dropout-snapshot-4000-data_aug-batch-2_1526869047/snapshot-_iter_500000.caffemodel' --network_prototxt='prototxt/vo-v4-2-resnet-l1loss-deploy.prototxt' --solver_prototxt='prototxt/solver-static.prototxt' --epoch=1 --dataset='videoset' --fold=5 --valid_iter=200 
 8174  clear && clear
 8175  python finetune_test_video.py --pretrained_model='/data/sunnycia/saliency_on_videoset/Train/training_output/salicon/vo-v4-2-resnet-l1loss-dropout-snapshot-4000-data_aug-batch-2_1526869047/snapshot-_iter_500000.caffemodel' --network_prototxt='prototxt/vo-v4-2-resnet-l1loss-deploy.prototxt' --solver_prototxt='prototxt/solver-static.prototxt' --epoch=1 --dataset='videoset' --fold=5 --valid_iter=200 
 8176  clear && clear
 8177  python finetune_test_video.py --pretrained_model='/data/sunnycia/saliency_on_videoset/Train/training_output/salicon/vo-v4-2-resnet-l1loss-dropout-snapshot-4000-data_aug-batch-2_1526869047/snapshot-_iter_500000.caffemodel' --network_prototxt='prototxt/vo-v4-2-resnet-l1loss-deploy.prototxt' --solver_prototxt='prototxt/solver-static.prototxt' --epoch=1 --dataset='videoset' --fold=500 --valid_iter=200 
 8178  [A
 8179  python finetune_test_video.py --pretrained_model='/data/sunnycia/saliency_on_videoset/Train/training_output/salicon/vo-v4-2-resnet-l1loss-dropout-snapshot-4000-data_aug-batch-2_1526869047/snapshot-_iter_500000.caffemodel' --network_prototxt='prototxt/vo-v4-2-resnet-l1loss-deploy.prototxt' --solver_prototxt='prototxt/solver-static.prototxt' --epoch=1 --dataset='videoset' --fold=500 --valid_iter=200 
 8180  clear && clear
 8181  python finetune_test_video.py --pretrained_model='/data/sunnycia/saliency_on_videoset/Train/training_output/salicon/vo-v4-2-resnet-l1loss-dropout-snapshot-4000-data_aug-batch-2_1526869047/snapshot-_iter_500000.caffemodel' --network_prototxt='prototxt/vo-v4-2-resnet-l1loss-deploy.prototxt' --solver_prototxt='prototxt/solver-static.prototxt' --epoch=10 --dataset='videoset' --fold=10 --valid_iter=5000 
 8182  clear && clear
 8183  python finetune_test_video.py --pretrained_model='/data/sunnycia/saliency_on_videoset/Train/training_output/salicon/vo-v4-2-resnet-l1loss-dropout-snapshot-4000-data_aug-batch-2_1526869047/snapshot-_iter_500000.caffemodel' --network_prototxt='prototxt/vo-v4-2-resnet-l1loss-deploy.prototxt' --solver_prototxt='prototxt/solver-static.prototxt' --epoch=50 --dataset='videoset' --fold=10 --valid_iter=5000 
 8184  clear && clear
 8185  python finetune_test_video.py --pretrained_model='/data/sunnycia/saliency_on_videoset/Train/training_output/salicon/vo-v4-2-resnet-l1loss-dropout-snapshot-4000-data_aug-batch-2_1526869047/snapshot-_iter_500000.caffemodel' --network_prototxt='prototxt/vo-v4-2-resnet-l1loss-deploy.prototxt' --solver_prototxt='prototxt/solver-static.prototxt' --epoch=50 --dataset='videoset' --fold=10 --valid_iter=5000 
 8186   top
 8187  top
 8188  nvidia-smi
 8189  cd utils/dsutil/
 8190  python find_entropy_video.py 
 8191  python
 8192  python find_entropy_video.py 
 8193  top
 8194  python find_entropy_video.py 
 8195  top
 8196  python find_entropy_video.py 
 8197  top
 8198  htop
 8199  lscpu
 8200  top
 8201  cd ../vizutil/
 8202  python inference_comparison.py --output_path='vg_inference.jpg' --wildcards_record='vg_wildcards_record.txt' --samples=8
 8203  df -h
 8204  cd ../dsutil/
 8205  python slice_frame.py --videobase='/data/SaliencyDataset/Video/VideoSet/Videos/videos_origin' --outputbase='/data/SaliencyDataset/Video/VideoSet/ImageSet/Seperate/frames'
 8206  python slice_frames.py --videobase='/data/SaliencyDataset/Video/VideoSet/Videos/videos_origin' --outputbase='/data/SaliencyDataset/Video/VideoSet/ImageSet/Seperate/frames'
 8207  cd -
 8208  vim vg_wildcards_record.txt 
 8209  python inference_comparison.py --output_path='vg_inference.jpg' --wildcards_record='vg_wildcards_record.txt' --samples=8
 8210  locate convert*
 8211  locate convert_type.py
 8212  cd -
 8213  python convert_img_type.py 
 8214  python convert_img_type.py --base='/data/SaliencyDataset/Video/VideoSet/Results/saliency_map/GBVS' 
 8215  cd -
 8216  python inference_comparison.py --output_path='vg_inference.jpg' --wildcards_record='vg_wildcards_record.txt' --samples=8
 8217  cd -
 8218  python convert_img_type.py --base='/data/SaliencyDataset/Video/VideoSet/Results/saliency_map/SALICON' 
 8219  python convert_img_type.py --base='/data/SaliencyDataset/Video/VideoSet/Results/saliency_map/FANG2' 
 8220  cd -
 8221  python inference_comparison.py --output_path='vg_inference.jpg' --wildcards_record='vg_wildcards_record.txt' --samples=8
 8222  python 
 8223  cd /data/sunnycia/saliency_on_videoset/Train_2
 8224  python debug.py 
 8225  clear && clear
 8226  python debug.py 
 8227  cd ../Train
 8228  python training_video_voxel_based.py --train_prototxt=prototxt/vo-v4-2-connect-resnet-dropout.prototxt --use_model='../pretrained_model/c3d_resnet18_sports1m_r2_iter_2800000.caffemodel' --plotiter=200 --validiter=4000 --savemodeliter=4000 --trainingexampleprops=0.99 --trainingbase='ledov' --videolength=16 --overlap=15 --extramodelinfo='connection_resnet' --batch=2
 8229  cd scripts/
 8230  python training_video_voxel_based.py --train_prototxt=prototxt/vo-v4-2-connect-resnet-dropout.prototxt --use_model='../pretrained_model/c3d_resnet18_sports1m_r2_iter_2800000.caffemodel' --plotiter=200 --validiter=4000 --savemodeliter=4000 --trainingexampleprops=0.99 --trainingbase='ledov' --videolength=16 --overlap=15 --extramodelinfo='connection_resnet' --batch=2
 8231  python training_video_voxel_based.py --train_prototxt=prototxt/vo-v4-2-connect-resnet-dropout.prototxt --use_model='../pretrained_model/c3d_resnet18_sports1m_r2_iter_2800000.caffemodel' --plotiter=200 --validiter=4000 --savemodeliter=4000 --trainingexampleprops=0.99 --trainingbase='ledov' --videolength=16 --overlap=15 --extramodinfo='connection_resnet' --batch=2
 8232  source set_env.sh ../C3D-v1.1 7
 8233  nvidia-smi
 8234  python training_video_voxel_based.py --train_prototxt=prototxt/vo-v4-2-connect-resnet-dropout.prototxt --use_model='../pretrained_model/c3d_resnet18_sports1m_r2_iter_2800000.caffemodel' --plotiter=200 --validiter=4000 --savemodeliter=4000 --trainingexampleprops=0.99 --trainingbase='ledov' --videolength=16 --overlap=15 --extramodinfo='connection_resnet' --batch=2
 8235  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-connect-resnet-dropout.prototxt' --use_model='../pretrained_model/c3d_resnet18_sports1m_r2_iter_2800000.caffemodel' --plotiter=200 --validiter=4000 --savemodeliter=4000 --trainingexampleprops=0.99 --trainingbase='ledov' --videolength=16 --overlap=15 --extramodinfo='connection_resnet' --batch=2
 8236  clear && clear
 8237  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-connect-resnet-dropout.prototxt' --use_model='../pretrained_model/c3d_resnet18_sports1m_r2_iter_2800000.caffemodel' --plotiter=200 --validiter=4000 --savemodeliter=4000 --trainingexampleprops=0.99 --trainingbase='ledov' --videolength=16 --overlap=15 --extramodinfo='connection_resnet' --batch=2
 8238  clear && clear
 8239  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-connect-resnet-dropout.prototxt' --use_model='../pretrained_model/c3d_resnet18_sports1m_r2_iter_2800000.caffemodel' --plotiter=200 --validiter=4000 --savemodeliter=4000 --trainingexampleprops=0.99 --trainingbase='ledov' --videolength=16 --overlap=15 --extramodinfo='connection_resnet' --batch=2 --connection
 8240  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-connect-resnet-dropout.prototxt' --use_model='../pretrained_model/c3d_resnet18_sports1m_r2_iter_2800000.caffemodel' --plotiter=200 --validiter=4000 --savemodeliter=4000 --trainingexampleprops=0.99 --trainingbase='ledov' --videolength=16 --overlap=15 --extramodinfo='connection_resnet' --batch=2 --connection=1
 8241  clear ** clear
 8242  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-connect-resnet-dropout.prototxt' --use_model='../pretrained_model/c3d_resnet18_sports1m_r2_iter_2800000.caffemodel' --plotiter=200 --validiter=4000 --savemodeliter=4000 --trainingexampleprops=0.99 --trainingbase='ledov' --videolength=16 --overlap=15 --extramodinfo='connection_resnet' --batch=2 --connection=1
 8243  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-connect-resnet-dropout.prototxt' --use_model='../pretrained_model/c3d_resnet18_sports1m_r2_iter_2800000.caffemodel' --plotiter=200 --validiter=4000 --savemodeliter=4000 --trainingexampleprops=0.999 --trainingbase='ledov' --videolength=16 --overlap=15 --extramodinfo='connection_resnet' --batch=2 --connection=1
 8244  clear && clear
 8245  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-connect-resnet-dropout.prototxt' --use_model='../pretrained_model/c3d_resnet18_sports1m_r2_iter_2800000.caffemodel' --plotiter=200 --validiter=4000 --savemodeliter=4000 --trainingexampleprops=0.999 --trainingbase='ledov' --videolength=16 --overlap=15 --extramodinfo='connection_resnet' --batch=2 --connection=1
 8246  vim ~/.bashrc
 8247  cd /data/sunnycia/saliency_on_videoset/Train/scripts/utils/dsutil
 8248  python dataset_information.py --video_directory='/data/SaliencyDataset/Video/VideoSet/Videos/videos_origin'
 8249  su
 8250  clear
 8251  cd /data/SaliencyDataset/Video/VideoSet/jnd3-data
 8252  python rename.py 
 8253  clear
 8254  python rename.py 
 8255  cd /data/sunnycia/saliency_on_videoset/Train/scripts/utils/dsutil
 8256  python gen_density.py -h
 8257  python gen_density.py --sigma=32 --fixation_base=/data/SaliencyDataset/Video/VideoSet/jnd3-data/fixation --density_base=/data/SaliencyDataset/Video/VideoSet/jnd3-data/density --fixationtype=image
 8258  cd /data/sunnycia/saliency_on_videoset/Train
 8259  git clone https://github.com/Xiaoyi-Jia/caffe-l1_loss_layer.git
 8260  cd /data/sunnycia/saliency_on_videoset/Train/C3D-v1.1-tmp
 8261  make clean
 8262  make -j8 all
 8263  make clena
 8264  make clean
 8265  make -j8 all
 8266  make clean
 8267  make -j8 all
 8268  make pycaffe
 8269  cd ../scripts/
 8270  ls
 8271  source set_env.sh ../C3D-v1.1-tmp/
 8272  clear && clear
 8273  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-resnet-l1loss-dropout.prototxt' --use_model='../pretrained_model/c3d_resnet18_sports1m_r2_iter_2800000.caffemodel' --plotiter=200 --validiter=4000 --savemodeliter=4000 --trainingexampleprops=0.995 --trainingbase='ledov' --videolength=16 --overlap=15 --extramodinfo='data_aug' --batch=2 --data_augmentation=True
 8274  source set_env.sh ../C3D-v1.1-tmp/ 4
 8275  nvidia-smi
 8276  clear && clear
 8277  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-resnet-l1loss-dropout.prototxt' --use_model='../pretrained_model/c3d_resnet18_sports1m_r2_iter_2800000.caffemodel' --plotiter=200 --validiter=4000 --savemodeliter=4000 --trainingexampleprops=0.995 --trainingbase='ledov' --videolength=16 --overlap=15 --extramodinfo='data_aug' --batch=2 --data_augmentation=True
 8278  clear && clear
 8279  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-resnet-l1loss-dropout.prototxt' --use_model='../pretrained_model/c3d_resnet18_sports1m_r2_iter_2800000.caffemodel' --plotiter=200 --validiter=4000 --savemodeliter=4000 --trainingexampleprops=0.995 --trainingbase='ledov' --videolength=16 --overlap=15 --extramodinfo='data_aug' --batch=2 --data_augmentation=True
 8280  cd utils/dsutil/
 8281  python find_entropy_video.py 
 8282  top
 8283  cd ../..
 8284  python test_video-h
 8285  python test_video -h
 8286  python test_video.py -h
 8287  python test_video.py --video_deploy_path='prototxt/vo-v4-2-resnet-deploy.prototxt' --video_model_path='../training_output/finetune/snapshot-_iter_500000/videoset/1527350421_9.caffemodel' --infertype='slide' --output_type='image' --test_base='videoset' --model_code='v4-2' --videolength=16
 8288  clear && clear
 8289  bash running_script.sh 
 8290  vim running_script.sh 
 8291  clear && clear
 8292  bash running_script.sh 
 8293  clear && clear
 8294  bash running_script.sh 
 8295  top
 8296  nvidia-smi
 8297  top
 8298  nvidia-smi
 8299  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-connect-resnet-dropout.prototxt' --use_model='../pretrained_model/c3d_resnet18_sports1m_r2_iter_2800000.caffemodel' --plotiter=200 --validiter=4000 --savemodeliter=4000 --trainingexampleprops=0.99 --trainingbase='ledov' --videolength=16 --overlap=15 --extramodinfo='connection_resnet' --batch=2 --connection=1
 8300  cd /data/sunnycia/saliency_on_videoset/Train/scripts
 8301  nvidia-smi
 8302  source set_env.sh ../C3D-v1.1 5
 8303  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-connect-resnet-dropout.prototxt' --use_model='../pretrained_model/c3d_resnet18_sports1m_r2_iter_2800000.caffemodel' --plotiter=200 --validiter=4000 --savemodeliter=4000 --trainingexampleprops=0.99 --trainingbase='ledov' --videolength=16 --overlap=15 --extramodinfo='connection_resnet' --batch=2 --connection=1
 8304  clear && clear
 8305  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-connect-resnet-dropout.prototxt' --solver_prototxt='prototxt/solver-static.prototxt' --staticsolver=True --use_model='../pretrained_model/c3d_resnet18_sports1m_r2_iter_2800000.caffemodel' --plotiter=200 --validiter=4000 --savemodeliter=4000 --trainingexampleprops=0.995 --trainingbase='ledov' --videolength=16 --overlap=15 --extramodinfo='connection_resnet' --batch=2 --connection=1
 8306  clear && clear
 8307  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-connect-resnet-dropout.prototxt' --solver_prototxt='prototxt/solver-static.prototxt' --staticsolver=True --use_model='../pretrained_model/c3d_resnet18_sports1m_r2_iter_2800000.caffemodel' --plotiter=200 --validiter=4000 --savemodeliter=4000 --trainingexampleprops=0.995 --trainingbase='ledov' --videolength=16 --overlap=15 --extramodinfo='connection_resnet' --batch=2 --connection=1
 8308  source set_env.sh ../C3D-v1.1-tmp 5
 8309  clear && clear
 8310  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-resnet-l1loss-dropout.prototxt' --use_model='../pretrained_model/c3d_resnet18_sports1m_r2_iter_2800000.caffemodel' --plotiter=200 --validiter=4000 --savemodeliter=4000 --trainingexampleprops=0.995 --trainingbase='ledov' --videolength=16 --overlap=8 --extramodinfo='data_aug' --batch=2 --data_augmentation=True
 8311  cd utils/dsutil/ &&  python convert_img_type.py --base='/data/SaliencyDataset/Video/VideoSet/Results/saliency_map/PQFT'
 8312  top
 8313  matlab -nodesktop
 8314  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-connect-resnet-dropout.prototxt' --use_model='../pretrained_model/c3d_resnet18_sports1m_r2_iter_2800000.caffemodel' --plotiter=200 --validiter=4000 --savemodeliter=4000 --trainingexampleprops=0.99 --trainingbase='ledov' --videolength=16 --overlap=15 --extramodinfo='connection_resnet' --batch=2 --connection=1
 8315  cd /data/sunnycia/saliency_on_videoset/Train/scripts
 8316  source set_env.sh ../C3D-v1.1 6
 8317  nvidia-smi
 8318  top
 8319  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-connect-resnet-dropout.prototxt' --use_model='../pretrained_model/c3d_resnet18_sports1m_r2_iter_2800000.caffemodel' --plotiter=200 --validiter=4000 --savemodeliter=4000 --trainingexampleprops=0.99 --trainingbase='ledov' --videolength=16 --overlap=15 --extramodinfo='connection_resnet' --batch=2 --connection=1
 8320  clear && clear
 8321  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-connect-resnet-dropout.prototxt' --use_model='../pretrained_model/c3d_resnet18_sports1m_r2_iter_2800000.caffemodel' --plotiter=200 --validiter=4000 --savemodeliter=4000 --trainingexampleprops=0.99 --trainingbase='ledov' --videolength=16 --overlap=15 --extramodinfo='connection_resnet' --batch=2 --connection=1
 8322  clear && clear
 8323  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-connect-resnet-dropout.prototxt' --use_model='../pretrained_model/c3d_resnet18_sports1m_r2_iter_2800000.caffemodel' --plotiter=200 --validiter=4000 --savemodeliter=4000 --trainingexampleprops=0.99 --trainingbase='ledov' --videolength=16 --overlap=15 --extramodinfo='connection_resnet' --batch=2 --connection=1
 8324  clear && clear
 8325  ls
 8326  nvidia-smi
 8327  clear && clear
 8328  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-resnet-softmaxloss-dropout.prototxt' --solver_prototxt='./prototxt/static-solver.prototxt' --satticsolver=True --use_model='../pretrained_model/c3d_resnet18_sports1m_r2_iter_2800000.caffemodel' --plotiter=200 --validiter=4000 --savemodeliter=4000 --trainingexampleprops=0.995 --trainingbase='ledov' --videolength=16 --overlap=15 --extramodinfo='data_aug' --batch=2 --data_augmentation=True
 8329  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-resnet-softmaxloss-dropout.prototxt' --solver_prototxt='./prototxt/static-solver.prototxt' --staticsolver=True --use_model='../pretrained_model/c3d_resnet18_sports1m_r2_iter_2800000.caffemodel' --plotiter=200 --validiter=4000 --savemodeliter=4000 --trainingexampleprops=0.995 --trainingbase='ledov' --videolength=16 --overlap=15 --extramodinfo='data_aug' --batch=2 --data_augmentation=True
 8330  clear && clear
 8331  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-resnet-softmaxloss-dropout.prototxt' --solver_prototxt='./prototxt/solver-static.prototxt' --staticsolver=True --use_model='../pretrained_model/c3d_resnet18_sports1m_r2_iter_2800000.caffemodel' --plotiter=200 --validiter=4000 --savemodeliter=4000 --trainingexampleprops=0.995 --trainingbase='ledov' --videolength=16 --overlap=15 --extramodinfo='data_aug' --batch=2 --data_augmentation=True
 8332  clear && clear
 8333  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-resnet-softmaxloss-dropout.prototxt' --solver_prototxt='./prototxt/solver-static.prototxt' --staticsolver=True --use_model='../pretrained_model/c3d_resnet18_sports1m_r2_iter_2800000.caffemodel' --plotiter=200 --validiter=4000 --savemodeliter=4000 --trainingexampleprops=0.995 --trainingbase='ledov' --videolength=16 --overlap=15 --extramodinfo='data_aug' --batch=2 --data_augmentation=True
 8334  clear && clear
 8335  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-resnet-softmaxloss-dropout.prototxt' --solver_prototxt='./prototxt/solver-static.prototxt' --staticsolver=True --use_model='../pretrained_model/c3d_resnet18_sports1m_r2_iter_2800000.caffemodel' --plotiter=200 --validiter=4000 --savemodeliter=4000 --trainingexampleprops=0.995 --trainingbase='ledov' --videolength=16 --overlap=15 --extramodinfo='data_aug' --batch=2 --data_augmentation=True
 8336  clear && clear
 8337  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-resnet-softmaxloss-dropout.prototxt' --solver_prototxt='./prototxt/solver-static.prototxt' --staticsolver=True --use_model='../pretrained_model/c3d_resnet18_sports1m_r2_iter_2800000.caffemodel' --plotiter=200 --validiter=4000 --savemodeliter=4000 --trainingexampleprops=0.995 --trainingbase='ledov' --videolength=16 --overlap=15 --extramodinfo='data_aug' --batch=2 --data_augmentation=True
 8338  clear && clear
 8339  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-resnet-l1loss-dropout.prototxt' --use_model='../pretrained_model/c3d_resnet18_sports1m_r2_iter_2800000.caffemodel' --plotiter=200 --validiter=10000 --savemodeliter=10000 --trainingexampleprops=0.995 --trainingbase='hollywood' --videolength=16 --overlap=8 --extramodinfo='data_aug' --batch=2 --data_augmentation=True
 8340  clear && clear
 8341  nvidia-smi
 8342  clear && clear
 8343  source set_env.sh ../C3D-v1.1-tmp/ 7
 8344  source set_env.sh ../C3D-v1.1-tmp/ 6
 8345  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-resnet-l1loss-dropout.prototxt' --use_model='../pretrained_model/c3d_resnet18_sports1m_r2_iter_2800000.caffemodel' --plotiter=200 --validiter=10000 --savemodeliter=10000 --trainingexampleprops=0.995 --trainingbase='hollywood' --videolength=16 --overlap=8 --extramodinfo='data_aug' --batch=2 --data_augmentation=True
 8346  top
 8347  df -h
 8348  top
 8349  cd /data/sunnycia/saliency_on_videoset/Train/scripts
 8350  source set_env.sh ../C3D-v1.0/ 7
 8351  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-resnet-voxelloss-dropout.prototxt' --use_model='../pretrained_model/c3d_resnet18_sports1m_r2_iter_2800000.caffemodel' --plotiter=200 --validiter=4000 --savemodeliter=4000 --trainingexampleprops=0.995 --trainingbase='ledov' --videolength=16 --overlap=15 --extramodinfo='data_aug' --batch=2 --data_augmentation=True
 8352  cd /data/sunnycia/saliency_on_videoset/Train/C3D-v1.1-tmp
 8353  make clean
 8354  make -j8 all
 8355  make clean
 8356  cd ..
 8357  cd scripts/
 8358  source set_env.sh ../C3D-v1.1 7
 8359  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-resnet-softmaxloss-dropout.prototxt' --use_model='../pretrained_model/c3d_resnet18_sports1m_r2_iter_2800000.caffemodel' --plotiter=200 --validiter=4000 --savemodeliter=4000 --trainingexampleprops=0.995 --trainingbase='ledov' --videolength=16 --overlap=15 --extramodinfo='data_aug' --batch=2 --data_augmentation=True
 8360  clear && clear
 8361  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-resnet-softmaxloss-dropout.prototxt' --use_model='../pretrained_model/c3d_resnet18_sports1m_r2_iter_2800000.caffemodel' --plotiter=200 --validiter=4000 --savemodeliter=4000 --trainingexampleprops=0.995 --trainingbase='ledov' --videolength=16 --overlap=15 --extramodinfo='data_aug' --batch=2 --data_augmentation=True
 8362  clear && clear
 8363  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-resnet-softmaxloss-dropout.prototxt' --use_model='../pretrained_model/c3d_resnet18_sports1m_r2_iter_2800000.caffemodel' --plotiter=200 --validiter=4000 --savemodeliter=4000 --trainingexampleprops=0.995 --trainingbase='ledov' --videolength=16 --overlap=15 --extramodinfo='data_aug' --batch=2 --data_augmentation=True
 8364  clear && clear
 8365  python finetune_test_video.py --pretrained_model='/data/sunnycia/saliency_on_videoset/Train/training_output/salicon/vo-v4-2-resnet-l1loss-dropout-snapshot-4000-data_aug-batch-2_1526869047/snapshot-_iter_500000.caffemodel' --network_prototxt='prototxt/vo-v4-2-resnet-l1loss-deploy.prototxt' --solver_prototxt='prototxt/solver-static.prototxt' --epoch=50 --dataset='videoset' --fold=10 --valid_iter=5000
 8366  source set_env.sh ../C3D-v1.1-tmp/ 5
 8367  nvidia-smi
 8368  top
 8369  nvidia-smi
 8370  top
 8371  nvidia-smi
 8372  source set_env.sh ../C3D-v1.1-tmp/ 7
 8373  clear && clear
 8374  python finetune_test_video.py --pretrained_model='/data/sunnycia/saliency_on_videoset/Train/training_output/salicon/vo-v4-2-resnet-l1loss-dropout-snapshot-4000-data_aug-batch-2_1526869047/snapshot-_iter_500000.caffemodel' --network_prototxt='prototxt/vo-v4-2-resnet-l1loss-deploy.prototxt' --solver_prototxt='prototxt/solver-static.prototxt' --epoch=50 --dataset='videoset' --fold=10 --valid_iter=5000
 8375  clear && clear
 8376  python finetune_test_video.py --pretrained_model='/data/sunnycia/saliency_on_videoset/Train/training_output/salicon/vo-v4-2-resnet-l1loss-dropout-snapshot-4000-data_aug-batch-2_1526869047/snapshot-_iter_500000.caffemodel' --network_prototxt='prototxt/vo-v4-2-resnet-l1loss-deploy.prototxt' --solver_prototxt='prototxt/solver-static.prototxt' --epoch=50 --dataset='videoset' --fold=10 --valid_iter=5000
 8377  clear && clear
 8378  python finetune_test_video.py --pretrained_model='/data/sunnycia/saliency_on_videoset/Train/training_output/salicon/vo-v4-2-resnet-l1loss-dropout-snapshot-4000-data_aug-batch-2_1526869047/snapshot-_iter_500000.caffemodel' --network_prototxt='prototxt/vo-v4-2-resnet-l1loss-deploy.prototxt' --solver_prototxt='prototxt/solver-static.prototxt' --epoch=50 --dataset='videoset' --fold=10 --valid_iter=5000
 8379  clear && clear
 8380  python finetune_test_video.py --pretrained_model='/data/sunnycia/saliency_on_videoset/Train/training_output/salicon/vo-v4-2-resnet-l1loss-dropout-snapshot-4000-data_aug-batch-2_1526869047/snapshot-_iter_500000.caffemodel' --network_prototxt='prototxt/vo-v4-2-resnet-l1loss-deploy.prototxt' --solver_prototxt='prototxt/solver-static.prototxt' --epoch=50 --dataset='videoset' --fold=10 --valid_iter=5000
 8381  clear && clear
 8382  python finetune_test_video.py --pretrained_model='/data/sunnycia/saliency_on_videoset/Train/training_output/salicon/vo-v4-2-resnet-l1loss-dropout-snapshot-4000-data_aug-batch-2_1526869047/snapshot-_iter_500000.caffemodel' --network_prototxt='prototxt/vo-v4-2-resnet-l1loss-dropout.prototxt' --solver_prototxt='prototxt/solver-static.prototxt' --epoch=50 --dataset='videoset' --fold=10 --valid_iter=5000
 8383  cd utils/dsutil/ &&  python convert_img_type.py --base='/data/SaliencyDataset/Video/VideoSet/Results/saliency_map/ISEEL'
 8384  cd /data/sunnycia/saliency_on_videoset/Train/scripts && source set_env.sh ../C3D-v1.1-tmp/ 7 && python test_video.py --video_deploy_path='prototxt/vo-v4-2-resnet-deploy.prototxt' --video_model_path='../training_output/finetune/snapshot-_iter_500000/videoset/1527350421_9.caffemodel' --infertype='slide' --output_type='image' --test_base='diem' --model_code='v4-2' --videolength=16
 8385  nvidia-smi
 8386  cd /data/sunnycia/saliency_on_videoset/Train/scripts && source set_env.sh ../C3D-v1.1-tmp/ 6 && python test_video.py --video_deploy_path='prototxt/vo-v4-2-resnet-deploy.prototxt' --video_model_path='../training_output/finetune/snapshot-_iter_500000/videoset/1527350421_9.caffemodel' --infertype='slide' --output_type='image' --test_base='diem' --model_code='v4-2' --videolength=16
 8387  clear
 8388  matlab -nodesktop -nodispaly
 8389  top
 8390  nvidia-smi
 8391  /data/sunnycia/saliency_on_videoset/_Train/video-classification-3d-cnn-pytorch
 8392  cd /data/sunnycia/saliency_on_videoset/_Train/video-classification-3d-cnn-pytorch
 8393  python3 main.py --input ./input --video_root ./test_video --output ./output.json --model ./models/resnet-34-kinetics.pth --mode score
 8394  export CUDA_VISIBLE_DEVICES=7
 8395  python3 main.py --input ./input --video_root ./test_video --output ./output.json --model ./models/resnet-34-kinetics.pth --mode score
 8396  python3
 8397  vim ~/.bashrc
 8398  python3 main.py --input ./input --video_root ./test_video --output ./output.json --model ./models/resnet-34-kinetics.pth --mode score
 8399  python3 main.py --input ./input --video_root ./test_video --output ./output.json --model ./models/resnet-34-kinetics.pth --mode feature
 8400  top
 8401  cd /data/sunnycia/saliency_on_videoset/_Model
 8402  python gen_saliency_SALICON.py 
 8403  python gen_saliency_SALICON.py --framebase='/data/SaliencyDataset/Video/VideoSet/ImageSet/Seperate/frames'
 8404  python gen_saliency_SALICON.py --framebase='/data/SaliencyDataset/Video/VideoSet/ImageSet/Seperate/frames' --outputbase='/data/SaliencyDataset/Video/VideoSet/Results/saliency_map/SALICON'
 8405  python gen_saliency_SALICON.py --framebase='/data/SaliencyDataset/Video/VideoSet/ImageSet/Seperate/frames' --outputbase='/data/SaliencyDataset/Video/VideoSet/Results/saliency_map/SALICON' --debug=True
 8406  nvidia-smi
 8407  top
 8408  python gen_saliency_SALICON.py --framebase='/data/SaliencyDataset/Video/VideoSet/ImageSet/Seperate/frames' --outputbase='/data/SaliencyDataset/Video/VideoSet/Results/saliency_map/SALICON' --debug=True --gpu=7
 8409  top
 8410  nvidia-smi
 8411  cd /data/sunnycia/saliency_on_videoset/Train
 8412  cd scripts/
 8413  python test_video.py --video_deploy_path='prototxt/vo-v4-2-resnet-deploy.prototxt' --video_model_path='../training_output/finetune/snapshot-_iter_500000/videoset/1527350421_9.caffemodel' --infertype='slide' --output_type='image' --test_base='videoset' --model_code='v4-2' --videolength=16 --overlap=0
 8414  source set_env.sh ../C3D-v1.1-tmp/ 7
 8415  python test_video.py --video_deploy_path='prototxt/vo-v4-2-resnet-deploy.prototxt' --video_model_path='../training_output/finetune/snapshot-_iter_500000/videoset/1527350421_9.caffemodel' --infertype='slide' --output_type='image' --test_base='videoset' --model_code='v4-2' --videolength=16 --overlap=0
 8416  python test_video.py --video_deploy_path='prototxt/vo-v4-2-resnet-deploy.prototxt' --video_model_path='../training_output/finetune/snapshot-_iter_500000/videoset/1527350421_9.caffemodel' --infertype='slide' --output_type='image' --test_base='videoset' --model_code='v4-2' --videolength=16 --overlap=0 -debug=True
 8417  python test_video.py --video_deploy_path='prototxt/vo-v4-2-resnet-deploy.prototxt' --video_model_path='../training_output/finetune/snapshot-_iter_500000/videoset/1527350421_9.caffemodel' --infertype='slide' --output_type='image' --test_base='videoset' --model_code='v4-2' --videolength=16 --overlap=0 --debug=True
 8418  python test_video.py --video_deploy_path='prototxt/vo-v4-2-resnet-deploy.prototxt' --video_model_path='../training_output/finetune/snapshot-_iter_500000/videoset/1527350421_9.caffemodel' --infertype='slide' --output_type='image' --test_base='videoset' --model_code='v4-2' --videolength=16 --overlap=8 --debug=True
 8419  python test_video.py --video_deploy_path='prototxt/vo-v4-2-resnet-deploy.prototxt' --video_model_path='../training_output/finetune/snapshot-_iter_500000/videoset/1527350421_9.caffemodel' --infertype='slide' --output_type='image' --test_base='videoset' --model_code='v4-2' --videolength=16 --overlap=0 --debug=True
 8420  top
 8421  cd /data/sunnycia/saliency_on_videoset/_Train/saliencysegment
 8422  python main.py 
 8423  ls -a ~/
 8424  vim ~/.keras
 8425  vim ~/.keras/keras.json 
 8426  export CUDA_VISIBLE_DEVICES=7
 8427  nvidia-smi
 8428  python main.py 
 8429  su
 8430  python main.py 
 8431  python
 8432  top
 8433  nvidia-smi
 8434  top
 8435  nvidia-smi
 8436  /data/sunnycia/saliency_on_videoset/_Train/artistic-videos
 8437  cd /data/sunnycia/saliency_on_videoset/_Train/artistic-videos
 8438  python
 8439  vim ~/.bashr
 8440  vim ~/.bashrc
 8441  df -h
 8442  vim ~/.bashrc
 8443  top
 8444  nvidia-smi
 8445  top
 8446  nvidia-smi
 8447  top
 8448  ssh qiudan@172.31.234.248
 8449  cd pwd/saliency_on_videoset/Train/metric-matlab/
 8450  mv videoset videoset_old
 8451  top
 8452  cd /data/sunnycia/saliency_on_videoset/Train/scripts/utils/vizutil
 8453  python
 8454  nvidia-smi
 8455  ssh sunnycia@172.31.234.248
 8456  cd /data/sunnycia/saliency_on_videoset/_Train/saliencysegment
 8457  python main.py 
 8458  python
 8459  su
 8460  vim ~/.keras/keras.json 
 8461  python
 8462  su
 8463  python main.py 
 8464  vim ~/.keras/keras.json 
 8465  python main.py 
 8466  vim ~/.keras/keras.json 
 8467  python main.py 
 8468  export CUDA_VISIBLE_DEVICES=7
 8469  python main.py 
 8470  [A
 8471  python main.py 
 8472  cd /data/sunnycia/saliency_on_videoset/_Train/OMCNN_2CLSTM
 8473  python TestDemo.py 
 8474  top
 8475  nvidia-smi
 8476  cd /data/sunnycia/saliency_on_videoset/Train/scripts
 8477  history > ../history
 8478  source set_env.sh ../C3D-v1.1-tmp/ 7
 8479  nvidia-smi
 8480  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-connect-resnet-dropout.prototxt' --use_model='../pretrained_model/c3d_resnet18_sports1m_r2_iter_2800000.caffemodel' --plotiter=200 --validiter=4000 --savemodeliter=4000 --trainingexampleprops=0.99 --trainingbase='ledov' --videolength=16 --overlap=15 --extramodinfo='connection_resnet' --batch=2 --connection=1
 8481  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-connect-resnet-dropout.prototxt' --use_model='../pretrained_model/c3d_resnet18_sports1m_r2_iter_2800000.caffemodel' --plotiter=200 --validiter=4000 --savemodeliter=4000 --trainingexampleprops=0.99 --trainingbase='hollywood' --videolength=16 --overlap=15 --extramodinfo='connection_resnet' --batch=2 --connection=1
 8482  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-connect-resnet-dropout.prototxt' --use_model='../pretrained_model/c3d_resnet18_sports1m_r2_iter_2800000.caffemodel' --plotiter=200 --validiter=4000 --savemodeliter=4000 --trainingexampleprops=0.999 --trainingbase='hollywood' --videolength=16 --overlap=15 --extramodinfo='connection_resnet' --batch=2 --connection=1
 8483  top
 8484  cd /data/sunnycia/saliency_on_videoset/Train/scripts/utils/vizutil
 8485  python transition_comparison.py 
 8486  cd ..
 8487  uname -r
 8488  top
 8489  nvidia-smi
 8490  pwd
 8491  cd /data/sunnycia/saliency_on_videoset/
 8492  ls
 8493  cd _Train/
 8494  ls
 8495  cd video-classification-3d-cnn-pytorch/
 8496  python main.py --input ./input --video_root ./videos --output ./output.json --model ./resnet-34-kinetics.pth --mode score
 8497  python main.py --input ./input --video_root ./videos --output ./output.json --model ./models/resnext-101-kinetics.pth --mode score
 8498  python main.py --input ./input --video_root ./videos --output ./output.json --model ./resnet-34-kinetics.pth --mode score
 8499  top
 8500  python main.py --input ./input --video_root ./videos --output ./output.json --model ./resnet-34-kinetics.pth --mode score
 8501  python main.py --input ./input --video_root ./videos --output ./output.json --model ./models/resnet-34-kinetics.pth --mode score
 8502  vim input
 8503  python main.py --input ./input --video_root ./videos --output ./output.json --model ./models/resnet-34-kinetics.pth --mode score
 8504  python main.py --input ./input --video_root ./test_video --output ./output.json --model ./models/resnet-34-kinetics.pth --mode score
 8505  vim input 
 8506  python main.py --input ./input --video_root ./test_video --output ./output.json --model ./models/resnet-34-kinetics.pth --mode score
 8507  su
 8508  python main.py --input ./input --video_root ./test_video --output ./output.json --model ./models/resnet-34-kinetics.pth --mode score
 8509  su
 8510  python main.py --input ./input --video_root ./test_video --output ./output.json --model ./models/resnet-34-kinetics.pth --mode score
 8511  python
 8512  vim ~/.bashrc
 8513  python3 main.py --input ./input --video_root ./test_video --output ./output.json --model ./models/resnet-34-kinetics.pth --mode score
 8514  pip3
 8515  su
 8516  top
 8517  cd /data/sunnycia/saliency_on_videoset/_Model/Rudoy
 8518  matlab -nodesktop -nodispaly
 8519  matlab -nodesktop -nodisplay
 8520  matlab
 8521  cd /data/sunnycia/saliency_on_videoset/_Model
 8522  matlab -nodesktop -nodisplay
 8523  top
 8524  cd /data/sunnycia/saliency_on_videoset/Train/scripts/utils/vizutil/
 8525  python inference_comparison.py --output_path='savam_inference.jpg' --wildcards_record='msu_wildcards_record.txt'
 8526  python inference_comparison.py --output_path='gazecom_inference.jpg' --wildcards_record='gazecom_wildcards_record.txt'
 8527  python transition_comparison.py --output_path='vg_transition.jpg' --wildcards_record='vg_wildcards_record.txt' 
 8528  top
 8529  cd ../../metric/
 8530  matlab -nodesktop -nodispaly
 8531  cd /data/sunnycia/saliency_on_videoset/Train/scripts && source set_env.sh ../C3D-v1.1-tmp/ 6 && python test_video.py --video_deploy_path='prototxt/vo-v4-2-resnet-deploy.prototxt' --video_model_path='../training_output/finetune/snapshot-_iter_500000/videoset/1527350421_9.caffemodel' --infertype='slide' --output_type='image' --test_base='gazecom' --model_code='v4-2' --videolength=16
 8532  clear
 8533  cd metric/
 8534  matlab -nodesktop -nodisplay
 8535  cd /data/sunnycia/saliency_on_videoset/Train/scripts
 8536  history> ../history
 8537  source set_env.sh ../C3D-v1.1-tmp/ 7
 8538  cd /data/sunnycia/saliency_on_videoset/Train/scripts && source set_env.sh ../C3D-v1.1-tmp/ 7 && python test_video.py --video_deploy_path='prototxt/vo-v4-2-resnet-deploy.prototxt' --video_model_path='../training_output/finetune/snapshot-_iter_500000/videoset/1527350421_9.caffemodel' --infertype='slide' --output_type='image' --test_base='msu' --model_code='v4-2' --videolength=16
 8539  clear
 8540  matlab -nodesktop -nodisplay
 8541  clear
 8542  matlab -nodesktop -nodisplay
 8543  ls
 8544  cd metric/
 8545  ls
 8546  python avg_metric.py /data/sunnycia/saliency_on_videoset/Train/metric-matlab/videoset
 8547  python avg_metric.py --metricdir=/data/sunnycia/saliency_on_videoset/Train/metric-matlab/videoset
 8548  python avg_metric.py --metricdir=/data/sunnycia/saliency_on_videoset/Train/metric-matlab/videoset/videoset_1527350421_9_threshold0_overlap15
 8549  python avg_metric.py --metricdir=/data/sunnycia/saliency_on_videoset/Train/metric-matlab/videoset/xu_lstm
 8550  top
 8551  ffmpeg
 8552  cd /data/sunnycia/saliency_on_videoset/_Train/DenseNetCaffe
 8553  python make_densenet.py 
 8554  cd /data/sunnycia/saliency_on_videoset/_Train/saliencysegment
 8555  python main.py 
 8556  nvidia-smi
 8557  export CUDA_VISIBLE_DEVICES=6
 8558  python main.py 
 8559  top
 8560  clear
 8561  cd /data/sunnycia/image_compression_challenge/_Train
 8562  tar xf libbpg-0.9.8.tar.gz 
 8563  cd libbpg-0.9.8/
 8564  make -j4
 8565  su
 8566  make -j4
 8567  make clean
 8568  make -j8
 8569  yasm
 8570  top
 8571  clear && clear
 8572  nvidia-smi
 8573  clear
 8574  cd /data/sunnycia/saliency_on_videoset/_Model/Surprise-iLab-saliency-20140505
 8575  ./configure 
 8576  make core
 8577  make clean
 8578  ./configure
 8579  make -j4 core
 8580  make clean
 8581  ./configure
 8582  make -j4 core
 8583  make clean
 8584  ./configure
 8585  make -j4 core
 8586  touch -d "2 hours ago" src/Raster/PngParser.C
 8587  make clean
 8588  ./configure -j4
 8589  ./configure
 8590  make -j4 core
 8591  touch -d "2 hours ago" src/Raster/PngParser.C
 8592  ./configure
 8593  touch -d "2 hours ago" src/Raster/PngParser.C
 8594  make clean
 8595  ./configure
 8596  make -j4 core
 8597  make clean
 8598  ./configure
 8599  cd /data/sunnycia/saliency_on_videoset/_Model/Surprise-iLab-saliency-20140505
 8600  make -j8 core
 8601  make clean
 8602  ./configure
 8603  make -j4 core
 8604  make clean
 8605  ./configure
 8606  make -j4
 8607   make clean
 8608  ./configure
 8609  cd /data/sunnycia/saliency_on_videoset/_Model/OBDL/SOURCE/../..
 8610  ls
 8611  cd Surprise-iLab-saliency-20140505/
 8612  ls
 8613  make clean
 8614  ./configure
 8615  pwd
 8616  su
 8617  ls
 8618  cd /data/sunnycia/image_compression_challenge/
 8619  ls
 8620  cd _Train/
 8621  ls
 8622  ls ..
 8623  cd libbpg-0.9.8/
 8624  ls
 8625  bpgenc
 8626  make clean
 8627  make -j4 all
 8628  pwd
 8629  touch "10 minutes ago"  Makefile 
 8630  make clean
 8631  make -j4
 8632  make -j2 install
 8633  ls
 8634  pngenc
 8635  bpgenc
 8636  ./bpgenc
 8637  chmod u+x bpgenc bpgdec
 8638  bpgenc
 8639  ./bpgenc -h > bpg_helper.txt
 8640  bpgenc wordcloud.png -q 50 -o wordcloud.bpg
 8641  ./bpgenc wordcloud.png -q 50 -o wordcloud.bpg
 8642  ls
 8643  python
 8644  bpgdec -h 
 8645  ./bpgdec -h 
 8646  su
 8647  pwd
 8648  cd ../../
 8649  ./bpgenc
 8650  bpgenc
 8651  ls
 8652  python bpg_wrapper.py --i test.jpeg --o test_bpg.bpg --q 50
 8653  ls
 8654  ls -la
 8655  pwd
 8656  history > history
 8657  python plot_scatter.py --dataset='KODAK' --ref_image_dir='/data/sunnycia/image_compression_challenge/dataset/KODAK' --metric_dir='./metric_data' --metric_name='Y-psnr' --metric_index=8  --output_dir='./metric_data/KODAK-YPSNR_atest'
 8658  ls
 8659  touch bpg_compress.py
 8660  vim jpeg_compress.sh
 8661  bash bpg_compress.sh KODAK
 8662  python image_metric.py --ref_dir='/data/sunnycia/image_compression_challenge/dataset/KODAK' --cps_dir='/data/sunnycia/image_compression_challenge/compressed_set/KODAK/bpg' --color_space='YVU' --codec='bpg' 
 8663  python plot_scatter.py --dataset='KODAK' --ref_image_dir='/data/sunnycia/image_compression_challenge/dataset/KODAK' --metric_dir='./metric_data' --metric_name='Y-psnr' --metric_index=8  --output_dir='./metric_data/KODAK-YPSNR_atest'
 8664  cd /data/sunnycia/saliency_on_videoset/_Model/Surprise-iLab-saliency-20140505/bin
 8665  ezvision
 8666  ./ezvision
 8667  cd ..
 8668  ./ezvision
 8669  cd bin/
 8670  ./ezvision 
 8671  ezvision -Y --nodisplay-additive --input-frames=@33Hz --output-frames=@0.005s --ehc-type=Simple --hsc-type=None --esc-type=Friction --foveate-input-depth=5 --nodisplay-foa --display-map-factor=50000 --in=frame#.png --out=display --out=raster
 8672  ./ezvision -Y --nodisplay-additive --input-frames=@33Hz --output-frames=@0.005s --ehc-type=Simple --hsc-type=None --esc-type=Friction --foveate-input-depth=5 --nodisplay-foa --display-map-factor=50000 --in=frame#.png --out=display --out=raster
 8673  cd /data/sunnycia/saliency_on_videoset/_Model/OBDL/SOURCE
 8674  matlab -nodesktop -nodisplay
 8675  top
 8676  cd /data/sunnycia/saliency_on_videoset/Train/scripts
 8677  nvidia-smi
 8678  history ../history
 8679  history > ../history
 8680  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-resnet-bhatloss-dropout.prototxt' --use_model='../pretrained_model/c3d_resnet18_sports1m_r2_iter_2800000.caffemodel' --plotiter=200 --validiter=4000 --savemodeliter=4000 --trainingexampleprops=0.999 --trainingbase='hollywood' --videolength=16 --overlap=8 --extramodinfo='bhatloss_hollywood_O8' --batch=2 --connection=1
 8681  source set_env.sh ../C3D-v1.1-tmp/ 7
 8682  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-resnet-bhatloss-dropout.prototxt' --use_model='../pretrained_model/c3d_resnet18_sports1m_r2_iter_2800000.caffemodel' --plotiter=200 --validiter=4000 --savemodeliter=4000 --trainingexampleprops=0.999 --trainingbase='hollywood' --videolength=16 --overlap=8 --extramodinfo='bhatloss_hollywood_O8' --batch=2 --connection=1
 8683  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-resnet-bhatloss-dropout.prototxt' --use_model='../pretrained_model/c3d_resnet18_sports1m_r2_iter_2800000.caffemodel' --plotiter=200 --validiter=4000 --savemodeliter=4000 --trainingexampleprops=0.999 --trainingbase='hollywood' --videolength=16 --overlap=8 --extramodinfo='bhatloss_hollywood_O8' --batch=2 
 8684  clear && clear
 8685  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-resnet-bhatloss-dropout.prototxt' --use_model='../pretrained_model/c3d_resnet18_sports1m_r2_iter_2800000.caffemodel' --plotiter=200 --validiter=4000 --savemodeliter=4000 --trainingexampleprops=0.999 --trainingbase='hollywood' --videolength=16 --overlap=8 --extramodinfo='bhatloss_hollywood_O8' --batch=2 
 8686  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-resnet-dropout.prototxt' --use_model='../pretrained_model/c3d_resnet18_sports1m_r2_iter_2800000.caffemodel' --plotiter=200 --validiter=4000 --savemodeliter=4000 --trainingexampleprops=0.999 --trainingbase='hollywood' --videolength=16 --overlap=8 --extramodinfo='bhatloss_hollywood_O8' --batch=2 
 8687  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-resnet-bhatloss-dropout.prototxt' --use_model='../pretrained_model/c3d_resnet18_sports1m_r2_iter_2800000.caffemodel' --plotiter=200 --validiter=4000 --savemodeliter=4000 --trainingexampleprops=0.999 --trainingbase='hollywood' --videolength=16 --overlap=8 --extramodinfo='bhatloss_hollywood_O8' --batch=2 
 8688  clear && clear
 8689  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-resnet-bhatloss-dropout.prototxt' --use_model='../pretrained_model/c3d_resnet18_sports1m_r2_iter_2800000.caffemodel' --plotiter=200 --validiter=4000 --savemodeliter=4000 --trainingexampleprops=0.999 --trainingbase='hollywood' --videolength=16 --overlap=8 --extramodinfo='bhatloss_hollywood_O8' --batch=2 
 8690  clear && clear
 8691  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-resnet-bhatloss-dropout.prototxt' --use_model='../pretrained_model/c3d_resnet18_sports1m_r2_iter_2800000.caffemodel' --plotiter=200 --validiter=4000 --savemodeliter=4000 --trainingexampleprops=0.999 --trainingbase='hollywood' --videolength=16 --overlap=8 --extramodinfo='bhatloss_hollywood_O8' --batch=2 
 8692  clear && clear
 8693  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-resnet-bhatloss-dropout.prototxt' --use_model='../pretrained_model/c3d_resnet18_sports1m_r2_iter_2800000.caffemodel' --plotiter=200 --validiter=4000 --savemodeliter=4000 --trainingexampleprops=0.999 --trainingbase='ledov' --videolength=16 --overlap=8 --extramodinfo='bhatloss_hollywood_O8' --batch=2 
 8694  clear && clear
 8695  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-resnet-bhatloss-dropout.prototxt' --use_model='../pretrained_model/c3d_resnet18_sports1m_r2_iter_2800000.caffemodel' --plotiter=200 --validiter=4000 --savemodeliter=4000 --trainingexampleprops=0.999 --trainingbase='ledov' --videolength=16 --overlap=8 --extramodinfo='bhatloss_ledov_O8_lw1e6' --batch=2 
 8696  clear && clear
 8697  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-resnet-pykldloss-dropout.prototxt' --use_model='../pretrained_model/c3d_resnet18_sports1m_r2_iter_2800000.caffemodel' --plotiter=200 --validiter=4000 --savemodeliter=4000 --trainingexampleprops=0.999 --trainingbase='ledov' --videolength=16 --overlap=8 --extramodinfo='pykldloss_ledov_O8' --batch=2 
 8698  clear && clear
 8699  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-resnet-pykldloss-dropout.prototxt' --use_model='../pretrained_model/c3d_resnet18_sports1m_r2_iter_2800000.caffemodel' --plotiter=200 --validiter=4000 --savemodeliter=4000 --trainingexampleprops=0.999 --trainingbase='ledov' --videolength=16 --overlap=8 --extramodinfo='pykldloss_ledov_O8_lw-1' --batch=2 
 8700  top
 8701  clear && clear
 8702  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-resnet-l1loss-softmax-dropout.prototxt' --use_model='../pretrained_model/c3d_resnet18_sports1m_r2_iter_2800000.caffemodel' --plotiter=200 --validiter=4000 --savemodeliter=4000 --trainingexampleprops=0.999 --trainingbase='ledov' --videolength=16 --overlap=8 --extramodinfo='l1oss_softmax_axis-1_ledov_O8' --batch=2 
 8703  clear && clear
 8704  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-resnet-l1loss-softmax-dropout.prototxt' --use_model='../pretrained_model/c3d_resnet18_sports1m_r2_iter_2800000.caffemodel' --plotiter=200 --validiter=4000 --savemodeliter=4000 --trainingexampleprops=0.999 --trainingbase='ledov' --videolength=16 --overlap=8 --extramodinfo='l1oss_softmax_axis-1_ledov_O8' --batch=2 
 8705  clear && clear
 8706  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-resnet-bhatloss-softmax-dropout.prototxt' --use_model='../pretrained_model/c3d_resnet18_sports1m_r2_iter_2800000.caffemodel' --plotiter=200 --validiter=4000 --savemodeliter=4000 --trainingexampleprops=0.999 --trainingbase='ledov' --videolength=16 --overlap=8 --extramodinfo='bhatloss_01norm_ledov_o8' --batch=2 
 8707  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-resnet-bhatloss-dropout.prototxt' --use_model='../pretrained_model/c3d_resnet18_sports1m_r2_iter_2800000.caffemodel' --plotiter=200 --validiter=4000 --savemodeliter=4000 --trainingexampleprops=0.999 --trainingbase='ledov' --videolength=16 --overlap=8 --extramodinfo='bhatloss_01norm_ledov_o8' --batch=2 
 8708  clear && clear
 8709  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-resnet-bhatloss-dropout.prototxt' --use_model='../pretrained_model/c3d_resnet18_sports1m_r2_iter_2800000.caffemodel' --plotiter=200 --validiter=4000 --savemodeliter=4000 --trainingexampleprops=0.999 --trainingbase='ledov' --videolength=16 --overlap=8 --extramodinfo='bhatloss_01norm_ledov_o8' --batch=2 
 8710  cd /data/sunnycia/saliency_on_videoset/_Train/3d-DenseNet
 8711  clear && clear
 8712  python run_dense_net_3d.py 
 8713  unrar x UCF101.rar 
 8714  cd data_prepare/
 8715  bash convert_video_to_images.sh ../UCF-101/
 8716  vim convert_video_to_images.sh 
 8717  bash convert_video_to_images.sh ../UCF-101/
 8718  bash convert_images_to_list.sh ../UCF-101/
 8719  vim convert_images_to_list.sh ../UCF-101/
 8720  bash convert_images_to_list.sh ../UCF-101/
 8721  clear && clear
 8722  bash convert_images_to_list.sh ../UCF-101/ 10
 8723  jot
 8724  ssh sunnycia@172.31.248.250
 8725  ssh sunnycia@172.31.234.250
 8726  ssh sunnycia@172.31.234.248
 8727  yum install jot
 8728  su
 8729  cd ~
 8730  cd /data/sunnycia/action_recognition/_Train/3d-DenseNet
 8731  python run_dense_net_3d.py --train --test -ds UCF-101/
 8732  nvidia-smi
 8733  export CUDA_VISIBLE_DEVICES=7
 8734  nvidia-smi
 8735  python run_dense_net_3d.py --train --test -ds UCF-101/
 8736  python run_dense_net_3d.py --train --test -ds UCF-101/ --gpu_id=7
 8737  python
 8738  python run_dense_net_3d.py --train --test -ds UCF-101/ --gpu_id=7
 8739  cd /data/sunnycia/saliency_on_videoset/Train/scripts && source set_env.sh ../C3D-v1.1-tmp/ 7
 8740  python test_video.py --video_deploy_path='prototxt/vo-v4-2-resnet-deploy.prototxt' --video_model_path='../training_output/salicon/vo-v4-2-resnet-bhatloss-dropout-base_lr-0.01-snapshot-4000-bhatloss_ledov_O8_lw_1000-batch-2_1528949547/snapshot-_iter_100000.caffemodel' --infertype='slide' --output_type='image' --test_base='msu' --model_code='v4-2' --videolength=16
 8741  python test_video.py --video_deploy_path='prototxt/vo-v4-2-resnet-deploy.prototxt' --video_model_path='../training_output/salicon/vo-v4-2-resnet-bhatloss-dropout-base_lr-0.01-snapshot-4000-bhatloss_ledov_O8_lw_1000-batch-2_1528949547/snapshot-_iter_100000.caffemodel' --infertype='slide' --output_type='image' --test_base='videoset' --model_code='v4-2' --videolength=16
 8742  cd /data/sunnycia/saliency_on_videoset/Train/C3D-v1.1-tmp
 8743  make clean
 8744  make -j8 all && make -j2 pycaffe
 8745  make clean
 8746  make -j10 all && make -j2 pycaffe
 8747  make clean
 8748  make -j10 all && make -j4 pycaffe
 8749  make clean
 8750  make -j8 all && make -j4 pycaffe
 8751  vim /data/sunnycia/saliency_on_videoset/Train/training_output/salicon/vo-v4-2-trimmed_densenet-deconvBN-l1loss-dropout-base_lr-0.01-snapshot-4000-dense3d-new-batch-2_1529414170/vo-v4-2-trimmed_densenet-deconvBN-l1loss-dropout.prototxt 
 8752  nvidia-smi
 8753  cd /data/sunnycia/saliency_on_videoset/Train/scripts
 8754  export CUDA_VISIBLE_DEVICES=5
 8755  source set_env.sh ../C3D-v1.1-tmp/ 5
 8756  python model_watcher.py 
 8757  cd metric/
 8758  matlab -nodesktop -nodisplay
 8759  cd ..
 8760  python test_video.py --model_base_dir='vo-v4-2-trimmed_densenet-deconvBN-l1loss-dropout-base_lr-0.01-snapshot-4000-dense3d-new-batch-2_1529414170' --infertype='slide' --output_type='image' --test_base='msu' --model_code='v4-2' --videolength=16 --overlap=8
 8761  python test_video.py --model_base_dir='vo-v4-2-trimmed_densenet-deconvBN-l1loss-dropout-base_lr-0.01-snapshot-4000-dense3d-new-batch-2_1529414170' --infertype='slide' --output_type='image' --test_base='videoset' --model_code='v4-2' --videolength=16 --overlap=8
 8762  nvidia-smi
 8763  env
 8764  export CUDA_VISIBLE_DEVICES=6
 8765  python test_video.py --model_base_dir='vo-v4-2-trimmed_densenet-deconvBN-l1loss-dropout-base_lr-0.01-snapshot-4000-dense3d-new-batch-2_1529414170' --infertype='slide' --output_type='image' --test_base='videoset' --model_code='v4-2' --videolength=16 --overlap=8
 8766  matlab -nodesktop -nodisplay
 8767  cd /data/sunnycia/saliency_on_videoset/Train/scripts/prototxt/..
 8768   python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-resnet-l1loss-softmax-dropout.prototxt' --use_model='../pretrained_model/c3d_resnet18_sports1m_r2_iter_2800000.caffemodel' --plotiter=200 --validiter=4000 --savemodeliter=4000 --training
 8769  source set_env.sh ../C3D-v1.1-tmp/ 6
 8770  nvidia-smi
 8771  source set_env.sh ../C3D-v1.1-tmp/ 5
 8772  clear && clear
 8773  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-resnet-l1loss-softmax-dropout.prototxt' --use_model='../pretrained_model/c3d_resnet18_sports1m_r2_iter_2800000.caffemodel' --plotiter=200 --validiter=4000 --savemodeliter=4000 --trainingexampleprops=0.999 --trainingbase='ledov' --videolength=16 --overlap=8 --extramodinfo='l1oss_softmax_axis-1_ledov_O8' --batch=2
 8774  clear && clear
 8775  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-resnet-l1loss-softmax-dropout.prototxt' --use_model='../pretrained_model/c3d_resnet18_sports1m_r2_iter_2800000.caffemodel' --plotiter=200 --validiter=4000 --savemodeliter=4000 --trainingexampleprops=0.999 --trainingbase='ledov' --videolength=16 --overlap=8 --extramodinfo='l1oss_softmax_axis-12_ledov_O8' --batch=2
 8776  clear && clear
 8777  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-resnet-l1loss-softmax-dropout.prototxt' --use_model='../pretrained_model/c3d_resnet18_sports1m_r2_iter_2800000.caffemodel' --plotiter=200 --validiter=4000 --savemodeliter=4000 --trainingexampleprops=0.999 --trainingbase='ledov' --videolength=16 --overlap=8 --extramodinfo='l1oss_softmax_axis-12_ledov_O8' --batch=2
 8778  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-resnet-l1loss-softmax-dropout.prototxt' --use_model='../pretrained_model/c3d_resnet18_sports1m_r2_iter_2800000.caffemodel' --plotiter=200 --validiter=4000 --savemodeliter=4000 --trainingexampleprops=0.999 --trainingbase='ledov' --videolength=16 --overlap=8 --extramodinfo='l1oss_softmax_axis-2_ledov_O8' --batch=2
 8779  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-resnet-l1loss-softmax-dropout.prototxt' --use_model='../pretrained_model/c3d_resnet18_sports1m_r2_iter_2800000.caffemodel' --plotiter=200 --validiter=4000 --savemodeliter=4000 --trainingexampleprops=0.999 --trainingbase='ledov' --videolength=16 --overlap=8 --extramodinfo='l1oss_softmax_axis-1_ledov_O8' --batch=2
 8780  clear && clear
 8781  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-resnet-l1loss-dropout.prototxt' --use_model='../pretrained_model/c3d_resnet18_sports1m_r2_iter_2800000.caffemodel' --plotiter=200 --validiter=4000 --savemodeliter=4000 --trainingexampleprops=0.999 --trainingbase='ledov' --videolength=16 --overlap=8 --extramodinfo='l1oss_dropout02_ledov_O8' --batch=2
 8782  top
 8783  nvidia-smi
 8784  top
 8785  python utils/vizutil/visualization_weight.py -h
 8786  python utils/vizutil/visualization_weight.py --modelpath='/data/sunnycia/saliency_on_videoset/Train/training_output/salicon/vo-v4-2-densenet-l1loss-dropout-base_lr-0.0001-snapshot-4000-dense3d-new-28000-batch-2_1529397527/snapshot-_iter_88000.caffemodel' --deploypath='/data/sunnycia/saliency_on_videoset/Train/training_output/salicon/vo-v4-2-densenet-l1loss-dropout-base_lr-0.0001-snapshot-4000-dense3d-new-28000-batch-2_1529397527/vo-v4-2-densenet-l1loss-dropout.prototxt' --outputpath='densetest.jpg' --type='3d' --layer='deconv3'
 8787  python utils/vizutil/visualization_weight.py --modelpath='/data/sunnycia/saliency_on_videoset/Train/training_output/salicon/vo-v4-2-densenet-l1loss-dropout-base_lr-0.0001-snapshot-4000-dense3d-new-28000-batch-2_1529397527/snapshot-_iter_88000.caffemodel' --deploypath='/data/sunnycia/saliency_on_videoset/Train/training_output/salicon/vo-v4-2-densenet-l1loss-dropout-base_lr-0.0001-snapshot-4000-dense3d-new-28000-batch-2_1529397527/vo-v4-2-densenet-l1loss-dropout.prototxt' --outputpath='densetest.jpg' --type='3d' --layer='predict'
 8788  python utils/vizutil/visualization_weight.py --modelpath='/data/sunnycia/saliency_on_videoset/Train/training_output/salicon/vo-v4-2-densenet-l1loss-dropout-base_lr-0.0001-snapshot-4000-dense3d-new-28000-batch-2_1529397527/snapshot-_iter_88000.caffemodel' --deploypath='/data/sunnycia/saliency_on_videoset/Train/training_output/salicon/vo-v4-2-densenet-l1loss-dropout-base_lr-0.0001-snapshot-4000-dense3d-new-28000-batch-2_1529397527/vo-v4-2-densenet-l1loss-dropout.prototxt' --outputpath='densetest.jpg' --type='3d' --layer='deconv4'
 8789  python utils/vizutil/visualization_weight.py --modelpath='/data/sunnycia/saliency_on_videoset/Train/training_output/salicon/vo-v4-2-densenet-l1loss-dropout-base_lr-0.0001-snapshot-4000-dense3d-new-28000-batch-2_1529397527/snapshot-_iter_88000.caffemodel' --deploypath='/data/sunnycia/saliency_on_videoset/Train/training_output/salicon/vo-v4-2-densenet-l1loss-dropout-base_lr-0.0001-snapshot-4000-dense3d-new-28000-batch-2_1529397527/vo-v4-2-densenet-l1loss-dropout.prototxt' --outputpath='densetest.jpg' --type='3d' --layer='deconv2'
 8790  python utils/vizutil/visualization_weight.py --modelpath='/data/sunnycia/saliency_on_videoset/Train/training_output/salicon/vo-v4-2-densenet-l1loss-dropout-base_lr-0.0001-snapshot-4000-dense3d-new-28000-batch-2_1529397527/snapshot-_iter_88000.caffemodel' --deploypath='/data/sunnycia/saliency_on_videoset/Train/training_output/salicon/vo-v4-2-densenet-l1loss-dropout-base_lr-0.0001-snapshot-4000-dense3d-new-28000-batch-2_1529397527/vo-v4-2-densenet-l1loss-dropout.prototxt' --outputpath='densetest.jpg' --type='3d' --layer='conv1'
 8791  python utils/vizutil/visualization_weight.py --modelpath='/data/sunnycia/saliency_on_videoset/Train/training_output/salicon/vo-v4-2-densenet-l1loss-dropout-base_lr-0.0001-snapshot-4000-dense3d-new-28000-batch-2_1529397527/snapshot-_iter_88000.caffemodel' --deploypath='/data/sunnycia/saliency_on_videoset/Train/training_output/salicon/vo-v4-2-densenet-l1loss-dropout-base_lr-0.0001-snapshot-4000-dense3d-new-28000-batch-2_1529397527/vo-v4-2-densenet-l1loss-dropout.prototxt' --outputpath='densetest.jpg' --type='3d' --layer='conv2'
 8792  python utils/vizutil/visualization_weight.py --modelpath='/data/sunnycia/saliency_on_videoset/Train/training_output/salicon/vo-v4-2-densenet-l1loss-dropout-base_lr-0.0001-snapshot-4000-dense3d-new-28000-batch-2_1529397527/snapshot-_iter_88000.caffemodel' --deploypath='/data/sunnycia/saliency_on_videoset/Train/training_output/salicon/vo-v4-2-densenet-l1loss-dropout-base_lr-0.0001-snapshot-4000-dense3d-new-28000-batch-2_1529397527/vo-v4-2-densenet-l1loss-dropout.prototxt' --outputpath='densetest.jpg' --type='3d' --layer='block1_conv1'
 8793  python utils/vizutil/visualization_weight.py --modelpath='/data/sunnycia/saliency_on_videoset/Train/training_output/salicon/vo-v4-2-densenet-l1loss-dropout-base_lr-0.0001-snapshot-4000-dense3d-new-28000-batch-2_1529397527/snapshot-_iter_88000.caffemodel' --deploypath='/data/sunnycia/saliency_on_videoset/Train/training_output/salicon/vo-v4-2-densenet-l1loss-dropout-base_lr-0.0001-snapshot-4000-dense3d-new-28000-batch-2_1529397527/vo-v4-2-densenet-l1loss-dropout.prototxt' --outputpath='densetest.jpg' --type='3d' --layer='block1_conv1_conv'
 8794  python utils/vizutil/visualization_weight.py --modelpath='/data/sunnycia/saliency_on_videoset/Train/training_output/salicon/vo-v4-2-densenet-l1loss-dropout-base_lr-0.0001-snapshot-4000-dense3d-new-28000-batch-2_1529397527/snapshot-_iter_8000.caffemodel' --deploypath='/data/sunnycia/saliency_on_videoset/Train/training_output/salicon/vo-v4-2-densenet-l1loss-dropout-base_lr-0.0001-snapshot-4000-dense3d-new-28000-batch-2_1529397527/vo-v4-2-densenet-l1loss-dropout.prototxt' --outputpath='densetest.jpg' --type='3d' --layer='deconv3'
 8795  python utils/vizutil/visualization_weight.py --modelpath='/data/sunnycia/saliency_on_videoset/Train/training_output/salicon/vo-v4-2-densenet-l1loss-dropout-base_lr-0.0001-snapshot-4000-dense3d-new-28000-batch-2_1529397527/snapshot-_iter_4000.caffemodel' --deploypath='/data/sunnycia/saliency_on_videoset/Train/training_output/salicon/vo-v4-2-densenet-l1loss-dropout-base_lr-0.0001-snapshot-4000-dense3d-new-28000-batch-2_1529397527/vo-v4-2-densenet-l1loss-dropout.prototxt' --outputpath='densetest.jpg' --type='3d' --layer='deconv3'
 8796  python utils/vizutil/visualization_weight.py --modelpath='/data/sunnycia/saliency_on_videoset/Train/training_output/salicon/vo-v4-2-trimmed_densenet-deconvBN-l1loss-dropout-base_lr-0.01-snapshot-4000-dense3d-new-batch-2_1529414170/snapshot-_iter_4000.caffemodel' --deploypath='/data/sunnycia/saliency_on_videoset/Train/training_output/salicon/vo-v4-2-trimmed_densenet-deconvBN-l1loss-dropout-base_lr-0.01-snapshot-4000-dense3d-new-batch-2_1529414170/vo-v4-2-trimmed_densenet-deconvBN-l1loss-dropout.prototxt' --outputpath='densetest.jpg' --type='3d' --layer='deconv3'
 8797  python utils/vizutil/visualization_weight.py --modelpath='/data/sunnycia/saliency_on_videoset/Train/training_output/salicon/vo-v4-2-trimmed_densenet-deconvBN-l1loss-dropout-base_lr-0.01-snapshot-4000-dense3d-new-batch-2_1529414170/snapshot-_iter_4000.caffemodel' --deploypath='/data/sunnycia/saliency_on_videoset/Train/training_output/salicon/vo-v4-2-trimmed_densenet-deconvBN-l1loss-dropout-base_lr-0.01-snapshot-4000-dense3d-new-batch-2_1529414170/vo-v4-2-trimmed_densenet-deconvBN-l1loss-dropout.prototxt' --outputpath='densetest.jpg' --type='3d' --layer='deconv3_deconv'
 8798  python utils/vizutil/visualization_weight.py --modelpath='/data/sunnycia/saliency_on_videoset/Train/training_output/salicon/vo-v4-2-trimmed_densenet-deconvBN-l1loss-dropout-base_lr-0.01-snapshot-4000-dense3d-new-batch-2_1529414170/snapshot-_iter_40000.caffemodel' --deploypath='/data/sunnycia/saliency_on_videoset/Train/training_output/salicon/vo-v4-2-trimmed_densenet-deconvBN-l1loss-dropout-base_lr-0.01-snapshot-4000-dense3d-new-batch-2_1529414170/vo-v4-2-trimmed_densenet-deconvBN-l1loss-dropout.prototxt' --outputpath='densetest.jpg' --type='3d' --layer='deconv3_deconv'
 8799  python utils/vizutil/visualization_weight.py --modelpath='/data/sunnycia/saliency_on_videoset/Train/training_output/salicon/vo-v4-2-trimmed_densenet-deconvBN-l1loss-dropout-base_lr-0.01-snapshot-4000-dense3d-new-batch-2_1529414170/snapshot-_iter_60000.caffemodel' --deploypath='/data/sunnycia/saliency_on_videoset/Train/training_output/salicon/vo-v4-2-trimmed_densenet-deconvBN-l1loss-dropout-base_lr-0.01-snapshot-4000-dense3d-new-batch-2_1529414170/vo-v4-2-trimmed_densenet-deconvBN-l1loss-dropout.prototxt' --outputpath='densetest.jpg' --type='3d' --layer='deconv3_deconv'
 8800  python test_video.py --infertype='slide' --output_type='image' --test_base='msu' --model_code='v4-2' --videolength=16 --model_base_dir='vo-v4-2-densenet-l1loss-dropout-base_lr-0.0001-snapshot-4000-dense3d-new-28000-batch-2_1529397527'
 8801  python test_video.py --infertype='slide' --output_type='image' --test_base='videoset' --model_code='v4-2' --videolength=16 --model_base_dir='vo-v4-2-densenet-l1loss-dropout-base_lr-0.0001-snapshot-4000-dense3d-new-28000-batch-2_1529397527'
 8802  python test_video.py --infertype='slide' --output_type='image' --test_base='videoset' --model_code='v4-2' --videolength=16 --model_base_dir='vo-v4-2-densenet-l1loss-dropout-base_lr-0.0001-snapshot-4000-dense3d-new-28000-batch-2_1529397527' --overlap=8
 8803   python metric/avg_metric.py --videoset_name='videoset'
 8804   python metric/metric_table.py --videoset_name='videoset'
 8805  yasm
 8806   python metric/metric_table.py --videoset_name='videoset'
 8807   python metric/metric_table.py --videoset_name='msu'
 8808  python test_video.py --test_base='msu' --model_base_dir='vo-v4-2-resnet-bhatloss-dropout-base_lr-0.01-snapshot-4000-bhatloss_ledov_O8_lw_1000-batch-2_1528949547'
 8809  top
 8810  top
 8811  nvidia-smi
 8812  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-resnet-bhatloss-dropout.prototxt' --use_model='../pretrained_model/c3d_resnet18_sports1m_r2_iter_2800000.caffemodel' --plotiter=200 --validiter=4000 --savemodeliter=4000 --trainingexampleprops=0.999 --trainingbase='hollywood' --videolength=16 --overlap=8 --extramodinfo='bhatloss_hollywood_O8' --batch=2
 8813  cd /data/sunnycia/saliency_on_videoset/Train/scripts/prototxt/..
 8814  source set_env.sh ../C3D-v1.1-tmp/ 7
 8815  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-resnet-bhatloss-dropout.prototxt' --use_model='../pretrained_model/c3d_resnet18_sports1m_r2_iter_2800000.caffemodel' --plotiter=200 --validiter=4000 --savemodeliter=4000 --trainingexampleprops=0.999 --trainingbase='hollywood' --videolength=16 --overlap=8 --extramodinfo='bhatloss_hollywood_O8' --batch=2
 8816  nvidia-smi
 8817  source set_env.sh ../C3D-v1.1-tmp/ 4
 8818  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-resnet-bhatloss-dropout.prototxt' --use_model='../pretrained_model/c3d_resnet18_sports1m_r2_iter_2800000.caffemodel' --plotiter=200 --validiter=4000 --savemodeliter=4000 --trainingexampleprops=0.999 --trainingbase='hollywood' --videolength=16 --overlap=8 --extramodinfo='bhatloss_hollywood_O8' --batch=2
 8819  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-resnet-bhatloss-dropout.prototxt' --use_model='../pretrained_model/c3d_resnet18_sports1m_r2_iter_2800000.caffemodel' --plotiter=200 --validiter=4000 --savemodeliter=4000 --trainingexampleprops=0.999 --trainingbase='ledov' --videolength=16 --overlap=8 --extramodinfo='bhatloss_hollywood_O8' --batch=2
 8820  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-resnet-bhatloss-dropout.prototxt' --use_model='../pretrained_model/c3d_resnet18_sports1m_r2_iter_2800000.caffemodel' --plotiter=200 --validiter=4000 --savemodeliter=4000 --trainingexampleprops=0.999 --trainingbase='hollywood' --videolength=16 --overlap=8 --extramodinfo='bhatloss_hollywood_O8' --batch=2
 8821  clear && clear
 8822  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-resnet-bhatloss-dropout.prototxt' --use_model='../pretrained_model/c3d_resnet18_sports1m_r2_iter_2800000.caffemodel' --plotiter=200 --validiter=4000 --savemodeliter=4000 --trainingexampleprops=0.999 --trainingbase='ledov' --videolength=16 --overlap=8 --extramodinfo='bhatloss_ledov_O8_lw1000' --batch=2
 8823  clear && clear
 8824  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-resnet-bhatloss-dropout.prototxt' --use_model='../pretrained_model/c3d_resnet18_sports1m_r2_iter_2800000.caffemodel' --plotiter=200 --validiter=4000 --savemodeliter=4000 --trainingexampleprops=0.999 --trainingbase='ledov' --videolength=16 --overlap=8 --extramodinfo='bhatloss_ledov_O8_lw100' --batch=2
 8825  cd /data/sunnycia/saliency_on_videoset/_Train/3D_DenseSeg
 8826  clear && clear
 8827  bash run_train.sh 
 8828  vim run_train.sh 
 8829  bash run_train.sh 
 8830  vim run_train.sh 
 8831  bash run_train.sh 
 8832  top
 8833  nvidia-smi
 8834  top
 8835  cd /data/sunnycia/saliency_on_videoset/Train/training_output/salicon
 8836  cd ../../..
 8837  cd Train/scripts/
 8838  clear && clear
 8839  nvidia-smi
 8840  top
 8841  source set_env.sh ../C3D-v1.1-tmp/ 7
 8842  clear && clear
 8843  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-densnet-dropout.prototxt'  --plotiter=200 --validiter=4000 --savemodeliter=4000 --trainingexampleprops=0.999 --trainingbase='ledov' --videolength=16 --overlap=15 --extramodinfo='dense3d' --batch=2 
 8844  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-densnet-l1loss-dropout.prototxt'  --plotiter=200 --validiter=4000 --savemodeliter=4000 --trainingexampleprops=0.999 --trainingbase='ledov' --videolength=16 --overlap=15 --extramodinfo='dense3d' --batch=2 
 8845  clear && clear
 8846  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-densnet-l1loss-dropout.prototxt'  --plotiter=200 --validiter=4000 --savemodeliter=4000 --trainingexampleprops=0.999 --trainingbase='ledov' --videolength=16 --overlap=15 --extramodinfo='dense3d' --batch=2 
 8847  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-densenet-l1loss-dropout.prototxt'  --plotiter=200 --validiter=4000 --savemodeliter=4000 --trainingexampleprops=0.999 --trainingbase='ledov' --videolength=16 --overlap=15 --extramodinfo='dense3d' --batch=2 
 8848  clear && clear
 8849  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-densenet-l1loss-dropout.prototxt'  --plotiter=200 --validiter=4000 --savemodeliter=4000 --trainingexampleprops=0.999 --trainingbase='ledov' --videolength=16 --overlap=15 --extramodinfo='dense3d' --batch=2 
 8850  clear && clear
 8851  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-densenet-l1loss-dropout.prototxt'  --plotiter=200 --validiter=4000 --savemodeliter=4000 --trainingexampleprops=0.999 --trainingbase='ledov' --videolength=16 --overlap=15 --extramodinfo='dense3d' --batch=2 
 8852  clear && clear
 8853  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-densenet-l1loss-dropout.prototxt'  --plotiter=200 --validiter=4000 --savemodeliter=4000 --trainingexampleprops=0.999 --trainingbase='ledov' --videolength=16 --overlap=15 --extramodinfo='dense3d' --batch=2 
 8854  clear && clear
 8855  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-densenet-l1loss-dropout.prototxt'  --plotiter=200 --validiter=4000 --savemodeliter=4000 --trainingexampleprops=0.999 --trainingbase='ledov' --videolength=16 --overlap=15 --extramodinfo='dense3d' --batch=2 
 8856  clear && clear
 8857  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-densenet-l1loss-dropout.prototxt'  --plotiter=200 --validiter=4000 --savemodeliter=4000 --trainingexampleprops=0.999 --trainingbase='ledov' --videolength=16 --overlap=15 --extramodinfo='dense3d' --batch=2 
 8858  clear && clear
 8859  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-densenet-l1loss-dropout.prototxt'  --plotiter=200 --validiter=4000 --savemodeliter=4000 --trainingexampleprops=0.999 --trainingbase='ledov' --videolength=16 --overlap=15 --extramodinfo='dense3d' --batch=2 
 8860  clear && clear
 8861  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-densenet-l1loss-dropout.prototxt'  --plotiter=200 --validiter=4000 --savemodeliter=4000 --trainingexampleprops=0.999 --trainingbase='ledov' --videolength=16 --overlap=15 --extramodinfo='dense3d' --batch=2 
 8862  clear && clear
 8863  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-densenet-l1loss-dropout.prototxt'  --plotiter=200 --validiter=4000 --savemodeliter=4000 --trainingexampleprops=0.999 --trainingbase='ledov' --videolength=16 --overlap=15 --extramodinfo='dense3d' --batch=2 
 8864  clear && clear
 8865  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-densenet-l1loss-dropout.prototxt'  --plotiter=200 --validiter=4000 --savemodeliter=4000 --trainingexampleprops=0.999 --trainingbase='ledov' --videolength=16 --overlap=15 --extramodinfo='dense3d' --batch=2 
 8866  clear && clear
 8867  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-densenet-l1loss-dropout.prototxt'  --plotiter=200 --validiter=4000 --savemodeliter=4000 --trainingexampleprops=0.999 --trainingbase='ledov' --videolength=16 --overlap=15 --extramodinfo='dense3d' --batch=2 
 8868  clear && clear
 8869  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-densenet-l1loss-dropout.prototxt'  --plotiter=200 --validiter=4000 --savemodeliter=4000 --trainingexampleprops=0.999 --trainingbase='ledov' --videolength=16 --overlap=15 --extramodinfo='dense3d' --batch=2 
 8870  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-densenet-l1loss-dropout.prototxt'  --plotiter=200 --validiter=4000 --savemodeliter=1000 --trainingexampleprops=0.999 --trainingbase='ledov' --videolength=16 --overlap=15 --extramodinfo='dense3d' --batch=2 
 8871  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-densenet-l1loss-dropout.prototxt'  --plotiter=200 --validiter=4000 --savemodeliter=100 --trainingexampleprops=0.9999 --trainingbase='ledov' --videolength=16 --overlap=15 --extramodinfo='dense3d' --batch=2 
 8872  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-densenet-l1loss-dropout.prototxt'  --plotiter=200 --validiter=4000 --savemodeliter=100 --trainingexampleprops=0.9999 --trainingbase='ledov' --videolength=16 --overlap=15 --extramodinfo='dense3d' --batch=2 --use_model='/data/sunnycia/saliency_on_videoset/Train/training_output/salicon/vo-v4-2-densenet-l1loss-dropout-base_lr-0.01-snapshot-100-dense3d-batch-2_1529372741/snapshot-_iter_100.caffemodel'
 8873  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-densenet-l1loss-dropout.prototxt'  --plotiter=200 --validiter=4000 --savemodeliter=100 --trainingexampleprops=0.9999 --trainingbase='ledov' --videolength=16 --overlap=15 --extramodinfo='dense3d' --batch=2 
 8874  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-densenet-l1loss-dropout.prototxt'  --plotiter=200 --validiter=4000 --savemodeliter=100 --trainingexampleprops=0.9999 --trainingbase='ledov' --videolength=16 --overlap=15 --extramodinfo='dense3d' --batch=2 --use_model='/data/sunnycia/saliency_on_videoset/Train/training_output/salicon/vo-v4-2-densenet-l1loss-dropout-base_lr-0.01-snapshot-100-dense3d-batch-2_1529373090/snapshot-_iter_100.caffemodel'
 8875  clear && clear
 8876  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-densenet-l1loss-dropout.prototxt'  --plotiter=200 --validiter=4000 --savemodeliter=100 --trainingexampleprops=0.9999 --trainingbase='ledov' --videolength=16 --overlap=15 --extramodinfo='dense3d' --batch=2 
 8877  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-densenet-l1loss-dropout.prototxt'  --plotiter=200 --validiter=4000 --savemodeliter=100 --trainingexampleprops=0.9999 --trainingbase='ledov' --videolength=16 --overlap=15 --extramodinfo='dense3d' --batch=2 --use_model='/data/sunnycia/saliency_on_videoset/Train/training_output/salicon/vo-v4-2-densenet-l1loss-dropout-base_lr-0.01-snapshot-100-dense3d-batch-2_1529373648/snapshot-_iter_100.caffemodel'
 8878  clear && clear
 8879  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-densenet-l1loss-dropout.prototxt'  --plotiter=200 --validiter=4000 --savemodeliter=4000 --trainingexampleprops=0.999 --trainingbase='ledov' --videolength=16 --overlap=15 --extramodinfo='dense3d-new' --batch=2 
 8880  clear && clear
 8881  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-trimmed_densenet-deconvBN-l1loss-dropout.prototxt'  --plotiter=200 --validiter=4000 --savemodeliter=4000 --trainingexampleprops=0.999 --trainingbase='ledov' --videolength=16 --overlap=15 --extramodinfo='dense3d-new' --batch=2 
 8882  clear && clear
 8883  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-trimmed_densenet-deconvBN-l1loss-dropout.prototxt'  --plotiter=200 --validiter=4000 --savemodeliter=4000 --trainingexampleprops=0.999 --trainingbase='ledov' --videolength=16 --overlap=15 --extramodinfo='dense3d-new' --batch=2 
 8884  python make_caffe_network.py > prototxt/vo-v4-2-trimmed_densenet-deconvBN-l1loss-dropout.prototxt
 8885  clear && clear
 8886  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-trimmed_densenet-deconvBN-l1loss-dropout.prototxt'  --plotiter=200 --validiter=4000 --savemodeliter=4000 --trainingexampleprops=0.999 --trainingbase='ledov' --videolength=16 --overlap=15 --extramodinfo='dense3d-new' --batch=2 
 8887  clear && clear
 8888  python make_caffe_network.py > prototxt/vo-v4-2-trimmed_densenet-deconvBN-l1loss-dropout.prototxt
 8889  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-trimmed_densenet-deconvBN-l1loss-dropout.prototxt'  --plotiter=200 --validiter=4000 --savemodeliter=4000 --trainingexampleprops=0.999 --trainingbase='ledov' --videolength=16 --overlap=15 --extramodinfo='dense3d-new' --batch=2 
 8890  python make_caffe_network.py > prototxt/vo-v4-2-trimmed_densenet-deconvBN-l1loss-dropout.prototxt
 8891  clear && clear
 8892  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-trimmed_densenet-deconvBN-l1loss-dropout.prototxt'  --plotiter=200 --validiter=4000 --savemodeliter=4000 --trainingexampleprops=0.999 --trainingbase='ledov' --videolength=16 --overlap=15 --extramodinfo='dense3d-new' --batch=2 
 8893  cd /data/sunnycia/saliency_on_videoset/Train/scripts
 8894  source set_env.sh ../C3D-v1.1-tmp/ 6
 8895  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-resnet-bhatloss-dropout.prototxt' --use_model='../pretrained_model/c3d_resnet18_sports1m_r2_iter_2800000.caffemodel' --plotiter=200 --validiter=4000 --savemodeliter=4000 --trainingexampleprops=0.999 --trainingbase='hollywood' --videolength=16 --overlap=8 --extramodinfo='bhatloss_hollywood_O8' --batch=2
 8896  clear && clear
 8897  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-resnet-bhatloss-dropout.prototxt' --use_model='../pretrained_model/c3d_resnet18_sports1m_r2_iter_2800000.caffemodel' --plotiter=200 --validiter=4000 --savemodeliter=4000 --trainingexampleprops=0.999 --trainingbase='ledov' --videolength=16 --overlap=8 --extramodinfo='bhatloss_hollywood_O8' --batch=2
 8898  clear && clear
 8899  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-resnet-bhatloss-dropout.prototxt' --use_model='../pretrained_model/c3d_resnet18_sports1m_r2_iter_2800000.caffemodel' --plotiter=200 --validiter=4000 --savemodeliter=4000 --trainingexampleprops=0.999 --trainingbase='ledov' --videolength=16 --overlap=8 --extramodinfo='bhatloss_ledov_O8_lw_100' --batch=2
 8900  clear && clear
 8901  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-resnet-bhatloss-dropout.prototxt' --use_model='../pretrained_model/c3d_resnet18_sports1m_r2_iter_2800000.caffemodel' --plotiter=200 --validiter=4000 --savemodeliter=4000 --trainingexampleprops=0.999 --trainingbase='ledov' --videolength=16 --overlap=8 --extramodinfo='bhatloss_ledov_O8_lw_1000' --batch=2
 8902  nvidia-smi
 8903  top
 8904  nvidia-smi
 8905  clear && clear
 8906  cd /data/sunnycia/saliency_on_videoset/Train/scripts
 8907  source set_env.sh ../C3D-v1.1-tmp 6
 8908  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-densenet-l1loss-dropout.prototxt'  --plotiter=200 --validiter=4000 --savemodeliter=4000 --trainingexampleprops=0.999 --trainingbase='ledov' --videolength=16 --overlap=15 --extramodinfo='dense3d_2' --batch=2
 8909  clear && clear
 8910  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-densenet-l1loss-dropout.prototxt'  --plotiter=200 --validiter=4000 --savemodeliter=4000 --trainingexampleprops=0.999 --trainingbase='ledov' --videolength=16 --overlap=15 --extramodinfo='dense3d_2' --batch=2
 8911  clear && clear
 8912  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-densenet-l1loss-dropout.prototxt'  --plotiter=200 --validiter=4000 --savemodeliter=4000 --trainingexampleprops=0.999 --trainingbase='ledov' --videolength=16 --overlap=15 --extramodinfo='dense3d_2' --batch=2
 8913   python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-densenet-l1loss-dropout.prototxt'  --plotiter=200 --validiter=15000 --savemodeliter=4000 --trainingexampleprops=0.95 --trainingbase='ledov' --videolength=16 --overlap=15 --extramodinfo='dense3d_2_reduceLR' --batch=2 --use_model='snapshot-_iter_40000.caffemodel'
 8914   python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-densenet-l1loss-dropout.prototxt'  --plotiter=200 --validiter=15000 --savemodeliter=4000 --trainingexampleprops=0.95 --trainingbase='ledov' --videolength=16 --overlap=15 --extramodinfo='dense3d_2_reduceLR' --batch=2 --use_model='../training_output/salicon/vo-v4-2-densenet-l1loss-dropout-base_lr-0.01-snapshot-4000-dense3d_2-batch-2_1529279669/snapshot-_iter_40000.caffemodel'
 8915   python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-densenet-l1loss-dropout.prototxt'  --plotiter=200 --validiter=15000 --savemodeliter=4000 --trainingexampleprops=0.95 --trainingbase='ledov' --videolength=16 --overlap=15 --extramodinfo='dense3d_2_reduceLR' --batch=2 --use_model='snapshot-_iter_40000.caffemodel'
 8916   python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-densenet-l1loss-dropout.prototxt'  --plotiter=200 --validiter=15000 --savemodeliter=4000 --trainingexampleprops=0.95 --trainingbase='ledov' --videolength=16 --overlap=15 --extramodinfo='dense3d_2_reduceLR' --batch=2 --use_model='../training_output/salicon/vo-v4-2-densenet-l1loss-dropout-base_lr-0.01-snapshot-4000-dense3d_2-batch-2_1529279669/snapshot-_iter_40000.caffemodel'
 8917   python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-densenet-l1loss-dropout.prototxt'  --plotiter=200 --validiter=15000 --savemodeliter=4000 --trainingexampleprops=0.95 --trainingbase='ledov' --videolength=16 --overlap=15 --extramodinfo='dense3d_2_reduceLR' --batch=2 --use_model='snapshot-_iter_40000.caffemodel'
 8918   python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-densenet-l1loss-dropout.prototxt'  --plotiter=200 --validiter=15000 --savemodeliter=4000 --trainingexampleprops=0.95 --trainingbase='ledov' --videolength=16 --overlap=15 --extramodinfo='dense3d_2_reduceLR' --batch=2 --use_model='../training_output/salicon/vo-v4-2-densenet-l1loss-dropout-base_lr-0.01-snapshot-4000-dense3d_2-batch-2_1529279669/snapshot-_iter_40000.caffemodel'
 8919  python test_video.py --video_deploy_path='/data/sunnycia/saliency_on_videoset/Train/training_output/salicon/vo-v4-2-resnet-l1loss-dropout-base_lr-0.01-snapshot-4000-l1oss_dropout02_ledov_O8-batch-2_1529045198/vo-v4-2-resnet-l1loss-deploy.prototxt' --video_model_path='/data/sunnycia/saliency_on_videoset/Train/training_output/salicon/vo-v4-2-resnet-l1loss-dropout-base_lr-0.01-snapshot-4000-l1oss_dropout02_ledov_O8-batch-2_1529045198/snapshot-_iter_400000.caffemodel' --infertype='slide' --output_type='image' --test_base='videoset' --model_code='v4-2' --videolength=16
 8920  top
 8921  nvidia-smi
 8922  top
 8923  nvidia-smi
 8924  cd /data/sunnycia/saliency_on_videoset/Train/scripts
 8925  python test_video.py --video_deploy_path='/data/sunnycia/saliency_on_videoset/Train/training_output/salicon/vo-v4-2-resnet-l1loss-dropout-base_lr-0.01-snapshot-4000-l1oss_dropout02_ledov_O8-batch-2_1529045198/vo-v4-2-resnet-l1loss-deploy.prototxt' --video_model_path='/data/sunnycia/saliency_on_videoset/Train/training_output/salicon/vo-v4-2-resnet-l1loss-dropout-base_lr-0.01-snapshot-4000-l1oss_dropout02_ledov_O8-batch-2_1529045198/snapshot-_iter_400000.caffemodel' --infertype='slide' --output_type='image' --test_base='videoset' --model_code='v4-2' --videolength=16 
 8926  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-densenet-l1loss-dropout.prototxt'  --plotiter=200 --validiter=4000 --savemodeliter=4000 --trainingexampleprops=0.999 --trainingbase='ledov' --videolength=16 --overlap=15 --extramodinfo='dense3d-new-28000' --batch=2 --use_model='/data/sunnycia/saliency_on_videoset/Train/training_output/salicon/vo-v4-2-densenet-l1loss-dropout-base_lr-0.01-snapshot-4000-dense3d-new-batch-2_1529373970/snapshot-_iter_28000.caffemodel'
 8927  cd /data/sunnycia/image_compression_challenge/_Train/libbpg-0.9.8
 8928  yasm
 8929  $HOME
 8930  su 
 8931  make clean
 8932  make -j4
 8933  make install
 8934  cd ~/ffmpeg_sources/x265/build/linux
 8935  cd /x265/build/linux
 8936  cd x265/build/linux
 8937  cmake -G "Unix Makefiles" -DCMAKE_INSTALL_PREFIX="$HOME/ffmpeg_build" -DENABLE_SHARED:bool=off ../../source
 8938  make
 8939  make clean
 8940  cmake -G "Unix Makefiles" -DCMAKE_INSTALL_PREFIX="$HOME/ffmpeg_build" -DENABLE_SHARED:bool=off ../../source
 8941  make -j4
 8942  make install
 8943  cd ../..
 8944  cd ..
 8945  make clean
 8946  make -j4 && make -j4 install
 8947  make -j4 install
 8948  cd -
 8949  vo-v4-2-resnet-BNdeconv-l1loss-dropout-base_lr-0.01-snapshot-4000-resnet_addBN_2_deconv-batch-2_1529458913
 8950  cd /data/sunnycia/saliency_on_videoset/Train/scripts
 8951  python test_video.py --test_base='videoset' --model_base_dir='vo-v4-2-resnet-BNdeconv-l1loss-dropout-base_lr-0.01-snapshot-4000-resnet_addBN_2_deconv-batch-2_1529458913'
 8952  source set_env.sh ../C3D-v1.1-tmp/ 7
 8953  nvidia-smi
 8954  top
 8955  nvidia-smi
 8956  source set_env.sh ../C3D-v1.1-tmp/ 7
 8957  python test_video.py --test_base='videoset' --model_base_dir='vo-v4-2-resnet-BNdeconv-l1loss-dropout-base_lr-0.01-snapshot-4000-resnet_addBN_2_deconv-batch-2_1529458913'
 8958  history > history
 8959  python test_video.py -h
 8960  python test_video.py --test_base='msu' --model_base_dir='vo-v4-2-resnet-l1loss-dropout-base_lr-0.01-snapshot-4000-l1oss_dropout02_ledov_O8-batch-2_1529045198' && python test_video.py --test_base='diem' --model_base_dir='vo-v4-2-resnet-l1loss-dropout-base_lr-0.01-snapshot-4000-l1oss_dropout02_ledov_O8-batch-2_1529045198' && python test_video.py --test_base='hollywood' --model_base_dir='vo-v4-2-resnet-l1loss-dropout-base_lr-0.01-snapshot-4000-l1oss_dropout02_ledov_O8-batch-2_1529045198'
 8961  python test_video --test_base='videoset' --model_base_dir='vo-v4-2-resnet-BNdeconv-l1loss-dropout-base_lr-0.01-snapshot-4000-resnet_addBN_2_deconv-batch-2_1529493349'
 8962  python test_video.py --test_base='videoset' --model_base_dir='vo-v4-2-resnet-BNdeconv-l1loss-dropout-base_lr-0.01-snapshot-4000-resnet_addBN_2_deconv-batch-2_1529493349'
 8963  top
 8964  python test_video.py --test_base='videoset' --model_base_dir='vo-v4-2-resnet-BNdeconv-l1loss-dropout-base_lr-0.01-snapshot-4000-resnet_addBN_2_deconv-batch-2_1529493349'
 8965  ezvision
 8966  cd /data/sunnycia/saliency_on_videoset/Train/scripts
 8967  history > ../history 
 8968  ./ezvision -Y --nodisplay-additive --input-frames=@33Hz --output-frames=@0.005s --ehc-type=Simple --hsc-type=None --esc-type=Friction --foveate-input-depth=5 --nodisplay-foa --display-map-factor=50000 --in=/data/SaliencyDataset/Video/frame#.jpg --out=display --out=raster
 8969  cd /data/sunnycia/saliency_on_videoset/_Model/Surprise-iLab-saliency-20140505/bin/
 8970  ./ezvision -Y --nodisplay-additive --input-frames=@33Hz --output-frames=@0.005s --ehc-type=Simple --hsc-type=None --esc-type=Friction --foveate-input-depth=5 --nodisplay-foa --display-map-factor=50000 --in=/data/SaliencyDataset/Video/frame#.jpg --out=display --out=raster
 8971  ./ezvision -Y --nodisplay-additive --input-frames=@33Hz --output-frames=@0.005s --ehc-type=Simple --hsc-type=None --esc-type=Friction --foveate-input-depth=5 --nodisplay-foa --display-map-factor=50000 --in=/data/SaliencyDataset/Video/frame_#.jpg --out=display --out=raster
 8972  ./ezvision -Y --nodisplay-additive --input-frames=@33Hz --output-frames=@0.005s --ehc-type=Simple --hsc-type=None --esc-type=Friction --foveate-input-depth=5 --nodisplay-foa --display-map-factor=50000 --in=/data/SaliencyDataset/Video/frame_#.jpg --out=raster
 8973  ./ezvision -Y --nodisplay-additive --input-frames=@1Hz --output-frames=@1Hz --ehc-type=Simple --hsc-type=None --esc-type=Friction --foveate-input-depth=5 --nodisplay-foa --display-map-factor=50000 --in=/data/SaliencyDataset/Video/frame_#.jpg --out=raster
 8974  ./ezvision -Y --nodisplay-additive --input-frames=@1Hz --output-frames=@1Hz --ehc-type=Simple --hsc-type=None --esc-type=Friction --foveate-input-depth=5 --nodisplay-foa --display-map-factor=50000 --in=/data/SaliencyDataset/Video/frame_#.jpg --out=png
 8975  ./ezvision -Y --nodisplay-additive --input-frames=@1Hz --output-frames=@1Hz --ehc-type=Simple --hsc-type=None --esc-type=Friction --foveate-input-depth=5 --nodisplay-foa --in=/data/SaliencyDataset/Video/frame_#.jpg --out=png
 8976  ./ezvision -Y --nodisplay-additive --input-frames=@1ms --output-frames=@1ms --ehc-type=Simple --hsc-type=None --esc-type=Friction --foveate-input-depth=5 --nodisplay-foa --in=/data/SaliencyDataset/Video/frame_#.jpg --out=png
 8977  ./ezvision -Y --nodisplay-additive --input-frames=@1ms --output-frames=@1ms --ehc-type=Simple  --in=/data/SaliencyDataset/Video/frame_#.jpg --out=png
 8978  cd ..
 8979  ./ezvision
 8980  cd ..
 8981  python gen_saliency_Surprise.py --framebase='/data/SaliencyDataset/Video/VideoSet/ImageSet/Seperate/frames' --outputbase='/data/SaliencyDataset/Video/VideoSet/Results/saliency_map'
 8982  ezvision
 8983  bash Surprise-iLab-saliency-20140505/bin/ezvision
 8984  ./Surprise-iLab-saliency-20140505/bin/ezvision
 8985  bash Surprise-iLab-saliency-20140505/bin/ezvision
 8986  python gen_saliency_Surprise.py --framebase='/data/SaliencyDataset/Video/VideoSet/ImageSet/Seperate/frames' --outputbase='/data/SaliencyDataset/Video/VideoSet/Results/saliency_map'
 8987  ls
 8988  ./Surprise-iLab-saliency-20140505/bin/ezvision
 8989  python gen_saliency_Surprise.py --framebase='/data/SaliencyDataset/Video/VideoSet/ImageSet/Seperate/frames' --outputbase='/data/SaliencyDataset/Video/VideoSet/Results/saliency_map'
 8990  chmod a+x /data/sunnycia/saliency_on_videoset/_Model/Surprise-iLab-saliency-20140505/bin/ezvision
 8991  python gen_saliency_Surprise.py --framebase='/data/SaliencyDataset/Video/VideoSet/ImageSet/Seperate/frames' --outputbase='/data/SaliencyDataset/Video/VideoSet/Results/saliency_map'
 8992  chmod u+x /data/sunnycia/saliency_on_videoset/_Model/Surprise-iLab-saliency-20140505/bin/ezvision
 8993  python gen_saliency_Surprise.py --framebase='/data/SaliencyDataset/Video/VideoSet/ImageSet/Seperate/frames' --outputbase='/data/SaliencyDataset/Video/VideoSet/Results/saliency_map'
 8994  clear && clear
 8995  python gen_saliency_Surprise.py --framebase='/data/SaliencyDataset/Video/VideoSet/ImageSet/Seperate/frames' --outputbase='/data/SaliencyDataset/Video/VideoSet/Results/saliency_map'
 8996  python gen_saliency_Surprise.py --framebase='/data/SaliencyDataset/Video/DIEM/frames' --outputbase='/data/SaliencyDataset/Video/DIEM/saliency_map'
 8997  top
 8998  cat /proc/cpuinfo | awk '/^processor/{print $3}' | tail -1
 8999  top
 9000  nvidia-smi
 9001  top
 9002  nvidia-smi
 9003  cd /data/sunnycia/saliency_on_videoset/_Model
 9004  cd /data/sunnycia/saliency_on_videoset/_Model/twostream_dynamicsaliency/scripts/
 9005  ls
 9006  python generate_saliencies.py 
 9007  cd ..
 9008  python test.py 
 9009   top
 9010  nvidia-smi
 9011  top
 9012  python
 9013  python test.py 
 9014  top
 9015  cd /data/sunnycia/saliency_on_videoset/_Model/Rudoy
 9016  clear
 9017  ls
 9018  matlab -nodesktop -nodisplay
 9019  cd /data/sunnycia/saliency_on_videoset/_Model/Surprise-iLab-saliency-20140505
 9020  make clean
 9021  ./configure
 9022  make -j4 core
 9023  make clean
 9024  ./configure
 9025  make -j4 core
 9026  yum install atlas, atlas-devel, blas blas-devel lapack lapack-devel
 9027  make clean
 9028  ./configure
 9029  make -j4 core
 9030  make clean
 9031  touch "2 hours ago" src/Image/ColorOps.C
 9032  make clean && ./configure && make -j4 core
 9033  touch "2 hours ago" src/Image/ColorOps.C
 9034  export PATH=$PATH:./
 9035  make clean
 9036  ./configure && make -j4 core
 9037  touch "10 minutes ago" src/Beowulf/SockServ.C
 9038  make clean
 9039  ./configure && make -j4 core
 9040  make clean
 9041  touch "10 minutes ago" src/Beowulf/SockServ.C
 9042  make clean
 9043  ./configure && make -j4 core
 9044  ls -h
 9045  ln -h
 9046  ln --help
 9047  cd src/
 9048  ln inst ../inst
 9049  ln ../inst inst
 9050  ln -s ../inst inst
 9051  cd ,,
 9052  cd ..
 9053  make clean
 9054  ./configure && make -j4 core
 9055  make clean
 9056  ./configure && make -j4 core
 9057  touch "1 hours ago" src/Raster/PngParser.C
 9058  make clean
 9059  ./configure && make -j4 core
 9060  ezvision
 9061  ./bin/ezvision
 9062  clear && clear
 9063  ./bin/ezvision
 9064          ./bin/ezvision --in=tests/inputs/ezframe#.pnm -T --out=display
 9065  ./bin/ezvision --in=tests/inputs/mpegclip1.mpg -T                 --out=display                 --out=png
 9066          ./bin/ezvision --in=tests/inputs/mpegclip1.mpg -T --out=display
 9067  ffmpeg
 9068  ./bin/ezvision --in=tests/inputs/mpegclip1.mpg -T --out=display  --out=png
 9069          ./bin/ezvision --in=tests/inputs/ezframe#.pnm -T --out=display
 9070          ./bin/ezvision --in=tests/inputs/ezframe#.pnm -T --out=png
 9071  ezvision -T --nodisplay-additive --input-frames=@30ms --output-frames=@3ms --in=frame#.png --out=display --out=raster
 9072  ./bin/ezvision -T --nodisplay-additive --input-frames=@30ms --output-frames=@3ms --in=frame#.png --out=display --out=raster
 9073  ./bin/ezvision -T --nodisplay-additive --input-frames=@30ms --output-frames=@3ms --in=/data/SaliencyDataset/Video/GAZECOM/frames/street/frame_#.jpg --out=display --out=raster
 9074  ./bin/ezvision -T --nodisplay-additive --input-frames=@30ms --output-frames=@3ms --in=/data/SaliencyDataset/Video/frame_#.jpg --out=display --out=raster
 9075  ./bin/ezvision -T --nodisplay-additive --input-frames=@30ms --output-frames=@3ms --in=/data/SaliencyDataset/Video/frame_#.jpg --out=display --out=png
 9076  python
 9077  ./bin/ezvision -T --nodisplay-additive --input-frames=@1ms --output-frames=@1ms --ehc-type=Simple --hsc-type=None --esc-type=Friction --foveate-input-depth=5 --nodisplay-foa --display-map-factor=50000 --in=/data/SaliencyDataset/Video/frame_#.jpg --out=display --out=png
 9078  ./bin/ezvision -T --nodisplay-additive --input-frames=@1ms --output-frames=@1ms --ehc-type=Simple --hsc-type=None --esc-type=Friction --foveate-input-depth=5 --nodisplay-foa --display-map-factor=50000 --in=/data/SaliencyDataset/Video/frame_#.jpg --out=display --out=raster
 9079  ./bin/ezvision -Y --nodisplay-additive --input-frames=@1ms --output-frames=@1ms --ehc-type=Simple --hsc-type=None --esc-type=Friction --foveate-input-depth=5 --nodisplay-foa --display-map-factor=50000 --in=/data/SaliencyDataset/Video/frame_#.jpg --out=display --out=raster
 9080  python
 9081  cd ..
 9082  clear && clear
 9083  matlab -nodesktop -nodisplay
 9084  2800000.caffemodel
 9085  I0614 00:25:48.467573 23494 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
 9086  I0614 00:25:48.500402 23494 net.cpp:744] Ignoring source layer pool5
 9087  I0614 00:25:48.500437 23494 net.cpp:744] Ignoring source layer fc8
 9088  Loading data...
 9089  56345 samples generated in total, 56288 training samples, 57 validation samples
 9090  Loss figure will be save to ../figure/vo-v4-2-resnet-bhatloss-dropout-base_lr-0.000001-snapshot-4000-bhatloss_hollywood_O8-batch-2_1528907146
 9091  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-resnet-bhatloss-dropout.prototxt' --use_model='../pretrained_model/c3d_resnet18_sports1m_r2_iter_2800000.caffemodel' --plotiter=200 --validiter=4000 --savemodeliter=4000 --trainingexampleprops=0.999 --trainingbase='hollywood' --videolength=16 --overlap=8 --extramodinfo='bhatloss_hollywood_O8' --batch=2
 9092  cd /data/sunnycia/saliency_on_videoset/Train/scripts
 9093  source set_env.sh ../C3D-v1.1-tmp/ 6
 9094  clear && clear
 9095  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-resnet-bhatloss-dropout.prototxt' --use_model='../pretrained_model/c3d_resnet18_sports1m_r2_iter_2800000.caffemodel' --plotiter=200 --validiter=4000 --savemodeliter=4000 --trainingexampleprops=0.999 --trainingbase='hollywood' --videolength=16 --overlap=8 --extramodinfo='bhatloss_hollywood_O8' --batch=2
 9096  source set_env.sh ../C3D-v1.1-tmp/ 5
 9097  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-resnet-bhatloss-dropout.prototxt' --use_model='../pretrained_model/c3d_resnet18_sports1m_r2_iter_2800000.caffemodel' --plotiter=200 --validiter=4000 --savemodeliter=4000 --trainingexampleprops=0.999 --trainingbase='hollywood' --videolength=16 --overlap=8 --extramodinfo='bhatloss_hollywood_O8' --batch=2
 9098  clear && clear
 9099  top
 9100  nvidia-smi
 9101  top
 9102  nvidia-smi
 9103  top
 9104  nvidia-smi
 9105  cd /data/sunnycia/saliency_on_videoset/Train/C3D-v1.1-tmp
 9106  make clean
 9107  make -j8 all && make pycaffe
 9108  make clean
 9109  make -j8 all && make pycaffe
 9110  make clean
 9111  make -j8 all && make pycaffe
 9112  cd /data/sunnycia/saliency_on_videoset/Train/scripts
 9113  python test_video.py --video_deploy_path='prototxt/vo-v4-2-densenet-l1loss-dropout.prototxt' --video_model_path='../training_output/salicon/vo-v4-2-densenet-l1loss-dropout-base_lr-0.01-snapshot-4000-dense3d-batch-2_1529218915/snapshot-_iter_100000.caffemodel' --infertype='slide' --output_type='image' --test_base='videoset' --model_code='v4-2'
 9114  python test_video.py --video_deploy_path='prototxt/vo-v4-2-densenet-l1loss-dropout.prototxt' --video_model_path='../training_output/salicon/vo-v4-2-densenet-l1loss-dropout-base_lr-0.01-snapshot-4000-dense3d_2-batch-2_1529279669/snapshot-_iter_40000.caffemodel' --infertype='slide' --output_type='image' --test_base='videoset' --model_code='v4-2'
 9115  python test_video.py --video_deploy_path='/data/sunnycia/saliency_on_videoset/Train/training_output/salicon/vo-v4-2-densenet-l1loss-dropout.prototxt' --video_model_path='../training_output/salicon/vo-v4-2-densenet-l1loss-dropout-base_lr-0.01-snapshot-4000-dense3d_2-batch-2_1529279669/snapshot-_iter_40000.caffemodel' --infertype='slide' --output_type='image' --test_base='videoset' --model_code='v4-2'
 9116  python test_video.py --video_deploy_path='/data/sunnycia/saliency_on_videoset/Train/training_output/salicon/vo-v4-2-densenet-l1loss-dropout-base_lr-0.01-snapshot-4000-dense3d_2-batch-2_1529279669/vo-v4-2-densenet-l1loss-dropout.prototxt' --video_model_path='../training_output/salicon/vo-v4-2-densenet-l1loss-dropout-base_lr-0.01-snapshot-4000-dense3d_2-batch-2_1529279669/snapshot-_iter_40000.caffemodel' --infertype='slide' --output_type='image' --test_base='videoset' --model_code='v4-2'
 9117  python make_caffe_network.py 
 9118  [A
 9119  python make_caffe_network.py 
 9120  [A
 9121  python make_caffe_network.py 
 9122  clear && clear
 9123  python make_caffe_network.py > atest.prototxt
 9124  python make_caffe_network.py 
 9125  python make_caffe_network.py > atest.prototxt
 9126  python make_caffe_network.py > prototxt/vo-v4-2-densenet-deconvBN-l1loss-dropout.prototxt
 9127  cd /data/sunnycia/saliency_on_videoset/Train/scripts/utils/vizutil
 9128  python visualization_weight.py 
 9129  cd ../..
 9130  python utils/visutil/visualization_weight.py 
 9131  python utils/vizutil/visualization_weight.py 
 9132  python utils/vizutil/visualization_weight.py --modelpath='/data/sunnycia/saliency_on_videoset/Train/training_output/salicon/vo-v4-2-densenet-l1loss-dropout-base_lr-0.0001-snapshot-4000-dense3d-new-28000-batch-2_1529397527/snapshot-_iter_20000.caffemodel' --deploypath='/data/sunnycia/saliency_on_videoset/Train/training_output/salicon/vo-v4-2-densenet-l1loss-dropout-base_lr-0.0001-snapshot-4000-dense3d-new-28000-batch-2_1529397527/vo-v4-2-densenet-l1loss-dropout.prototxt'
 9133  python utils/vizutil/visualization_weight.py --modelpath='/data/sunnycia/saliency_on_videoset/Train/training_output/salicon/vo-v4-2-densenet-l1loss-dropout-base_lr-0.0001-snapshot-4000-dense3d-new-28000-batch-2_1529397527/snapshot-_iter_20000.caffemodel' --deploypath='/data/sunnycia/saliency_on_videoset/Train/training_output/salicon/vo-v4-2-densenet-l1loss-dropout-base_lr-0.0001-snapshot-4000-dense3d-new-28000-batch-2_1529397527/vo-v4-2-densenet-l1loss-dropout.prototxt' --output_path='test.jpg'
 9134  python utils/vizutil/visualization_weight.py --modelpath='/data/sunnycia/saliency_on_videoset/Train/training_output/salicon/vo-v4-2-densenet-l1loss-dropout-base_lr-0.0001-snapshot-4000-dense3d-new-28000-batch-2_1529397527/snapshot-_iter_20000.caffemodel' --deploypath='/data/sunnycia/saliency_on_videoset/Train/training_output/salicon/vo-v4-2-densenet-l1loss-dropout-base_lr-0.0001-snapshot-4000-dense3d-new-28000-batch-2_1529397527/vo-v4-2-densenet-l1loss-dropout.prototxt' --outputpath='test.jpg'
 9135  python utils/vizutil/visualization_weight.py --modelpath='/data/sunnycia/saliency_on_videoset/Train/training_output/salicon/vo-v4-2-densenet-l1loss-dropout-base_lr-0.0001-snapshot-4000-dense3d-new-28000-batch-2_1529397527/snapshot-_iter_20000.caffemodel' --deploypath='/data/sunnycia/saliency_on_videoset/Train/training_output/salicon/vo-v4-2-densenet-l1loss-dropout-base_lr-0.0001-snapshot-4000-dense3d-new-28000-batch-2_1529397527/vo-v4-2-densenet-l1loss-dropout.prototxt' --outputpath='test.jpg' --type='3d'
 9136  python utils/vizutil/visualization_weight.py --type='3d' --modelpath='/data/sunnycia/saliency_on_videoset/Train/training_output/salicon/vo-v4-2-resnet-l1loss-dropout-base_lr-0.01-snapshot-4000-l1oss_dropout02_ledov_O8-batch-2_1529045198/snapshot-_iter_484000.caffemodel' --deploypath='/data/sunnycia/saliency_on_videoset/Train/training_output/salicon/vo-v4-2-resnet-l1loss-dropout-base_lr-0.01-snapshot-4000-l1oss_dropout02_ledov_O8-batch-2_1529045198/vo-v4-2-resnet-l1loss-deploy.prototxt' --outputpath='test2.jpg'
 9137  python utils/vizutil/visualization_weight.py --modelpath='/data/sunnycia/saliency_on_videoset/Train/training_output/salicon/vo-v4-2-densenet-l1loss-dropout-base_lr-0.0001-snapshot-4000-dense3d-new-28000-batch-2_1529397527/snapshot-_iter_20000.caffemodel' --deploypath='/data/sunnycia/saliency_on_videoset/Train/training_output/salicon/vo-v4-2-densenet-l1loss-dropout-base_lr-0.0001-snapshot-4000-dense3d-new-28000-batch-2_1529397527/vo-v4-2-densenet-l1loss-dropout.prototxt' --outputpath='test.jpg' --type='3d' --layer='predict'
 9138  python utils/vizutil/visualization_weight.py --modelpath='/data/sunnycia/saliency_on_videoset/Train/training_output/salicon/vo-v4-2-densenet-l1loss-dropout-base_lr-0.0001-snapshot-4000-dense3d-new-28000-batch-2_1529397527/snapshot-_iter_20000.caffemodel' --deploypath='/data/sunnycia/saliency_on_videoset/Train/training_output/salicon/vo-v4-2-densenet-l1loss-dropout-base_lr-0.0001-snapshot-4000-dense3d-new-28000-batch-2_1529397527/vo-v4-2-densenet-l1loss-dropout.prototxt' --outputpath='test.jpg' --type='3d' --layer='deconv1'
 9139  python utils/vizutil/visualization_weight.py --modelpath='/data/sunnycia/saliency_on_videoset/Train/training_output/salicon/vo-v4-2-densenet-l1loss-dropout-base_lr-0.0001-snapshot-4000-dense3d-new-28000-batch-2_1529397527/snapshot-_iter_20000.caffemodel' --deploypath='/data/sunnycia/saliency_on_videoset/Train/training_output/salicon/vo-v4-2-densenet-l1loss-dropout-base_lr-0.0001-snapshot-4000-dense3d-new-28000-batch-2_1529397527/vo-v4-2-densenet-l1loss-dropout.prototxt' --outputpath='test.jpg' --type='3d' --layer='deconv3'
 9140  python utils/vizutil/visualization_weight.py --modelpath='/data/sunnycia/saliency_on_videoset/Train/training_output/salicon/vo-v4-2-densenet-l1loss-dropout-base_lr-0.0001-snapshot-4000-dense3d-new-28000-batch-2_1529397527/snapshot-_iter_20000.caffemodel' --deploypath='/data/sunnycia/saliency_on_videoset/Train/training_output/salicon/vo-v4-2-densenet-l1loss-dropout-base_lr-0.0001-snapshot-4000-dense3d-new-28000-batch-2_1529397527/vo-v4-2-densenet-l1loss-dropout.prototxt' --outputpath='test.jpg' --type='3d' --layer='deconv2'
 9141  nvidia-smi
 9142  cd metric/
 9143  clear && clear
 9144  matlab -nodesktop -nodisplay
 9145  clear && clear
 9146  cd ..
 9147  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-resnet-BNdeconv-l1loss-dropout.prototxt' --use_model='../pretrained_model/c3d_resnet18_sports1m_r2_iter_2800000.caffemodel' --plotiter=200 --validiter=4000 --savemodeliter=4000 --trainingexampleprops=0.999 --trainingbase='ledov' --videolength=16 --overlap=12 --extramodinfo='resnet_addBN_2_deconv' --batch=2 --connection=1
 9148  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-resnet-BNdeconv-l1loss-dropout.prototxt' --use_model='../pretrained_model/c3d_resnet18_sports1m_r2_iter_2800000.caffemodel' --plotiter=200 --validiter=4000 --savemodeliter=4000 --trainingexampleprops=0.999 --trainingbase='ledov' --videolength=16 --overlap=12 --extramodinfo='resnet_addBN_2_deconv' --batch=2
 9149  clear && clear
 9150  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-resnet-BNdeconv-l1loss-dropout.prototxt' --use_model='../pretrained_model/c3d_resnet18_sports1m_r2_iter_2800000.caffemodel' --plotiter=200 --validiter=4000 --savemodeliter=4000 --trainingexampleprops=0.999 --trainingbase='ledov' --videolength=16 --overlap=12 --extramodinfo='resnet_addBN_2_deconv' --batch=2
 9151  clear && clear
 9152  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-resnet-BNdeconv-l1loss-dropout.prototxt' --use_model='../pretrained_model/c3d_resnet18_sports1m_r2_iter_2800000.caffemodel' --plotiter=200 --validiter=4000 --savemodeliter=4000 --trainingexampleprops=0.99 --trainingbase='ledov' --videolength=16 --overlap=12 --extramodinfo='resnet_addBN_2_deconv' --batch=2
 9153  clear && clear
 9154  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-resnet-BNdeconv-l1loss-dropout.prototxt' --use_model='../pretrained_model/c3d_resnet18_sports1m_r2_iter_2800000.caffemodel' --plotiter=200 --validiter=4000 --savemodeliter=4000 --trainingexampleprops=0.99 --trainingbase='ledov' --videolength=16 --overlap=12 --extramodinfo='resnet_addBN_2_deconv' --batch=2
 9155  cd pwd/saliency_on_videoset/
 9156  ls
 9157  cd Train
 9158  ls
 9159  cd metric
 9160  matlab -nodesktop -nodisplay
 9161  clear && clear
 9162  matlab -nodesktop -nodisplay
 9163  cd /data/sunnycia/saliency_on_videoset/Train/scripts
 9164  history > ../history
 9165  top
 9166  ls
 9167  cd /data/sunnycia/saliency_on_videoset/Train
 9168  ls
 9169  history > history
 9170  cd scripts/
 9171  source set_env.sh ../C3D-v1.1-tmp/ 7
 9172  nvidi-asmi
 9173  python test_video.py --model_base_dir='vo-v4-2-resnet-BNdeconv-l1loss-dropout-base_lr-0.01-snapshot-4000-resnet_addBN_2_deconv-batch-2_1529493349' --test_base='diem'
 9174  screen -S diem_inference
 9175  screen -l
 9176  screen -ls
 9177  screen -S diem_inference
 9178  screen -ls
 9179  screen -S diem_metric
 9180  screen -ls
 9181  df -h
 9182  top
 9183  cd metric/
 9184  matlab -nodesktop -nodisplay
 9185  screen -ls
 9186  source set_env.sh ../C3D-v1.1-tmp/ 7
 9187  python test_video.py --model_base_dir='vo-v4-2-resnet-BNdeconv-l1loss-dropout-base_lr-0.01-snapshot-4000-resnet_addBN_2_deconv-batch-2_1529493349' --test_base='diem'
 9188  cd /data/sunnycia/saliency_on_videoset/Train/scripts
 9189  source set_env.sh ../C3D-v1.1-tmp 7
 9190  python test_video.py -h
 9191  python test_video.py --test_base='videoset' --model_base_dir='vo-v4-2-resnet-BNdeconv-l1loss-dropout-base_lr-0.01-snapshot-4000-resnet_addBN_2_deconv-batch-2_1529493349' &&  python test_video.py --test_base='msu' --model_base_dir='vo-v4-2-resnet-BNdeconv-l1loss-dropout-base_lr-0.01-snapshot-4000-resnet_addBN_2_deconv-batch-2_1529493349'
 9192  cd /data/sunnycia/saliency_on_videoset/Train/scripts/metric
 9193  matlab -nodesktop -nodisplay
 9194  cd ../
 9195  ls
 9196  cd Train/scripts/metric/
 9197  matlab -nodesktop -nodisplay
 9198  top
 9199  cd/data/sunnycia/saliency_on_videoset/_Model 
 9200  cd /data/sunnycia/saliency_on_videoset/_Model 
 9201  python gen_saliency_Surprise.py --framebase='/data/SaliencyDataset/Video/MSU/frames' --outputbase='/data/SaliencyDataset/Video/MSU/saliency_map'
 9202  matlab -nodesktop -nodisplay
 9203  matlab -nodesktop -nodisplay
 9204  cd /data/sunnycia/saliency_on_videoset/_Model
 9205  matlab -nodesktop -nodisplay
 9206  pwd
 9207  matlab -nodesktop -nodisplay
 9208  top
 9209  clear
 9210  matlab -nodesktop -nodisplay
 9211  top
 9212  nvidia-smi
 9213  top
 9214  topq
 9215  top
 9216  screen -ls
 9217  top
 9218  nvidia-smi
 9219  top
 9220  screen -ls
 9221  scree -h
 9222  screen -h
 9223  scree -ls
 9224  screen -ls
 9225  screen -R diem_metric
 9226  top
 9227  screen -ls
 9228  screen -R diem_metric
 9229  screen -ls
 9230  top
 9231  screen -ls
 9232  screen -X -S diem_metric
 9233  screen -R diem_metric
 9234  screen -X -S diem_metric
 9235  screen -ls
 9236  screen -R diem_inference
 9237  screen -S hou_metric
 9238  cd /data/sunnycia/saliency_on_videoset/Train/scripts
 9239  cd metric/
 9240  ls
 9241  ls -t
 9242  ls metric_table.py 
 9243  python metric_table.py --videoset_name='diem' --first_line='metric'
 9244  screen -ls
 9245  screen -R hou_metric
 9246  screen -S bndeconv_test
 9247  screen -ls
 9248  screen -R hou_metric
 9249  top
 9250  nvidia-smi
 9251  top
 9252  clear && clear
 9253  top
 9254  screen -ls
 9255  top
 9256  screen -ls
 9257  screen -R bndeconv_metric
 9258  screen -ls
 9259  screen -R hou_metric
 9260  screen -r
 9261  screen -S surprise_msu
 9262  screen -ls
 9263  python metric_table.py -h
 9264  python metric_table --videoset_name=diem --first_line=metric
 9265  python metric_table.py --videoset_name=diem --first_line=metric
 9266  python metric_table.py --videoset_name=videoset --first_line=metric
 9267  python metric_table.py --videoset_name=msu --first_line=metric
 9268  python metric_table.py --videoset_name=videoset --first_line=metric
 9269  screen -ls
 9270  screen -S videoset_metric
 9271  screen -ls
 9272  screen -R videoset_metric
 9273  top
 9274  screen -S videoset_metric
 9275  screen -ls
 9276  screen -S msu_metric
 9277  screen -R videoset_metric
 9278  screen -R msu_metric
 9279  screen -ls
 9280  screen -r uw_msu
 9281  screen -r surprise_msu
 9282  top
 9283  clear && clear
 9284  top
 9285  nvidia-smi
 9286  top
 9287  screen -ls
 9288  top
 9289  python metric_table.py -h
 9290  python metric_table.py --videoset_name=videoset --first_line=metric
 9291  top
 9292  python metric_table.py --videoset_name=msu --first_line=metric
 9293  python metric_table.py --videoset_name=diem --first_line=metric
 9294  top
 9295  screen -ls
 9296  screen -r msu_metric
 9297  screen -ls
 9298  screen -r msu_metric
 9299  screen -ls
 9300  screen -r videoset_metric
 9301  python metric_table.py -h
 9302  python metric_table.py --videoset_name=msu --first_line=metric
 9303  top
 9304  screen -ls
 9305  screen -r uw_msu
 9306  screen -S uw_metric
 9307  top
 9308  screen -r
 9309  top
 9310  python metric_table.py -h
 9311  python metric_table.py --videoset_name=diem --first_line=model
 9312  python metric_table.py --videoset_name=msu --first_line=model
 9313  python metric_table.py --videoset_name=videoset --first_line=model
 9314  top
 9315  cd ..
 9316  python test_video.py -h
 9317  python test_video.py --test_base=videoset --overlap=0 --model_base_dir='vo-v4-2-resnet-BNdeconv-l1loss-dropout-base_lr-0.01-snapshot-4000-resnet_addBN_2_deconv-batch-2_1529493349'
 9318  source set_env.sh ../C3D-v1.1-tmp 7
 9319  clear && clear
 9320  python test_video.py --test_base=videoset --overlap=0 --model_base_dir='vo-v4-2-resnet-BNdeconv-l1loss-dropout-base_lr-0.01-snapshot-4000-resnet_addBN_2_deconv-batch-2_1529493349'
 9321  top 
 9322  top
 9323  clear && clear
 9324  top
 9325  screen -r
 9326  screen -r 0o_metric
 9327  cp -R /data/SaliencyDataset/Video/VideoSet/ImageSet/Seperate/frames/* /data/sunnycia/saliency_on_videoset/_Model/saliencysegment/VSG
 9328  cd /data/sunnycia/saliency_on_videoset/_Model/saliencysegment
 9329  python main.py 
 9330  export CUDA_VISIBLE_DEVICES=7
 9331  python main.py 
 9332  top
 9333  cd /data/sunnycia/video_compression/Train/scripts
 9334  source set_env.sh ../C3D-v1.1-tmp/ 6
 9335  nvidia-smi
 9336  clear && clear
 9337   python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-resnet-BNdeconv-l2loss-dropout.prototxt' --use_model='../pretrained_model/c3d_resnet18_sports1m_r2_iter_2800000.caffemodel' --plotiter=200 --validiter=4000 --savemodeliter=4000 --trainingexampleprops=0.99 --trainingbase='hollywood' --videolength=16 --overlap=8 --batch=2
 9338  clear && clear
 9339   python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-resnet-BNdeconv-l2loss-dropout.prototxt' --use_model='../pretrained_model/c3d_resnet18_sports1m_r2_iter_2800000.caffemodel' --plotiter=200 --validiter=4000 --savemodeliter=4000 --trainingexampleprops=0.99 --trainingbase='hollywood' --videolength=16 --overlap=8 --batch=2
 9340  cd /data/sunnycia/saliency_on_videoset/_Model/Rudoy
 9341  matlab -nodesktop -nodisplay
 9342  cd /data/sunnycia/saliency_on_videoset/_Model
 9343  ls
 9344  which('saliencyHouNips')
 9345  matlab -nodesktop -nodisplay
 9346  cd Hou/
 9347  python saliency.py 
 9348  top
 9349  nvidia-smi
 9350  python spectral_residual.py 
 9351  python saliency.py 
 9352  cd ../
 9353  python get_saliency_Hou.py --dataset='videoset' && python get_saliency_Hou.py --dataset='diem' && python get_saliency_Hou.py --dataset='savam'
 9354  clear && clear
 9355  python get_saliency_Hou.py --dataset='videoset' && python get_saliency_Hou.py --dataset='diem' && python get_saliency_Hou.py --dataset='savam'
 9356  top
 9357  nvidia-smi
 9358  screen -ls
 9359  screen -R bndeconv_test
 9360  screen -S bndeconv_metric
 9361  top
 9362  screen -ls
 9363  screen -R bndeconv_metric
 9364  top
 9365  top 
 9366  screen -ls
 9367  top
 9368  ls
 9369  screen -ls
 9370  top
 9371  screen -r
 9372  top
 9373  clear
 9374  cd /data/sunnycia/saliency_on_videoset/Train/scripts
 9375  cd metric/
 9376  python metric_table.py 
 9377  python metric_table.py --videoset_name=msu --first_list=metric
 9378  python metric_table.py --videoset_name=msu --first_line=metric
 9379  screen -ls
 9380  screen -S uw_msu
 9381  top
 9382  cd /data/sunnycia/saliency_on_videoset/Train/scripts/metric
 9383  python metric_table.py -h
 9384  python metric_table.py --videoset_name=msu --first_line=metric
 9385  top
 9386  screen -ls
 9387  top
 9388  nvidia-smi
 9389  top
 9390  screen -ls
 9391  screen -S 0o_metric
 9392  top
 9393  screen -r
 9394  screen -r 0o_metric
 9395  screen -r
 9396  screen -r uw_metric
 9397  top
 9398  nvidia-smi
 9399  top
 9400  cp -R /data/sunnycia/saliency_on_videoset/_Model/saliencysegment/VSG/dynamic_saliency/* /data/SaliencyDataset/Video/VideoSet/Results/saliency_map/Shen
 9401  screen -ls
 9402  screen -r
 9403  screen -S shen_metric
 9404  screen -r
 9405  top
 9406  clear && clear
 9407  top
 9408  screen -r
 9409  top
 9410  screen -r
 9411  cd /data/sunnycia/image_compression_challenge/_Train/xvc/
 9412  mkdir build
 9413  cd build/
 9414  cmake .. && make -j8
 9415  cmake
 9416  cd /data/sunnycia/video_compression/Train/scripts
 9417  pwd
 9418  history > history
 9419  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-resnet-BNdeconv-l1loss-dropout.prototxt' --use_model='../pretrained_model/c3d_resnet18_sports1m_r2_iter_2800000.caffemodel' --plotiter=200 --validiter=4000 --savemodeliter=4000 --trainingexampleprops=0.99 --trainingbase='ledov' --videolength=16 --overlap=12 --extramodinfo='resnet_addBN_2_deconv' --batch=2
 9420  source set_env.sh ../C3D-v1.1-tmp/ 7
 9421  nvidia-smi
 9422  top
 9423  source set_env.sh ../C3D-v1.1-tmp/ 7
 9424  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-resnet-BNdeconv-l1loss-dropout.prototxt' --use_model='../pretrained_model/c3d_resnet18_sports1m_r2_iter_2800000.caffemodel' --plotiter=200 --validiter=4000 --savemodeliter=4000 --trainingexampleprops=0.99 --trainingbase='ledov' --videolength=16 --overlap=8 --batch=2
 9425  clear && clear
 9426  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-resnet-BNdeconv-l1loss-dropout.prototxt' --use_model='../pretrained_model/c3d_resnet18_sports1m_r2_iter_2800000.caffemodel' --plotiter=200 --validiter=4000 --savemodeliter=4000 --trainingexampleprops=0.99 --trainingbase='ledov' --videolength=16 --overlap=8 --batch=2
 9427  clear && clear
 9428  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-resnet-BNdeconv-l1loss-dropout.prototxt' --use_model='../pretrained_model/c3d_resnet18_sports1m_r2_iter_2800000.caffemodel' --plotiter=200 --validiter=4000 --savemodeliter=4000 --trainingexampleprops=0.99 --trainingbase='ledov' --videolength=16 --overlap=8 --batch=2
 9429  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-resnet-BNdeconv-l1loss-dropout.prototxt' --use_model='../pretrained_model/c3d_resnet18_sports1m_r2_iter_2800000.caffemodel' --plotiter=200 --validiter=4000 --savemodeliter=4000 --trainingexampleprops=0.99 --trainingbase='hollywood' --videolength=16 --overlap=8 --batch=2
 9430  clear && clear
 9431  python training_video_voxel_based.py --train_prototxt='prototxt/vo-v4-2-resnet-BNdeconv-l1loss-dropout.prototxt' --use_model='../pretrained_model/c3d_resnet18_sports1m_r2_iter_2800000.caffemodel' --plotiter=200 --validiter=4000 --savemodeliter=4000 --trainingexampleprops=0.99 --trainingbase='hollywood' --videolength=16 --overlap=8 --batch=2
 9432  python test_video.py --video_deploy_path='/data/sunnycia/saliency_on_videoset/Train/training_output/salicon/vo-v4-2-densenet-l1loss-dropout-base_lr-0.01-snapshot-4000-dense3d_2-batch-2_1529279669/vo-v4-2-densenet-l1loss-dropout.prototxt' --video_model_path='../training_output/salicon/vo-v4-2-densenet-l1loss-dropout-base_lr-0.01-snapshot-4000-dense3d_2-batch-2_1529279669/snapshot-_iter_40000.caffemodel' --infertype='slide' --output_type='image' --test_base='videoset' --model_code='v4-2'
 9433  cd /data/sunnycia/video_compression/Train/scripts
 9434  source set_env.sh ../C3D-v1.1-tmp/ 6
 9435  nvidia-smi
 9436  python test_video.py -h
 9437  python test_video.py --model_base_dir='vo-v4-2-resnet-BNdeconv-l2loss-dropout-base_lr-0.01-snapshot-4000--batch-2_1530267105' --test_base='gazecom'
 9438  python test_video.py --model_base_dir='vo-v4-2-resnet-BNdeconv-l2loss-dropout-base_lr-0.01-snapshot-4000--batch-2_1530267105' --test_base='gazecom' --output_type=video
 9439  python test_video.py --model_base_dir='vo-v4-2-resnet-BNdeconv-l2loss-dropout-base_lr-0.01-snapshot-4000--batch-2_1530267105' --test_base='gazecom'
 9440  top
 9441  python test_video.py --model_base_dir='vo-v4-2-resnet-BNdeconv-l2loss-dropout-base_lr-0.01-snapshot-4000--batch-2_1530267105' --test_base='gazecom'
 9442  cd /data/sunnycia/saliency_on_videoset/Train/scripts
 9443  python test_video.py --model_base_dir='vo-v4-2-resnet-BNdeconv-l1loss-dropout-base_lr-0.01-snapshot-4000-resnet_addBN_2_deconv-batch-2_1529493349' --test_base='ledov'
 9444   cd metric/
 9445  clear && clear
 9446  matlab -nodesktop -nodisplay
 9447  cd /data/sunnycia/saliency_on_videoset/Train/scripts/utils/vizutil
 9448  python inference_comparison.py --output_path=vsg_.jpg --wildcards_record=vg_wildcards_record.txt
 9449  python inference_comparison.py --output_path=diem_.jpg --wildcards_record=diem_wildcards_record.txt
 9450  python gen_saliency_SALICON.py --gpu=7 --framebase='/data/SaliencyDataset/Video/ActionInTheEye/Hollywood2/frames' --outputbase='/data/SaliencyDataset/Video/ActionInTheEye/Hollywood2/saliency_map/salicon'
 9451  cd /data/sunnycia/saliency_on_videoset/_Model/mlnet-master
 9452  python main.py 
 9453  python
 9454  vim ~/.bashrc
 9455  source ~/.bashrc
 9456  python
 9457  vim ~/.keras/keras.json 
 9458  python
 9459  python main.py 
 9460  python main.py test sample_images/psb.jpg 
 9461  pip show kers
 9462  pip show keras
 9463  pip show opencv
 9464  pip show cv2
 9465  pip show opencv-python
 9466  vim ~/.keras/keras.json 
 9467  python main.py test sample_images/psb.jpg 
 9468  vim ~/.keras/keras.json 
 9469  python main.py test sample_images/psb.jpg 
 9470  vim ~/.keras/keras.json 
 9471  python main.py test sample_images/psb.jpg 
 9472  set "KERAS_BACKEND=theano"
 9473  python main.py test sample_images/psb.jpg 
 9474  set "KERAS_BACKEND=tensorflow"
 9475  python main.py test sample_images/psb.jpg 
 9476  python
 9477  rm -rf ~/.keras
 9478  python main.py test sample_images/psb.jpg 
 9479  export KERAS_BACKEND=tensorflow
 9480  export KERAS_BACKEND=theano
 9481  python main.py test sample_images/psb.jpg 
 9482  pip uninstall keras
 9483  pip install keras==2.0.0
 9484  pip install --upgrade pip
 9485  python main.py test sample_images/psb.jpg 
 9486  pip install keras==1.1.0
 9487  python main.py test sample_images/psb.jpg 
 9488  pip show theano
 9489  su
 9490  vim ~/.bashrc
 9491  source ~/.bashrc
 9492  cd /data/sunnycia/saliency_on_videoset/_Model
 9493  python gen_saliency_SALICON.py --gpu=7 --framebase='/data/SaliencyDataset/Video/ActionInTheEye/Hollywood2/frames' --outputbase='/data/SaliencyDataset/Video/ActionInTheEye/Hollywood2/saliency_map/salicon'
 9494  cd /data/sunnycia/saliency_on_videoset/_Model
 9495  python gen_saliency_Hou.py --dataset=hollywood
 9496  top
 9497   cd /data/sunnycia/saliency_on_videoset/_Model/SALICON
 9498  python
 9499  cd ..
 9500  unzip OpenSALICON-master.zip 
 9501  cd OpenSALICON-master/
 9502  python
 9503  top
 9504  nvidia-smi
 9505  top
 9506  python
 9507  cd ~/caffe-master/
 9508  ls
 9509  make clean
 9510  vim Makefile.config
 9511  make -j4 all && make pycaffe
 9512  gcc --version
 9513  cd /home/sunnycia
 9514  unizp nccl-master.zip 
 9515  unzip nccl-master.zip 
 9516  cd nccl-master/
 9517  su
 9518  cd ../caffe-master/
 9519  make clean
 9520  make -j8 all && make -j4 pycaffe
 9521  vim Makefile.config
 9522  make clean
 9523  make -j8 all && make -j4 pycaffe
 9524  cd /data/sunnycia/saliency_on_videoset/_Model/OpenSALICON-master
 9525  python
 9526  screen salicon_hollywood
 9527  screen -S salicon_hollywood
 9528  top
 9529  nvidia-smi
 9530  top
 9531  df -h
 9532  cd /data/sunnycia/saliency_on_videoset/_Model
 9533  unrar --help
 9534  unrar -h
 9535  unrar
 9536  unrar x ACL.rar 
 9537  cd ACL/
 9538  python main.py 
 9539  vim ~/.theanorc
 9540  python main.py 
 9541  vim ~/.theanorc
 9542  python main.py 
 9543  vim ~/.theanorc
 9544  python main.py 
 9545  vim ~/.theanorc
 9546  python main.py 
 9547  vim ~/.theanorc
 9548  python main.py 
 9549  python
 9550  git clone https://github.com/Theano/libgpuarray.git
 9551  cd libgpuarray
 9552  git checkout tags/v0.6.5 v0.7.5
 9553  git checkout tags/v0.6.5 v0.7.0
 9554  git checkout tags/v0.6.5 v0.6.9
 9555  git checkout tags/v0.6.5 tags/v0.7.5
 9556  git checkout tags/v0.6.5 -b v0.7.5
 9557  mkdir build
 9558  cd build/
 9559  cmake .. -DCMAKE_BUILD_TYPE=Release
 9560  yum info cmake
 9561  su
 9562  cmake .. -DCMAKE_BUILD_TYPE=Release
 9563  cmake
 9564  whereis cmake
 9565  usr
 9566  su
 9567  vim ~/.bashrc
 9568  vim ~/.pip/pip.conf
 9569  su
 9570  pip show keras
 9571  cd /data/sunnycia/saliency_on_videoset/_Model/mlnet-master
 9572  python main.py sample_images/psb.jpg 
 9573  vim ~/.keras/keras.json 
 9574  python main.py sample_images/psb.jpg 
 9575  python main.py test sample_images/psb.jpg 
 9576  python main.py test sample_images
 9577  python main.py test sample_images/
 9578  top
 9579  python main.py actioncliptrain00779/ actioncliptrain00779_sal
 9580  python main.py test actioncliptrain00779/ actioncliptrain00779_sal
 9581  nvidia-smi
 9582  su
 9583  python main.py test actioncliptrain00779/ actioncliptrain00779_sal
 9584  cd ..
 9585  python gen_saliency_mlnet.py --dataset=savam
 9586  screen -r
 9587  top
 9588  cd /data/SaliencyDataset/Video/DHF1K
 9589  cd /data/sunnycia/saliency_on_videoset/_Model
 9590  matlab -nodesktop -nodisplay
 9591  top
 9592  nvidia-smi
 9593  top
 9594  cd /data/sunnycia/saliency_on_videoset/_Model/ACL
 9595  top
 9596  nvidia-smi
 9597  python main.py --ds_name='diem' && python main.py ds_name='savam'
 9598  python main.py --ds_name='diem' && python main.py --ds_name='savam'
 9599  cd /data/sunnycia/saliency_on_videoset/_Model/ACL
 9600  python main.py --ds_name='hollywood' 
 9601  vim ~/.bashrc
 9602  top
 9603  nvidia-smi
 9604  cd /data/sunnycia/saliency_on_videoset/_Model/ACL
 9605  python main.py --ds_name='dhf1k'
 9606  cd ..
 9607  cd /data/sunnycia/
 9608  ls
 9609  mkdir openEXR
 9610  ls
 9611  cd openEXR
 9612  wget http://download.savannah.gnu.org/releases/openexr/pyilmbase-2.2.1.tar.gz
 9613  tar -xf openexr-2.2.1.tar.gz 
 9614  tar -xf openexr_viewers-2.2.1.tar.gz 
 9615  tar -xf ilmbase-2.2.1.tar.gz 
 9616  tar -xf pyilmbase-2.2.1.tar.gz 
 9617  cd openexr_viewers-2.2.1/
 9618  ./configure
 9619  cd ..
 9620  ls
 9621  cd openexr
 9622  cd openexr-2.2.1/
 9623  ./configure
 9624  ./configure --help
 9625  cd ..
 9626  cd ilmbase-2.2.1/
 9627  ./config
 9628  ./configure
 9629  make -j4
 9630  su
 9631  cd ../openexr-2.2.1/
 9632  ./configure
 9633  make -j4
 9634  su
 9635  cd ../openexr_viewers-2.2.1/
 9636  ./configure
 9637  make -j4 
 9638  su
 9639  cd ..
 9640  tar xf openexr-images-master.zip 
 9641  unzip openexr-images-master.zip 
 9642  exrdisplay
 9643  exrdisplay./
 9644  ./exrdisplay
 9645  cd openexr_viewers-2.2.1/
 9646  cd playexr/
 9647  ls
 9648  make -j4
 9649  make
 9650  cd ..
 9651  make clean
 9652  ./configure
 9653   top
 9654  vim ~/.pip/pip.conf 
 9655  top
 9656  cd /data/sunnycia/saliency_on_videoset/Train/scripts/metric
 9657  matlab -nodesktop -nodisplay
 9658  su
 9659  python
 9660  top
 9661  python
 9662  pip2 show tensorflow
 9663  pip2 show tensorflow-gpu
 9664  pip install --upgrade tensorflow-gpu
 9665  su
 9666  top
 9667  python
 9668  top
 9669  nvidia-smi
 9670  top
 9671  nvidia-smi
 9672  top
 9673  nvidia-smi
 9674  top
 9675  vim ~/.theanorc
 9676  rm  ~/.theanorc
 9677  python
 9678  pip show theeano
 9679  pip show theano
 9680  python main.py test sample_images/psb.jpg 
 9681  top
 9682  nvidia-smi
 9683  top
 9684  screen -S hollywood_salicon
 9685  top
 9686  clear
 9687  cd /data/sunnycia/saliency_on_videoset/Train
 9688  cd scripts/metric/
 9689  matlab -nodesktop -nodisplay
 9690  vim ~/.bashrc
 9691  screen -R
 9692  top
 9693  vim ~/.bashrc
 9694  cd /data/sunnycia/saliency_on_videoset/_Model
 9695  python gen_saliency_SALICON.py --gpu=2
 9696  nvidia-smi
 9697  python gen_saliency_SALICON.py --gpu=1 --framebase='/data/SaliencyDataset/Video/DHF1K/frames' --outputbase='/data/SaliencyDataset/Video/DHF1K/saliency_map/salicon'
 9698  ls
 9699  clear
 9700  cd ACL/
 9701  ls
 9702  python main.py
 9703  clear
 9704  python main.py 
 9705  python gen_saliency_ACL.py --ds_name='videoset'
 9706  python main.py --ds_name='videoset'
 9707  clear && clear
 9708  python main.py --ds_name='videoset'
 9709  top
 9710  screen -ls
 9711  top
 9712  cd /data/sunnycia/saliency_on_videoset/_Model
 9713  matlab -nodesktop -nodisplay 
 9714  cd /data/sunnycia/saliency_on_videoset/_Model
 9715  screen -S hollywood_salicon
 9716  python gen_saliency_SALICON.py --gpu=7 --framebase='/data/SaliencyDataset/Video/ActionInTheEye/Hollywood2/frames' --outputbase='/data/SaliencyDataset/Video/ActionInTheEye/Hollywood2/saliency_map/salicon'
 9717  python gen_saliency_Surprise.py --framebase='/data/SaliencyDataset/Video/ActionInTheEye/Hollywood2/frames' --outputbase='/data/SaliencyDataset/Video/ActionInTheEye/Hollywood2/saliency_map'
 9718  nvidia-smi
 9719  wget
 9720  ls
 9721  cd /data/sunnycia/
 9722  ls
 9723  cd /data/SaliencyDataset/
 9724  ls
 9725  cd Video
 9726  wget -P ETHyma  ftp://ftp.ivc.polytech.univ-nantes.fr/ETHyma/
 9727  top
 9728  nvidia-smi
 9729  top
 9730  nvidia-smi
 9731  top
 9732  nvidia-smi
 9733  cd /data/sunnycia/saliency_on_videoset/Train/scripts/utils/dsutil
 9734  cd -
 9735  pwd
 9736  cd -
 9737  python slice_frames.py --videobase='' --outputbase='' 
 9738  vim ~/.bashrc
 9739  vim ~/.pip/pip.conf 
 9740  python slice_frames.py --videobase='/data/SaliencyDataset/Video/DHF1K/video' --outputbase='/data/SaliencyDataset/Video/DHF1K/frames' 
 9741  top
 9742  nvidia-smi
 9743  cd -
 9744  pwd
 9745  cd -
 9746  cd /data/sunnycia/saliency_on_videoset/_Model
 9747  python gen_saliency_ACL.py --ds_name=videoset
 9748  cd ACL/
 9749  python main.py 
 9750  cd /data/SaliencyDataset/Video/VideoSet/ImageSet/Seperate/frames
 9751  python
 9752  cd /data/sunnycia/saliency_on_videoset/_Model
 9753  python gen_saliency_Surprise.py --framebase='/data/SaliencyDataset/Video/DHF1K/frames' --outputbase='/data/SaliencyDataset/Video/DHF1K/saliency_map'
 9754  top
 9755  cd /data/sunnycia/saliency_on_videoset/_Model/ACL/libgpuarray/build
 9756  cmake .. -DCMAKE_BUILD_TYPE=Release
 9757  make -j4
 9758  su
 9759  make -j4
 9760  su
 9761  python 
 9762  python
 9763  ls -la /usr/lib64/python2.7/site-packages/pygpu-0.6.5-py2.7-linux-x86_64.egg/pygpu/__init__.pyc 
 9764  cd ..
 9765  ls
 9766  pip uninstall pygpu
 9767  git checkout tags/v0.6.5 -b v0.7.5
 9768  git checkout tags/v0.6.5 -b v0.7.0
 9769  make clean
 9770  cd build/
 9771  cmake .. -DCMAKE_BUILD_TYPE=Release
 9772  make -j4
 9773  su
 9774  pwd
 9775  python
 9776  pip uninstall theano
 9777  pipw uninstall theano
 9778  pip2 uninstall theano
 9779  vim ~/.theanorc 
 9780  python
 9781  cd ..
 9782  vim test_gpu.py
 9783  python test_gpu.py 
 9784  vim ~/.theanorc
 9785  python test_gpu.py 
 9786  pip  uninstall theano
 9787  su
 9788  sudo pip uninstall theano
 9789  sudo pip install theano=0.9.0
 9790  sudo pip install theano==0.9.0
 9791  sudo pip install theano==0.9.1
 9792  sudo pip install theano==0.9
 9793  sudo pip install Theano==0.9.0
 9794  vim ~/.bashrc
 9795  pip install Theano
 9796  pip2 install Theano
 9797  sudo pip2 install Theano
 9798  su
 9799  mkdir ~/.pip
 9800  vim ~/.pip/pip.conf
 9801  sudo pip2 install Theano
 9802  su
 9803  vim ~/.theanorc 
 9804  python
 9805  python main.py 
 9806  cd /data/SaliencyDataset/Video/DHF1K/
 9807  unrar x annotation.rar 
 9808  df -h
 9809  unrar
 9810  unrar x video.rar 
 9811  ls
 9812  matlab -nodesktop -nodisplay
 9813  numFrames
 9814  python convert_annotation_format.py 
 9815  ls
 9816  python rename.py 
 9817  top
 9818  nvidia-smi
 9819  cd /data/sunnycia/saliency_on_videoset/Train/scripts/utils/vizutil
 9820  history > history
 9821  python transition_comparison.py --output_path='vsg_transition.jpg' --wildcards_record='vg_wildcards_record.txt'
 9822  clear && clear
 9823  cd /data/SaliencyDataset/Video/DHF1K
 9824  python rename.py 
 9825  top
 9826  cd /data/sunnycia/saliency_on_videoset/Train/scripts
 9827  cd ../../_Model/
 9828  ls
 9829  matlab -nodesktop -nodisplay
 9830  cd /data/sunnycia/saliency_on_videoset/Train/scripts
 9831  source set_env.sh ../C3D-v1.1-tmp/ 6
 9832  python test_video.py -h
 9833  python test_video.py --model_base_dir='vo-v4-2-resnet-BNdeconv-l1loss-dropout-base_lr-0.01-snapshot-4000-resnet_addBN_2_deconv-batch-2_1529493349' --test_base='hollywood' 
 9834  ssh wangxu@172.31.70.212
 9835  locate vgg16.pkl
 9836  locate gen_modelWeights0090.mpz
 9837  locate gen_modelWeights0090.npz
 9838  cd /data/sunnycia/saliency_on_videoset/_Model/deepattention/models
 9839  unzip model-20180707T071235Z-001.zip 
 9840  cd /data/sunnycia/saliency_on_videoset/_Model/deepattention
 9841  matlab -nodesktop -nodisplay
 9842  ccd external/
 9843  cd external/
 9844  unrar -h
 9845  unrar -help
 9846  unrar --help
 9847  unrar
 9848  unrar x caffe.rar 
 9849  cd cafe
 9850  cd caffe
 9851  make -j8 all
 9852  make matcaffe
 9853  matlab -nodesktop -nodisplay
 9854  make matcaffe
 9855  ls /bin/sh: /usr/local/MATLAB/R2014a/bin/
 9856  ls /usr/local/MATLAB/R2014a/bin/
 9857  vim Makefile.config
 9858  make clean
 9859  make -j8 all && make matcaffe
 9860  nvidia-smi
 9861  top
 9862  cd /data/sunnycia/saliency_on_videoset/_Model
 9863  matlab -nodesktop -nodisplay
 9864  cd ../Train/scripts/
 9865  python test_video.py --help
 9866  python test_video.py --model_base_dir='vo-v4-2-resnet-BNdeconv-l1loss-dropout-base_lr-0.01-snapshot-4000-resnet_addBN_2_deconv-batch-2_1529493349' --test_base='dhf'
 9867  source set_env.sh ../C3D-v1.1-tmp/ 7
 9868  nvidia-smi
 9869  clear && clear
 9870  python test_video.py --model_base_dir='vo-v4-2-resnet-BNdeconv-l1loss-dropout-base_lr-0.01-snapshot-4000-resnet_addBN_2_deconv-batch-2_1529493349' --test_base='dhf'
 9871  df -h
 9872  ls
 9873  top
 9874  clear && clear
 9875  cd /data/sunnycia/saliency_on_videoset/_Train/OMCNN_2CLSTM
 9876  python test.py --videodir='/data/SaliencyDataset/Video/DHF1K/videos' --outputdir='/data/SaliencyDataset/Video/DHF1K/saliency_map' --outputtype=image
 9877  nvidia-smi
 9878  export CUDA_VISIBLE_DEVICES=7
 9879  python test.py --videodir='/data/SaliencyDataset/Video/DHF1K/videos' --outputdir='/data/SaliencyDataset/Video/DHF1K/saliency_map' --outputtype=image
 9880  python -e
 9881  python -c 'import tensorflow as tf;print tf.__file__'
 9882  cd ~
 9883  python -c 'import tensorflow as tf;print tf.__file__'
 9884  cd -
 9885  cd ../..
 9886  ls
 9887  cd Train/metric
 9888  matlab -nodesktop -nodispaly
 9889  top
 9890  cd /data/sunnycia/saliency_on_videoset/Train/scripts/metric
 9891  matlab -nodesktop -nodisplay
 9892  cd /data/sunnycia/saliency_on_videoset/_Model
 9893  python gen_saliency_Hou.py --dataset=dhf
 9894  top
 9895  cd /data/sunnycia/saliency_on_videoset/Train/scripts/utils/dsutil
 9896  python spatial_temporal_complexity.py 
 9897  python compute_spatial_temporal_complexity.py 
 9898  python compute_spatial_temporal_complexity.py  --dsname=videoset
 9899  python compute_spatial_temporal_complexity.py  --ds_name=videoset
 9900  python
 9901  python compute_spatial_temporal_complexity.py  --ds_name=videoset && python compute_spatial_temporal_complexity.py  --ds_name=savam && python compute_spatial_temporal_complexity.py  --ds_name=ledov && python compute_spatial_temporal_complexity.py  --ds_name=diem
 9902  python compute_spatial_temporal_complexity.py  --ds_name=gazecom
 9903  cd /data/sunnycia/saliency_on_videoset/_Train/OMCNN_2CLSTM
 9904  top
 9905  export CUDA_VISIBLE_DEVICES=7
 9906  nvidia-smi
 9907  python test.py --videodir='/data/SaliencyDataset/Video/ActionInTheEye/Hollywood2/Hollywood2-actions/AVIClips' --outputdir='/data/SaliencyDataset/Video/ActionInTheEye/Hollywood2/saliency_map' --outputtype='image'
 9908  python test.py --videodir='/data/SaliencyDataset/Video/ActionInTheEye/Hollywood2/Hollywood2-actions/AVIClips' --outputdir='/data/SaliencyDataset/Video/ActionInTheEye/Hollywood2/saliency_map/omcnn_lstm' --outputtype='image'
 9909  top
 9910  whereis matlab
 9911  top
 9912  clear
 9913  cd /data/sunnycia/saliency_on_videoset/_Model
 9914  matlab -nodesktop -nodisplay
 9915  df -h
 9916  su
 9917  clear
 9918  cd /data/sunnycia/saliency_on_videoset/Train/scripts/metric/
 9919  matlab -nodesktop
 9920  matlab -nodesktop -nodisplay
 9921  top
 9922  vim ~/.bashrc
 9923  cd /data/sunnycia/saliency_on_videoset/_Model
 9924  python gen_saliency_SALICON.py --gpu=0 --framebase='/data/SaliencyDataset/Video/ActionInTheEye/Hollywood2/frames' --outputbase='/data/SaliencyDataset/Video/ActionInTheEye/Hollywood2/saliency_map/salicon'
 9925  screen -ls
 9926  vim ~/.bashrc
 9927  env
 9928  ls /usr/local
 9929  ls -a /usr/local
 9930  ls -l /usr/local
 9931  top
 9932  nvidia-smi
 9933  ls /home
 9934  su
 9935  ssh lishikai@172.31.234.205
 9936  cd pwd/
 9937  ls
 9938  git clone https://github.com/charlesq34/pointnet2.git
 9939  unzip pointnet2-master.zip 
 9940  cd pointnet2-master/
 9941  ls
 9942  cd tf_ops/3d_interpolation/
 9943  ls
 9944  bash tf_interpolate_compile.sh 
 9945  TF_INC=$(python -c 'import tensorflow as tf; print(tf.sysconfig.get_include())')
 9946          TF_INC=$(python -c 'import tensorflow as tf; print(tf.sysconfig.get_include())')
 9947  TF_INC
 9948  $TF_INC
 9949          TF_LIB=$(python -c 'import tensorflow as tf; print(tf.sysconfig.get_lib())')
 9950  bash tf_interpolate_compile.sh 
 9951  cd /data/sunnycia/saliency_on_videoset/Train/scripts
 9952  cd metric/
 9953  ls
 9954  matlab -nodesktop -nodisplay
 9955  cd ~/pwd/
 9956  unzip HDR_Toolbox-master.zip 
 9957  cd HDR_Toolbox-master/
 9958  ls
 9959  matlab -nodesktop -nodisplay
 9960  th
 9961  whereis th
 9962  cd  /usr/local/torch/
 9963  cd install/share/lua/5.1/hdf5
 9964  ls
 9965  ls -la
 9966  su
 9967  cd /data/sunnycia
 9968  ls
 9969  cd pwd/
 9970  ls
 9971  cd ..
 9972  mkdir hdr_works
 9973  cd hdr_works/
 9974  ls
 9975  git clone https://github.com/gabrieleilertsen/hdrcnn.git
 9976  cd ~
 9977  ls
 9978  cd cvpr_paperlist_10years/
 9979  ls
 9980  python paper_list
 9981  python paper_list.py 
 9982  python
 9983  python paper_list.py 
 9984  otpq
 9985  top
 9986  cd /data/sunnycia/hdr_works
 9987  unzip DrTMO.zip 
 9988  cd DrTMO/
 9989  ls
 9990  python main.py 
 9991  pip install piexif
 9992  su
 9993  python main.py 
 9994  python
 9995  su
 9996  python main.py 
 9997  cd /data/sunnycia/hdr_works/DrTMO
 9998  python main.py 
 9999  su
10000  python main.py 
10001  cd models/
10002  unzip models.zip 
10003  cd -
10004  python  main.py 
10005  python
10006  pip show chainer
10007  pip2 show chainer
10008  su
10009  python main.py 
10010  python main.py -gpu=0,1
10011  python
10012  cd /data/sunnycia/hdr_works/Nima
10013  unzip SIGGRAPH17_HDR_Code_v1.0.zip 
10014  unzip SIGGRAPH17_HDR_Testset.zip 
10015  unzip SIGGRAPH17_HDR_Trainingset.zip 
10016  cd ..
10017  git clone https://github.com/gabrieleilertsen/hdrcnn.git
10018  ls
10019  su
10020  ls ~/.gitconfig 
10021  vim ~/.gitconfig 
10022  unzip hdrcnn-master.zip 
10023  top
10024  nvidia-smi
10025  cd /data/sunnycia/hdr_works/hdr-expandnet
10026  unzip hdr-expandnet-master.zip 
10027  cd ..
10028  unzip hdr*zip
10029  cd hdr-expandnet-master
10030  python expand.py 
10031  python expand.py  assets/examples.jpg 
10032  python expand.py  641.jpg 
10033  top
10034  df -h
10035  mex
10036  mex -setup
10037  cd /data/sunnycia/hdr_works/toolbox
10038  unzip colour-hdri-develop.zip 
10039  unzip hydra-master.zip 
10040  unzip HdrHistogram_py-master.zip 
10041  python
10042  cd hydra-master/
10043  python setup.py 
10044  python setup.py --install
10045  python setup.py --help
10046  python setup.py build
10047  python setup.py install
10048  su
10049  cd examples/
10050  ls
10051  python tone_mapping.py 
10052  python
10053  ls /usr/lib/python2.7/site-packages/hydra/
10054  cd ..
10055  python setup.py build
10056  su
10057  cd examples/
10058  python tone_mapping.py 
10059  ls
10060  python ldr_to_hdr.py 
10061  python inv_tmo.py 
10062  python bilateral_filter.py 
10063  python load_and_save.py 
10064  cd /data/sunnycia/hdr_works/toolbox/colour-hdri-develop
10065  cd ..
10066  unzip oiio-master.zip 
10067  cd oiio-master/
10068  ls
10069  mkdir build
10070  cd build/
10071  cmake ..
10072  make install
10073  make -j8 install
10074  su
10075  cd ../../colour-hdri-develop/
10076  ls
10077  python setup.py 
10078  python setup.py --help
10079  python setup.py build
10080  su
10081  cd colour_hdri/examples/
10082  ls
10083  python examples_absolute_luminance_calibration.ipynb 
10084  ipython examples_absolute_luminance_calibration.ipynb 
10085  ipython nbconvert notebook.ipynb --to script
10086  ipython nbconvert examples_absolute_luminance_calibration.ipynb --to script
10087  ls
10088  pwd
10089  python examples_absolute_luminance_calibration.py
10090  cd 
10091  cd /data/sunnycia/hdr_works/toolbox
10092  unzip image_difference-master.zip 
10093  cd image_difference-master/
10094  ls
10095  python image_difference.py img/image1.png img/image2.png 
10096  su
10097  python image_difference.py img/image1.png img/image2.png 
10098  su
10099  python image_difference.py img/image1.png img/image2.png 
10100  su
10101  cd /data/sunnycia/hdr_works/dataset/nvidia_sample_images
10102  python i
10103  python 
10104  python read_exr_script.py kite2.exr 
10105  python read_exr_script.py kite2.exr hey
10106  python read_exr_script.py kite2.exr hey.jpg
10107  python read_exr_script.py kite2.exr hey.png
10108  python read_exr_script.py kite2.exr hey.bmp
10109  python read_exr_script.py kite2.exr hey.exr
10110  python read_exr_script.py kite1.exr hey.exr
10111  cd /data/sunnycia/hdr_works
10112  cd crack/
10113  ls
10114  unzip Ob3vil1on-master.zip 
10115  cd Ob3vil1on-master/
10116  ls
10117  python Obevilion.py ../dummy.7z 
10118  su
10119  python Obevilion.py ../dummy.7z 
10120  su
10121  python Obevilion.py ../dummy.7z 
10122  su
10123  python Obevilion.py ../dummy.7z 
10124  ls /usr/bin/7z
10125  7z
10126  p7zip
10127  python Obevilion.py ../dummy.7z 
10128  cd /data/sunnycia/hdr_works/crack/Ob3vil1on-master
10129  python Obevilion.py ../dummy.7z 
10130  7z
10131  su
10132  python Obevilion.py ../dummy.7z 
10133  python Obevilion.py --help
10134  pytho Obevilion.py --easy_mode
10135  python Obevilion.py --easy_mode
10136  python Obevilion.py --help
10137  python Obevilion.py --cli ../dummy.7z 
10138  python Obevilion.py --easy_mode
10139  python Obevilion.py --cli -b /path/to/archive.zip
10140  python Obevilion.py --cli -b ../dummy.7z 
10141  cd ../..
10142  ls
10143  rm -rf crack/
10144  cd /data/sunnycia/hdr_works/reference_source_code
10145  unzip lbvs-hdr-master.zip 
10146  python
10147  ls /home/zhangpp/
10148  ssh zhangpp@172.31.234.205
10149  vim ~/.bashrc
10150  cd /data/sunnycia/hdr_works/source_code 
10151  > read_hdr_test.py
10152  python
10153  su
10154  python
10155  ls
10156  python read_hdr_test.py 
10157  su
10158  git clone https://github.com/SemanticsOS/smc.freeimage.git
10159  cd smc.freeimage/
10160  su
10161  git clone https://github.com/mm2/Little-CMS.git
10162  cd Little-CMS/
10163  su
10164  python
10165  top
10166  nvidia-smi
10167  top
10168  cd /data/sunnycia/saliency_on_videoset/Train/scripts/metric
10169  matlab -nodesktop -nodisplay
10170  cd /data/sunnycia/saliency_on_videoset/_Model
10171  matlab -nodesktop -nodisplay
10172  cd /data/sunnycia/saliency_on_videoset/_Model && matlab -nodesktop -nodisplay
10173  cd /data/sunnycia/hdr_works/source_code
10174  python
10175  cd /data/SaliencyDataset/Image/HDREYE/images/HDR
10176  python
10177  ssh wenxuanzheng@172.31.234.205
10178  su
10179  ssh wenxuanzheng@172.31.234.248
10180  ls /home
10181  su
10182  cd /data/SaliencyDataset/Image/HDREYE
10183  python convert_img_fmt.py 
10184  cd /data/sunnycia/saliency_on_videoset/_Model
10185  matlab -nodesktop -nodisplay
10186  cd /data/sunnycia/saliency_on_videoset/_Model
10187  python gen_saliency_SALICON.py --help
10188  nvidia-smi
10189  python gen_saliency_SALICON.py --help
10190  python gen_saliency_SALICON.py --gpu=7 --framebase='/data/SaliencyDataset/Image/HDREYE/images/HDR' --outputbase='/data/SaliencyDataset/Image/HDREYE/saliency_map/HDR'
10191  python gen_saliency_SALICON.py --gpu=7 --framebase='/data/SaliencyDataset/Image/HDREYE/images/HDR' --outputbase='/data/SaliencyDataset/Image/HDREYE/saliency_map/HDR/salicon'
10192  matlab -nodesktop -nodisplay
10193  cd /data/sunnycia/saliency_on_videoset/_Model
10194  matlab -nodesktop -nodisplay
10195  cd /data/SaliencyDataset/Image/HDREYE
10196  python gen_fix_imgs.py 
10197  python rename.py /data/SaliencyDataset/Image/HDREYE/fixation_map/HDR
10198  python rename.py /data/SaliencyDataset/Image/HDREYE/fixation_map/LDR
10199  python rename.py /data/SaliencyDataset/Image/HDREYE/saliency_map/salicon/HDR
10200  python rename.py /data/SaliencyDataset/Image/HDREYE/images/HDR
10201  python rename.py /data/SaliencyDataset/Image/HDREYE/images/LDR
10202  python rename.py /data/SaliencyDataset/Image/HDREYE/density_map/HDR
10203  python rename.py /data/SaliencyDataset/Image/HDREYE/density_map/LdR
10204  python rename.py /data/SaliencyDataset/Image/HDREYE/density_map/LDR
10205  cd /data/sunnycia/saliency_on_videoset/Train/scripts
10206  python test_image.py --modelpath='../training_output/salicon/train_kldloss-base_lr-0.0001-weight_decay-0.000005-momentum-0.95-batch-8_1513602632_usesnapshot_1509584263_snapshot-_iter_100000/snapshot-_iter_200000.caffemodel' --testset='hdreye'
10207  python test_image.py --modelpath='../training_output/salicon/train_kldloss-base_lr-0.0001-weight_decay-0.000005-momentum-0.95-batch-8_1513602632_usesnapshot_1509584263_snapshot-_iter_100000/snapshot-_iter_300000.caffemodel' --testset='hdreye'
10208  top
10209  vim ~/.bashrc
10210  cd /data/SaliencyDataset/Image/HDREYE
10211  python padding_img.py 
10212  cd /data/sunnycia/saliency_on_videoset/_Model
10213  matlab -nodesktop -nodisplay
10214  cd /data/sunnycia/hdr_works/reference_source_code/Hdr display
10215  cd /data/sunnycia/hdr_works/reference_source_code/Hdr_display
10216  git clone https://github.com/shaderjp/HDRImageViewer.git
10217  python
10218  pip show gi
10219  pip2 show gi
10220  unzip HDR-10bpp-Display-Test-master.zip 
10221  cd HDR-10bpp-Display-Test-master/
10222  ls
10223  python Viewer.py 
10224  pip show cairo
10225  pip2 show cairo
10226  python
10227  nvidia-smi
10228  python Viewer.py 
10229  python
10230  pip install cario==1.12
10231  pip install pycario
10232  pip2 install pycario
10233  pip isntall --upgrade pip
10234  pip install --upgrade pip
10235  su
10236  pip install --upgrade pip --user
10237  pip install pycairo
10238  pip install pycairo==1.12 --user
10239  pip2 install pycairo==1.12 --user
10240  python
10241  python Viewer.py 
10242  cd /data/sunnycia/hdr_works/toolbox/HDR_Toolbox-master
10243  su
10244  matlab -nodesktop -nodisplay
10245  top
10246  cd /data/sunnycia/hdr_works/reference_source_code/Hdr_display/HDR-10bpp-Display-Test-master
10247  python Viewer.py 
10248  cd /data/sunnycia/hdr_works/reference_source_code/Hdr_display/HDR-10bpp-Display-Test-master
10249  python Viewer.py 
10250  cd /data/sunnycia/hdr_works/reference_source_code/Hdr_display
10251  unzip HDRImageViewer-master.zip 
10252  cd HDRImageViewer-master/
10253  ls
10254  cd ..
10255  rm -rf HDRImageViewer-master
10256  git clone --recursive https://github.com/shaderjp/HDRImageViewer.git
10257  virtualenv
10258  pip install virtualenv
10259  pip2 install virtualenv
10260  su
10261  virtualenv --python=python3 myvenv
10262  source myvenv/bin/activate
10263  pip install pygobject
10264  ls
10265  vim hello.py
10266  python hello.py 
10267  cd /data/sunnycia/hdr_works/reference_source_code/Hdr_display/HDR-10bpp-Display-Test-master
10268  python Viewer.py 
10269  cd /data/sunnycia/saliency_on_videoset/_Model
10270  python gen_saliency_SALICON.py --gpu=7 --framebase='/data/SaliencyDataset/Image/HDREYE/images/LDR-JPG' --outputbase='/data/SaliencyDataset/Image/HDREYE/saliency_map/salicon'
10271  history
10272  cd /data/sunnycia/saliency_on_videoset/Train/scripts
10273  python test_image.py --modelpath='../training_output/salicon/train_kldloss-base_lr-0.0001-weight_decay-0.000005-momentum-0.95-batch-8_1513602632_usesnapshot_1509584263_snapshot-_iter_100000/snapshot-_iter_200000.caffemodel' --testset='hdreye-ldr'
10274  python test_image.py --modelpath='../training_output/salicon/train_kldloss-base_lr-0.0001-weight_decay-0.000005-momentum-0.95-batch-8_1513602632_usesnapshot_1509584263_snapshot-_iter_100000/snapshot-_iter_300000.caffemodel' --testset='hdreye-ldr'
10275  cd /data/SaliencyDataset/Image/HDREYE/images/HDR
10276  python
10277  cd /data/sunnycia/saliency_on_videoset/Train/scripts/metric
10278  matlab -nodesktop -nodisplay
10279  ssh qiudan@172.31.234.191
10280  ssh sunzhenhao@172.31.234.191
10281  ssh qiudan@172.31.234.191
10282  ssh sunzhenhao@172.31.234.191
10283  ssh qiudan@172.31.234.191
10284  python
10285  cd /data/sunnycia/hdr_works/reference_source_code
10286  unzip HDR_Toolbox-master.zip 
10287  cd /data/sunnycia/hdr_works/source_code
10288  matlab -nodesktop -nodisplay
10289  su
10290  vim ~/.bashrc
10291  df -h
10292  cd /data/sunnycia/hdr_works/source_code/show_demo/HDR-DEMO
10293  python application_demo.py 
10294  source ~/pyg_venv/bin/activate
10295  python application_demo.py 
10296  python
10297  python application_demo.py 
10298  df -h
10299  python main.py 
10300  cd ../../hdr_saliency/
10301  python io_utils.py 
10302  deactivate
10303  python io_utils.py 
10304  python
10305  top
10306  python
10307  ls -la /usr/local
10308  su
10309  vim ~/.bashrc
10310  pip show tensorflow
10311  python
10312  vim ~/.bashrc
10313  source ~/.bashrc
10314  python
10315  source ~/.bashrc
10316  cd /data/sunnycia/saliency_on_videoset/_Model
10317  matlab
10318  top
10319  nvidia-smi
10320  top
10321  cd /data/sunnycia/hdr_works/source_code/hdr_saliency/training
10322  git clone https://github.com/NUS-VIP/salicon-evaluation.git
10323  python
10324  git clone https://github.com/BVLC/caffe.git
10325  cd caffe/
10326  ls
10327  cp Makefile.config.example Makefile.config
10328  vim Makefile.config
10329  make -j8 all && make -j4 pycaffe
10330  cd ..
10331  python train.py 
10332  su
10333  cd 8), theano (0.9.0)  *
10334  *                              
10335  cd /data/sunnycia/hdr_works/source_code/hdr_saliency/training
10336  python train.py 
10337  vim ~/.bashrc
10338  source /etc/profile
10339  python train.py 
10340  su
10341   cd -
10342  cd /data/sunnycia/hdr_works/source_code/hdr_saliency/training
10343  python train.py 
10344  cd /data/sunnycia/hdr_works/source_code/hdr_saliency/training/caffe/python/
10345  python
10346  cd ..
10347  python train.py 
10348  vim ~/.bashrc
10349  source ~/.bashrc
10350  python train.py 
10351  cd /data/sunnycia/hdr_works/source_code/hdr_saliency/training
10352  python train.py 
10353  vim ~/.bashrc
10354  python train.py 
10355  export PYTHONPATH=/data/sunnycia/hdr_works/source_code/hdr_saliency/training/caffe/python:$PYTHONPATH
10356  python train.py 
10357  firefox
10358  cd /data/sunnycia/hdr_works/source_code/hdr_saliency/training
10359  python train.py 
10360  python
10361  python train.py 
10362  top
10363  cd /data/sunnycia/hdr_works/source_code/hdr_saliency/training/caffe/scripts
10364  bash build_docs.sh 
10365  bash build_docs.sh /data/sunnycia/hdr_works/source_code/hdr_saliency/training/caffe/docs
10366  bash build_docs.sh /data/sunnycia/hdr_works/source_code/hdr_saliency/training/caffe/docs 6699
10367  bash build_docs.sh /data/sunnycia/hdr_works/source_code/hdr_saliency/training/caffe/docs [6699]
10368  bash build_docs.sh /data/sunnycia/hdr_works/source_code/hdr_saliency/training/caffe/docs 2333
10369  bash build_docs.sh 2333
10370  cd /data/sunnycia/hdr_works/source_code/hdr_saliency/training/caffe/python
10371  python detect.py 
10372  top
10373  cd /data/SaliencyDataset/Video/LEDOV/saliency_map/pqft/manmade_yacht03/frame_369.jpg
10374  cd /data/sunnycia/hdr_works/source_code/hdr_saliency/training
10375  python generate_net.py --depth
10376  vim ~/.bashrc
10377  source ~/.bashrc
10378  python generate_net.py --depth
10379  python generate_net.py --depth=50
10380  python generate_net.py --depth 50
10381  vim ~/.bashrc
10382  bash train.sh
10383  vim train.sh 
10384  bash train.sh
10385  top
10386  cd /data/sunnycia/hdr_works/source_code/hdr_saliency
10387  python io_utils.py 
10388  python
10389  python io_utils.py 
10390  cd training/
10391  python hdr_utils.py 
10392  %T
10393  date
10394  date+%T
10395  date+"%T"
10396  date +"%T"
10397  DATE=`date "+%Y%m%d"`
10398  DATE
10399  $DATE
10400  DATE=`date "+%Y%m%d%T"`
10401  $DATE
10402  nvidia-smi
10403  clear
10404  cd /data/sunnycia/hdr_works/source_code/hdr_saliency/training
10405  train.sh
10406  chmod u+x train.sh
10407  train.sh
10408  bash train.sh
10409  vim train.sh 
10410  bash train.sh
10411  mkdir snapshot/v1_basic/2018091215:20:26
10412  python
10413  bash train.sh
10414  python
10415  bash train.sh
10416  cd caffe
10417  make clean && make -j8 all && make -j4 pycaffe
10418  cd ..
10419  bash train.sh 
10420  nvidia-smi
10421  bash train.sh 
10422  python
10423  bash train.sh 
10424  python
10425  bash train.sh 
10426  git init
10427  vim .gitignore
10428  git rm -r --cached caffe
10429  git rm -r --cached caffe/
10430  git init
10431  git add .
10432  git commit -m "initialize code"
10433  git remote add origin https://github.com/sunnycia/HSal.git
10434  git remote -v
10435  git push origin master
10436  bash train.sh 
10437  cd -
10438  cd /data/sunnycia/hdr_works/source_code/hdr_saliency/training
10439  bash train.sh
10440  python
10441  bash train.sh
10442  nvidia-smi
10443  bash train.sh
10444  pwd
10445  bash train.sh
10446  git status
10447  git add .
10448  git commit -m "problem occured version"
10449  git push -u origin master
10450  git log
10451  git hist
10452  git log
10453  git checkout f5f9353d41fb95524b5efbf6819d5f9246ae068d
10454  bash train.sh 
10455  top
10456  git status
10457  git add .
10458  git commit -m "add pretrain interface, change gen_net name to standard"
10459  git push -u origin master
10460  nvidia-smi
10461  git status
10462  git push -u origin master
10463  git log  -1
10464  git checkout master
10465  git checkout -f master
10466  git reflog
10467  git log --graph --oneline --all
10468  git reset --hard 79b0d09
10469  git checkout master
10470  git status
10471  git pull
10472  git push -u origin master
10473  git pull --rebase
10474  git push -u origin master
10475  git status
10476  git pull
10477  git commit -a
10478  git reflog
10479  vim ~/.bashrc
10480  source ~/.bashrc
10481  vim ~/.bashrc
10482  su
10483  top
10484  su
10485  cd /data/sunnycia/saliency_on_videoset/Train/metric-matlab
10486  rm -rf ledov/
10487  su
10488  cd -
10489  cd /data/sunnycia/saliency_on_videoset/Train/scripts/metric
10490  matlatb -nodesktop -nodisplay
10491  matlab -nodesktop -nodisplay
10492  source pyg_venv/bin/activate
10493  cd /data/sunnycia/hdr_works/reference_source_code/Hdr_display/HDR-10bpp-Display-Test-master
10494  python Viewer.py 
10495  cd -
10496  df -h
10497  du -h /data
10498  su
10499  history
10500  python2
10501  pip install opencv-python
10502  pip install opencv
10503  cd /data/sunnycia/hdr_works/source_code/hdr_saliency
10504  python io_utils.py 
10505  deactivate
10506  python io_utils.py 
10507  df -h
10508  cd ~
10509  ls
10510  source myvenv/bin/activate
10511  pip install numpy
10512  pip install xlrd
10513  pip3 install xlrd
10514  vim ~/.bashrc
10515  matlab -v
10516  matlab 
10517  vim ~/.bashrc
10518  vim /etc/profile
10519  top
10520  clear
10521  cd /data/sunnycia/hdr_works/source_code/hdr_saliency
10522  top
10523  vim ~/.bashrc
10524  top
10525  nvidia-smi
10526  cd /data/sunnycia/saliency_on_videoset/_Model
10527  matlab -nodesktop -nodisplay
10528  top
10529  cd /data/sunnycia/saliency_on_videoset/_Model
10530  alias matlab='matlab -nodesktop -nodisplay'
10531  matlab
10532  cd /data/sunnycia/saliency_on_videoset/_Model
10533  python gen_saliency_Surprise.py --framebase='/data/SaliencyDataset/Video/LEDOV/frames' --outputbase='/data/SaliencyDataset/Video/LEDOV/saliency_map'
10534  nvidia-smi
10535  top
10536  git status
10537  cd /data/sunnycia/hdr_works/source_code/hdr_saliency/training
10538  git status
10539  git reflog
10540  git add .
10541  git commit -m "2fix bug of tmp dir;stable version"
10542  git push -u origin master
10543  git clone https://github.com/NUS-VIP/salicon-evaluation.git
10544  git clone  https://github.com/herrlich10/saliency.git
10545  git status
10546  vim .gitignore
10547  git status
10548  top
10549  nvidia-smi
10550  top
10551  nvidia-smi
10552  top
10553  clear
10554  bash playground.sh 
10555  bim playground.sh 
10556  vim playground.sh 
10557  bim playground.sh 
10558  bash playground.sh 
10559  vim playground.sh 
10560  bash playground.sh 
10561  vim playground.sh 
10562  bash playground.sh 
10563  PATH
10564  env
10565  printenv SNAPSHOT_DIR
10566  bash playground.sh 
10567  cd /data/sunnycia/saliency_on_videoset/_Model
10568  matlab -nodesktop -nodisplay
10569  cd /data/sunnycia/hdr_works/source_code/hdr_saliency/training
10570  vim ~/.bashr_alias
10571  cd /data/sunnycia/saliency_on_videoset/_Model
10572  matlab -nodesktop -nodisplay
10573  python gen_saliency_Hou.py --dataset='ledov'
10574  top
10575  nvidia-smi
10576  top
10577  nvidia-smi
10578  ssh qiudan@172.31.234.248
10579  nvidia-smi
10580  top
10581  top 
10582  top
10583  top
10584  cd /data/sunnycia/saliency_on_videoset/_Train/OMCNN_2CLSTM
10585  python test.py --videodir='/data/SaliencyDataset/Video/LEDOV/videos' --outputdir='/data/SaliencyDataset/Video/LEDOV/saliency_map/omcnn' --outputtype='image'
10586  export CUDA_VISIBLE_DEVICES=6
10587  python test.py --videodir='/data/SaliencyDataset/Video/LEDOV/videos' --outputdir='/data/SaliencyDataset/Video/LEDOV/saliency_map/omcnn' --outputtype='image'
10588  top
10589  watch -n 1 nvidia-smi
10590  watch -n 0.1 nvidia-smi
10591  top
10592  cd /data/sunnycia/hdr_works/source_code/hdr_saliency/training
10593  git log
10594  cd ..
10595  ls
10596  cd training/
10597  git reflog
10598  git checkout 0757c89
10599  git reset
10600  git checkout 0757c89
10601  vim .gitignore
10602  git reset
10603  git rm 
10604  git rm -f --cache CustomLossFunction.pyc
10605  git rm -f --cache dataset.pyc
10606  git rm -f --cache prototxt/solver.prototxt
10607  git checkout 0757c89
10608  git checkout -- .
10609  git checkout 0757c89
10610  git checkout -h
10611  git checkout -f 0757c89
10612  bash trian.sh
10613  bash train.sh
10614  git reflog
10615  git diff 0757c89..f5f9353
10616  git diff 0757c89..f5f9353 > ../diff.txt
10617  git reflog
10618  git checkout -f f5f9353
10619  vim .gitignore 
10620  git status
10621  bash train.sh
10622  git checkout -- .
10623  git status
10624  vim .gitignore
10625  git add .
10626  git commit -m "update .gitignore"
10627  git push -u origin master
10628  vim .gitignore 
10629  python
10630  bash train.sh
10631  vim .gitignore
10632  git status
10633  git add .
10634  git commit -m "add debug mode"
10635  git rm -f --cache CustomLossFunction.pyc
10636  git rm -f --cache prototxt/
10637  git rm -rf --cache prototxt/
10638  git push -u origin master
10639  git status
10640  git reflog
10641  clear && clear
10642  bash train.sh
10643  python
10644  git status
10645  git add .
10646  git status
10647  git commit -m "fix bug of tmp dir;stable version"
10648  git push -u origin master
10649  clear && clear
10650  bash train.sh
10651  clear && clear
10652  bash train.sh
10653  git log --graph --pretty-oneline --abbrev-commit
10654  git log --graph --pretty=oneline --abbrev-commit
10655  git reset --hard HEAD~`
10656  `
10657  git log --graph --pretty-oneline --abbrev-commit
10658  git log --graph --pretty=oneline --abbrev-commit
10659  git reflog
10660  git log --graph --pretty=oneline --abbrev-commit
10661  git pull
10662  git log --graph --pretty=oneline --abbrev-commit
10663  git push -u origin master
10664  top
10665  nvidia-smi
10666  bash train.sh
10667  clear && clear
10668  bash train.sh
10669  clear && clear
10670  bash train.sh
10671  cd /data/sunnycia/hdr_works/source_code/hdr_saliency/training
10672  bash train.sh
10673  nvidia-smi
10674  bash train.sh
10675  cd /data/sunnycia/hdr_works/source_code/hdr_saliency/training
10676  bash train.sh
10677  cd /data/sunnycia/hdr_works/source_code/hdr_saliency/training
10678  bash playground.sh 
10679  vim pla
10680  bash playground.sh 
10681  bash shell_playground.sh
10682  top
10683  nvidia-smi
10684  top
10685  nvidia-smi
10686  bash train.sh 
10687  top
10688  bash train.sh 
10689  git status
10690  cd /data/sunnycia/hdr_works/source_code/hdr_saliency/training
10691  git status
10692  vim .gitignore
10693  git status
10694  vim .gitignore
10695  bash shell_playground.sh 
10696  clear
10697  bash shell_playground.sh 
10698  bash shell_playground.sh  haha
10699  nvidia-smi
10700  git status
10701  git add .
10702  git commit -m "snapshot restorage"
10703  git push -u origin master
10704  bash train.sh
10705  top
10706  nvidia-smi
10707  ls /usr/local/caffe-master/
10708  cd /usr/local/caffe-master/python/
10709  python
10710  vim /etc/profile
10711  sudo vim /etc/profile
10712  protoc -v
10713  protoc --version
10714  sudo vim /etc/profile
10715  source /etc/profile
10716  pip -v
10717  pip --version
10718  cd ..
10719  ls
10720  cd build/
10721  ls
10722  cd tools/
10723  ls
10724  caffe
10725  cd ../..
10726  ls
10727  cd tools/
10728  ls
10729  caffe
10730  cd ..
10731  ls
10732  cd /usr/local/caffe-master/.build_release/tools
10733  caffe
10734  ./caffe
10735  cd ..
10736  ls
10737  cd ..
10738  ls
10739  sudo vim /etc/profile
10740  source /etc/profile
10741  ./caffe
10742  caffe
10743  vim /etc/profile
10744  sudo vim /etc/profile
10745  source /etc/profile
10746  caffe
10747  top
10748  nvidia-smi
10749  top
10750  nvidia-smi
10751  cd data/sunnycia/hdr_works/source_code/hdr_saliency/training
10752  cd /data/sunnycia/hdr_works/source_code/hdr_saliency/training
10753  git status
10754  git add .
10755  git commit -m "add luminance layer; add v1_basic_bn"
10756  git push -u origin master
10757  clear && claer
10758  top
10759  nvidia-smi
10760  git status
10761  top
10762  nvidia-smi
10763  top
10764  nvidia-smi
10765  top
10766  nvidia-smi
10767  bash train.sh
10768  python
10769  bash train.sh
10770  top
10771  nvidia-smi
10772  bash train.sh
10773  top
10774  nviia-smi
10775  nvidia-smi
10776  git  status
10777  git add .
10778  git add --all
10779  git commit -m "add validation metric plot; add salicon_val_small "
10780  git push -u origin master
10781  top
10782  nvidia-smi
10783  df -h
10784  clear
10785  bash train.sh
10786  top
10787  clear && clear
10788  cd /data/sunnycia/hdr_works/source_code/hdr_saliency/training
10789  git status
10790  git add .
10791  git commit -m "add GBD loss"
10792  git push -u origin master
10793  nvidia-smi
10794  top
10795  nvidia-smi
10796  bash train.sh
10797  clear && clear
10798  top
10799  nvidia-smi
10800  git status
10801  cd /data/sunnycia/hdr_works/source_code/hdr_saliency/training
10802  git status
10803  git add .
10804  git commit -m "add v1_ndeconv"
10805  git push -u origin master
10806  bash train.sh
10807  clear && clear
10808  bash train.sh
10809  clear && clear
10810  cd /data/sunnycia/hdr_works/source_code/hdr_saliency/training
10811  bash train.sh
10812  clear && clear
10813  bash train.sh
10814  clear && clear
10815  top
10816  nvidia-smi
10817  cd /data/sunnycia/hdr_works/source_code/hdr_saliency/training
10818  git status
10819  git add .
10820  git add -A
10821  git commit -m "stable version 2, bilinear deconv"
10822  git push -u origin master
10823  clear && clear
10824  bash test_eval.sh
10825  bash test_eval.sh snapshot/v1_basic/deprecated-msra-weigth-init-version/2018091500:20:02/
10826  top
10827  nvidia-smi
10828  bash train.sh
10829  clear && clear
10830  nvidia-smi
10831  top
10832  clear && clear
10833  bash train.sh
10834  clear && clear
10835  cd /data/sunnycia/hdr_works/source_code/hdr_saliency/training
10836  bash train.sh
10837  clear && clear
10838  bash train.sh
10839  clear && clear
10840  bash train.sh
10841  clear && clear
10842  bash train.sh
10843  claer && clear
10844  clear && clear
10845  bash train.sh
10846  clear && clear
10847  ls .git*
10848  top
10849  nvidia-smi
10850  top
10851  cd /data/sunnycia/hdr_works/source_code/hdr_saliency/training
10852  bash train.sh
10853  clear && clear
10854  nvidia-smi
10855  bash train.sh
10856  clear && clear
10857  nvidia-smi
10858  bash train.sh 
10859  clear && clear
10860  bash train.sh
10861  clear && claer 
10862  clear && clear 
10863  bash train.sh
10864  clear && clear
10865  cd /data/sunnycia/hdr_works/source_code/hdr_saliency/training
10866  git status
10867  git add .
10868  git commit -m "fix bug;snapshot restorage"
10869  git push -u origin master
10870  top
10871  nvidia-smi
10872  python test_eval.py --model_dir='./snapshot/v1_basic/2018091321:47:38' --dsname='hdreye_hdr' --stops=3 --width=512 --height=384 --metric
10873  python
10874  python test_eval.py --model_dir='./snapshot/v1_basic/2018091321:47:38' --dsname='hdreye_hdr' --stops=3 --width=512 --height=384 --metric
10875  python test_eval.py --model_dir='./snapshot/v1_basic/2018091413:42:43' --dsname='hdreye_hdr' --stops=3 --width=512 --height=384 --metric
10876  python test_eval.py --model_dir='./snapshot/v1_basic/2018091413:42:43' --dsname='salicon_eval' --stops=3 --width=512 --height=384 --metric 
10877  python test_eval.py --model_dir='./snapshot/v1_basic/2018091413:42:43' --dsname='salicon_eval' --stops=3 --width=512 --height=384 
10878  python test_eval.py --model_dir='./snapshot/v1_basic/2018091413:42:43' --dsname='salicon' --stops=3 --width=512 --height=384 
10879  python test_eval.py --model_dir='./snapshot/v1_basic/2018091413:42:43' --dsname='salicon' --stops=3 --width=512 --height=384 --metric
10880  git status
10881  git add .
10882  git commit -m "deploy network. add dataset"
10883  git push -u origin master
10884  bash train.sh
10885  git status
10886  git add .
10887  git commie -m "add validation, not finished yet"
10888  git commit -m "add validation, not finished yet"
10889  git push -u origin master
10890  bash train.sh 
10891  clear && clear
10892  bash train.sh
10893  clear && clear
10894  bash train.sh
10895  clear && clear
10896  bash train.sh
10897  clear && claer
10898  bash train.sh
10899  clear && clear
10900  cd /data/sunnycia/hdr_works/source_code/hdr_saliency/training
10901  git status
10902  git reflog
10903  git add .
10904  git commit -m "fix some bug"
10905  git commit -m origin master
10906  git push -u origin master
10907  bash shell_playground.sh 
10908  bash train.sh
10909  top
10910  bash train.sh
10911  nvidia-si
10912  nvidia-smi
10913  top
10914  nvidia-smi
10915  top
10916  bash train.sh
10917  bash test_eval.sh snapshot/v1_basic/2018091500:20:02
10918  clear
10919  bash test_eval.sh snapshot/v1_basic/2018091500:20:02
10920  bash train.sh 
10921  bash train.sh
10922  bash test_eval.sh
10923  bash test_eval.sh snapshot/v1_basic/2018091500:20:02
10924  bash train.sh 
10925  git status
10926  bash train.sh 
10927  clear && clear
10928  git status
10929  git add .
10930  git commit -m "add validation; bilinear initialize deconv"
10931  git status
10932  git add .
10933  git commit -a
10934  git commit -m "remove tmp dir"
10935  git push -u origin master
10936  bash train.sh
10937  df -h
10938  clear && clear
10939  bash train.sh
10940  clear && clear
10941  bash train.sh 
10942  clear && clear
10943  nvidia-smi
10944  bash train.sh
10945  clear && clear
10946  nvidia-smi
10947  bash trian.sh
10948  bash train.sh
10949  clear && clear
10950  bash train.sh
10951  clear && clear
10952  ls
10953  mv /data/sunnycia/hdr_works/reference_source_code/Hdr_display ./
10954  mv ./Hdr_display/ /data/sunnycia/hdr_works/reference_source_code/
10955  mv /data/sunnycia/hdr_works/reference_source_code/Hdr_display/myenv ./
10956  mv /data/sunnycia/hdr_works/reference_source_code/Hdr_display/myvenv ./
10957  source myvenv/bin/activate
10958  deactivate
10959  cd /data/sunnycia/hdr_works/source_code/show_demo/pygtk-demo/demos
10960  python appwindow.py 
10961  cd ..
10962  git clone https://github.com/strycore/pygobject-demos.git && git clone https://github.com/wweiradio/pygobject.git
10963  cd pygobject-demos/
10964  python welcome.py 
10965  python3 welcome.py 
10966  source ~/myvenv/bin/activate
10967  python welcome.py 
10968  python displays.py 
10969  cd /data/sunnycia/hdr_works/source_code/show_demo/pygobject-demos
10970  python box.py 
10971  python application.py 
10972  python3 application.py 
10973  deactivate
10974  su
10975  virtualenv --python=python3 ~/pyg_venv
10976  ~/pyg_venv/bin/activate
10977  source ~/pyg_venv/bin/activate
10978  python
10979  pip install pygobject
10980  python application.py 
10981  python welcome.py 
10982  cd ..
10983  git clone https://github.com/sebp/PyGObject-Tutorial.git
10984  cd /data/sunnycia/hdr_works/reference_source_code/Hdr_display/HDR-10bpp-Display-Test-master
10985  python Viewer.py 
10986  pip install imageio
10987  python Viewer.py 
10988  cd /data/sunnycia/hdr_works/source_code/show_demo
10989  python gtk_image.py 
10990  git clone git@github.com:sunnycia/HDR-DEMO.git
10991  git clone https://github.com/sunnycia/HDR-DEMO.git
10992  git add .
10993  cd HDR-DEMO/
10994  git add .
10995  git status
10996  git commit -m "upload gtk-3 tutorial"
10997  git push -u origin master
10998  git --version
10999  git config --global credential.helper cache
11000  git config --global credential.helper 'cache --timeout=604800'
11001  cd -
11002  python main.py 
11003  top
11004  git add . && git commit -m "init code"
11005  git push -u origin master
11006  python file_chooser.py 
11007  python main.py 
11008  python viewer.py 
11009  python main.py 
11010  git add . && git commit -m "button done" && git push -u origin master
11011  cd /data/sunnycia/hdr_works/source_code/show_demo/PyGObject-Tutorial/examples
11012  python application_example.py 
11013  top
11014  cd /data/sunnycia/saliency_on_videoset/_Model
11015  python gen_saliency_SALICON.py --framebase='/data/SaliencyDataset/Video/LEDOV/frames' --outputbase='/data/SaliencyDataset/Video/LEDOV/saliency_map/salicon' --gpu=7 --settype='video'
11016  deactivate
11017  python gen_saliency_SALICON.py --framebase='/data/SaliencyDataset/Video/LEDOV/frames' --outputbase='/data/SaliencyDataset/Video/LEDOV/saliency_map/salicon' --gpu=7 --settype='video'
11018  cd /data/sunnycia/saliency_on_videoset/Train/scripts/metric
11019  matlab -nodesktop -nodisplay
11020  clear && clear
11021  top
11022  nvidia-smi
11023  clear && clear
11024  top
11025  nvidia-smi
11026  top
11027  clear && clear
11028  top
11029  nvidia-smi
11030  clear && clear
11031  nvidia-smi
11032  clear && clear
11033  top
11034  nvidia-smi
11035  top
11036  nvidia-smi
11037  cd /data/sunnycia/hdr_works/source_code/hdr_saliency/training/dataset_utils
11038  python luminance_dataset.py 
11039  df -h
11040  top
11041  nvidia-smi
11042  cd /data/sunnycia/hdr_works/source_code/hdr_saliency
11043  git clone https://github.com/KAIST-VCLAB/xlrcam.git
11044  cd xlrcam/
11045  ls
11046  brew
11047  matlab -nodesktop -nodisplay
11048  matlab
11049  cd /data/sunnycia/hdr_works/source_code/hdr_saliency/HDR_Toolbox-master
11050  cd demos/
11051  ls
11052  matlab -nodesktop -nodisplay
11053  matlab
11054  cd /data/sunnycia/saliency_on_videoset/Train/scripts/utils/dsutil
11055  python compute_spatial_temporal_complexity.py --ds_name=dhf1k
11056  top
11057  nvidia-smi
11058  top
11059  nvidia-smi
11060  vim /etc/profile
11061  top
11062  nvidia-smi
11063  cd /data/sunnycia/saliency_on_videoset/Train/scripts/utils/vizutil
11064  python inference_comparison.py --output_path='vsg_inf.jpg' --wildcards_record='vg_wildcards_record.txt' 
11065  history > history
